{
  "name": "Jinwoo Choi 0001",
  "homepage": "https://sites.google.com/site/jchoivision",
  "status": "success",
  "content": "Jinwoo ChoiSearch this siteEmbedded FilesSkip to main contentSkip to navigationJinwoo Choi's HomepageJinwoo Choi (최진우), Ph.D.Assistant ProfessorVision and Learning LabSchool of ComputingKyung Hee UniversityContactE-mail: jinwoochoi [at] khu [dot] ac [dot] kr (official) Tel: +82-31-201-3758Office: 324 Electronic Information College Building, 1732, Deogyeong-daero, Giheung-gu, Yongin-si, Gyeonggi-do, Rep. of Korea, 17104CV / Google Scholar / LinkedIn / TwitterAbout MeI am an Assistant Professor in the School of Computing, Kyung Hee University, leading the Vision and Learning Lab. I obtained my Ph.D. from the Bradley Department of Electrical and Computer Engineering, Virginia Tech, in 2020, advised by Jia-Bin Huang. During my Ph.D. course, I was lucky to have opportunities to work with Gaurav Sharma, Samuel Schulter, and Manmohan Chandraker at NEC Labs America as a research intern. From 2010 to 2015, I completed my alternative military duty as a computer vision researcher at the Electronics and Telecommunications Research Institute (ETRI). Before that, I completed my master's degree at Seoul National University (SNU), advised by Sang-Uk Lee. During the master's course, I closely collaborated with Chang-Su Kim. Research InterestsComputer Vision and Machine Learning I am especially interested in video understanding, video representation learning, multi-modal learning, mitigating biases in visual recognition, learning with limited supervision, and explainable AI.I am also interested in object detection, semantic segmentation, scene understanding and other visual recognition problems.Education2020 : Ph.D. in Computer Engineering, Virginia Tech.2010 : M.S. in Electrical Engineering and Computer Science, Seoul National University (SNU), Seoul, Korea.2008 : B.S. in Electrical Engineering, Seoul National University (SNU), Seoul, Korea. NewsOct. 2025   One work is accepted to TPAMI (IF 18.6, JCR top 1.1%).Sep. 2025   One work on video explainable AI is accepted to NeurIPS 2025 as a Spotlight (3.5% acceptance rate)!Aug. 2025   MASH-VLM has been covered by Digital Chosun Ilbo!Jul. 2025     ESSENTIAL is selected as a Highlight (2.9% acceptance rate) in ICCV 2025!Jun. 2025    One paper is accepted to ICCV 2025.May  2025    Multi-Purpose Visual Information Coding for Human and Machine Vision (인간과 기계 시각을 동시에 지원하는 다목적 시각정보 압축 연구) has been selected as a Global Basic Research Lab funded by the NRF, Korea (한국연구재단 글로벌기초연구실).Apr. 2025     MASH-VLM is selected as a Highlight (3.7% acceptance rate) in CVPR 2025!Feb. 2025    Two papers are accepted to CVPR 2025.Dec. 2024    One paper is accepted to AAAI 2025.Aug. 2024    One paper is accepted to ECCV 2024 as an Oral (2.3% acceptance rate).Mar. 2024    I serve as an Industry Chair of KCCV 2024, Busan, Korea.Feb. 2024    Two papers are accepted to CVPR 2024.Selected Publications († equally contributed first authors, * indicates the corresponding author(s))- CA2ST: Cross-Attention in Audio, Space, and Time for Holistic Video RecognitionAccepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2025. (Impact Factor 18.6, JCR top 1.1%) [arXiv]Jongseo Lee†, Joohyun Chang†, Dongho Lee, Jinwoo Choi*- Disentangled Concepts Speak Louder Than Words: Explainable Video Action RecognitionTo appear in Proceedings of Neural Information Processing Systems (NeurIPS), 2025. (Spotlight! presentation, 3.5% acceptance rate) [arXiv][project page][code]Jongseo Lee†, Wooil Lee, Gyeong-Moon Park*, Seong Tae Kim*, Jinwoo Choi*- ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental LearningTo appear in IEEE/CVF International Conference on Computer Vision (ICCV), 2025. (Highlight! presentation, 2.9% acceptance rate) [arXiv][project page][code]Jongseo Lee†, Kyungho Bae†, Kyle Min, Gyeong-Moon Park*, Jinwoo Choi*- PCBEAR: Pose Concept Bottleneck for Explainable Action RecognitionXAI4CV Workshop, IEEE/CVF Computer Vision and Pattern Recognition (CVPR), (Spotlight! presentation, 16.7% acceptance rate) 2025. [pdf][arXiv]Jongseo Lee, Wooil Lee, Gyeong-Moon Park*, Seong Tae Kim* and Jinwoo Choi*- MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through Disentangled Spatial-Temporal RepresentationsIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025. (Highlight! presentation, 3.7% acceptance rate) [pdf][arXiv][press coverage]Kyungho Bae, Jinhyung Kim, Sihaeng Lee, Soonyoung Lee, Gunhee Lee*, Jinwoo Choi*- Universal Domain Adaptation for Semantic SegmentationIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025. [arXiv]Seun-An Choe, Keon-Hee Park, Jinwoo Choi, Gyeong-Moon Park*- HiCM^2: Hierarchical Compact Memory Modeling for Dense Video Captioning.AAAI Conference on Artificial Intelligence (AAAI), 2025. [arXiv]Minkuk Kim, Hyeon Bae Kim, Jinyoung Moon, Jinwoo Choi*, Seong Tae Kim*- DEVIAS: Learning Disentangled Video Representations of Action and SceneEuropean Conference on Computer Vision (ECCV) 2024. (Oral! presentation, 2.3% acceptance rate) [arXiv][project page][talk][code]Kyungho Bae†, Geo Ahn†, Youngrae Kim†, Jinwoo Choi*- Do You Remember? Dense Video Captioning with Cross-Modal Memory RetrievalIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. [arXiv][code]Minkuk Kim, Hyeon Bae Kim, Jinyoung Moon, Jinwoo Choi*, Seong Tae Kim*- Open Set Domain Adaptation for Semantic SegmentationIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024. [arXiv][code]Seun-An Choe†, Ah-Hyung Shin†, Keon-Hee Park, Jinwoo Choi*, Gyeong-Moon Park*- CAST: Cross-Attention in Space and Time for Video Action RecognitionProceedings of Neural Information Processing Systems (NeurIPS), 2023. [arXiv] [project page] [code]Dongho Lee†, Jongseo Lee†, Jinwoo Choi*- Learning Representational Invariances for Data-Efficient Action RecognitionComputer Vision and Image Understanding (CVIU) 2023. [pdf] [arXiv] [project page] [code]Yuliang Zou, Jinwoo Choi*, Qitong Wang, and Jia-Bin Huang     - Shuffle and Attend: Video Domain AdaptationEuropean Conference on Computer Vision (ECCV) 2020. (26.4% acceptance rate) [pdf] [project page] [short talk] [long talk] [supplementary]Jinwoo Choi, Gaurav Sharma, Samuel Schulter, and Jia-Bin Huang      - Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from DronesWinter Conference on Applications of Computer Vision (WACV) 2020. (Oral presentation) [pdf] [project page] [talk video]Jinwoo Choi, Gaurav Sharma, Manmohan Chandraker, and Jia-Bin Huang             - Why Can’t I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition    Proceedings of Neural Information Processing Systems (NeurIPS), 2019. (21.2% acceptance rate) [pdf] [arXiv] [project page] [code] [poster]Jinwoo Choi, Chen Gao, Joseph Messou, and Jia-Bin Huang- The Visual Object Tracking VOT2014 Challenge ResultsEuropean Conference on Computer Vision (ECCV) Workshop, 2014. [pdf, slide]Matej Kristan et al. (including Jinwoo Choi),  Google SitesReport abuseGoogle SitesReport abuse",
  "content_length": 7048,
  "method": "requests",
  "crawl_time": "2025-12-01 13:31:12"
}