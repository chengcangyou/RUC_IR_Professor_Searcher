{
  "name": "Joachim Denzler",
  "homepage": "http://www.inf-cv.uni-jena.de/denzler.html",
  "status": "success",
  "content": "Prof. Dr. Joachim Denzler – Computer Vision Group Jena Skip to content Prof. Dr.-Ing. Joachim Denzler Contact Secretary Phone: +49 3641 946301 Fax: +49 3641 946302 Direct Email: joachim (dot) denzler (at) uni-jena (dot) de Phone: +49 3641 946420 Consultation hours: Monday, 2-3 pm (during the lecture periods) Postal Address Lehrstuhl für Digitale Bildverarbeitung Friedrich-Schiller-Universität Jena 07737 Jena, Germany Delivery & Parcel Address Lehrstuhl für Digitale Bildverarbeitung Raum 3026 Inselplatz 5 07743 Jena, Germany Publications 2026 Dong Han, Joachim Denzler, Yong Li: Realistic Face Reconstruction from Facial Embeddings via Diffusion Models. AAAI Conference on Artificial Intelligence (AAAI). 2026. (accepted) [bibtex] Niklas Penzel, Joachim Denzler: Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients. Winter Conference on Applications of Computer Vision (WACV). 2026. (accepted) [bibtex] [web] [doi] [abstract] Deep learning models achieve high predictive performance but lack intrinsic interpretability, hindering our understanding of the learned prediction behavior. Existing local explainability methods focus on associations, neglecting the causal drivers of model predictions. Other approaches adopt a causal perspective but primarily provide more general global explanations. However, for specific inputs, it's unclear whether globally identified factors apply locally. To address this limitation, we introduce a novel framework for local interventional explanations by leveraging recent advances in image-to-image editing models. Our approach performs gradual interventions on semantic properties to quantify the corresponding impact on a model's predictions using a novel score, the expected property gradient magnitude. We demonstrate the effectiveness of our approach through an extensive empirical evaluation on a wide range of architectures and tasks. First, we validate it in a synthetic scenario and demonstrate its ability to locally identify biases. Afterward, we apply our approach to analyze network training dynamics, investigate medical skin lesion classifiers, and study a pre-trained CLIP model with real-life interventional data. Our results highlight the potential of interventional explanations on the property level to reveal new insights into the behavior of deep models. Sai Karthikeya Vemuri, Tim Büchner, Joachim Denzler: F-INR: Functional Tensor Decomposition for Implicit Neural Representations. Winter Conference on Applications of Computer Vision (WACV). 2026. (accepted) [bibtex] [doi] [abstract] Implicit Neural Representations (INRs) model signals as continuous, differentiable functions. However, monolithic INRs scale poorly with data dimensionality, leading to excessive training costs. We propose F-INR, a framework that addresses this limitation by factorizing a high-dimensional INR into a set of compact, axis-specific sub-networks based on functional tensor decomposition. These sub-networks learn low-dimensional functional components that are then combined via tensor operations. This factorization reduces computational complexity while additionally improving representational capacity. F-INR is both architecture- and decomposition-agnostic. It integrates with various existing INR backbones (e.g., SIREN, WIRE, FINER, Factor Fields) and tensor formats (e.g., CP, TT, Tucker), offering fine-grained control over the speed-accuracy trade-off via the tensor rank and mode. Our experiments show F-INR accelerates training by up to and improves fidelity by over 6.0 dB PSNR compared to state-of-the-art INRs. We validate these gains on diverse tasks, including image representation, 3D geometry reconstruction, and neural radiance fields. We further show F-INR's applicability to scientific computing by modeling complex physics simulations. Thus, F-INR provides a scalable, flexible, and efficient framework for high-dimensional signal modeling. 2025 Adithya Ashok Chalain Valapil, Carl Messerschmidt, Maha Shadaydeh, Michael Schmitt, Jürgen Popp, Joachim Denzler: Deep Learning-Assisted Dynamic Mode Decomposition for Non-resonant Background Removal in CARS Spectroscopy. DAGM German Conference on Pattern Recognition (DAGM-GCPR). 2025. (accepted) [bibtex] [abstract] Coherent Anti-Stokes Raman Spectroscopy (CARS) provides non-invasive, label-free chemical analysis at high spatial resolution, making it a powerful tool for biomedical and material imaging. However, their effectiveness is hindered by a dominant and unpredictable non-resonant background (NRB) that distorts meaningful spectral features. Existing NRB removal methods often require additional measurements or computationally intensive post-processing. In this work, we present a physics-informed framework that leverages the broadband, low-rank structure of the NRB using Dynamic Mode Decomposition (DMD) for unsupervised separation of resonant Raman modes from non-resonant contributions in the spectral domain. We further introduce DA-DMD - a Deep Learning-Assisted DMD approach, that uses an attention mechanism to adaptively weight DMD modes and a CNN with skip connection to enhance Raman signal reconstruction. Trained entirely on synthetic data, DA-DMD eliminates the need for experimental labels or calibration. We validate our methods on synthetic and real CARS measurements, demonstrating superior background suppression, fidelity preservation, and generalization compared to existing approaches. DA-DMD offers fast inference and improves robustness, positioning it as a practical tool for scalable chemical imaging in complex environments. Aishwarya Venkataramanan, Joachim Denzler: Distance-informed Neural Processes. Annual Conference on Neural Information Processing Systems (NeurIPS). 2025. (accepted at NeurIPS) [bibtex] [doi] [abstract] We propose the Distance-informed Neural Process (DNP), a novel variant of Neural Processes that improves uncertainty estimation by combining global and distance-aware local latent structures. Standard Neural Processes (NPs) often rely on a global latent variable and struggle with uncertainty calibration and capturing local data dependencies. DNP addresses these limitations by introducing a global latent variable to model task-level variations and a local latent variable to capture input similarity within a distance-preserving latent space. This is achieved through bi-Lipschitz regularization, which bounds distortions in input relationships and encourages the preservation of relative distances in the latent space. This modeling approach allows DNP to produce better-calibrated uncertainty estimates and more effectively distinguish in- from out-of-distribution data. Empirical results demonstrate that DNP achieves strong predictive performance and improved uncertainty calibration across regression and classification tasks. Aishwarya Venkataramanan, Paul Bodesheim, Joachim Denzler: Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models. International Conference on Uncertainty in Artificial Intelligence (UAI). Pages 4309-4328. 2025. [bibtex] [web] [doi] [code] [abstract] Vision-Language Models (VLMs) learn joint representations by mapping images and text into a shared latent space. However, recent research highlights that deterministic embeddings from standard VLMs often struggle to capture the uncertainties arising from the ambiguities in visual and textual descriptions and the multiple possible correspondences between images and texts. Existing approaches tackle this by learning probabilistic embeddings during VLM training, which demands large datasets and does not leverage the powerful representations already learned by large-scale VLMs like CLIP. In this paper, we propose GroVE, a post-hoc approach to obtaining probabilistic embeddings from frozen VLMs. GroVE builds on Gaussian Process Latent Variable Model (GPLVM) to learn a shared low-dimensional latent space where image and text inputs are mapped to a unified representation, optimized through single-modal embedding reconstruction and cross-modal alignment objectives. Once trained, the Gaussian Process model generates uncertainty-aware probabilistic embeddings. Evaluation shows that GroVE achieves state-of-the-art uncertainty calibration across multiple downstream tasks, including cross-modal retrieval, visual question answering, and active learning. Aishwarya Venkataramanan, Sai Karthikeya Vemuri, Adithya Ashok Chalain Valapil, Joachim Denzler: Uncertainty-aware Physics-informed Neural Networks for Robust CARS-to-Raman Signal Reconstruction. EurIPS Workshop on Differentiable Systems and Scientific Machine Learning (EurIPS-WS). 2025. (accepted) [bibtex] [abstract] Coherent anti-Stokes Raman scattering (CARS) spectroscopy is a powerful and rapid technique widely used in medicine, material science, and chemical analyses. However, its effectiveness is hindered by the presence of a non-resonant background that interferes with and distorts the true Raman signal. Deep learning methods have been employed to reconstruct the true Raman spectrum from measured CARS data using labeled datasets. A more recent development integrates the domain knowledge of Kramers-Kronig relationships and smoothness constraints in the form of physics-informed loss functions. However, these deterministic models lack the ability to quantify uncertainty, an essential feature for reliable deployment in high-stakes scientific and biomedical applications. In this work, we evaluate and compare various uncertainty quantification (UQ) techniques within the context of CARS-to-Raman signal reconstruction. Furthermore, we demonstrate that incorporating physics-informed constraints into these models improves their calibration, offering a promising path toward more trustworthy CARS data analysis. Ana E. Bonato Asato, Claudia Guimaraes-Steinicke, Gideon Stein, Berit Schreck, Teja Kattenborn, Anne Ebeling, Stef",
  "content_length": 478930,
  "method": "requests",
  "crawl_time": "2025-12-01 13:31:31"
}