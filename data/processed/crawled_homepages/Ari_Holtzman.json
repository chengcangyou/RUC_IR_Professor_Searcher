{
  "name": "Ari Holtzman",
  "homepage": "https://ariholtzman.com",
  "status": "success",
  "content": "Ari HoltzmanAri HoltzmanI‚Äôm doing it with LLMs or I‚Äôm not doing it at all.üìú google scholar | ‚úâÔ∏è aholtzman@uchicago.edu Head of Conceptualization LabSecond ever Communication & Intelligence researcherCheck out our C&I blogAssistant Professor at UChicago CSUChicago DSITTIC (by courtesy)Office: DSI 315I am actively looking for PhD students to apply through both UChicago CS and the Data Science Institute. Experience with LLMs/generative models is a plus, but not required! I no longer have time to reply to all emails from prospective PhD students but I highly encourage you to check out my lab website and apply!Previously:Post-Doc @ FAIR @ Meta PhD from UW advised by¬†Luke ZettlemoyerCommunication & IntelligenceMachine CommunicationGenerative Models as a Complex Systems ScienceHoltzman CV.pdf110.5KBI work on pragmatic narrative‚Äîstories about models and models that produce stories.Events2025/12‚ÄîGiving a talk at CogInterp @ NeurIPS on December 7th!2025/11‚ÄîGave a talk at Universit√© du Qu√©bec √† Montr√©al‚Äôs S√©minaire en Informatique Cognitive on the 20th over zoom and UChicago‚Äôs Theoretical Philosophy Workshop on November 21st!2025/10‚ÄîExcited to give a talk at CMU‚Äôs LTI Colloquium seminar on Halloween üéÉüëª2025/09‚ÄîGave a talk at the COLM Visions of Language Modeling Workshop!2025/07‚Äîthe Economist published my letter2025/06‚Äîgave a talk about Articulating the Ineffable at MMLS! 2024/10‚ÄîThe UChicago Communication and Intelligence Symposium was a great success!2024/07‚ÄîOfficially started at UChicago as an Assistant Professor!2023/09‚ÄîStarted a Post-doc at Meta2023/09‚ÄîGave a keynote talk at the International Conference on Social Computing about LLMs as Linguistic SpiesNightly Research StatementLarge language models farm corpora for the heuristics and strategies embedded in data. How can we extract the abstractions crystalized in LLMs?What can we do with LLMs that has never been done, or even thought of, before? Can we pushback against the current bounds of ineffability to help humans articulate what was previously inarticulable? Can we make narrative video games with a dense graph of states where one learns through bad decisions instead of replaying failures? Research FociMy primary interest is in generative models, how they work and how we can get them to generate text and other media that communicate with humans in useful and novel ways. Lately, I‚Äôve been thinking about how language models fit the definition of complex systems, systems in which we understand the low-level components (neurons) but can‚Äôt explain or even fully describe the high-level behaviors (e.g., in-context learning) as they emerge with more data and parameters. In the spirit of complex systems, I want to create a taxonomy of model behavior, analogous to the periodic table of elements in Chemistry, which hardly explains complex chemical processes in its own right, but gives a description of elementary components and their interactions that can be used to build-up more complex hypotheses. Currently, we rely on benchmark performance or vague intuitive descriptions to pin-point specific phenomena, which means most hypotheses rely on imprecise vocabulary that won‚Äôt stand the test of time.In the short-term, I‚Äôm interested in thinking how we can map out what models can and can‚Äôt do, which I believe will naturally relate to long-form generation. It is incredibly difficult to evaluate long-form generation rigorously, and it is hard to show long-form generations in power point slides, which has made coordinating the issues in long-form generation difficult for the academic community. In the medium-term, I think we need to tackle the non-objective aspects of language, as almost all communication is open to interpretation, relying instead on the pragmatic attempt at cooperation to bridge this gap. Focusing on easy-to-evaluate aspects of language doesn‚Äôt do it justice. Perhaps looking at indirect evaluation, where we evaluate what generated language can be used for, rather than whether it is ‚Äúcorrect‚Äù can help move researchers in that direction. My long-term goal is to create¬†discursive machines.Selected PublicationsAbsenceBench: Language Models Can‚Äôt Tell What‚Äôs MissingHarvey Yiyun Fu, Aryan Shrivastava, Jared Moore, Peter West, Chenhao Tan, Ari Holtzman[paper][dataset][code]Prompting as Scientific Inquiry Ari Holtzman & Chenhao Tan[paper]Predicting vs. Acting: A Trade-off Between World Modeling & Agent ModelingMargaret Li, Weijia Shi, Artidoro Pagnoni, Peter West, Ari Holtzman[paper]Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?Ari Holtzman, Peter West, Luke Zettlemoyer[paperRethinking the Role of Demonstrations: What Makes In-Context Learning Work?EMNLP 2022Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, Luke Zettlemoyer[paper] [code]Surface Form Competition: Why the Highest Probability Answer Isn‚Äôt Always Right EMNLP 2021 =Ari Holtzman, =Peter West, Vered Shwartz, Yejin Choi, and Luke Zettlemoyer= equal contribution [paper] [project page] [code]The Curious Case of Neural Text DegenerationICLR 2019 Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi[paper] [code] [huggingface] [openai api] [fairseq]Useful StuffMaterials from the Academic Job MarketHoltzman_Ariel_Cover_Letter_UoChicago.pdf115.9KBHoltzman_Ariel_CV.pdf105.8KBHoltzman_Ariel_DEI_Statement.pdf50.6KBHoltzman_Ariel_Research_Statement.pdf2026.5KBHoltzman_Ariel_Teaching_Statement.pdf45.4KB",
  "content_length": 5484,
  "method": "requests",
  "crawl_time": "2025-12-01 13:00:42"
}