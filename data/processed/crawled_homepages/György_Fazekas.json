{
  "name": "György Fazekas",
  "homepage": "http://www.eecs.qmul.ac.uk/~gyorgyf",
  "status": "success",
  "content": "Research Home - George Fazekas Home Research Teaching Software Publications Bio “When I use a word, it means just what I choose it to mean — neither more, no less.” — Humpty Dumpty, Through the Looking-Glass by Lewis Carroll, 1872 Why combine DSP and Neural Networks? This question intrigued a lot of my researchers in recent years. In the following I summarise my view and point to some of our recent work. Read More Semantic Audio Research My main research interest is Semantic Audio, an interdisciplinary field in the confluence of Digital Signal Processing, Machine Learning including Deep Learning, and various knowledge representation and knowledge sharing technologies such as Semantic Web Ontologies, Linked-data, knowledge-based reasoning and the Semantic Web. I'm interested in extracting, analysing and linking data about music and developing applications that use semantic metadata, bringing the power of semantic technologies to music technology. Read More Information for PhD applicants If you are interested to study for a PhD under my supervision, please see the topics I'm interested in and information about funding here. You may also propose your own PhD topic in music informatics, semantic audio and related areas. Please contact me by email with a short paragraph outlining your idea. News 14 November 2025: I'm closing an exciting week highlighted by two very excellent events at the Royal Academy of Engineering related to my recently started RAEng / Leverhulme Trust Research Fellowship . I had the pleasure to present my project at the Academy's reserach committee meeting amongst other Fellows showing a range of truly fascinating engineering and inventions. I also attended the Academy's induction event for new Research Fellows, demonstrating the truly versatile support the RAEng is providing to its Fellows. 25 Sept. 2025: I'm thrilled to share that our paper Audio synthesizer inversion in symmetric parameter spaces with approximately equivariant flow matching co-authored and presented by Ben Hayes and co-authored with Charis Saitis has won best student paper award at the 26th International Society for Music Information Retrieval Conference (ISMIR 2025). Ben was also recognied as an outstanding reviewer at the same conference. Our paper proposes permutation equivariant continuous normalizing flows to handle the ill-posed problem of audio synthesizer inversion, where multiple parameter configurations can produce identical sounds due to intrinsic symmetries in synthesizer design. By explicitly modeling these symmetries, particularly permutation invariance across repeated components like oscillators and filters, the method outperforms both regression-based approaches and symmetry-naive generative models on both synthetic tasks and a real-world synthesizer (Surge XT). 21 Sept. 2025: I'm delighted to announce that my amazing team of PhD students are presenting 5 papers at the 26th International Society for Music Information Retrieval Conference (ISMIR 2025) at KAIST in Daejeon, South Korea. * Audio synthesizer inversion in symmetric parameter spaces with approximately equivariant flow matching — by Ben Hayes, * SLAP: Siamese Language-Audio Pretraining without negative samples for Music Understanding — by Julien Guinot, * MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling — by Jingjing Tang. * CoDiCodec: Unifying Continuous and Discrete Compressed Representations of Audio — by Marco Pasini, * GD-Retriever: Controllable generative text-music retrieval with diffusion models — by Julien Guinot. Three of our papers (by Jingjing, Ben and Julien) were nominated for an award. 10 Sept. 2025: We closed a hugely successful conference titled 2025 AES International Conference on Artificial Intelligence and Machine Learning for Audio (AIMLA). The conference had over 250 participants, far exceeding expectations. I was papers co-chair with Brecht De Man. 8 Sept. 2025: I'm happy to announce that I have been promoted to Reader in Semantic Audio. (This title is fairly specific to the UK academic system and it is approximately equivalent to Professor or Associate Professor.) 5 Sept. 2025: My PhD student Elona Shatri from C4DM and UKRI's Artificial Intelligence and Music (AIM) CDT successful passed the PhD viva today. Elona's research focussed on advancing Optical Music Recognition (OMR) by developing large-scale annotated datasets, exploring neural architectures for music notation, their integration through knowledge-driven fusion, and a multi-dimensional evaluation framework connecting symbol-level recognition with higher-level musical structure. These contributions significantly improve recognition accuracy. 15 August 2025: My PhD student Sebastian Löbbers successful passed the PhD viva today. Sebastian was a student in C4DM and received funding from UKRI's Media and Arts Technology (MAT) CDT at QMUL. Sebastian's PhD focussed on graphical sketching as an intuitive, perceptually informed way to control sound synthesis, bridging research in cross-modal perception with human-computer interaction, and advancing understanding of how visual and auditory domains interact. 13 August 2025: I have been awaded a prestigious Research Fellowship from the Royal Academy of Engineering (RAEng) / Leverhulme Trust. My research topic is titled Knowledge-driven deep learning for music informatics, looking at incorporating structured priors into Deep Learning / AI models. 15 December 2024: Co-organised the hugely successful Muse Hub Hackathon - Create an audio app in 24 hours in collaboration with Music Hackspace and with partners MuseHub and The Audio Programmer. Over 12 apps were submitted from 70+ participants, including students from QMUL's Sound and Music Computing (SMC MSc) masters programme. 2 December 2024: Fully funded PhD studentships are available at the the Centre for Digital Music I have two PhD topics one is with industry funding within the AIM CDT listed here. Additional topics of interest can be found on my research page. 28 November 2024: PhD student Ilaria Manco successfully passed her viva. Her Thesis is titled: Learning Music Representations from Audio and Language. 17 Nov. 2024: Best student paper award at KDIR 2024 for our paper with PhD Student Elona Shatri titled Knowledge Discovery in Optical Music Recognition: Enhancing Information Retrieval with Instance Segmentation. 16 Nov. 2024: Best paper award at ISMIR 2024 for our paper with PhD Student Ilaria Manco titled MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models. 17 October 2024: PhD student Gary Bromham successfully passed his viva. His Thesis is titled: Enveloping and Shaping the Sound: Analysis of the perception of retro aesthetics in popular music production. 11 July 2024: I'm papers co-chair of the 2025 AES International Conference on Artificial Intelligence and Machine Learning for Audio with Brecht De Man. The conference chaired by Prof. Josh Reiss will be held at QMUL between September 8-10, 2025. 7 May 2024: PhD student Elisabeth Wilson successfully passed her viva. Her Thesis is titled: Affective Live Coding: Fostering Human-Machine Collaboration with Autonomous Agents. 1 December 2023: I'm a co-chair of QMUL's new AI, Ethics and Society Group which aims to create a platform for critical examination and exploration of the ethical dimensions of AI by engaging with scholars, researchers, and practitioners from different fields. 5 Nov. 2023: Best paper nomination at ISMIR 2023 for our paper with PhD Student Chin-Yun Yu titled Singing Voice Synthesis Using Differentiable LPC and Glottal-Flow-Inspired Wavetables. 25 October 2023: Best Paper Award at WASPAA 2023 for our paper with Sound and Music Computing (SMC MSc) student Matthew Rice titled General Purpose Audio Effect Removal. 19 October 2023: Gave an invited talk titled Artificial Intelligence + Music: Motivations and Perspectives at Steinberg Music Technologies GmbH. 24 May 2023: PhD student Syed Rafee successfully passed his viva. His Thesis is titled: Unveiling the Art of Piano Performance: A Study of Pianist Identification through Statistical and Hierarchical Models. 10 May 2023: Queen Mary Innovation awards large Impact Accelerator Award for the project titled: ReVamp: Community Focused Software for Music and AI Research in collaboration with the BBC R&D and Steinberg Media Technologies. The project is looking to embed Sonic Visualiser into Digital Audio Workstations. 1 March 2023: IEEE has launched the IEEE Emerging Technology Initiative (ETI) on the Internet of Sounds (IoS). I'm a founding member and officer responsible for seminars. You can find more information at the IoS Research Network's homepage. 10 Sept 2022: Best paper award at DAFx 2022 for our paper with PhD Student Cyrus Vahidi titled Differentiable Time-Frequency Scattering on GPU. 27 February 2021: Delivered keynote speech titled Ontology based Machine Learning in Semantic Audio Applications at at the International Semantic Intelligence Conference (ISIC 2021). 30 November 2020: Several fully funded PhD studentships are available at the UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM CDT) I have several PhD topics listed here. Additional topics of interest can be found on my research page. 1 September 2020: Journal of Audio Engineering Society (JAES) Special Issue on the Internet of Sounds. I'm editing this JAES Special Issue with Dr. Luca Turchet, Dr. Cristina Rottondi and Dr. Carlo Fischione. Submissions due 1 March 2021. 27 July 2020: I'm Keynote Speaker at the International Semantic Intelligence Conference (ISIC 2021). ISIC is an international platform for the Artificial Intelligence, Machine Learning and the Semantic Web communities. The conference will be held between 25-27 Feb. 2021 7 May 2020: My PhD student Dr Di Sheng has been awarded her degree for her Thesis titled Intelligent Control of the Dynamic Range Compressor 27 April 2020: My",
  "content_length": 15726,
  "method": "requests",
  "crawl_time": "2025-12-01 13:16:53"
}