{
  "name": "Muhammad Ali Gulzar",
  "homepage": "http://people.cs.vt.edu/~gulzar",
  "status": "success",
  "content": "Muhammad Ali Gulzar I am an assistant professor in the Computer Science Department at Virginia Tech. I am also an Amazon Scholar at Amazon Web Services. I received my Ph.D. in Computer Science at the University of California, Los Angeles where I was a Google Ph.D. Fellow 2017-20. My research vision is to build systems that improve developer productivity through automated debugging and testing for applications in the emerging domains, including data-intensive software such as dataflow programs, ML/AI applications, and scientific analysis software such as computations notebooks. Under these broader goals, I redesign existing software productivity tools for emerging applications in three areas. I am interested in (1) automated tracking-code localization techniques in web applications, (2) re-engineering testing and debugging for data-intensive applications, and (3) advancing current testing and debugging practices in Federated Learning Applications. My past work has focused on interactive and automated debugging for Apache Spark, symbolic execution based test generation for dataflow programs, and performance debugging in Apache Spark. gulzar cs.vt.edu | Google Scholar | Github | LinkedIn News In collaboration with University of Minnesota and UMass Amherst, we received a $1.1 million NSF award for raising the robustness and privacy of Federated Learning systems. Our findings on the accessibility of web advertisements are featured in VT News. Our work on pathological non-executable notebooks is accepted to MSR 2025—congrats, Tien! Our work on semantic cache for LLMs is accepted to IPDPS. Congrats, Waris! My student,Haddi, co-authored the 2024 Web Almanac’s Privacy Chapter. Our research on rare-path coverage and evidence-based tech hirring are accepted to SANER 2025. Our work on using neuron provenance to identify responsible clients in FL is accepted to ICSE 2025. Congrats, Waris! Our work on web ads decreasing the accessibility of web pages is accepted to ICSE 2025. Congrats, Haddi! Our work on blocking JS tracking functions received the ACM CCS 2024 Distinguished Artifact Award. Congrats, Haddi! FedDebug is now availabel as Flower FL baseline. Older news Publications 2025 [ICSE 2025] Accessibility Issues in Ad-Driven Web Applications Abdul Haddi Amjad, Muhammad Danish, Bless Jah, and Muhammad Ali Gulzar The 47th IEEE/ACM International Conference of Software Engineering. 2025 Abstract Website accessibility is essential for inclusiveness and regulatory compliance. Although third-party advertisements (ads) are a vital revenue source for free web services, they introduce significant accessibility challenges. Leasing a websiteś space to ad-serving technologies like DoubleClick results in developers losing control over ad content accessibility. Even on highly accessible websites, third-party ads can undermine adherence to Web Content Accessibility Guidelines (WCAG). We conduct the first large-scale investigation of 430K website elements, including nearly 100K ad elements, to understand the accessibility of ads on websites. We seek to understand the prevalence of inaccessible ads and their overall impact on the accessibility of websites. Our findings show that 67% of websites experience increased accessibility violations due to ads, with common violations including Focus Visible and On Input. Popular ad-serving technologies like Taboola, DoubleClick, and RevContent often serve ads that fail to comply with WCAG standards. Even when ads are WCAG compliant, 27% of them have alternative text in ad images that misrepresents information, potentially deceiving users. Manual inspection of a sample of these misleading ads revealed that user-identifiable data is collected on 94% of websites through interactions, such as hovering or pressing enter. Since users with disabilities often rely on tools like screen readers that require hover events to access website content, they have no choice but to compromise their privacy in order to navigate website ads. Based on our findings, we further dissect the root cause of these violations and provide design guidelines to both website developers and ad-serving technologies to achieve WCAG-compliant ad integration. [ICSE 2025] TraceFL: Interpretability-Driven Debugging in Federated Learning via Neuron Provenance Waris Gill, Ali Anwar, and Muhammad Ali Gulzar The 47th IEEE/ACM International Conference of Software Engineering. 2025 Abstract In Federated Learning, clients train models on local data and send updates to a central server, which aggregates them into a global model using a fusion algorithm. This collaborative yet privacy-preserving training comes at a cost—FL developers face significant challenges in attributing global model predictions to specific clients. Localizing responsible clients is a crucial step towards (a) excluding clients primarily responsible for incorrect predictions and (b) encouraging clients who contributed high quality models to continue participating in the future. Existing ML explainability approaches are inherently inapplicable as they are designed for single-model, centralized training. We introduce TraceFL, a fine-grained neuron provenance capturing mechanism that identifies clients responsible for the global model’s prediction by tracking the flow of information from individual clients to the global model. Since inference on different inputs activates a different set of neurons of the global model, TraceFL dynamically quantifies the significance of the global model’s neurons in a given prediction. It then selectively picks a slice of the most crucial neurons in the global model and maps them to the corresponding neurons in every participating client to determine each client’s contribution, ultimately localizing the responsible client. We evaluate TraceFL on six datasets, including two real-world medical imaging datasets and four neural networks, including advanced models such as GPT. TraceFL achieves 99% accuracy in localizing the responsible client in FL tasks spanning both image and text classification tasks. At a time when state-of-the-art ML debugging approaches are mostly domain-specific (e.g., image classification only), TraceFL is the first technique to enable highly accurate automated reasoning across a wide range of FL applications. [MSR 2025] Are the Majority of Public Computational Notebooks Pathologically Non-Executable? ( EMSE Special Issue Invitee) Tien Nguyen, Waris Gill, and Muhammad Ali Gulzar The 22nd IEEE/ACM International Conference on Mining Software Repositories. 2025 Abstract Computational notebooks are the de facto platforms for exploratory data science, offering an interactive programming environment where users can create, modify, and execute code cells in any sequence. However, this flexibility often introduces code quality issues, with prior studies showing that approximately 76% of public notebooks are non-executable, raising significant concerns about reusability. We argue that the traditional notion of executability—requiring a notebook to run fully and without error—is overly rigid, misclassifying many notebooks and overestimating their non-executability. This paper investigates pathological executability issues in public notebooks under varying notions and degrees of executability. Notebooks, by construction, are incrementally and interactively executed, where each cell execution advances logic toward the notebook’s goal. Even partially improving executability can improve code comprehension and offer a pathway for dynamic analyses. With this insight, we first categorize notebooks into potentially restorable and pathological non-executable notebooks and then measure how removing misconfiguration and superficial execution issues in notebooks can improve their executability (i.e., additional cells executed without error). For instance, we use a Large-Language Model (LLM) to generate synthetic input data to restore non-executable notebooks with “FileNotFound” errors. In a dataset of 42,546 popular public notebooks, containing 34,659 non-executable notebooks, only 21.3% are truly pathologically non-executable. For restorable notebooks, LLM-based methods fully restore 5.4% of previously non-executable notebooks. Among the partially restored, it improves the notebook’s executability by 42.7% and 28% by installing the correct modules and generating synthetic data. These findings challenge prior assumptions, suggesting that notebooks have higher executability than previously reported, many of which offer valuable partial execution, and that their executability should be evaluated within the interactive notebook paradigm rather than through traditional software executability standards. [IPDPS 2025] MeanCache: User-Centric Semantic Caching for LLM Web Services Waris Gill, Mohamed Elidrisi, Pallavi Kalapatapu, Ammar Ahmed, Ali Anwar, and Muhammad Ali Gulzar The 39th IEEE International Parallel & Distributed Processing Symposium 2025 Abstract Large Language Models (LLMs) like ChatGPT and Llama have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters, where inference demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries, which constitute about 31% of the total queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries nor do they operate on contextual queries, leading to unacceptable false hit-and-miss rates. This paper introduces MeanCache, a user-centric semantic cache for LLM-based services that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user’s semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCac",
  "content_length": 72866,
  "method": "requests",
  "crawl_time": "2025-12-01 14:02:08"
}