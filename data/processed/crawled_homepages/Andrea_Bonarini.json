{
  "name": "Andrea Bonarini",
  "homepage": "http://home.deib.polimi.it/bonarini",
  "status": "success",
  "content": "Andrea Bonarini - Personal site Andrea Bonarini Home Welcome! About me I like to develop things that really work, and can help people enjoying life. My formation includes Computer Engineering (Ms and PhD from Polimi), but also many other topics, from Neurolinguistic Progamming (Master, 3 years) and other topics related to psychology, to Tai Chi Chuan (20+ years), theatre improvisation (Improv, 4 years), furniture design and making, mask design and making, kite design, making, and flying, Japanese-style painting, sax, flute, and clarinet playing, and many others. I've a position as Full Professor at Politecnico di Milano (POLIMI), Department of Electronics, Information, and Bioengineering (DEIB), and Responsible for the activities of the AI and Robotics Lab (AIRLab), established in 1973, which, from February 2020, is proudly partner of the Leonardo Robotics Labs cluster at POLIMI. RESEARCH My current research activities, August 2025 After years of research on User Modeling, Human-machine Interaction, Knowledge Representation and Acquisition, Expert Systems, Qualitative Reasoning, Fuzzy Systems, Genetic Algorithms, Reinforcement Learning, Autonomous Robots, Affective Computing, I'm currently focusing my basic research on few topics in the Human-Robot Interaction and Machine learning fields. Human-Robot Interaction Robots can be implemented with many different bodies, in many materials, opening a lot of interaction possibilities, including many different communication channels and emotional expressions. We explored human-robot interaction in the application areas listed here below. Robots and art We are developing autonomous robots performing on stage or in exhibits. An autonomous theatrical robot should be able to play with actors safely, and consistently. The final goal of this research line is the implementation of a robot able to improvise with professionals. Interactive art also inlcudes exhibits where robots are interacting with people with artistic purposes. In this, we are also exploring the possibility to implement in the physical world the experiences usually done in virtual reality (physical metaverse). We are developing an environment equipped with physical sensors that transduce the person activity in the activity of a robot placed elsewhere, a kind of physical avatar that can interact with others. This can provide an embodiment experience intersting to explore brain plasticity, artistic production, and robot design. Robogames Playing with autonomous robots rises many issues related to engagement and enjoyment of the experience. Designing autonomous robots able to effectively play requires integrating shape and behavior design, with machine learning, and the usual autonomous robots abilities (control, navigation, planning, etc.) Playbot4All: inclusive games Autonomous robots can play with everybody, including people with disabilities. Robots, and their activities, should be designed to consider disabilities. Machine learning is used to adapt the robot's behavior to the specific player, providing the care givers and players with new tools. Objective reports of the activities can be obtained from the robot itself. We have just published a book about these topics (Bonarini A., Besio S. (2022) \"Robot play for all\" ), also reporting the experiences done in the last 15 years. Interactive objects Active everyday objects can be developed to explore new interaction possibilities. Design of shape and interaction is needed to obtain interesting objects. Up to now we have designed a mobile coat-hanger (IGHOR), a couple of trash bins, a naughty fan, a mobile money box, ... Machine Learning I'm focusing on basic issues of Machine Learning, in the quest of the \"ML Holy Grail\": learning quickly with cheap computers. To do this, we are currently exploring learning systems with cognitive characteristics (curiosity, sociality, selective perception, ...) and systems that could exploit general knowledge to improve Deep Learning. Cognitive Learning Systems We have explored the possibility to influence the learning activity by psychological attitudes, or \"personality traits\" that the learning agents may have, so to better adapt to different characteristics of the environment. Improving Deep Learning Systems We have explored how to modify the perception of learning agents and also the selection of the experiences to put in the short-term memory to improve speed and quality of Deep Reinforcement Learning algorithms. We are evaluating different aspects to improve the existing algorithms' speed, in particular to exploit quickly learned drivers to optimize the learning process. We are also exploring different ways to integrate Genetic Algorithms and Deep Reinforcement Learning to exploit the best characeristics of each of the two techniques. You can find a list of my publications from my Google Scholar page, or my OrcID page - orcid.org/0000-0002-4880-4521 A set of movies of developed robots are available from the AIRLab YouTube channel. TEACHING My teaching activities, August 2025 I believe that it is possible to teach both curricula and transversal skills in the same course, and I'm experimenting innovative teaching approaches, following suggestions by the POLIMI teaching innovation staff. I'm currently teaching these courses: [Ms] \"Uncertainty in AI\", \"Robotics and Design\", \"Envisioning AI in Design\", and [Bs] and \"Artificial Intelligence (IOL)\". I've taught \"Soft Computing\" for more than 20 years, the root from which \"Machine Learning\", \"Neural Networks and Deep Learning\" and components of other AI courses offered at POLIMI originated. I've taught \"Uncertainty representation\", \"Soft Computing\", \"Designing Interaction\" at PhD level, and \"Expert Systems and Uncertainty\" within professional master courses on AI at CEFRIEL. I've also offered a course about \"Playbot4all: technological toys for all\" within the Passion in Action activity of Politecnico di Milano (\"Beyond the curriculum: training and passion\"). I'm advising PhD Thesis in Information Technology and in Design, Master Thesis in Computer Engineering, Automation, Bioengineering, Design, as well as Bachelor thesis in Biomedical Engineering. Thesis tutored from 2010 are available from the POLIMI Thesis Archive POLITESI. Here below is a list of some of the currently open thesis proposals. If you are interested in any of these, just drop me an e-mail, with subject starting by [Tesi]. Thesis proposals The theses I am advising, with students belonging to the Computer Engineering track, the Automation Engineering track, the Bioengineering track, and different Design tracks, are almost all related to the interaction between robots and people. Physical Metaverse We are developing robots that could move driven by sensors that perceive signals from people (e.g., werable sensors, VR headsets) and providing to this people signals from their own sensors. This would enable a sort of \"real virtual reality\", an experience similar to virtual reality, but with physical avatars interacting in the real world. We have performed different experiences also evaluating how persons can interact with robots with unusual shapes (including a bunch of trash) with only gestures and sounds. This is included in a research line investigating about robots in the arts, whose reference page on the AIRLab site is this. TheatreBot We are developing robot actors able to play a role on the stage together with people, adapting to the situation. The final goal will be to produce a robot able to improvise on stage with improvising actors. This is included in a research line investigating about robots in the arts, whose reference page on the AIRLab site is this. Emotion and activity recognition Recognizing activity of people from a camera on a mobile robot is needed to select a target to offer a service. We have developed systems to do this \"in the wild\" so learning from clips taken in real environments. There is the possibility to integrate these systems in a robot and actually test them in a real environment, covering topics that concern also selection criteria. The same holds for emotion recognition from face, micro-movements, and body posture. These results can also be integrated in most of the other projects. Playbot4All The development of play activities for people with physical and cognitive disabilities, involving robots, brings to these people the possibility to play, with the effect of developing abilities. Collaborations with care centers are active and we are developing many simple, but effective robotic play activities every year, as well as interactive robots for free play. Robots are tools for therapists, enabling a different rapport with the subjects. Moreover, they can be used in inclusive game contexts. Robots can also provide a way to collect objective data that could be used to design further experiences. Here, the importance of adaptation to the subject abilities is even more important than in Robogames, and the cost of the device even more critical. A website dedicated to the initiative supporting this subject is http://playbot4all.polimi.it. Two projects are currently active, one is funded by PNRR and the other in collaboration with other universities is funded by the Ministry of Research and University (PRIN). Robogames Development of games where robots play physically with people. Examples of these have been Jedi Trainer, Drone Laser Game, RoboTower, and RoboTower 2.0. The current main issue is to use machine learning to adapt the behavior of the robot to the ability and strategy of the players so to maximize their enjoyement and engagement. Issues arise from the need of having all the needed computational power on board of the robot, and from the fact that we have to spend as less time as possible to build a player model. Here are some examples of developed games. Interactive objects Up to now we have developed a naughty fan that comes to you and blows unexpectedly, some emotional trash b",
  "content_length": 13712,
  "method": "requests",
  "crawl_time": "2025-12-01 12:56:41"
}