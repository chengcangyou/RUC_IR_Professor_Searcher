{
  "name": "Luo Mai",
  "homepage": "https://luomai.github.io",
  "status": "success",
  "content": "Luo Mai Search Luo Mai Associate Professor University of Edinburgh About Me I am a Reader (Associate Professor) in the School of Informatics at the University of Edinburgh, where I lead the Large-Scale Machine Learning Systems Group. I also co-lead the UK EPSRC Centre for Doctoral Training in Machine Learning Systems and a UK ARIA Project on Scaling AI Compute. My research group works across the full stack of machine learning systems – from models and data to systems and software – pursuing co-designs that can collectively achieve a 1000× leap in efficiency, scalability, and reliability. My work has been recognized with research awards and rising-star honors from both academia and industry. I am passionate about open-source and knowledge exchange. I co-founded open-source AI system libraries that have collectively received over 20,000 GitHub stars and co-edited the open-source textbook Machine Learning Systems: Design and Implementation. Before joining Edinburgh, I was a Research Associate at Imperial College London, working with Peter Pietzuch, and a Visiting Researcher at Microsoft Research. My PhD, supervised by Paolo Costa and Alexander L. Wolf, was supported by a Google Fellowship in Cloud Computing. Fully funded PhD and postdoctoral positions are available. If you are interested, please contact me and describe your research interests and motivation. Interests Computer Systems Machine Learning Data Management Education PhD in Computer Science, 2018 Imperial College London, UK MRes in Advanced Computing, 2012 Imperial College London, UK News [09/25, Paper] MoE-CAP accepted to NeurIPS 2025 (Dataset and Benchmark Track). [08/25, Grant] Win a prestigious award to build systems for powering AI4Math breakthroughs. [07/25, Paper] WaferLLM, the world fastest LLM inference system, accepted to OSDI 2025. [03/25, Achievement] Starting August 2025, I’ll be Reader (Associate Professor). [10/24, Grant] Secured a prestigious ARIA grant with Imperial College & Cambridge University. [10/24, Paper] Tenplex, the first elastic LLM system, accepted to SOSP 2024. [07/24, Student Achievement] Congrats to Yao Fu on Winning 2024 Rising Star in ML & Systems. [07/24, Paper] ServerlessLLM, the first serverless LLM system, accepted to OSDI 2024. [05/24, Award] Win a Microsoft Research Startrack Scholar Award. [03/24, Grant] Secured funds from EPSRC and industry partners to build a CDT for ML Systems. See all posts Publications Dayou Du, Shijie Cao, Jianyi Cheng, Luo Mai, Ting Cao, Mao Yang (2026). BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache. In HPCA. PDF Yinsicheng Jiang *, Yao Fu *, Yeqi Huang *, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Dayou Du, Tairan Xu, Kai Zou, Edoardo Ponti, Luo Mai (2025). MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems. In NeurIPS. PDF Congjie He, Yeqi Huang, Pei Mu, Ziming Miao, Jilong Xue, Lingxiao Ma, Fan Yang, Luo Mai (2025). WaferLLM: Large Language Model Inference at Wafer Scale. In OSDI. PDF Project Marcel Wagenländer, Guo Li, Bo Zhao, Luo Mai, Peter Pietzuch (2024). Tenplex: Dynamic Parallelism for Deep Learning using Parallelizable Tensor Collections. In SOSP. PDF Chuanhao Sun, Zhihang Yuan, Kai Xu, Luo Mai, N Siddharth, Shuo Chen, Mahesh K Marina (2024). Learning high-frequency functions made easy with sinusoidal positional encoding. In ICML. PDF Code Yao Fu, Leyang Xue, Yeqi Huang, Andrei-Octavian Brabete, Dmitrii Ustiugov, Yuvraj Patel, Luo Mai (2024). ServerlessLLM: Low-Latency Serverless Inference for Large Language Models. In OSDI. PDF Code Project Jie Ren*, Xidong Feng*, Bo Liu*, Xuehai Pan*, Yao Fu, Luo Mai, Yaodong Yang (2023). TorchOpt: An Efficient Library for Differentiable Optimization. In JMLR. PDF Code Hanjing Wang*, Man-Kit Sit*, Congjie He, Ying Wen, Weinan Zhang, Jun Wang, Yaodong Yang, Luo Mai (2023). GEAR: A GPU-Centric Experience Replay System for Large Reinforcement Learning Models. In ICML. PDF Code Chijun Sima*, Yao Fu*, Man-Kit Sit, Liyi Guo, Xuri Gong, Feng Lin, Junyu Wu, Yongsheng Li, Haidong Rong, Pierre-Louis Aublin, Luo Mai (2022). Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update. In USENIX OSDI. PDF Bo Liu, Xidong Feng, Jie Ren, Luo Mai, Rui Zhu, Haifeng Zhang, Jun Wang, Yaodong Yang (2022). A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning. In NeurIPS. PDF See all publications Software ServerlessLLM Serverless LLM serving for everyone. MegBA A GPU-Based Distributed Library for Large-Scale Bundle Adjustment. TorchOpt An efficient library for differentiable optimization built upon PyTorch. Quiver PyTorch Library for Low-Latency, High-Throughput Graph Learning on GPUs. KungFu Adaptive Large-scale Deep Learning TensorLayer Easy-to-use Deep Learning Library HyperPose Real-time Visual Computing Library RLzoo Reinforcement Learning Model Zoo Group Researchers Xuan Sun Research Associate Le Xu Research Fellow Alec Diallo Research Associate Cheng Deng Research Fellow Haocheng Xiao Research Associate Grad Students Leyang Xue PhD Student (Primary supervisor Mahesh Marina) Man-Kit Sit PhD Student Yao Fu PhD Student Congjie He PhD Student Yeqi Huang PhD Student Maria Durackova PhD Student (Primary supervisor Boris Grot) Matej Sandor PhD Student Dayou Du PhD Student (Primary supervisor Jianyi Cheng) Yinsicheng Jiang PhD Student Zhan Lu PhD Student Karen Zheng PhD Student (Primary supervisor Jingjie Li) Yanwei Ye PhD Student (Primary supervisor Jackson Woodruff) Yi-Chieh Wang PhD Student Tairan Xu PhD Student Yangsheng Deng PhD Student Teaching Course designer and organizer for popular courses (150+ students) at Edinburgh: Machine Learning Systems 24/25 Extreme Computing 23/24, 22/23 and 21/22 Service and Awards Selected Research Awards and Grants Winner of AI for Math fund (Renaissance Philanthropy), 2025 ARIA project for benchmarking AI evolution, 2025 ARIA project for scaling AI compute, 2024 Microsoft Research Asia StarTrack Scholar Award, 2024 EPSRC CDT for ML Systems, 2024 Chancellor Rising Star in Research (Finalist), 2023 Tencent Research Award, 2022 Alibaba Innovative Research Award, 2020 Microsoft Azure Research Award, 2018 ACM Multimedia Best Open-Source Software Award, 2017 Google PhD Fellowship in Cloud Computing, 2012 - 2016 ACM CoNEXT Conference Best Paper Finalist, 2014 IEEE MASS Conference Best Paper Finalist, 2012 Conference Organization: EuroSys 2026, General Co-Chair (with Antonio Barbalace) International Workshop on Efficient Generative AI 2024, General Co-Chair (with Edoardo Ponti) Selected Conference Committee Memberships: ISCA (2026) ASPLOS (2026) EuroSys (2025) ICDE (2021-2025) SoCC (2023-2025) MICRO (2022) Contact luo.mai@ed.ac.uk IF-2.03, Informatics Forum, University of Edinburgh, Edinburgh, EH8 9AB Cite × Copy Download",
  "content_length": 6888,
  "method": "requests",
  "crawl_time": "2025-12-01 13:48:54"
}