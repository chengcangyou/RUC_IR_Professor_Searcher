{
  "name": "Huaxiu Yao",
  "homepage": "https://www.huaxiuyao.io",
  "status": "success",
  "content": "Huaxiu Yao's Personal Website Huaxiu Yao (姚骅修)Assistant ProfessorDepartment of Computer Science | School of Data Science and SocietyUniversity of North Carolina at Chapel HillEmail | Google Scholar | Twitter | LinkedIn | WeChat | 小红书HOMEAIMING LAB ABOUTSTUDENTSOPENINGS PUBLICATIONSTEACHINGSERVICECONTACT About meShort Bio. I am a tenure-track Assistant Professor in the Department of Computer Science at the University of North Carolina at Chapel Hill, with a joint appointment in the School of Data Science and Society and an adjunct appointment in the Department of Biostatistics. My lab, AIMING, studies adaptive intelligence through alignment, interaction and learning, and is affiliated with the UNC NLP group. I was a Postdoctoral Scholar at Stanford University hosted by Chelsea Finn. I received my Ph.D. degree in 2021 at Pennsylvania State University under the advisory of Zhenhui (Jessie) Li. During my Ph.D, I also spent time visiting CMU hosted by Eric P. Xing. Lab Openings:- We will recruit 3 Ph.D. students for Fall 2026 and multiple interns or visiting students all year. Please read THIS for detailed recruitment information. Research Interests. My research focuses on both the theoretical and applied aspects of building generalizable, well-aligned, agentic foundation models (e.g., LLMs, VLMs, Diffusion Models). Additionally, I am keen on utilizing these models to facilitate applications in biomedicine/healthcare and robotics. Currently, my primary endeavors revolve around the following key directions:Exploring effective strategies to fine-tune foundation models for enhanced generalization, reasoning, and alignment.Steering AI models toward improved reasoning and adaptability in unseen environments and tasks.Pioneering agentic and interactive systems that seamlessly integrate humans, foundation models, and tools to achieve shared goals.Related ML topics: AI alignment and preference learning (e.g., RLHF/RLAIF), AI Agent, reinforcement learning, out-of-distribution generalization and adaptation, uncertainty estimation and calibration.Focused applications: robot learning and embodied AI, biomedicine and healthcare. You can follow me on Twitter at @HuaxiuYaoML or 小红书 at Huaxiu Yao. News and Travel[2025-2026 Service] Senior Area Chair in ACL 2025, EMNLP 2025; Area Chair in ICML 2025, NeurIPS 2025, ICLR 2025, AISTATS 2025; Action Editor: TMLR[2025.09] Four papers were accepted by EMNLP 2025 (two main track, two findings)[2025.07] Two papers were accepted by COLM 2025[2025.05] Three papers were accepted by ICML 2025, four papers were accepted by ACL 2025 (two main track, two findings)[2025.01] Six papers were accepted by ICLR 2025, two papers were accepted by findings of NAACL 2025, and one paper was accepted by ICRA[2024.09] Five papers were accepted by NeurIPS 2024 (three main track, two D&B track), One paper was accepted by EMNLP 2024AwardsAmazon Research Awards, 2025UNC Junior Faculty Development Award, 2025PharmAlliance Early Career Researcher Award, 2025KDD Health Day Distinguished Vision Award, 2025TMLR Outstanding Paper Award, 2024KDD Best Paper Award, 2024Cisco Faculty Research Award, 2024National AI Research Resource Pilot Award, 2024Creativity Hubs Seed-funding Winner, 2024NC TraCS Pilot Award, 2024AAAI New Faculty Highlights, 2024AI2000 Most Influential Scholar Award Honorable Mention, 2022AI Rising Stars in Chinese Students, Baidu Research, 2021College of IST Ph.D. Award for Research Excellence, Penn State University, 2020 publicationS Here are selected publications that most closely align with my research focus. Please see the complete list in Google Scholar.The underline authors are students (co-)mentored by me; †: equal advising[AI Alignment], [ML Generalization], [AI Agent], [Embodied AI], [Multimodal], [AI for Health] Preprints[1] Siwei Han, Peng Xia, Ruiyi Zhang, Tong Sun, Yun Li, Hongtu Zhu, Huaxiu Yao, MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding, arXiv 2503.13964. [arXiv] [Code][AI Agent], [Multimodal][2] Puzhen Yuan, Angyuan Ma, Yunchao Yao, Huaxiu Yao, Masayoshi Tomizuka, Mingyu Ding, REMAC: Self-Reflective and Self-Evolving Multi-Agent Collaboration for Long-Horizon Robot Manipulation, arXiv 2503.22122. [arXiv][Embodied AI], [AI Agent][3] Haibo Tong*, Zhaoyang Wang*, Zhaorun Chen, Haonian Ji, Shi Qiu, Siwei Han, Kexin Geng, Zhongkai Xue, Yiyang Zhou, Peng Xia, Mingyu Ding, Rafael Rafailov, Chelsea Finn, Huaxiu Yao, MJ-VIDEO: Fine-Grained Benchmarking and Rewarding Video Preferences in Video Generation, arXiv 2502.01719. [arXiv] [Project Page][AI Alignment], [Multimodal][4] Zijian Zhang, Kaiyuan Zheng, Zhaorun Chen, Joel Jang, Yi Li, Chaoqi Wang, Mingyu Ding, Dieter Fox, Huaxiu Yao, GRAPE: Generalizing Robot Policy via Preference Alignment, arXiv 2411.19309. [arXiv] [Project Page][Embodied AI], [AI Alignment], [ML Generalization], [Multimodal] [5] Shuo Xing, Hongyuan Hua, Xiangbo Gao, Shenzhe Zhu, Renjie Li, Kexin Tian, Xiaopeng Li, Heng Huang, Tianbao Yang, Zhangyang Wang, Yang Zhou, Huaxiu Yao, Zhengzhong Tu, AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving, arXiv 2412.15206. [arXiv] [Project Page][Embodied AI], [ML Generalization], [Multimodal] [6] Zhaorun Chen*, Yichao Du*, Zichen Wen*, Yiyang Zhou*, Chenhang Cui, Zhenzhen Weng, Haoqin Tu, Chaoqi Wang, Zhengwei Tong, Qinglan Huang, Canyu Chen, Qinghao Ye, Zhihong Zhu, Yuqing Zhang, Jiawei Zhou, Zhuokai Zhao, Rafael Rafailov, Chelsea Finn, Huaxiu Yao, MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?, arXiv 2407.04842. [arXiv] [Project Page][AI Alignment], [Multimodal] [7] Yiyang Zhou*, Chenhang Cui*, Rafael Rafailov, Chelsea Finn, Huaxiu Yao, Aligning Modalities in Vision Large Language Models via Preference Fine-tuning, arXiv 2402.11411. [arXiv] [Code][AI Alignment], [Multimodal] [8] Chenhang Cui*, Yiyang Zhou*, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, Huaxiu Yao, Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges, arXiv 2311.03287. [arXiv] [Code][Multimodal], [ML Generalization]2025[1] Yiyang Zhou*, Linjie Li*, Shi Qiu*, Zhengyuan Yang, Yuyang Zhao, Siwei Han, Yangfan He, Kangqi Li, Haonian Ji, Zihao Zhao, Haibo Tong, Lijuan Wang, Huaxiu Yao, GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them? in Proceeding of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025), Suzhou, China, Nov 2025.[Multimodal][2] Shuo Xing, Peiran Li, Yuping Wang, Ruizheng Bai, Yueqi Wang, Chan-Wei Hu, Chengxuan Qian, Huaxiu Yao, Zhengzhong Tu, Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization, in Proceeding of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025), Suzhou, China, Nov 2025.[AI Alignment], [Multimodal][3] Wenhao Zheng, Liaoyaqi Wang, Dongshen Peng, Hongxia Xu, Yun Li, Hongtu Zhu, Tianfan Fu, Huaxiu Yao, LIFTED: Multimodal Clinical Outcome Prediction via Large Language Models and Mixture-of-Experts, in Findings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025 Findings), Suzhou, China, Nov 2025.[AI for Health][4] Wenhao Zheng*, Yixiao Chen*, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P Xing, Hongyi Wang, Huaxiu Yao, CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing, in Proceeding of the 2nd Conference on Language Modeling (COLM 2025), Montreal, Canada, Oct 2025.[AI Agent][5] Fan Nie, Lan Feng, Haotian Ye, Weixin Liang, Pan Lu, Huaxiu Yao, Alexandre Alahi, James Zou, Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors, in Proceeding of the 2nd Conference on Language Modeling (COLM 2025), Montreal, Canada, Oct 2025.[AI Alignment], [AI Agent][6] Kangyu Zhu*, Peng Xia*, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao, MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization, in Proceeding of the Forty-second International Conference on Machine Learning (ICML 2025), Vancouver, Canada, Jul 2025.[AI Alignment], [Multimodal], [AI for Health][7] Fan Nie, Xiaotian Hou, Shuhang Lin, James Zou, Huaxiu Yao, Linjun Zhang, FactTest: Factuality Testing in Large Language Models with Finite-Sample and Distribution-Free Guarantees, in Proceeding of the Forty-second International Conference on Machine Learning (ICML 2025), Vancouver, Canada, Jul 2025.[8] Yiyang Zhou*, Zhaoyang Wang*, Tianle Wang*, Shangyu Xing, Peng Xia, Bo Li, Kaiyuan Zheng, Zijian Zhang, Zhaorun Chen, Wenhao Zheng, Xuchao Zhang, Chetan Bansal, Weitong Zhang, Ying Wei, Mohit Bansal, Huaxiu Yao, AnyPrefer: An Agentic Framework for Preference Data Synthesis, in Proceeding of the 13th International Conference on Learning Representations (ICLR 2025), Singapore, Apr 2025.[AI Alignment], [ML Generalization], [Multimodal], [AI Agent][9] Zhaoyang Wang, Weilei He, Zhiyuan Liang, Xuchao Zhang, Chetan Bansal, Ying Wei, Weitong Zhang, Huaxiu Yao, CREAM: Consistency Regularized Self-Rewarding Language Models, in Proceeding of the 13th International Conference on Learning Representations (ICLR 2025), Singapore, Apr 2025. [arXiv] [Code][AI Alignment][10] Peng Xia, Kangyu Zhu, Haoran Li, Tianze Wang, Weijia Shi, Sheng Wang, Linjun Zhang, James Zou, Huaxiu Yao, MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models, in Proceeding of the 13th International Conference on Learning Representations (ICLR 2025), Singapore, Apr 2025. [arXiv] [Code][AI Alignment], [Multimodal], [AI for Health][11] Peng Xia*, Siwei Han*, Shi Qiu*, Yiyang Zhou, Zhaoyang Wang, Wenhao Zheng, Zhaorun Chen, Chenhang Cui, Mingyu Ding, Linjie Li, Lijuan Wang, Huaxiu Yao, MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models, in Proceeding of the 13th International Conference on Learning Representations (ICLR 2025), Singapore, Apr 2",
  "content_length": 25520,
  "method": "requests",
  "crawl_time": "2025-12-01 13:21:20"
}