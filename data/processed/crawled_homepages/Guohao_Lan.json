{
  "name": "Guohao Lan",
  "homepage": "https://guohao.netlify.app",
  "status": "success",
  "content": "Guohao Lan | Homepage Guohao Lan, Ph.D. Assistant Professor Embedded Systems Group Delft University of Technology Email: g.lan AT tudelft.nl Office: 2.W.720, Building 28 Address: Van Mourik Broekmanweg 6, 2628 XE Delft, The Netherlands I am a tenured Assistant Professor in the Embedded Systems Group of the Faculty of Electrical Engineering, Mathematics and Computer Science (EEMCS) at Delft University of Technology, the Netherlands. My research interests are in the intersection of pervasive systems and machine learning. Specifically, my research explores how to augment the environment and human body with smart cyber-physical systems that can sense, communicate, and learn, to enhance human capabilities in comprehension, perception, and decision-making — a vision I refer to as `Pervasive Augmented Intelligence'. Before joining TU Delft, I was a postdoctoral researcher at Duke University, working with Maria Gorlatova. I earned my Ph.D. in Computer Science and Engineering from the University of New South Wales, Australia, in November 2018, where I worked under the supervision of Mahbub Hassan and Wen Hu. I was also a member of the Networks Research Group at Data61-CSIRO. Prior to my Ph.D., I obtained my M.Sc. degree in Computer Science from KAIST, Korea, in February 2015 under the supervision of Myungchul Kim. MSc Project: We have multiple MSc thesis projects available. Before reaching out, please take the time to review my notes to prospective students and the available thesis topics. If you think there is a match, feel free to send me an email. Please note that I DO NOT respond to general or non-specific project inquiries. News [2025/7/7] Our paper entitled ``Through the Eyes of Emotion'', led by two fantastic Master’s students, Tongyun Yang and Bishwas Regmi, has been accepted to appear in ACM UbiComp 2025! The work presents a first-of-its-kind eye-tracking dataset in VR, combining high-frame-rate periocular videos and high-frequency gaze data to enable accurate, multimodal emotion recognition. The dataset and software will be avaliable soon at project repository. [2025/6/18] Invited to serve on the TPC of SenSys 2026. [2025/5/15] Invited to serve on the TPC of INFOCOM 2026. [2025/3/31] Invited to serve on the TPC of NDSS 2026. [2025/2/25] Our paper entitled ``SecureGaze: Defending Gaze Estimation Against Backdoor Attacks'' has been accepted to appear in ACM SenSys 2025. This is the first work that demonstrates and mitigates the backdoor vulnerability of gaze estimation models. A physical-world demonstration and the associated implementation can be found in the project repository. [2024/11/8] Invited to serve on the TPC of SenSys 2025 and MobiSys 2025. [2024/11/1] Starting to serve as an Associate Editor of the Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (PACM IMWUT). [2024/9/30] Our paper entitled ``SEESys: Online Pose Error Estimation System for Visual SLAM'' has been accepted to appear in ACM SenSys 2024. [2024/8/5] Our paper entitled ``PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking Services'' has been accepted to appear in ACM IMWUT 2024. [2024/8/5] Our paper entitled ``REHSense: Towards Battery-Free Wireless Sensing via Radio Frequency Energy Harvesting'' has been accepted to appear in ACM MobiHoc 2024. [2024/8/5] Our paper entitled ``Leveraging Foundation Models for Zero-Shot IoT Sensing'' has been accepted to appear in ECAI 2024. [2023/9/23] Our paper entitled ``EV-Eye: Rethinking High-frequency Eye Tracking through the Lenses of Event Cameras'' has been accepted to appear in NeurIPS 2023. [2023/9/2] Our paper entitled ``Screen Perturbation: Adversarial Attack and Defense on Under-Screen Camera'' has been accepted to appear in ACM MobiCom 2023. [2023/7/18] Our paper entitled ``FreeGaze: Resource-efficient Gaze Estimation via Frequency-domain Contrastive Learning'' has been accepted to appear in EWSN 2023. [2023/6/22] Our paper entitled ``SolarKey: Battery-free Key Generation using Solar Cells'' has been accepted to appear in ACM Transactions on Sensor Networks. [2023/3/20] Our EMGSense paper received the Mark Weiser Best Paper Award at IEEE PerCom 2023. [2022/12/21] Our paper entitled ``EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing'' has been accepted to appear in IEEE PerCom 2023. [2022/9/18] Our paper entitled ``Eavesdropping Mobile App Activity via Radio-frequency Energy Harvesting'' has been accepted to appear in USENIX Security 2023. [2022/4/22] We are organizing the 1th ACM Workshop on Smart Wearable Systems and Applications (in conjunction with ACM MobiCom'22). Please consider sharing your great work with us. [2022/2/19] Our paper entitled ``EyeSyn: Psychology-inspired Eye Movement Synthesis for Gaze-based Activity Recognition'' has been accepted to appear in ACM/IEEE IPSN 2022. [2022/1/25] Our paper entitled ``Recognizing Hand Gestures using Solar Cells'' has been accepted to appear in IEEE Transactions on Mobile Computing. [2022/1/10] Our ongoing work and vision on privacy-preserving eye tracking for AR/VR are mentioned in the Wall Street Journal article \"Come the Metaverse, Can Privacy Exist?\". [2021/9/30] Received the Facebook Research Award with Xucong Zhang to design privacy-preserving eye tracking for AR/VR and beyond. Thank you Facebook! Selected Publications UbiComp'25 \"Through the eyes of emotion: A multi-faceted eye tracking dataset for emotion recognition in virtual reality\" Tongyun Yang, Bishwas Regmi, Lingyu Du, Andreas Bulling, Xucong Zhang, and Guohao Lan Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2025. SenSys'25 \"SecureGaze: Defending gaze estimation against backdoor attacks\" Lingyu Du, Yupei Liu, Jinyuan Jia, and Guohao Lan Proceedings of the 23nd ACM Conference on Embedded Networked Sensor Systems, 2025. UbiComp'24 \"PrivateGaze: Preserving user privacy in black-box mobile gaze tracking services\" Lingyu Du, Jinyuan Jia, Xucong Zhang, and Guohao Lan Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2024. SenSys'24 \"SEESys: Online pose error estimation system for visual SLAM\" Tianyi Hu, Tim Scargill, Ying Chen, Fan Yang, Guohao Lan, and Maria Gorlatova Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems, 2024. NeurIPS'23 \"EV-Eye: Rethinking high-frequency eye tracking through the lenses of event cameras\" Guangrong Zhao, Yurun Yang, Jingwei Liu, Ning Chen, Yiran Shen, Hongkai Wen, and Guohao Lan Proceedings of the 37th Conference on Neural Information Processing Systems, 2023. MobiCom'23 \"Screen perturbation: Adversarial attack and defense on under-screen camera\" Hanting Ye, Guohao Lan, Jinyuan Jia, and Qing Wang Proceedings of the 29th ACM Annual International Conference On Mobile Computing And Networking, 2023. Security'23 \"Eavesdropping mobile app activity via radio-frequency energy harvesting\" Tao Ni, Guohao Lan, Jia Wang, Qingchuan Zhao, and Weitao Xu Proceedings of the 32nd on USENIX Security Symposium, 2023. IPSN'22 \"EyeSyn: Psychology-inspired eye movement synthesis for gaze-based activity recognition\" Guohao Lan, Tim Scargill, and Maria Gorlatova Proceedings of the 21th ACM/IEEE International Conference on Information Processing in Sensor Networks, 2022. SenSys'20 \"GazeGraph: Graph-based few-shot cognitive context sensing from human visual behavior\" Guohao Lan, Bailey Heit, Tim Scargill, and Maria Gorlatova Proceedings of the 18th ACM Conference on Embedded Networked Sensor Systems, 2020. IPSN'20 \"CollabAR: Edge-assisted collaborative image recognition for mobile augmented reality\" Zida Liu, Guohao Lan, Jovan Stojkovic, Yunfan Zhang, Carlee Joe-Wong, and Maria Gorlatova Proceedings of the 19th ACM/IEEE International Conference on Information Processing in Sensor Networks, 2020.",
  "content_length": 7868,
  "method": "requests",
  "crawl_time": "2025-12-01 13:16:30"
}