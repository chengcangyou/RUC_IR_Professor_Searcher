{
  "name": "Anna Rohrbach",
  "homepage": "https://anna-rohrbach.net",
  "status": "success",
  "content": "Anna Rohrbach – Vision and Language Skip to content I have joined TU Darmstadt and hessian.AI as a full Professor on “Multimodal Grounded Learning”, further supported by a €2M LOEWE Start Professorship. Prior to that I was a Research Scientist at UC Berkeley, working with Prof. Trevor Darrell. I have completed my PhD at Max Planck Institute for Informatics under supervision of Prof. Bernt Schiele. My research is at the intersection of vision and language. I have worked on a variety of tasks, including image and video description, visual grounding, visual question answering, text-to-image synthesis, multimodal forensics. I am interested in building explainable and compositional models, diagnosing and addressing bias, and developing multimodal models that can learn from language advice. I am looking for prospective postdocs in multimodal AI. Prior experience in multimodal AI (aka vision&language) expected. Please do not email me, but apply here! I am Ukrainian and I stand with my people against Russian aggression. One-pager with tiny instructions that make a huge difference. News 2025 “Reasonable Artificial Intelligence” (RAI) Cluster of Excellence is looking for PhD students! For this and other positions, see here. Super excited to join the organizers’ team of ECCV’26 as a Program Chair! Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection and Classifiers Understand Compositionality, but Conditions Apply accepted at NeurIPS’25 and NeurIPS’25 D&B, respectively! Our work When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning accepted at COLM 2025! I am co-organizing the 10th “anniversary” edition of the Closing the Loop between the Vision and Language (CLVL) workshop at ICCV 2025, submissions are welcome! I am co-organizing the 1st Workshop on the Findings of ICCV (at ICCV 2025), submissions are welcome! Very proud an honored that our “Reasonable Artificial Intelligence” (RAI) project is funded as a new Cluster of Excellence! Our multimodal fact-checking approach DEFAME to appear in ICML 2025! I am serving as an Area Chair for ICCV 2025 2024 I am serving as an Area Chair for CVPR 2025 Congratulations to my team on scoring first in the AVERITEC Shared Task (FEVER Workshop @ EMNLP 2024)! Check out our paper! Honored by the ECCV 2024 as an Outstanding Area Chair! I was featured in the “120+ Women Spearheading Advances in Visual Tech and AI” , appreciate being included in the outstanding company! The website for The Multimodal AI Lab, jointly led by me and Marcus Rohrbach at TU Darmstadt, is now live! 2023 I am honored to receive the DAGM German Pattern Recognition Award 2023 I have joined TU Darmstadt (Germany) as a full W3-Professor I have been awarded €2M LOEWE Start Professorship from the state of Hesse I am serving as an Area Chair for ICCV 2023, CVPR 2024 2022 Congrats to my team for winning the Ego4D PNR Temporal Localization Challenge 2022, technical report here! Recognized as an Outstanding Reviewer at CVPR 2022 I am serving as an Area Chair for NeurIPS Datasets and Benchmarks 2022 An open letter from engineers and researchers around the world to IEEE Spectrum: Open Letter: IEEE Spectrum editors apparently fell for Russian propaganda Check out our blog post on Accelerating Ukraine Intelligence Analysis with Computer Vision on Synthetic Aperture Radar Imagery 2021 Recognized as an Outstanding Reviewer at NeurIPS 2021. I co-organized the 4th Workshop on Closing the Loop Between Vision and Language (in conjunction with ICCV 2021). I gave a talk at the 2021 VizWiz Grand Challenge Workshop, in conjunction with CVPR 2021. I gave a talk at the 2nd Workshop on Advances in Language and Vision Research (ALVR), in conjunction with NAACL 2021. Recognized as an Outstanding Reviewer at CVPR 2021. I am serving as an Area Chair for ICCV 2021. 2020 I gave a talk at the The 2nd workshop on Video Turing Test: Toward Human-Level Video Story Understanding, in conjunction with ECCV 2020. I gave talks at the Visual Question Answering and Dialog Workshop  and The End-of-End-to-End: A Video Understanding Pentathlon, in conjunction with CVPR 2020. Preprints and Technical Reports DeepFake Doctor: Diagnosing and Treating Audio-Video Fake Detection,Marcel Klemt*, Carlotta Segna*, Anna Rohrbach* indicate equal contribution Erased but Not Forgotten: How Backdoors Compromise Concept ErasureJonas Henry Grebe*, Tobias Braun*, Marcus Rohrbach, Anna Rohrbach* indicate equal contribution Chrono: A Simple Blueprint for Representing Time in MLLMsBoris Meinardus, Hector Rodriguez, Anil Batra, Anna Rohrbach, Marcus Rohrbach Structured Video Tokens @ Ego4D PNR Temporal Localization Challenge 2022Elad Ben-Avraham, Roei Herzig, Karttikeya Mangalam, Amir Bar, Anna Rohrbach, Leonid Karlinsky, Trevor Darrell, Amir Globerson Recent Publications Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution DetectionReihaneh Zohrabi*, Hosein Hasani*, Mahdieh Soleymani Baghshah, Anna Rohrbach, Marcus Rohrbach, Mohammad Hossein RohbanNeurIPS’25, * indicate equal contribution Classifiers Understand Compositionality, but Conditions Apply,Yujin Jeong*, Arnas Uselis*, Seong Joon Oh, Anna RohrbachNeurIPS’25 D&B, * indicate equal contribution When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM ReasoningNishad Singhi*, Hritik Bansal*, Arian Hosseini*, Aditya Grover, Kai-Wei Chang, Marcus Rohrbach, Anna RohrbachCOLM 2025, * indicate equal contribution DEFAME: Dynamic Evidence-based FAct-checking with Multimodal ExpertsTobias Braun*, Mark Rothermel*, Marcus Rohrbach, Anna RohrbachICML 2025, * indicate equal contribution V² Dial: Unification of Video and Visual Dialog via Multimodal ExpertsAdnen Abdessaied, Anna Rohrbach, Marcus Rohrbach, Andreas BullingCVPR 2025 InFact: A Strong Baseline for Automated Fact-CheckingMark Rothermel*, Tobias Braun*, Marcus Rohrbach, Anna RohrbachFEVER @ EMNLP 2024, * indicate equal contribution Shape-Guided Diffusion with Inside-Outside AttentionDong Huk Park*, Grace Luo*, Clayton Toste, Samaneh Azadi, Xihui Liu, Maka Karalashvili, Anna Rohrbach, Trevor DarrellWACV 2024, * indicate equal contribution MammalNet: A Large-scale Video Benchmark for Mammal Recognition and Behavior UnderstandingJun Chen*, Ming Hu*, Darren Cooker, Michale Berumen, Blair Costelloe, Sara Beery, Anna Rohrbach, Mohamed ElhoseinyCVPR 2023, * indicate equal contribution Using Language to Extend to Unseen Domains Lisa Dunlap, Clara Mohri, Devin Guillory, Han Zhang, Trevor Darrell, Joseph E Gonzalez, Aditi Raghunanthan, Anna RohrbachICLR 2023, Notable-top-25% (aka Spotlight) Watch Those Words: Video Falsification Detection Using Word-Conditioned Facial MotionShruti Agarwal, Liwen Hu, Evonne Ng, Trevor Darrell, Hao Li, Anna RohrbachWACV 2023 More Control for Free! Image Synthesis with Semantic Diffusion GuidanceXihui Liu, Dong Huk Park, Samaneh Azadi, Gong Zhang, Arman Chopikyan, Yuxiao Hu, Humphrey Shi, Anna Rohrbach, Trevor DarrellWACV 2023 G^3: Geolocation via Guidebook GroundingGrace Luo*, Giscard Biamby*, Trevor Darrell, Daniel Fried, Anna RohrbachFindings of EMNLP 2022, * indicate equal contribution Focus! Relevant and Sufficient Context Selection for News Image CaptioningMingyang Zhou, Grace Luo, Anna Rohrbach, Zhou YuFindings of EMNLP 2022 K-LITE: Learning Transferable Visual Models with External KnowledgeSheng Shen*, Chunyuan Li*, Xiaowei Hu*, Jianwei Yang, Yujia Xie, Pengchuan Zhang, Zhe Gan, Lijuan Wang, Lu Yuan, Ce Liu, Kurt Keutzer, Trevor Darrell, Anna Rohrbach, Jianfeng GaoNeurIPS 2022, * indicate equal contribution, Oral Bringing Image Scene Structure to Video via Frame-Clip Consistency of Object TokensElad Ben-Avraham, Roei Herzig, Karttikeya Mangalam, Amir Bar, Anna Rohrbach, Leonid Karlinsky, Trevor Darrell, Amir GlobersonNeurIPS 2022 TL;DW? Summarizing Instructional Videos with Task Relevance & Cross-Modal SaliencyMedhini Narasimhan, Arsha Nagrani, Chen Sun, Michael Rubinstein, Trevor Darrell*, Anna Rohrbach*,  Cordelia Schmid*ECCV 2022, * indicate equal contribution Reliable Visual Question Answering: Abstain Rather Than Answer IncorrectlySpencer Whitehead, Suzanne Petryk, Vedaad Shakib, Joseph Gonzalez, Trevor Darrell, Anna Rohrbach, Marcus RohrbachECCV 2022 The Abduction of Sherlock Holmes: A Dataset for Visual Abductive ReasoningJack Hessel, Jena D Hwang, Jae Sung Park, Rowan Zellers, Chandra Bhagavatula, Anna Rohrbach, Kate Saenko, Yejin ChoiECCV 2022, Oral Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal MisinformationGiscard Biamby, Grace Luo, Trevor Darrell, Anna RohrbachNAACL 2022 Exposing the Limits of Video-Text Models through Contrast SetsJae Sung Park, Sheng Shen, Ali Farhadi, Trevor Darrell, Yejin Choi, Anna RohrbachNAACL 2022 On Guiding Visual Attention with Language SpecificationSuzanne Petryk, Lisa Dunlap, Keyan Nasseri, Joseph Gonzalez, Trevor Darrell, Anna RohrbachCVPR 2022 Object-Region Video TransformersRoei Herzig, Elad Ben-Avraham, Karttikeya Mangalam, Amir Bar, Gal Chechik, Anna Rohrbach, Trevor Darrell, Amir GlobersonCVPR 2022 DETReg: Unsupervised Pretraining with Region Priors for Object DetectionAmir Bar, Xin Wang, Vadim Kantorov, Colorado J. Reed, Roei Herzig, Gal Chechik, Anna Rohrbach, Trevor Darrell, Amir GlobersonCVPR 2022 ReCLIP: A Strong Zero-Shot Baseline for Referring Expression ComprehensionSanjay Subramanian, William Merrill, Trevor Darrell, Matt Gardner, Sameer Singh, Anna RohrbachACL 2022 How Much Can CLIP Benefit Vision-and-Language Tasks? Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei Chang, Zhewei Yao, Kurt KeutzerICLR 2022 CLIP-It! Language-Guided Video Summarization Medhini Narasimhan, Anna Rohrbach, Trevor DarrellNeurIPS 2021 NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal MediaGrace Luo, Trevor Darrell, Anna RohrbachEMNLP 2021, Oral Benchmark for Compositional Text-to-Image SynthesisDong Huk Park, Samaneh Azadi",
  "content_length": 10485,
  "method": "requests",
  "crawl_time": "2025-12-01 12:59:03"
}