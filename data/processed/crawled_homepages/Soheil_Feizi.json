{
  "name": "Soheil Feizi",
  "homepage": "https://www.cs.umd.edu/~sfeizi",
  "status": "success",
  "content": "Soheil Feizi - Computer Science Faculty at UMD Home Publications Advising Awards Teaching Contact Soheil Feizi Associate Professor, CS @ UMD Short Bio: Soheil Feizi is a faculty and the director of Reliable AI Lab in the Computer Science department at University of Maryland, College Park (UMD). Currently on leave from his academic position, he is the Founder and CEO of RELAI , a startup dedicated to advancing AI reliability. He holds a Ph.D. from MIT and completed postdoctoral research at Stanford University . He has published over 100 peer-reviewed papers and given more than 50 invited talks. He has received multiple awards for his work including the ONR's Young Investigator Award, the NSF CAREER Award, the ARO's Early Career Program Award, two best paper awards, the Ernst Guillemin Thesis Award, a Teaching Award, and more than fifteen research awards from national agencies such as NSF, DARPA, ARL, ONR, DOE, NIST as well as industry such as Meta, IBM, Amazon, Qualcomm and Capital One. His work has been featured by major outlets such as the Washington Post, BBC, MIT Technology Review, Bloomberg, and the Wire . Recently, he testified before the U.S. House's Bipartisan Task Force on AI, reflecting his commitment to ensuring AI is developed with safety, accuracy, and reliability in mind. He is committed to promoting diversity in STEM and has mentored several high school, undergraduate, and graduate students through various programs. Research My research is centered around developing reliable and trustworthy Artificial Intelligence (AI) with a focus on understanding its robustness (to natural and/or adversarial input variations), generalizability (to unforeseen data domains) and interpretability (of both test and training time predictions). I am interested in the reliability anslysis of both predictive and generative AI models. Read More Highlights New: Launched: RELAI, , a startup whose goal is to make AI reliability accessible and achievable for all. New: Testified before the U.S. House's Bipartisan Task Force on AI. . New: Interviews with: Washington Post, Wired, MIT Technology Review, Bloomberg ARO's Early Career Program Award Read More. ONR Young Investigator Award Read More. NSF CAREER AWARD. Read More. Note to Prospective Students: I am looking for students and post-docs interested in working in theoritical and practical aspects of AI/ML. Information for prospective students can be found here. Update: I am currently on leave in AY24-25 and will not take new students. For oppurtunities regarding RELAI, please visit Career Page . For more info, see my profiles in Google Scholar, DBLP, LinkedIn and Twitter. Read More NEWS: Launched RELAI 2024 Founded RELAI, a startup whose goal is to make AI reliability accessible and achievable for all. [Read more]. Testified in US Congress 2024 I restified before the U.S. House's Bipartisan Task Force on AI. [Read more]. Four NeurIPS Papers 2024 Four papers accepted in NeurIPS'24 [Read more] two icml two EMNLP Early Career Award 2023 I received ARO's Early Career Program Award to study robust dynamic AI systems . [Read more]. Talk at Google's GenAI Workshop 2023 I gave a talk on (un)reliability of AI-text detectors at Google's GenAI workshop [Read more] AI4All Summer Camp 2023 We hosted a two-week long AI4All camp for high school students at UMD. [Read more] NSF AI Institute 2023 Our NSF AI Institute on Trustworthy AI in Law & Society (TRAILS) got funded. [Read more]. Amazon Award 2023 I received an Amazon Research Award on understanding spurious correlations in deep learning. [Read more] Three ICML Papers 2023 Three papers on poisoning robustness and interpretability accepted in ICML'23 [Read more] Young Investigator Award 2022 I received ONR's Young Investigator Award on studying foundations of robust learning [Read more]. Five NeurIPS Papers 2022 Five papers on adv/distributional robustness, poisoning and Hard ImageNet accepted in NeurIPS'22 [Read more] ICLR Area Chair 2022 I'll serve as an area chair for ICLR'23. [Read more] ML Rising Stars 2022 Our ML Rising Stars program is now accepting applications [Read more]. Two ICML Papers 2022 Two works (FOCUS, Improved poisoning Robustness) accepted in ICML'22 [Read more] ICML Workshop Panelist 2022 I was a panelist in the Shift Happens workshop in ICML'22 [Read more] Plenary Talk 2022 I gave a plenary talk on generative models in the FinDer summer school [Read more] Three ICLR Papers 2022 Three works (Salient Imagenet, Policy Smoothing, Improved L2 Robustness) accepted in ICLR'22 [Read more] Two CVPR Papers 2021 Two works (RIVAL10 dataset and analysis, Patch defense for object detection) accepted in CVPR'22 [Read more] Simons Talk 2022 I gave a talk on studying failure modes of deep learning at Simons/UC Berkeley [Watch here]. CISS Talks 2022 I give two talks on RL robustness and distributional robustness at CISS (Princeton) [Read more] AISTATS Paper 2021 Our work on provable robustness against fractional threat models accepted in AISTATS'22 [Read more] ICML Area Chair 2022 I will serve as an area chair for ICML 2022 [Read more]. UCSD Talk 2021 I give a talk at UCSD's HDSI on studying failure models of deep learning. [Read more] USC Talk 2021 I give a talk at USC's ML Symposium on studying failure models of deep learning. UMD Talk 2021 I give a deptartment colloquium talk at UMD on studying failure models of deep learning. [Read more] NeurIPS paper 2021 Our work on a new training procedure for DL interpretability has been accepted in NeurIPS. [Read more] COLT Area Chair 2021 I'll serve as a COLT 2022 area chair. [Read more] NIST Panel Organizer 2021 Organizer and moderator at NIST AI Measurement and Evaluation Workshop. [Read more] Two ICML papers 2021 Two ICML papers including a long talk (among top 3% of submissions). [Read more] AISTATS Paper 2021 Our Subadditive GANs work is in AISTATS'21 (oral presentation, among top 3% of submissions)) [Read more] NeurIPS Area Chair 2021 I serve as a NeurIPS 2021 area chair [Read more] ICLR Area Chair 2021 I serve as an ICLR 2022 area chair. [Read more] AAAI Area Chair 2021 I serve as an AAAI 2022 area chair. [Read more] MIT/Harvard Talk 2021 I gave a talk on distributional robustness at a joint MIT/Harvard seminar. UW/UT Austin Talk 2021 I gave a talk on generalizable adversarial robustness at a joint UW/UT Austin seminar. EPFL Talk 2021 I gave a talk on foundations of robust learning at EPFL. NSF CAREER AWARD 2020 Received CAREER award on foundations of deep generative models. [Read more] Five ICLR papers 2021 Five ICLR papers on adversarial robustness, GANs and influence functions. [Read more] AAAI 2021 Paper Our work on Lottery Tickets in Generative Models has been accepted in AAAI'21 [Read more] FAccT 2021 Paper 2020 Our work on Adversarial Fairness has been accepted in FAccT'21 [Read more] Five NeurIPS papers 2020 Five NeurIPS papers on robustness, GANs and interpretability. [Read more] NeurIPS 2020 Workshop 2020 I am an organizer of a NeurIPS deep inverse workshop. [Read more] NIST AWARD 2020 Received an award from National Institute of Standards and Technology supporting our research on robustness. Best Paper Award 2020 from MIT-IBM Watson AI Lab at KDD's Adv ML workshop for our provable poisoning defense. [Read more] COLT 2021 Area Chair 2020 I am an area chair for COLT 2021 [Read more] ICLR 2021 Area Chair 2020 I am an area chair for ICLR 2021 [Read more] Talk at Princeton's IAS 2020 On Generalizable Adversarial Robustness to Unforeseen Attacks. [Talk Video] Talk at Simons 2020 Reunion of deep learning foundations workshop. [Read more] Talk at Capital One 2020 I gave a talk on Unsupervised Anomaly Detection at Capital One Modeling and Analytics Conference. Three ICML Papers 2020 On curvature-based robustness certificates, smoothing-based robustness certificates, and influence functions. [Read more] AWS ML Research Award 2020 For âExplainable Deep Learning: Accuracy, Robustness and Fairnessâ. [Read more] Area Chair at NeurIPS 2020 2020 I am serving as an area chair in NeurIPS 2020. [Read more] UMD Research Excellence 2020 I was an honeree at 2020 Maryland Research Excellence Celebration. [Read more] Deep Generative Model at ITA 2020 I organized a session on deep generative models at ITA 2020. [Read more] Talk at NIST 2020 I gave a talk on certifiably robust method against adversarial examples at NIST. Talk at NeurIPS Dec, 2019 Gave a talk in the ML with Guarantees workshop at NeurIPS [Watch the Video] Two AISTATS Papers Dec, 2019 Two AISTATS papers on non-LP adv. robustness and flow-based generative models. [Read more] Three NeurIPS papers Three NeurIPS papers on GANs, interpretability and adversarial examples. [Read more] Robustness Talk Oct, 2019 I gave a talk on certifiably robust method against adversarial examples [Read more] Paper on arXiv! Oct, 2019 Our work on Wasserstein Smoothing [paper] is available on arXiv. Teaching Award I received the teaching award at UMD for my Fall 2018 and Spring 2019 courses. [Read more] ICCV Paper Jul, 2019 Our work on Normalized Wasserstein [paper] has been accepted to ICCV 2019. Deep Learning Workshop Sept, 2019 I am attending a theory of deep learning workshop at IST, Austria. ICML Paper APR, 2019 Our work on deep learning interpretation [paper] has been accepted to ICML 2019. ICML Paper APR, 2019 Our work on Entropic GANs meet VAEs [paper] has been accepted to ICML 2019. Best Paper Award APR, 2019 Our work on Multivariate Maximal Correlation [paper] has received TNSE's best paper award. Awarded Simons-Berkeley Fellowship I have received the Simons-Berkeley Research Fellowship on Deep Learning Foundations. Department Colloquium 8 FEB, 2019 I gave a talk on deep learning foundations. Read More New Paper on arXiv 4 FEB, 2019 Our work on Normalized Wasserstein Distance [paper] is available on arXiv. New Paper on arXiv 4 FEB, 2019 Our work on Deep Learning Interpretation [paper] is available on arXiv. New Paper on arXiv 4 FEB, 2019 Our w",
  "content_length": 11959,
  "method": "requests",
  "crawl_time": "2025-12-01 14:29:12"
}