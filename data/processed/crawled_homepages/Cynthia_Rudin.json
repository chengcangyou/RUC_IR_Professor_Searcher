{
  "name": "Cynthia Rudin",
  "homepage": "https://users.cs.duke.edu/~cynthia/home.html",
  "status": "success",
  "content": "Cynthia Rudin Cynthia Rudin Home Interpretable  ML Lab Papers Code Teaching Announcements  Media, Talks CV Personal Cynthia Rudin Cynthia Rudin Gilbert, Louis, and Edward Lehrman Distinguished Professor of Computer Science Departments of Computer Science, Electrical and Computer Engineering, Statistical Science, Mathematics, and Biostatistics & Bioinformatics PI, Interpretable Machine Learning Lab Duke University Office: LSRC D207 Research Drive Durham NC, 27708 USA Research: My research focuses on interpretable machine learning and its applications; that is, designing machine learning models whose reasoning processes people can understand. This includes algorithms for extremely sparse models, interpretable neural networks, interpretable matching methods for causal inference, and dimension reduction for data visualization. My lab applies these techniques to critical societal problems in healthcare, criminal justice, materials science, computer vision, and in other domains. Here are some of my major projects: My collaborators and I develop practical code for sparse models, such as decision lists, decision trees, and additive models that provably optimize accuracy and sparsity (e.g., see our NeurIPS 2022 oral, KDD 2017 oral, NeurIPS 2019 spotlight, ICML 2020, AAAI 2022 papers). We presented a new paradigm for machine learning called the Rashomon Set paradigm, where ML algorithms return many good models and the user can choose among them. This allows humans to interact with machine learning algorithms and troubleshoot machine learning models much more easily. I discussed this in my ICML 2024 spotlight “Amazing Things Come From Having Many Good Models.” My collaborators and I have been developing theory for why simpler models often perform well. Our hypothesis is that noise in the data leads to the existence of simpler models, and we prove this in special cases. This is important, because it allows us to know something about the simplicity of models before even seeing the data. My lab's PaCMAP algorithm for dimension reduction for data visualization is used by many scientists, particularly in bioinformatics, biology, and ecology. It has won two software awards from the American Statistical Association. My team's work on optimal scoring systems (sparse linear models with integer coefficients) has been applied to many important healthcare and criminal justice applications. Our work on seizure prediction in ICU patients won the 2019 INFORMS Innovative Applications in Analytics Award. It helps to prevent severe brain damage in critically ill patients. It is the only AI model currently widely used in critical care brain monitoring. I led a team in the first major effort to maintain an underground electrical distribution network using machine learning, in joint work with Con Edison in NYC. This won the 2013 INFORMS Innovative Applications in Analytics Award. My collaborators and I developed code for detecting crime series in cities. This methodology (specifically, the Series Finder algorithm) was developed in Cambridge MA and adapted by the NYPD and their application (Patternizr) has been running live in NYC since 2016 for determining whether each new crime is related to past crimes. I solved a well-known previously-unsolved theoretical problem in machine learning as a PhD student, which is whether AdaBoost maximizes the margin like SVM. (The answer is that sometimes it provably does and sometimes it provably doesn't.) Subsequent work solved a published COLT open problem, earning a prize. I have given invited and keynote talks at INFORMS, KDD (2014 and 2019), SDM, AISTATS, ECML-PKDD, Machine Learning in Healthcare, FAT-ML (Fairness, Accountability, and Transparency), the Nobel Conference, SPIE, the Conference on Statistical Practice, and at several other venues. I enjoy competing in data science competitions and coaching students of teams. My teams have won awards in several competitions, including the ASA Data Challenge Expo in 2022, FICO Recognition Award for the Explainable Machine Learning Competition in 2018, NTIRE Superresolution competition in 2018, and PoeTix Literary Turing Competition in 2018. I am one of three co-PIs of the Almost-Matching-Exactly Lab, which develops matching methods for use in interpretable causal inference. Major Awards: IJCAI-25 John McCarthy Award, 2025. Award given to a mid-career AI scientist, given by the International Joint Conferences on Artificial Intelligence Organization. Squirrel AI Award for Artificial Intelligence for the Benefit of Humanity, Association for the Advancement of Artificial Intelligence (AAAI), 2022. An extremely prestigious award in the field of artificial intelligence. Like the Nobel prize and Turing award, it carried a $1M prize. INFORMS Society on Data Mining Prize, 2024. This award is the highest accomplishment the society can bestow upon a member. It recognizes a senior researcher for outstanding contributions to the field of data mining over the course of their career. Guggenheim Fellowship, 2022. Best OM Paper in OR Award, INFORMS, 2021. For best operations management paper published in Operations Research. FICO Recognition Award for the Explainable Machine Learning Challenge, 2018 INFORMS Innovative Applications in Analytics Award, 2019 Daniel H. Wagner Prize Finalist, 2017 INFORMS Innovative Applications in Analytics Award, 2016 INFORMS Innovative Applications in Analytics Award, 2013 (link to one of my presentations) Many other best paper awards are listed with their associated papers here and additional awards are listed here. Long Bio: Cynthia Rudin is the Gilbert, Louis, and Edward Lehrman Distinguished Professor of Computer Science at Duke University. She is a member of the Departments of Computer Science, Electrical and Computer Engineering, Statistical Science, Mathematics, and Biostatistics & Bioinformatics at Duke, and directs the Interpretable Machine Learning Lab. Previously, Prof. Rudin held positions at MIT, Columbia, and NYU. She holds an undergraduate degree from the University at Buffalo, and a PhD from Princeton University. She is the recipient of the 2022 Squirrel AI Award for Artificial Intelligence for the Benefit of Humanity from the Association for the Advancement of Artificial Intelligence (AAAI). This is an extremely prestigious award in the field of artificial intelligence. Similar only to world-renowned recognitions, such as the Nobel Prize and the Turing Award, it carried a monetary reward at the million-dollar level. Prof. Rudin is the winner of the 2024 INFORMS Society on Data Mining Prize, and a three-time winner of the INFORMS Innovative Applications in Analytics Award. She was named as one of the “Top 40 Under 40” by Poets and Quants in 2015, and was named by Businessinsider.com as one of the 12 most impressive professors at MIT in 2015. She is a 2022 Guggenheim fellow, as well as a fellow of the American Statistical Association, the Institute of Mathematical Statistics, and AAAI. Prof. Rudin is past chair of both the INFORMS Data Mining Section and the Statistical Learning and Data Science Section of the American Statistical Association. She has also served on committees for DARPA, the National Institute of Justice, AAAI, and ACM SIGKDD. She has served on three committees for the National Academies of Sciences, Engineering and Medicine, including the Committee on Applied and Theoretical Statistics, the Committee on Law and Justice, and the Committee on Analytic Research Foundations for the Next-Generation Electric Grid. She has given keynote/invited talks at several conferences including KDD (twice), AISTATS, INFORMS, Machine Learning in Healthcare (MLHC), Fairness, Accountability and Transparency in Machine Learning (FAT-ML), ECML-PKDD, and the Nobel Conference. Her work has been featured in news outlets including the NY Times, Washington Post, Wall Street Journal, and Boston Globe. Short Bio: Cynthia Rudin is the Gilbert, Louis, and Edward Lehrman Distinguished Professor of Computer Science at Duke University. She directs the Interpretable Machine Learning Lab, and her goal is to design predictive models that people can understand. Her lab applies machine learning in many areas, such as healthcare, criminal justice, and energy reliability. She holds degrees from the University at Buffalo and Princeton. She is the recipient of the 2022 Squirrel AI Award for Artificial Intelligence for the Benefit of Humanity from the Association for the Advancement of Artificial Intelligence (the “Nobel Prize of AI”), as well as the INFORMS Society of Data Mining Prize in 2024. She received a 2022 Guggenheim fellowship, and is a fellow of the American Statistical Association, the Institute of Mathematical Statistics, and the Association for the Advancement of Artificial Intelligence. Page generated 2025-11-06, by jemdoc+MathJax.",
  "content_length": 8870,
  "method": "requests",
  "crawl_time": "2025-12-01 12:55:46"
}