{
  "name": "Julian Togelius",
  "homepage": "http://engineering.nyu.edu/people/julian-togelius",
  "status": "success",
  "content": "Julian Togelius | NYU Tandon School of Engineering Skip to Main Content Search NYU Tandon Fulltext search Looking for News or Events? Julian Togelius Associate Professor Computer Science and Engineering Connect Email julian.togelius [at] nyu.edu Phone 917-285-3152 Website http://julian.togelius.com I work on artificial intelligence and games. I research and develop methods for making games more fun, easier to design and develop, more adaptive, or just to enable games and interactive experiences that we cannot yet create. I'm interested in all kinds of games that people actually play: video games, board games, card games or mind games. When it comes to AI techniques I'm flexible and willing to engage with all kinds of methods, but my methodological roots are in evolutionary computation and neural networks. Read more about my work with AI and gaming. Watch Office Hours with Julian Togelius: AI and the Future of Gaming Research Interests AI, player modelling, procedural content generation, automatic game design, believable bot behaviour, coevolution, neuroevolution, cybersecurity, emerging media, genetic programming and monte carlo tree search Education University of Essex 2007 Doctor of Philosophy, Computer Science University of Sussex 2003 Master of Science, Evolutionary and Adaptive Systems Lund University 2002 Bachelor of Arts, Philosophy Research News View More AI produces Connections puzzles that rival human-created ones Can artificial intelligence (AI) create word puzzles as engaging and challenging as those crafted by human experts? A new study suggests the answer may be yes — at least when it comes to The New York Times' popular Connections game. Researchers from NYU Tandon School of Engineering and Jester Labs have developed an AI system capable of generating novel Connections puzzles that often rival those created by Times puzzle designers. In a user study, participants played both AI-generated and official Times puzzles without knowing their source. In roughly half of head-to-head comparisons, players judged the AI puzzles to be equally or more enjoyable, creative, and difficult than their human-created counterparts. Their findings shed light on the creative capabilities of large language models like GPT-4. Connections, which debuted in June 2023, challenges players to sort 16 words into four thematically linked groups of four. The game quickly became one of the Times' most popular online offerings, second only to Wordle, with billions of plays per year. To create AI-generated puzzles, the researchers employed an \"agentic workflow\" approach. This method involves using GPT-4 in multiple specialized roles throughout the puzzle creation process. Rather than asking the AI to generate an entire puzzle at once, researchers broke down the task into smaller, more focused steps. For each step, they prompted GPT-4 with specific instructions, effectively having it play different roles such as puzzle creator, editor, and difficulty assessor. This approach allowed the team to leverage the AI's capabilities more effectively by guiding it through a process that mimics how human designers might approach puzzle creation. \"We found that solving a complex problem like generating a Connections puzzle requires more than just asking an AI to do it,\" said Timothy Merino, a Ph.D. student in NYU Tandon’s Game Innovation Lab who is the lead author of the study. \"By breaking the task into smaller, more manageable steps and using the LLM as a tool in various ways, we achieved better results.\" The paper’s senior author, Julian Togelius — NYU Tandon associate professor of computer science and engineering, and the Director of the Game Innovation Lab — emphasized the importance of this approach. \"The LLM is crucial to our system, but it's not in the driving seat. We use it in different parts of the system for specific tasks, like asking for the best concept that would apply to a particular list of words.\" The researchers also identified two key ways puzzles introduce difficulty: \"Intentional overlap\" and \"False groups.\" They analyzed word similarity in relation to difficulty levels, finding that easier word groups tend to have more similar words, while trickier groups have less similar words. “I was consistently surprised at how good GPT was at creating a clever word group,” said Merino. “One of my favorites the AI generated is ‘Beatles Album Words’: ‘Abbey’, ‘Mystery,’ \"Pepper,’ and ‘White.’” The research has implications beyond word games, according to the researchers. It is a step toward better understanding both AI capabilities and human creativity. \"This work isn't just about generating puzzles,\" Togelius said. \"It's about using AI to test and refine our theories of what makes a good puzzle in the first place. Connections is a worthy area of research because what makes a good game isn’t easy to define. We can refine our understanding of game design by creating theories of what makes for good games, implement them into algorithms, and see whether the games that are generated by the algorithms are actually good.\" This recent paper builds upon the Game Innovation Lab's ongoing research into AI and Connections. In a study published earlier this year, the lab's researchers evaluated various AI models' proficiency in solving Connections puzzles. Their findings revealed that while GPT-4 outperformed other models, it still fell short of mastering the game, successfully solving only about 29 percent of the puzzles presented. Merino, Tim & Earle, Sam & Sudhakaran, Ryan & Sudhakaran, Shyam & Togelius, Julian. (2024). Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game. READ THE ARTICLE August 8, 2024 NYU Tandon School of Engineering researchers test AI systems’ ability to solve The New York Times’ Connections puzzle Can artificial intelligence (AI) match human skills for finding obscure connections between words? Researchers at NYU Tandon School of Engineering turned to the daily Connections puzzle from The New York Times to find out. Connections gives players five attempts to group 16 words into four thematically linked sets of four, progressing from “simple” groups generally connected through straightforward definitions to “tricky” ones reflecting abstract word associations requiring unconventional thinking. In a study that will be presented at the IEEE 2024 Conference on Games – taking place in Milan, Italy from August 5 - 8 – the researchers investigated whether modern natural language processing (NLP) systems could solve these language-based puzzles. With Julian Togelius, NYU Tandon Associate Professor of Computer Science and Engineering (CSE) and Director of the Game Innovation Lab, as the study’s senior author, the team explored two AI approaches. The first leveraged GPT-3.5 and recently-released GPT-4, powerful large language models (LLMs) from OpenAI, capable of understanding and generating human-like language. The second approach used sentence embedding models, namely BERT, RoBERTa, MPNet, and MiniLM, which encode semantic information as vector representations but lack the full language understanding and generation capabilities of LLMs. The results showed that while all the AI systems could solve some of the Connections puzzles, the task remained challenging overall. GPT-4 solved about 29% of puzzles, significantly better than the embedding methods and GPT-3.5, but far from mastering the game. Notably, the models mirrored human performance in finding the difficulty levels aligned with the puzzle's categorization from \"simple\" to \"tricky.\" \"LLMs are becoming increasingly widespread, and investigating where they fail in the context of the Connections puzzle can reveal limitations in how they process semantic information,” said Graham Todd, PhD student in the Game Innovation Lab who is the study’s lead author. The researchers found that explicitly prompting GPT-4 to reason through the puzzles step-by-step significantly boosted its performance to just over 39% of puzzles solved. “Our research confirms prior work showing this sort of ‘chain-of-thought’ prompting can make language models think in more structured ways,” said Timothy Merino, PhD student in the Game Innovation Lab who is an author on the study. “Asking the language models to reason about the tasks that they're accomplishing helps them perform better.” Beyond benchmarking AI capabilities, the researchers are exploring whether models like GPT-4 could assist humans in generating novel word puzzles from scratch. This creative task could push the boundaries of how machine learning systems represent concepts and make contextual inferences. The researchers conducted their experiments with a dataset of 250 puzzles from an online archive representing daily puzzles from June 12th, 2023 to February 16th, 2024. Along with Togelius, Todd and Merino, Sam Earle, a PhD student in the Game Innovation Lab, was also part of the research team. The study contributes to Togelius’ body of work that uses AI to improve games and vice versa. Togelius is the author of the 2019 book Playing Smart: On Games, Intelligence, and Artificial Intelligence. arXiv:2404.11730v2 [cs.CL] 21 Apr 2024 Read the full paper May 8, 2024 NYU Tandon researchers mitigate racial bias in facial recognition technology with demographically diverse synthetic image dataset for AI training Facial recognition technology has made great strides in accuracy thanks to advanced artificial intelligence (AI) models trained on massive datasets of face images. These datasets often lack diversity in terms of race, ethnicity, gender, and other demographic categories, however, causing facial recognition systems to perform worse on underrepresented demographic groups compared to groups ubiquitous in the training data. In other words, the systems are less likely to accurately match different images depicting the same person if that person belongs to a group that was insufficiently represented in ",
  "content_length": 14222,
  "method": "requests",
  "crawl_time": "2025-12-01 13:37:30"
}