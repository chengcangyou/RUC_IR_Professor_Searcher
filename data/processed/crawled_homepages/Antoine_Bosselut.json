{
  "name": "Antoine Bosselut",
  "homepage": "https://atcbosselut.github.io",
  "status": "success",
  "content": "Antoine Bosselut Search Antoine Bosselut Assistant Professor EPFL Biography I am an assistant professor in the School of Computer and Communication Sciences at EPFL. I lead the EPFL NLP group where we conduct research on natural language processing (NLP) systems that can model, represent, and reason about human and world knowledge. I am also on the steering committee of the Swiss AI Initiative and a co-lead of the Apertus project to design large-scale, trustworthy LLMs. Previously, I was a postdoctoral researcher at Stanford University in the SNAP and NLP groups working with Jure Leskovec and Chris Manning. I completed a PhD in CS at the University of Washington, where I worked with Yejin Choi, and a BEng in EE at McGill University. I will be taking on new PhD students this year (and next year). For these and other inquiries about joining EPFL NLP, please read the Join Us page. What’s New? Sep 2025 Apertus released! Sep 2025 I’ve been awarded an ERC Starting Grant Sep 2025 4 papers accepted to EMNLP + 2 to Findings Sep 2025 3 papers accepted to NeurIPS Sep 2025 1 paper accepted to ICCV Jul 2025 2 papers accepted to COLM Jun 2025 Keynote at Advances in Data Science and AI Conference May 2025 Outstanding Paper Award at NAACL 2025 Apr 2025 Keynote at the NTU IAS Frontiers Conference on AI Feb 2025 1 paper accepted to CVPR Jan 2025 4 papers accepted to NAACL Jan 2025 INCLUDE is accepted to ICLR (spotlight) Jan 2025 We won a Meta LLM Evaluation Research Grant! Nov 2024 Named ELLIS Scholar Jul 2024 Talk at ICML Large Language Models and Cognition Workshop Jan 2024 Talk at AI House in Davos about the Swiss AI Initiative Dec 2023 The Swiss AI Initiative is launched! Dec 2023 Talk at EMNLP BlackboxNLP Workshop 2023 Nov 2023 Neuro-Symbolic AI Panel at ISWC 2023 Oct 2023 Talk at Johns Hopkins University Oct 2023 Talk at University of Maryland Jul 2023 Outstanding Paper Award at ACL 2023 Jan 2023 Panel at Infrarouge Jan 2023 Talk at IBM Neuro-symbolic AI Workshop Mar 2022 Talk at EPFL Center for Intelligent Systems Jan 2022 Talk at IBM Research Dec 2021 Panel at World Congress of Science & Factual Producers Nov 2021 Talk at ETH Zurich Nov 2021 Talk at CIKM Workshop: Knowledge Injection in Neural Networks (KINN) Nov 2021 Talk at KR Workshop: Knowledge Representation for Hybrid and Compositional AI (KRHCAI) Sep 2021 Talk at Stanford Graph Learning Workshop Aug 2021 Talk at IJCAI Workshop: Is Neuro-symbolic SOTA still a myth for NLI? (NSNLI) Apr 2021 Named to the Forbes 30 under 30 list in Science & Healthcare Mar 2021 Talk at Microsoft Research Feb 2021 Talk at AAAI Workshop in Hybrid Artificial Intelligence Feb 2021 Tutorial on Commonsense Knowledge Acquisition and Representation at AAAI 2021 Nov 2020 Tutorial on Neural Language Generation at EMNLP 2020 Nov 2020 Talk at UCSD Health Informatics Seminar Nov 2020 Talk at Stanford Cognitive Science Seminar Jul 2020 Tutorial on Commonsense Knowledge at ACL 2020 Sep 2019 Talk at WeCNLP 2019 Research Interests Reasoning agents are the next frontier of AI. My research investigates how we can develop AI reasoning agents for the benefit of society, focusing both on designing novel AI reasoning methodologies, and adapting them for applications such as health, education, and global fairness. My group’s research draws on methods in natural language processing, deep learning, machine learning, and artificial intelligence to investigate these problems. Topics that I focus on include: LLM Representations of Knowledge. Figuring out how to go from an LLM to a reasoning agent requires understanding what LLMs know, how they represent that knowledge, and how they compose that information internally. My research investigates how LLM subnetworks (and other LLM representations) encode discrete forms of knowledge, how those representations can be modified, and how closely they align with measurements of the human brain [1,2,3,4,5,6] Reasoning Algorithms. LLMs fail dramatically and unexpectedly when presented with seemingly simple reasoning problems that humans effortlessly solve. We draw on methods from diverse research areas (e.g., symbolic systems, neuroscience, cognitive science, psychology) to devise new methods and frameworks for LLM reasoning. [1,2,3,4,5,6,7] Large-scale AI Development. LLMs behave differently at small scale compared to large scale. Our work bridges the research gap between these two settings by developing open-source, open-weight, and open-data foundation models. We specifically focus on developing multilingual models trained on compliant data to enable use in diverse regulatory and cultural settings [1,2,3,4] AI Democratization. Much like previous generations of AI advancement, AI reasoners will be experienced differently by different groups based on their current digital and AI maturity. Across practice areas in health, education, and global fairness, my works works with end users to develop models, theories, and evaluations that enable responsible development of LLM-based AI. [1,2,3,4] EPFL NLP Group Check out our lab website for more details! Postdoctoral Scholars Syrielle Montariol Gail Weiss Anna Sotnikova PhD Students Badr AlKhamissi Deniz Bayazit Beatriz Borges Zeming (Eric) Chen Silin Gao Yifan Hou Mete Ismayilzada Sepideh Mamooler Li Mi Madhur Panwar Auguste Poiroux Angelika Romanou Ayush Tarun Visiting PhDs Masters Theses Interns Alumni PhD Students Negar Foroutan Shaobo Cui Postdoctoral Scholars Debjit Paul Visiting PhDs Tianqing Fang Alberto Muñoz-Ortiz Mike Zhang Interns Khai Loong Aw Rishika Bhagwatkar Antara Bhattacharya Antoine Bonnet Alejandro Hernández Cano Nicolo De Sabbata Spyridon Chalkias Anna Dai Yu Fei Karina Halevy Grace Kim Sheryl Mathew Francesco Salvi Jakhongir Saydaliev Paul Teiletche Fawzia Zeitoun Masters Theses Michal Bien Roberto Ceraolo Wenkai Chen Ghali Chraibi Nicolo De Sabbata Yiyang Feng Maria Grandury Elif Kurtay Axel Marmet Giovanni Monea Julian Schnitzler Alexandre Variengien Publications Please see my Google Scholar for an up-to-date list of publications. Highlighted Recent Works APERTUS: Democratizing Open and Compliant LLMs for Global Language Environments Alejandro Hernández-Cano, Alexander Hägele, Allen Hao Huang, Angelika Romanou, Antoni-Joan Solergibert, Barna Pasztor, Bettina Messmer, Dhia Garbaya, Eduard Frank Ďurech, Ido Hakimi, Juan García Giraldo, Mete Ismayilzada, Negar Foroutan, Skander Moalla, Tiancheng Chen, Vinko Sabolčec, Yixuan Xu, Michael Aerni, Badr AlKhamissi, Ines Altemir Marinas, Mohammad Hossein Amani, Matin Ansaripour, Ilia Badanin, Harold Benoit, Emanuela Boros, Nicholas Browning, Fabian Bösch, Maximilian Böther, Niklas Canova, Camille Challier, Clement Charmillot, Jonathan Coles, Jan Deriu, Arnout Devos, Lukas Drescher, Daniil Dzenhaliou, Maud Ehrmann, Dongyang Fan, Simin Fan, Silin Gao, Miguel Gila, María Grandury, Diba Hashemi, Alexander Hoyle, Jiaming Jiang, Mark Klein, Andrei Kucharavy, Anastasiia Kucherenko, Frederike Lübeck, Roman Machacek, Theofilos Manitaras, Andreas Marfurt, Kyle Matoba, Simon Matrenok, Henrique Mendoncça, Fawzi Roberto Mohamed, Syrielle Montariol, Luca Mouchel, Sven Najem-Meyer, Jingwei Ni, Gennaro Oliva, Matteo Pagliardini, Elia Palme, Andrei Panferov, Léo Paoletti, Marco Passerini, Ivan Pavlov, Auguste Poiroux, Kaustubh Ponkshe, Nathan Ranchin, Javi Rando, Mathieu Sauser, Jakhongir Saydaliev, Muhammad Ali Sayfiddinov, Marian Schneider, Stefano Schuppli, Marco Scialanga, Andrei Semenov, Kumar Shridhar, Raghav Singhal, Anna Sotnikova, Alexander Sternfeld, Ayush Kumar Tarun, Paul Teiletche, Jannis Vamvas, Xiaozhe Yao, Hao Zhao Alexander Ilic, Ana Klimovic, Andreas Krause, Caglar Gulcehre, David Rosenthal, Elliott Ash, Florian Tramèr, Joost VandeVondele, Livio Veraldi, Martin Rajman, Thomas Schulthess, Torsten Hoefler, Antoine Bosselut†, Martin Jaggi†, Imanol Schlag† arXiv Featured in: Financial Times, RTS, SRF 1, RSI LA 1, Le Temps, 24 Heures, NZZ, The Verge, Engadget, TeleTicino, Blick, SwissInfo, ICT Journal INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge Angelika Romanou, Negar Foroutan*, Anna Sotnikova*, Sree Harsha Nelaturu, Shivalika Singh, Rishabh Maheshwary, Micol Altomare, Zeming Chen, Snegha A, Alfonso Amayuelas, Azril Hafizi Amirudin, Danylo Boiko, Michael Chang, Jenny Chim, Gal Cohen, Aditya Kumar Dalmia, Abraham Diress, Sharad Duwal, Daniil Dzenhaliou, Daniel Fernando Erazo Florez, Fabian Farestam, Mohamed A. Haggag, Joseph Marvin Imperial, Shayekh Bin Islam, Perttu Isotalo, Maral Jabbarishiviari, Börje F. Karlsson, Eldar Khalilov, Christopher Klamm, Fajri Koto, Dominik Krzeminski, Gabriel Adriano de Melo, Syrielle Montariol, Yiyang Nan, Joel Niklaus, Jekaterina Novikova, Johan Samir Obando Ceron, Debjit Paul, Esther Ploeger, Jebish Purbey, Swati Rajwal, Selvan Sunitha Ravi, Sara Rydell, Roshan Santhosh, Drishti Sharma, Marjana Prifti Skenduli, Arshia Soltani Moakhar, Bardia soltani moakhar, Ayush Kumar Tarun, Azmine Toushik Wasi, Thenuka Ovin Weerasinghe, Serhan Yilmaz, Mike Zhang, Imanol Schlag, Marzieh Fadaee, Sara Hooker, Antoine Bosselut ICLR 2025 Spotlight Paper, Top 5% of papers A Logical Fallacy-Informed Framework for Argument Generation Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings NAACL 2025 Outstanding Paper Award, Top 10 papers Could ChatGPT get an Engineering Degree? Evaluating Higher Education Vulnerability to AI Assistants Beatriz Borges*, Negar Foroutan*, Deniz Bayazit*, Anna Sotnikova*, Syrielle Montariol, Tanya Nazaretzky, Mohammadreza Banaei, Alireza Sakhaeirad, Philippe Servant, Seyed Parsa Neshaei, Jibril Frej, Angelika Romanou, Gail Weiss, Sepideh Mamooler, Zeming Chen, Simin Fan, Silin Gao, Mete Ismayilzada, Debjit Paul, Philippe Schwaller, Sacha Friedli, Patrick Jermann, Tanja Kaser, Antoine Bosselut, EPFL Grader Consortium, EPFL Data Consortium Proceedings of the National Academy of Sciences (PNAS) Featured in: Le Temps, 20 Minutes, Radio Fréquence Jura, Radio France MEDITR",
  "content_length": 33304,
  "method": "requests",
  "crawl_time": "2025-12-01 12:59:36"
}