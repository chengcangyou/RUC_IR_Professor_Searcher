{
  "name": "Lu Lin 0001",
  "homepage": "https://louise-lulin.github.io",
  "status": "success",
  "content": "Lu Lin Bio: Hi, I am an Assistant Professor in the College of Information Sciences and Technology at Penn State University; I am also affiliated with the Institute for Computational and Data Sciences and the Center for Socially Responsible AI. Prior to that, I received my Ph.D. from University of Virginia supervised by Dr. Hongning Wang in Computer Science. I have also interned at Didi Lab, LinkedIn and Pinterest Lab. Curriculum Vitae. Research Interests: My research contributes to accountable machine learning, particularly through methods for improving robustness and transparency under data imperfections and deployment mismatches. I’m particularly facinated by transformative ML paradigms, including large language models (LLMs), multimodal models, federated learning, self-supervised learning, graph neural networks and more. By understanding and hardening their working mechanism, my research vision is to establish algorithmic foundations for AI-enabled systems to work reliably in practical environment concerning biased, noisy, and out-of-distribution inputs. Openings for 2024-2025: I’m looking for highly motivated students, including PhDs (fully-funded), Masters, undergraduates, and interns. Please kindly read Open Position for more information before contacting me. News Sep 28, 2024 One paper is accepted to NeurIPS 2024! May 15, 2024 Two papers are accepted to ACL 2024! May 01, 2024 One paper is accepted to ICML 2024! Jan 16, 2024 Two papers are accepted to WWW 2024! Jan 01, 2024 One paper is accepted to ICLR 2024! Sep 01, 2023 One paper is accepted to NeurIPS 2023! Apr 24, 2023 Two papers are accepted to ICML 2023! Jan 01, 2023 One paper is accepted to ICLR 2023! Sep 01, 2022 I am officially on board as a tenure-track faculty at IST@PSU! May 01, 2022 I am honored to receive CS John A. Stankovic Graduate Research Award from UVa. Selected Publications ACL JoPA: Explaining Large Language Model’s Generation via Joint Prompt Attribution Yurui Chang*, Bochuan Cao* , Yujia Wang, Jinghui Chen, and Lu Lin In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics , 2025 Bib HTML Code @inproceedings{chang2025xprompt, title = {JoPA: Explaining Large Language Model's Generation via Joint Prompt Attribution}, author = {Chang*, Yurui and Cao*, Bochuan and Wang, Yujia and Chen, Jinghui and Lin, Lu}, booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics}, year = {2025}, category = {conference}, } ACL Findings Monitoring Decoding: Mitigating Hallucination via Evaluating the Factuality of Partial Response during Generation Yurui Chang, Bochuan Cao, and Lu Lin In Findings of the 63rd Annual Meeting of the Association for Computational Linguistics , 2025 Bib HTML Code @inproceedings{chang2025monitoring, title = {Monitoring Decoding: Mitigating Hallucination via Evaluating the Factuality of Partial Response during Generation}, author = {Chang, Yurui and Cao, Bochuan and Lin, Lu}, booktitle = {Findings of the 63rd Annual Meeting of the Association for Computational Linguistics}, year = {2025}, category = {conference}, } ICML AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models Yaopei Zeng, Yuanpu Cao, Bochuan Cao, Yurui Chang, Jinghui Chen, and Lu Lin In Proceedings of the 42nd International Conference on Machine Learning , 2025 Bib HTML Code @inproceedings{zeng2025advi2i, title = {AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models}, author = {Zeng, Yaopei and Cao, Yuanpu and Cao, Bochuan and Chang, Yurui and Chen, Jinghui and Lin, Lu}, booktitle = {Proceedings of the 42nd International Conference on Machine Learning}, year = {2025}, category = {conference}, } KDD Boosting E-commerce Content Diversity: A Graph-based RAG Approach with User Reviews Jiaxi Yang, Yiling Jia , Carl Yang, Yi Liang, and Lu Lin In Proceedings of the 31st SIGKDD Conference on Knowledge Discovery and Data Mining , 2025 Bib HTML @inproceedings{yang2025boosting, title = {Boosting E-commerce Content Diversity: A Graph-based RAG Approach with User Reviews}, author = {Yang, Jiaxi and Jia, Yiling and Yang, Carl and Liang, Yi and Lin, Lu}, booktitle = {Proceedings of the 31st SIGKDD Conference on Knowledge Discovery and Data Mining}, year = {2025}, category = {conference}, } NeurIPS Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization Yuanpu Cao, Tianrong Zhang, Bochuan Cao, Ziyi Yin, Lu Lin, Fenglong Ma, and Jinghui Chen In Proceedings of the 38th Annual Conference on Neural Information Processing Systems , 2024 Bib HTML Code @inproceedings{cao2024personalized, title = {Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization}, author = {Cao, Yuanpu and Zhang, Tianrong and Cao, Bochuan and Yin, Ziyi and Lin, Lu and Ma, Fenglong and Chen, Jinghui}, booktitle = {Proceedings of the 38th Annual Conference on Neural Information Processing Systems}, year = {2024}, category = {conference}, } ACL Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM Bochuan Cao, Yuanpu Cao, Lu Lin, and Jinghui Chen In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , 2024 Bib HTML Code @inproceedings{cao2024defending, title = {Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM}, author = {Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui}, booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, year = {2024}, category = {conference}, } ICLR Backdoor Contrastive Learning via Bi-level Trigger Optimization Weiyu Sun, Xinyu Zhang, Hao Lu, Ying-Cong Chen , Ting Wang, Jinghui Chen, and Lu Lin In Proceedings of of the 12th International Conference on Learning Representations , 2024 Bib HTML Code @inproceedings{sun2024backdoor, title = {Backdoor Contrastive Learning via Bi-level Trigger Optimization}, author = {Sun, Weiyu and Zhang, Xinyu and Lu, Hao and Chen, Ying-Cong and Wang, Ting and Chen, Jinghui and Lin, Lu}, booktitle = {Proceedings of of the 12th International Conference on Learning Representations}, year = {2024}, category = {conference}, } WWW Globally Interpretable Graph Learning via Distribution Matching Yi Nian*, Yurui Chang*, Wei Jin, and Lu Lin In Proceedings of the Web Conference , 2024 Bib HTML @inproceedings{nian2024globally, title = {Globally Interpretable Graph Learning via Distribution Matching}, author = {Nian*, Yi and Chang*, Yurui and Jin, Wei and Lin, Lu}, booktitle = {Proceedings of the Web Conference}, year = {2024}, category = {conference}, } WWW Graph Contrastive Learning via Interventional View Generation Zengyi Wo, Minglai Shao , Wenjun Wang, Xuan Guo, and Lu Lin In Proceedings of the Web Conference , 2024 Bib HTML @inproceedings{wo2024graph, title = {Graph Contrastive Learning via Interventional View Generation}, author = {Wo, Zengyi and Shao, Minglai and Wang, Wenjun and Guo, Xuan and Lin, Lu}, booktitle = {Proceedings of the Web Conference}, year = {2024}, category = {conference}, } NeurIPS A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning Hangfan Zhang, Jinyuan Jia, Jinghui Chen, Lu Lin, and Dinghao Wu In Proceedings of the 37th Conference on Neural Information Processing Systems , 2023 Bib HTML Code @inproceedings{zhang2023a3fl, title = {A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning}, author = {Zhang, Hangfan and Jia, Jinyuan and Chen, Jinghui and Lin, Lu and Wu, Dinghao}, booktitle = {Proceedings of the 37th Conference on Neural Information Processing Systems}, year = {2023}, category = {conference}, } ICML FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning Songtao Liu, Zhengkai Tu, Minkai Xu, Zuobai Zhang, Lu Lin, Rex Ying, Jian Tang, Peilin Zhao, and Dinghao Wu In Proceedings of the 40th International Conference on Machine Learning , 2023 Abs Bib HTML Code Retrosynthetic planning aims to devise a complete multi-step synthetic route from starting materials to a target molecule. Current strategies use a decoupled approach of single-step retrosynthesis models and search algorithms, taking only the product as the input to predict the reactants for each planning step and ignoring valuable context information along the synthetic route. In this work, we propose a novel framework that utilizes context information for improved retrosynthetic planning. We view synthetic routes as reaction graphs and propose to incorporate context through three principled steps: encode molecules into embeddings, aggregate information over routes, and readout to predict reactants. Our approach is the first attempt to utilize in-context learning for retrosynthesis prediction in retrosynthetic planning. The entire framework can be efficiently optimized in an end-to-end fashion and produce more practical and accurate predictions. Comprehensive experiments demonstrate that by fusing in the context information over routes, our model significantly improves the performance of retrosynthetic planning over baselines that are not context-aware, especially for long synthetic routes. Code is available at Github. @inproceedings{liu2023fusionretro, title = {FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning}, author = {Liu, Songtao and Tu, Zhengkai and Xu, Minkai and Zhang, Zuobai and Lin, Lu and Ying, Rex and Tang, Jian and Zhao, Peilin and Wu, Dinghao}, booktitle = {Proceedings of the 40th International Conference on Machine Learning}, year = {2023}, category = {conference}, } ICML Graph Contrastive Backdoor Attacks Hangfan Zhang, Jinghui Chen, Lu Lin, Jinyuan Jia, and Dinghao Wu In Proceedings of the 40th International Conference on Machine Learning , 2023 Abs Bib HTML Graph Contrastive Learning (GCL) has attracted considerable interest due to its impr",
  "content_length": 16387,
  "method": "requests",
  "crawl_time": "2025-12-01 13:48:08"
}