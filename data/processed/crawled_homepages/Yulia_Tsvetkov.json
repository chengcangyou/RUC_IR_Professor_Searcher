{
  "name": "Yulia Tsvetkov",
  "homepage": "https://homes.cs.washington.edu/~yuliats",
  "status": "success",
  "content": "Yulia Tsvetkov I am an associate professor in the Paul G. Allen School of Computer Science & Engineering, at the University of Washington. I work on natural language processing, and I'm particularly interested in hybrid solutions at the intersection of machine learning and theoretical or social linguistics, i.e., solutions that combine interesting learning/modeling methods and insights about human languages or about people speaking these languages. Much of my research group's work focuses on understanding and advancing large language models, AI ethics, multilingual learning, and machine learning for NLP. This research is motivated by a unified goal: to extend the capabilities of human language technology beyond individual populations and across language and culture boundaries, thereby enabling NLP for all users. Here are my CV and Google Scholar page. Previously, I was an assistant professor in the Language Technologies Institute, School of Computer Science at Carnegie Mellon University (I'm currently an adjunct professor at LTI), and before that I was a postdoc in the Stanford NLP Group. I got my PhD from CMU. Publications ( this list is more likely to be updated) 2025 Biased AI can Influence Political Decision-Making. Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel W. Fisher, Jennifer Pan, Yulia Tsvetkov, and Katharina Reinecke. In Sub, 2025. PDF Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligence. Shangbin Feng, Zifeng Wang, Yike Wang, Sayna Ebrahimi, Hamid Palangi, Lesly Miculicich, Achin Kulshrestha, Nathalie Rauschmayr, Yejin Choi, Yulia Tsvetkov, Chen-Yu Lee, and Tomas Pfister. In Sub, 2025. PDF JPEG-LM: LLMs as Image Generators with Canonical Codec Representations. Xiaochuang Han, Marjan Ghazvininejad, Pang Wei Koh, and Yulia Tsvetkov. In Sub, 2025. PDF Explore Theory of Mind: Program-guided Adversarial Data Generation for Theory of Mind Reasoning. Melanie Sclar, Jane Yu, Maryam Fazel-Zarandi, Yulia Tsvetkov, Yonatan Bisk, Yejin Choi, and Asli Celikyilmaz. Proc. ICLR, 2025. PDF Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only. Jihan Yao, Wenxuan Ding, Shangbin Feng, Lucy Lu Wang, and Yulia Tsvetkov. Proc. ICLR, 2025. PDF ComPO: Community Preferences for Language Model Personalization. Sachin Kumar, Chan Young Park, Yulia Tsvetkov, Noah A. Smith, and Hannaneh Hajishirzi. Proc. NAACL, 2025. PDF Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs. Aly M. Kassem, Omar Mahmoud, Niloofar Mireshghallah, Hyunwoo Kim, Yulia Tsvetkov, Yejin Choi, Sherif Saad, and Santu Rana. Proc. NAACL, 2025. PDF Know Your Limits: A Survey of Abstention in Large Language Models. Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, and Lucy Lu Wang. TACL, 2025. PDF 2024 Learning Syntax Without Planting Trees: Understanding When and Why Transformers Generalize Hierarchically. Kabir Ahuja, Vidhisha Balachandran, Madhur Panwar, Tianxing He, Noah A. Smith, Navin Goyal, and Yulia Tsvetkov. TACL. PDF MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning. Shuyue Stella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang Wei Koh, and Yulia Tsvetkov. Proc. NeurIPS 2024. PDF MAGNET: Improving the Multilingual Fairness of Language Models with Adaptive Gradient-Based Tokenization. Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Valentin Hoffman, Tomasz Limisiewicz, Yulia Tsvetkov, and Noah A. Smith. Proc. NeurIPS 2024. PDF MatFormer: Nested Transformer for Elastic Inference. Fnu Devvrit, Sneha Kudugunta, Aditya Kusupati, Tim Dettmers, Kaifeng Chen, Inderjit S Dhillon, Yulia Tsvetkov, Hannaneh Hajishirzi, Sham M. Kakade, Ali Farhadi, and Prateek Jain. Proc. NeurIPS 2024. PDF The Art of Saying No: Contextual Noncompliance in Language Models. Faeze Brahman, Sachin Kumar, Vidhisha Balachandran, Pradeep Dasigi, Valentina Pyatkin, Abhilasha Ravichander, Sarah Wiegreffe, Nouha Dziri, Khyathi Chandu, Jack Hessel, Yulia Tsvetkov, Noah A. Smith, Yejin Choi, and Hannaneh Hajishirzi. Proc. NeurIPS 2024, Datasets and Benchmarks Track. PDF Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia. Farhan Samir, Chan Young Park, Anjalie Field, Vered Shwartz, and Yulia Tsvetkov. Proc. EMNLP 2024. PDF Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects. Orevaoghene Ahia, Anuoluwapo Aremu, Diana Abagyan, Hila Gonen, David Ifeoluwa Adelani, Daud Abolade, Noah A. Smith, and Yulia Tsvetkov. Proc. EMNLP 2024. PDF Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration. Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian Fisher, Chan Young Park, Yejin Choi, and Yulia Tsvetkov. Proc. EMNLP 2024. PDF Teaching LLMs to Abstain across Languages via Multilingual Feedback. Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Orevaoghene Ahia, Shuyue Stella Li, Vidhisha Balachandran, Sunayana Sitaram, and Yulia Tsvetkov. Proc. EMNLP 2024. PDF Can LLM Graph Reasoning Generalize beyond Pattern Memorization? Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, and Yulia Tsvetkov. Proc. EMNLP 2024, findings. PDF Can Machines Learn Morality? The Delphi Experiment. Liwei Jiang, Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jenny Liang, Jesse Dodge, Keisuke Sakaguchi, Maxwell Forbes, Jon Borchardt, Saadia Gabriel, Yulia Tsvetkov, Oren Etzioni, Maarten Sap, Regina Rini, and Yejin Choi. Nature Machine Intelligence. PDF Resolving Knowledge Conflicts in Large Language Models. Yike Wang, Shangbin Feng, Heng Wang, Weijia Shi, Vidhisha Balachandran, Tianxing He, and Yulia Tsvetkov. Proc. COLM 2024. PDF Tuning Language Models by Proxy. (Spotlight Paper) Alisa Liu, Xiaochuang Han, Yizhong Wang, Yulia Tsvetkov, Yejin Choi, and Noah A. Smith. Proc. COLM 2024. PDF Fine-grained Hallucination Detection and Editing for Language Models. Abhika Mishra, Akari Asai, Vidhisha Balachandran, Yizhong Wang, Graham Neubig, Yulia Tsvetkov, and Hannaneh Hajishirzi. Proc. COLM 2024. PDF Do Membership Inference Attacks Work on Large Language Models?. Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettlemoyer, Yulia Tsvetkov, Yejin Choi, David Evans, and Hannaneh Hajishirzi. Proc. COLM 2024. PDF DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and Closely-Related Languages. (Best Social Impact Paper Award) Fahim Faisal, Orevaoghene Ahia, Aarohi Srivastava, Kabir Ahuja, David Chiang, Yulia Tsvetkov, and Antonios Anastasopoulos. Proc. ACL 2024. PDF Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration. (Outstanding Paper Award & Area Chair Award, QA track) Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Vidhisha Balachandran, and Yulia Tsvetkov. Proc. ACL 2024. PDF What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection. Shangbin Feng, Herun Wan, Ningnan Wang, Zhaoxuan Tan, Minnan Luo, and Yulia Tsvetkov. Proc. ACL 2024. PDF Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks. Yichen Wang, Shangbin Feng, Abe Bohan Hou, Xiao Pu, Chao Shen, Xiaoming Liu, Yulia Tsvetkov, and Tianxing He. Proc. ACL 2024. PDF Knowledge Crosswords: Geometric Knowledge Reasoning with Large Language Models. Wenxuan Ding, Shangbin Feng, Yuhan Liu, Zhaoxuan Tan, Vidhisha Balachandran, Tianxing He, and Yulia Tsvetkov. Proc. ACL 2024, findings. PDF DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection. Herun Wan, Shangbin Feng, Zhaoxuan Tan, Heng Wang, Yulia Tsvetkov, and Minnan Luo. Proc. ACL 2024, findings. PDF David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs.  Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, and Marjan Ghazvininejad.   Proc. NAACL. PDF P3Sum: Preserving Author's Perspective in News Summarization with Diffusion Language Models.  Yuhan Liu, Shangbin Feng, Xiaochuang Han, Vidhisha Balachandran, Chan Young Park, Sachin Kumar, and Yulia Tsvetkov.   Proc. NAACL. PDF Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers.  Roy Xie, Orevaoghene Ahia, Yulia Tsvetkov, and Antonios Anastasopoulos.   Proc. NAACL. PDF BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer.  Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi.   Proc. NAACL. PDF Trusting Your Evidence: Hallucinate Less with Context-aware Decoding.  Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, and Scott Wen-tau Yih.   Proc. NAACL. PDF SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation.  Abe Bohan Hou, Jingyu Zhang, Tianxing He, Yichen Wang, Yung-Sung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, and Yulia Tsvetkov.   Proc. NAACL. PDF LatticeGen: Hiding Generated Text in a Lattice for Privacy-Aware Large Language Model Generation on Cloud.  Mengke Zhang, Tianxing He, Tianle Wang, Lu Mi, Niloofar Mireshghallah, Binyi Chen, Hao Wang, and Yulia Tsvetkov.   Proc. NAACL Findings. PDF KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models. (Oral)  Yuyang Bai, Shangbin Feng, Vidhisha Balachandran, Zhaoxuan Tan, Shiqi Lou, Tianxing He, and Yulia Tsvetkov.   Proc. WebConf. PDF Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions.  Sachin Kumar, Chan Young Park, and Yulia Tsvetkov.   Proc. ICLR. PDF Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models. (Oral)  Shangbin Feng, Weijia Shi, Yuyang Bai, Vidhisha Balachandran, Tianxing He, and Yulia Tsvetkov.   Proc. ICLR. PDF Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory. (Spotlight paper)  Niloofar Mireshghallah, Hyunwoo Ki",
  "content_length": 31925,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:44"
}