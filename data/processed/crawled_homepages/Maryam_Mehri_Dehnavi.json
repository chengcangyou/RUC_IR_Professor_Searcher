{
  "name": "Maryam Mehri Dehnavi",
  "homepage": "https://www.cs.toronto.edu/~mmehride",
  "status": "success",
  "content": "Maryam Mehri Dehnavi Associate Professor of Computer Science Principal Research Scientist at NVIDIA Canada Research Chair in Parallel and Distributed Computing Checkout our lab Paramathics for latest news on our research! Home Students Teaching Contact Research: My research group, ParaMathics, works on various aspects of cloud computing, machine learning, numerical analysis, compilers, programming languages, and high-performance computing. We develop scalable numerical methods, high-performance libraries, and domain-specific languages and compilers for high-performance and cloud computing platforms. CV (PDF) News \"Adaptive Algebraic Reuse of Reordering in Cholesky with Dynamic Sparsity Patterns\" to appear at SIGGRAPH'25 (journal track). Paper \"SLiM: One-shot Quantization and Sparsity with Low-rank Approximation for LLM Weight Compression\" to appear at ICML 2025. Paper \"SLoPe: Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining of LLMs\" accepted at ICLR25. Paper \"SpEQ: Translation of Sparse Codes using Equivalences\" accepted at PLDI24. Paper \"MKOR: Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 Updates\" accepted at Neurips23. Paper I will give the keynote/plenary talk at SIAM PP 2024 and will serve as a panelist in the AI-HPC Panel at SC23. \"Register Tiling for Unstructured Sparsity in Neural Network Inference\" accepted at PLDI23. Paper \"Runtime Composition of Iterations for Fusing Loop-carried Sparse Dependence\" accepted at SC23. Paper Avery wins first-place at the PACT 2022 Student Research Competition! Kazem starts a tenure track faculty position at McMaster University! \"Vectorizing Sparse Matrix Computations with Partially-Strided Codelets\" accepted at SC22. Paper \"HyLo: A Hybrid Low-Rank Natural Gradient Descent Method\" accepted at SC22. Paper \"Combining Run-time Checks and Compile-time Analysis to Improve Control Flow Auto-Vectorization\" accepted at PACT22. Paper I am the general chair of PPOPP 2023. Call for papers is out! Please submit your work. Link \"HDAGG: Hybrid Aggregation in Sparse Matrix Computations\" accepted at IPDPS22. Paper I am appointed as the Canada Research Chair in Parallel and Distributed Computing. I am the recipient of the Ontario Early Researcher Award 2021. \"Randomized Gossiping with Effective Resistance Weights: Performance Guarantees and Applications\" accepted at IEEE Transactions on Control of Network Systems 2022. Paper \"Composing Loop-carried Dependence with Other Loops\" is online! Paper \"L-DQN: An Asynchronous Limited-Memory Distributed Quasi-Newton Method\" accepted at IEEE Conference on Decision and Control, CDC21. Paper \"NASOQ: Numerically Accurate Sparsity-Oriented QP Solver\" accepted at SIGGRAPH20. Paper Our project on Neurocomputation of Brain-body Interactions is awarded the NSERC New Frontiers in Research Fund. Kazem Cheshmi receives the 2020 ACM-IEEE CS George Michael Memorial HPC fellowship. Our work TENGraD on a Time-efficient Natural Gradient Descent method is now online! Paper Kazem Cheshmi receives the 2018 Adobe Research Fellowship. Sympiler is now online! \"Sympiler: Transforming Sparse Matrix Codes by Decoupling Symbolic Analysis\" accepted at SC17. Paper Kazem Cheshmi wins First Place in the 2017 Grand Finals of the ACMâs Student Research Competition for our work on \"Decoupling Symbolic from Numeric in Sparse Matrix Computations.\" The SRC Grand Finals are the culmination of a year-long competition that involved more than 300 students presenting research projects at 25 major ACM conferences. Maryam Dehnavi receives the NSF CRII grant on Performance-in-Depth Sparse Solvers for Heterogeneous Parallel Platforms. Follow @MaryamDehnavi Maryam Mehri Dehnavi © Maryam Mehri Dehnavi",
  "content_length": 3714,
  "method": "requests",
  "crawl_time": "2025-12-01 13:55:05"
}