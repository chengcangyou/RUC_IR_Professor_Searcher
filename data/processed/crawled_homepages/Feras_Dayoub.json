{
  "name": "Feras Dayoub",
  "homepage": "https://researchers.adelaide.edu.au/profile/feras.dayoub",
  "status": "success",
  "content": "Dr Feras Dayoub | Researcher Profiles Skip to main content × Search Researcher Profiles Return to search Login Dr Feras Dayoub Senior Lecturer School of Computer and Mathematical Sciences Faculty of Sciences, Engineering and Technology I work at the intersection of computer vision, machine learning, and robotics, specializing in Embodied AI and Robotic Vision as part of the Australian Institute for Machine Learning (AIML) at the University of Adelaide. I co-direct CROSSING, a French-Australian laboratory focused on human-autonomous agent teaming. In addition to my role at AIML, I hold an Adjunct position at Queensland University of Technology (QUT) and serve as an Associate Investigator with the QUT Centre for Robotics. Previously, I was a Chief Investigator at the ARC Centre of Excellence for Robotic Vision. My research is dedicated to advancing the reliable deployment of computer vision and machine learning on mobile robots in real-world environments. I worked on applied robotic vision projects spanning agricultural innovation, environmental conservation, and autonomous infrastructure monitoring. As an educator, I am passionate about teaching programming, computer vision, machine learning, and robotic perception. Career Publications Supervision Contact Expand All Appointments Date Position Institution name 2026 - ongoing Associate Professor Adelaide University 2022 - 2025 Senior Lecturer University of Adelaide 2022 - 2025 Adjunct Senior Lecturer Queensland University of Technology 2019 - 2022 Senior Lecturer Queensland University of Technology 2016 - 2019 Centre Research Fellow Center for Excellence in Robotic Robotics Vision (ACRV) 2012 - 2016 Postdoctoral Research Fellow Queensland University of Technology Research Interests Computer Vision Knowledge Representation and Machine Learning Robotics and Automation Expand All Journals Year Citation 2023 Pershouse, D., Dayoub, F., Miller, D., & Sünderhauf, N. (2023). Addressing the Challenges of Open-World Object Detection. 2023 Shi, X., Qiao, Y., Wu, Q., Liu, L., & Dayoub, F. (2023). Improving Online Source-free Domain Adaptation for Object Detection by Unsupervised Data Acquisition. 2023 Chapman, N. H., Dayoub, F., Browne, W., & Lehnert, C. (2023). Predicting Class Distribution Shift for Reliable Domain Adaptive Object Detection. IEEE Robotics and Automation Letters, 8(8), 1-8. DOI Scopus6 WoS4 2022 Hall, D., Talbot, B., Bista, S. R., Zhang, H., Smith, R., Dayoub, F., & Sünderhauf, N. (2022). BenchBot environments for active robotics (BEAR): Simulated data for active scene understanding research. International Journal of Robotics Research, 41(3), 259-269. DOI Scopus3 WoS3 2022 Rahman, Q. M., Sunderhauf, N., Corke, P., & Dayoub, F. (2022). FSNet: A Failure Detection Framework for Semantic Segmentation. IEEE Robotics and Automation Letters, 7(2), 1-8. DOI Scopus16 WoS14 2022 Miller, D., Sunderhauf, N., Milford, M., & Dayoub, F. (2022). Uncertainty for identifying open-set errors in visual object detection. IEEE Robotics and Automation Letters, 7(1), 215-222. DOI Scopus36 WoS30 2021 Talbot, B., Dayoub, F., Corke, P., & Wyeth, G. (2021). Robot navigation in unseen spaces using an abstract map. IEEE Transactions on Cognitive and Developmental Systems, 13(4), 791-805. DOI Scopus17 WoS12 2021 Rahman, Q. M., Corke, P., & Dayoub, F. (2021). Run-time monitoring of machine learning for robotic perception: a survey of emerging trends. IEEE Access, 9, 20067-20075. DOI Scopus53 WoS45 2020 Haviland, J., Dayoub, F., & Corke, P. (2020). Control of the Final-Phase of Closed-Loop Visual Grasping using Image-Based Visual Servoing. 2020 Arain, B., Dayoub, F., Rigby, P., & Dunbabin, M. (2020). Close-Proximity Underwater Terrain Mapping Using Learning-based Coarse Range Estimation. 2019 Skinner, J., Hall, D., Zhang, H., Dayoub, F., & Sünderhauf, N. (2019). The Probabilistic Object Detection Challenge. 2019 Sünderhauf, N., Dayoub, F., Hall, D., Skinner, J., Zhang, H., Carneiro, G., & Corke, P. (2019). A probabilistic challenge for object detection. Nature Machine Intelligence, 1(9), 443. DOI WoS3 2018 Ahn, H. S., Sa, I., & Dayoub, F. (2018). Introduction to the Special Issue on Precision Agricultural Robotics and Autonomous Farming Technologies. IEEE Robotics and Automation Letters, 3(4), 4435-4438. DOI Scopus5 WoS3 2018 Hall, D., Dayoub, F., Perez, T., & McCool, C. (2018). A rapidly deployable classification system using visual data for the application of precision weed management. Computers and Electronics in Agriculture, 148, 107-120. DOI Scopus22 WoS16 Europe PMC2 2017 Bawden, O., Kulk, J., Russell, R., McCool, C., English, A., Dayoub, F., . . . Perez, T. (2017). Robot for weed species plant-specific management. Journal of Field Robotics, 34(6), 1179-1199. DOI Scopus166 WoS138 2017 Sa, I., Lehnert, C., English, A., McCool, C., Dayoub, F., Upcroft, B., & Perez, T. (2017). Peduncle Detection of Sweet Pepper for Autonomous Crop Harvesting-Combined Color and 3-D Information. IEEE Robotics and Automation Letters, 2(2), 765-772. DOI Scopus106 WoS88 2016 Sa, I., Ge, Z., Dayoub, F., Upcroft, B., Perez, T., & McCool, C. (2016). Deepfruits: A fruit detection system using deep neural networks. Sensors (Switzerland), 16(8), 1-23. DOI Scopus993 WoS724 Europe PMC204 2015 Dayoub, F., Morris, T., & Corke, P. (2015). Rubbing shoulders with mobile service robots. IEEE Access, 3, 333-342. DOI Scopus8 WoS8 2011 Dayoub, F., Cielniak, G., & Duckett, T. (2011). Long-term experiments with an adaptive spherical view representation for navigation in changing environments. Robotics and Autonomous Systems, 59(5), 285-295. DOI Scopus50 WoS42 - Clement, B., Dubromel, M., Santos, P. E., Sammut, K., Oppert, M., & Dayoub, F. (2024). Hybrid Navigation Acceptability and Safety. Proceedings of the AAAI Symposium Series, 2(1), 11-17. DOI Books Year Citation 2020 Garg, S., Sünderhauf, N., Dayoub, F., Morrison, D., Cosgun, A., Carneiro, G., . . . Milford, M. (2020). Semantics for Robotic Mapping, Perception and Interaction: A Survey (Vol. 8). United States: Now Publishers. DOI Book Chapters Year Citation 2025 Shi, X., Qiao, Y., Wu, Q., Liu, L., & Dayoub, F. (2025). Improving Online Source-Free Domain Adaptation for Object Detection by Unsupervised Data Acquisition. In A. DelBue, C. Canton, J. Pont-Tuset, & T. Tommasi (Eds.), Lecture Notes in Computer Science (Vol. 15629 LNCS, pp. 195-205). SPRINGER INTERNATIONAL PUBLISHING AG. DOI Scopus1 WoS1 2017 Perez, T., Bawden, O., Kulk, J., Russell, R., McCool, C., English, A., & Dayoub, F. (2017). Overview of mechatronic design for a weed-management robotic system. In D. Zhang, & B. Wei (Eds.), Robotics and Mechatronics for Agriculture (1st ed., pp. 23-49). Boca Raton, USA: CRC Press. DOI 2015 Dayoub, F., Cielniak, G., & Duckett, T. (2015). Eight weeks of episodic visual navigation inside a non-stationary environment using adaptive spherical views. In L. Mejias, P. Corke, & J. Roberts (Eds.), Springer Tracts in Advanced Robotics (Vol. 105, pp. 379-392). SPRINGER-VERLAG BERLIN. DOI Scopus2 WoS2 2011 Dayoub, F., Cielniak, G., & Duckett, T. (2011). Long-term experiment using an adaptive appearance-based map for visual navigation by mobile robots. In Lecture Notes in Computer Science (Vol. 6856 LNAI, pp. 400-401). Springer Berlin Heidelberg. DOI Scopus1 Conference Papers Year Citation 2025 Podgorski, S., Garg, S., Hosseinzadeh, M., Mares, L., Dayoub, F., & Reid, I. (2025). TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals. In 2025 IEEE International Conference on Robotics and Automation (ICRA) (pp. 2399-2406). Atlanta, GA, USA: IEEE. DOI 2025 Deng, J., He, T., Jiang, L., Wang, T., Dayoub, F., & Reid, I. (2025). 3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (pp. 3772-3782). IEEE. DOI 2025 Lin, C. -J., Garg, S., Chin, T. -J., & Dayoub, F. (2025). Robust Scene Change Detection Using Visual Foundation Models and Cross-Attention Mechanisms. In 2025 IEEE International Conference on Robotics and Automation (ICRA) (pp. 8337-8343). Atlanta, GA, USA: IEEE. DOI 2025 Zhang, W., Li, Y., Qiao, Y., Huang, S., Liu, J., Dayoub, F., . . . Liu, L. (2025). Effective Tuning Strategies for Generalist Robot Manipulation Policies. In 2025 IEEE International Conference on Robotics and Automation (ICRA) (pp. 7255-7262). Atlanta, GA, USA: IEEE. DOI 2025 Abraham, S. S., Garg, S., & Dayoub, F. (2025). To Ask or Not to Ask? Detecting Absence of Information in Vision and Language Navigation. In Proceedings - 2025 IEEE Winter Conference on Applications of Computer Vision, WACV 2025 (pp. 7480-7489). Tucson, AZ, USA Funding Agency: Authors Savitha Sam Abraham Australian Institute for Machine Learning, The University of Adelaide, Australia Sourav Garg Australian Institute for Machine Learning, The University of Adelaide, Australia Feras Dayoub Australian Institute for Machine Learning, The University of Adelaide, Australia Figures References Keywords Metrics Contact IEEE to Subscribe: IEEE. DOI 2025 Chapman, N. H., Lehnert, C., Browne, W., & Dayoub, F. (2025). Enhancing Embodied Object Detection with Spatial Feature Memory. In Proceedings - 2025 IEEE Winter Conference on Applications of Computer Vision, WACV 2025 (pp. 6921-6931). Tucson, AZ, USA: IEEE. DOI Scopus1 2024 McLeod, S., Chng, C. K., Ono, T., Shimizu, Y., Hemmi, R., Holden, L., . . . Chin, T. J. (2024). Robust Perspective-n-Crater for Crater-based Camera Pose Estimation. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (pp. 6760-6769). Seattle: IEEE. DOI Scopus2 WoS2 2024 Yuan, D., Maire, F., & Dayoub, F. (2024). Temporal Attention for Cross-View Sequential Image Localization. In IEEE International Conference on Intelligent Robots and Systems (pp. 7429-7436). Abu Dhabi, United Arab Emirates: IEEE. DOI 2024 Abou-Chakra, J., Rana, K., Dayoub, F., & Sünderhauf, ",
  "content_length": 26791,
  "method": "requests",
  "crawl_time": "2025-12-01 13:09:51"
}