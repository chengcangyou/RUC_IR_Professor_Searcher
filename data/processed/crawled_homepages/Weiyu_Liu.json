{
  "name": "Weiyu Liu",
  "homepage": "https://www.weiyuliu.com",
  "status": "success",
  "content": "Weiyu Liu Weiyu Liu I am an incoming Assistant Professor in the Kahlert School of Computing at the University of Utah. Currently, I am part of the research team at a stealth startup developing robotic foundation models. I was a Postdoctoral Scholar working with Jiajun Wu in the Stanford Vision and Learning Lab (SVL). I completed my Ph.D. in robotics at Georgia Institute of Technology, advised by Sonia Chernova. During my Ph.D., I interned at the NVIDIA Seattle Robotics Lab, working with Dieter Fox, Tucker Hermans, Animesh Garg, and Chris Paxton. Prior to joining the Ph.D. program, I received my Bachelor's degree in Electrical Engineering from Georgia Tech. Email  / CV (Dec 2024)  / Google Scholar  / Github  / Twitter Research The goal of my research is to develop robots that can effectively perceive, model, and interact with the real world. I am particularly interested in the application where human users can easily command robots to complete long-horizon tasks via simple language commands, such as \"make the tea\". Achieving this requires robust generalization across various dimensions, including objects, environments, actions, and tasks. My core insight is that strong generalization can be achieved through a structured representation of world knowledge. Rather than constructing this representation from scratch, robots should leverage the rich knowledge embedded in human language, grounding it through interactions with their environments to connect abstract knowledge to their sensorimotor capabilities. My prior research has investigated core components of this structured knowledge representation, methods to extract and refine this knowledge extracted from humans, and algorithms that enable reasoning with this knowledge to support broad generalization. News 05/2025 – Organized the CVPR 2025 Workshop on Foundation Models for Embodied Agents 04/2025 – Gave a guest lecture in CS 8001: Robotics and Human-Robot Interaction at Georgia Tech 03/2025 – Served as an Area Chair (AC) for CoRL 2025 02/2025 – Gave a guest lecture in CS 396: Reasoning and Planning in the Foundation Model Era at Northwestern University 10/2024 – Gave an oral presentation at the LEAP Workshop at CoRL 2024 06/2024 – Organized the ICRA 2024 Workshop on Vision-Language Models for Navigation and Manipulation 01/2023 – Gave an invited talk at the InterACT Lab at UC Berkeley 06/2022 – Selected as an RSS Pioneer 03/2022 – Gave an invited talk at the Toronto AI in Robotics Seminar at the University of Toronto 03/2022 – Gave an invited talk at the Laboratory for Progress at the University of Michigan 05/2019 – Won First Place in Fetch It! The Mobile Manipulation Challenge Click here to read more Group I am looking for motivated and talented students to join my research group in Fall 2026. Click here to read more Thank you for your interest in joining our research group! Please review the information below about our research environment and goals. If you are a prospective PhD student interested in joining my group, especially for the coming application season, please fill out this PhD Opportunities Form. If you are interested in working with me as an undergraduate student, master's student, postdoc, research intern, or visiting scholar, please complete this Research Opportunities Form. I apologize that I might not be able to respond to all emails, but I will carefully review all submitted forms. Research Vision We tackle problems that bring new ideas and make a real-world difference. Our projects can lead to new algorithms, datasets, benchmarks, or integrated hardware and software solutions. Publishing and Dissemination I encourage students to publish one paper each year, something you are genuinely proud to share. Alongside the paper, we release code, datasets, project websites, and other materials to help the community build on our work. Mentorship and Advising I will schedule recurring meetings with all group members and make it a priority to meet individually with each PhD student every week. We also hold regular lab meetings / reading groups to share ideas and learn from one another. I believe strong research comes from a supportive, honest, and intellectually open environment. For research, I will support your growth in identifying meaningful questions, developing solutions, writing, sharing work, managing projects, giving and receiving constructive feedback, and shaping a strong research narrative over time. For your career, I will provide advice on finding internships, building your network, mentoring junior students, and preparing for academic or industry jobs. For personal growth beyond research, I encourage you to balance work and life, travel (for example, by attending international conferences), and continue developing your interests and hobbies. Funding and Resources I will work to secure funding to support PhD students. Students will have access to high-performance compute resources, robot hardware, personal computers, and travel support for attending conferences. What I'm Looking For I'm looking for students who are excited in the research directions we pursue. Ideal candidates: Have prior research experience in robot learning, manipulation, task and motion planning, or related fields such as AI, machine learning, computer vision, NLP Think deeply and communicate clearly Have strong coding and hands-on skills Are self-driven Publications Show Selected / Show By Date Years: 2024 / 2023 / 2022 / 2021 / 2020 / 2019 / Before 2018 Your browser does not support the video tag. Learning Compositional Behaviors from Demonstration and Language Weiyu Liu*, Neil Nie*, Ruohan Zhang, Jiayuan Mao†, Jiajun Wu† Conference on Robot Learning (CoRL), 2024 2nd Workshop on Learning Effective Abstractions for Planning (LEAP), 2024 (Oral Presentation) paper / website / bibtex Your browser does not support the video tag. Composable Part-Based Manipulation Weiyu Liu, Jiayuan Mao, Joy Hsu, Tucker Hermans, Animesh Garg, Jiajun Wu Conference on Robot Learning (CoRL), 2023 arxiv / website / bibtex Learning Planning Abstractions from Language Weiyu Liu*, Geng Chen*, Joy Hsu, Jiayuan Mao†, Jiajun Wu† International Conference on Learning Representations (ICLR), 2024 arxiv / website / bibtex Your browser does not support the video tag. IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos Yunong Liu, Cristobal Eyzaguirre, Manling Li, Shubh Khanna, Juan Carlos Niebles, Vineeth Ravi, Saumitra Mishra, Weiyu Liu†, Jiajun Wu† Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track, 2024 paper / website / code and data / bibtex Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners Chun Feng*, Joy Hsu*, Weiyu Liu, Jiajun Wu IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024 paper / website / code / bibtex Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making Manling Li*, Shiyu Zhao*, Qineng Wang*, Kangrui Wang*, Yu Zhou*, Sanjana Srivastava, Cem Gokmen, Tony Lee, Li Erran Li, Ruohan Zhang, Weiyu Liu, Percy Liang, Li Fei-Fei, Jiayuan Mao, Jiajun Wu Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track, 2024 (Oral Presentation) paper / website / code / bibtex MARPLE: A Benchmark for Long-Horizon Inference Emily Jin, Zhuoyi Huang, Jan-Philipp Fränken, Weiyu Liu, Hannah Cha, Sarah A. Wu, Erik Brockbank, Ruohan Zhang, Jiajun Wu, Tobias Gerstenberg Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track, 2024 arxiv / website / code and data / bibtex A Survey of Semantic Reasoning Frameworks for Robotic Systems Weiyu Liu1, Angel Daruna1, Maithili Patel2, Kartik Ramachandruni2, Sonia Chernova Robotics and Autonomous Systems, 2023 paper / bibtex Your browser does not support the video tag. StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects Weiyu Liu, Yilun Du, Tucker Hermans, Sonia Chernova, Chris Paxton Robotics: Science and Systems (RSS), 2023 CoRL Workshop on Language and Robot Learning, 2022 arxiv / code & data / website / bibtex Your browser does not support the video tag. Latent Space Planning for Multi-Object Manipulation with Environment-Aware Relational Classifiers Yixuan Huang, Nichols Crawford Taylor, Adam Conkey, Weiyu Liu, Tucker Hermans Transactions on Robotics (TR-O), 2023 arxiv / website / bibtex GraspGPT: Leveraging Semantic Knowledge from a Large Language Model for Task-Oriented Grasping Chao Tang, Dehao Huang Wenqi Ge, Weiyu Liu, Hong Zhang Robotics and Automation Letters (RA-L), 2023 arxiv / code & data / website / bibtex Your browser does not support the video tag. StructFormer: Learning Spatial Structure for Language-Guided Semantic Rearrangement of Novel Objects Weiyu Liu, Chris Paxton, Tucker Hermans, Dieter Fox International Conference on Robotics and Automation (ICRA), 2022 arxiv / code & data / website / talk / bibtex Your browser does not support the video tag. Learning Instance-Level N-Ary Semantic Knowledge At Scale For Robots Operating in Everyday Environments Weiyu Liu, Dhruva Bansal, Angel Daruna, Sonia Chernova Robotics: Science and Systems (RSS), 2021 Autonomous Robots, 2023 (Invited Submission) paper / journal (extended version) / code & data / talk / bibtex Your browser does not support the video tag. Towards Robust One-shot Task Execution using Knowledge Graph Embeddings Angel Daruna, Lakshmi Nair, Weiyu Liu, Sonia Chernova International Conference on Robotics and Automation (ICRA), 2021 arxiv / bibtex Your browser does not support the video tag. An Affordance Keypoint Detection Network for Robot Manipulation Ruinian Xu, Fu-Jen Chu, Chao Tang, Weiyu Liu, Patricio Vela IEEE Robotics and Automation Letters (RA-L), 2021 paper / code & data / bibtex Your browser does not support the video tag. Same Object, Different Grasps: Data and Semantic Knowledge for Task-Oriented Grasping Adithya Murali, Weiyu Liu, Kenneth Marino, Sonia Chernova, Abhinav Gupt",
  "content_length": 12862,
  "method": "requests",
  "crawl_time": "2025-12-01 14:46:02"
}