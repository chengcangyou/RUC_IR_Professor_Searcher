{
  "name": "Yu Zhang 0044",
  "homepage": "https://yuzhimanhua.github.io",
  "status": "success",
  "content": "Contact | Yu ZHANG 张彧 Contact Email: yuzhang [AT] tamu [DOT] edu; yuz9yuz [AT] gmail [DOT] com Office: 222 Peterson Building, 435 Nagle St, College Station, TX 77843 About Me I am an Assistant Professor at the Department of Computer Science & Engineering at Texas A&M University. I lead the SKY Lab. Prior to TAMU, I received my Ph.D. and M.Sc. degrees in Computer Science from the University of Illinois at Urbana-Champaign, advised by Prof. Jiawei Han. During my graduate study, I visited the University of Washington, working with Prof. Sheng Wang; I interned at Microsoft Research Redmond three times, working with Dr. Iris Shen, Dr. Hao Cheng, Dr. Xiaodong Liu, and Dr. Yuxiao Dong. My Ph.D. thesis won the ACM SIGKDD Dissertation Award Runner-Up. Prior to UIUC, I received my B.Sc. degree in Computer Science from Peking University, advised by Prof. Yan Zhang. During my undergraduate study, I got the China National Scholarship; I visited Carnegie Mellon University, working with Prof. Kathleen M. Carley. Research Interests NLP and Data Mining for Science (Biology, Medicine, Mathematics, and Science of Science) LLM Agents with Structural Knowledge (Graphs, Ontologies, and Structural Memory) Teaching Spring 2026: CSCE 670 - Information Storage and Retrieval Fall 2025: CSCE 670 - Information Storage and Retrieval Spring 2025: CSCE 689 - Special Topics in NLP for Science What’s New [What’s Not New…] 2025-07 to 2025-12 Invited to be a PC member of KDD 2026 (Area Chair) and WWW 2026. 2025-11-28 One paper got accepted by WSDM 2026 short paper track! 2025-11-01 One tutorial proposal got accepted by WSDM 2026 tutorial track! 2025-10-30 Gave a guest lecture at Auburn University. 2025-10-08 Our paper on Scientific Document Retrieval was selected as one of the top-ranked papers published at WSDM 2025 and invited to the “Best Papers of WSDM 2025” Special Issue of ACM TIST! 2025-08-20 One paper got accepted by EMNLP 2025 Findings! 2025-08-03 Attended KDD 2025 in Toronto, Canada. Thrilled to receive the ACM SIGKDD Dissertation Award Runner-Up and give my award talk! 2025-01 to 2025-06 Invited to be a PC member of KDD 2025 (Area Chair), ACL 2025 (Area Chair), NeurIPS 2025 (Area Chair), and EMNLP 2025 (Senior Area Chair). 2025-05-15 Two papers got accepted by ACL 2025 (1 main conference + 1 findings)! 2025-04-30 Attended SDM 2025 in Washington, DC to present our tutorial. 2025-04-11 Gave a talk at the University of Kansas. 2025-03-07 We will hold two KDD 2025 workshops on Structured Knowledge for Large Language Models (SKnowLLM) and Machine Learning on Graphs in the Era of Artificial General Intelligence (MLoG-GenAI)! See you in Toronto! 2025-01-20 Our paper on Paper-Reviewer Matching was accepted by WWW 2025 as an oral presentation! The acceptance rate is 19.8% (409/2062). 2025-01-01 Joined Texas A&M University as an Assistant Professor! Selected Publications [Full List] (“*” indicates equal contribution. Unless otherwise specified, the paper is accepted as a research track long/regular paper.) Preprint In-the-Flow Agentic System Optimization for Effective Planning and Tool Use [arXiv] [project page] [code] [model] [demo] Zhuofeng Li, Haoxiang Zhang, Seungju Han, Sheng Liu, Jianwen Xie, Yu Zhang, Yejin Choi, James Zou, and Pan Lu. arXiv:2510.05592. Survivors, Complainers, and Borderliners: Upward Bias in Online Discussions of Academic Conference Reviews [arXiv] Hangxiao Zhu, Yian Yin, and Yu Zhang. arXiv:2509.16831. Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning [arXiv] Shubham Parashar, Shurui Gui, Xiner Li, Hongyi Ling, Sushil Vemuri, Blake Olson, Eric Li, Yu Zhang, James Caverlee, Dileep Kalathil, and Shuiwang Ji. arXiv:2506.06632. RM-R1: Reward Modeling as Reasoning [arXiv] [code] Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, and Heng Ji. arXiv:2505.02387. 2026 Knowledge Homophily in Large Language Models [arXiv] Utkarsh Sahu, Zhisheng Qi, Mahantesh Halappanavar, Nedim Lipka, Ryan A. Rossi, Franck Dernoncourt, Yu Zhang, Yao Ma, and Yu Wang. WSDM 2026. Boise, ID, USA. (Short Paper) 2025 Internal and External Impacts of Natural Language Processing Papers [PDF] [arXiv] [dataset] Yu Zhang. ACL 2025. Vienna, Austria. (Short Paper) Chain-of-Factors Paper-Reviewer Matching [PDF] [arXiv] [code] Yu Zhang, Yanzhen Shen, SeongKu Kang, Xiusi Chen, Bowen Jin, and Jiawei Han. WWW 2025. Sydney, Australia. Protein Large Language Models: A Comprehensive Survey [PDF] [arXiv] [project page] Yijia Xiao, Wanjia Zhao, Junkai Zhang, Yiqiao Jin, Han Zhang, Zhicheng Ren, Renliang Sun, Haixin Wang, Guancheng Wan, Pan Lu, Xiao Luo, Yu Zhang, James Zou, Yizhou Sun, and Wei Wang. EMNLP 2025 Findings. Suzhou, China. A Unified Taxonomy-Guided Instruction Tuning Framework for Entity Set Expansion and Taxonomy Expansion [PDF] [arXiv] [code] Yanzhen Shen, Yu Zhang, Yunyi Zhang, and Jiawei Han. ACL 2025 Findings. Vienna, Austria. Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation [PDF] [arXiv] SeongKu Kang, Bowen Jin, Wonbin Kweon, Yu Zhang, Dongha Lee, Jiawei Han, and Hwanjo Yu. WSDM 2025. Hannover, Germany. (Best Papers of WSDM 2025, Invited to ACM TIST) 2024 Structure-Enhanced Text Mining for Science [link] [award talk] Yu Zhang. Ph.D. Thesis. (ACM SIGKDD Dissertation Award Runner-Up) A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery [PDF] [arXiv] [project page] Yu Zhang*, Xiusi Chen*, Bowen Jin*, Sheng Wang, Shuiwang Ji, Wei Wang, and Jiawei Han. EMNLP 2024. Miami, FL, USA. Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains [PDF] [arXiv] [code] Yu Zhang*, Yunyi Zhang*, Yanzhen Shen, Yu Deng, Lucian Popa, Larisa Shwartz, ChengXiang Zhai, and Jiawei Han. AAAI 2024. Vancouver, Canada. Ontology Enrichment for Effective Fine-grained Entity Typing [PDF] [arXiv] Siru Ouyang, Jiaxin Huang, Pranav Pillai, Yunyi Zhang, Yu Zhang, and Jiawei Han. KDD 2024. Barcelona, Spain. Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs [PDF] [arXiv] [code] Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, and Jiawei Han. ACL 2024 Findings. Bangkok, Thailand. 2023 Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding [PDF] [arXiv] [project page] [code] [model] [dataset] [PMC-Patients leaderboard] Yu Zhang*, Hao Cheng*, Zhihong Shen, Xiaodong Liu, Ye-Yi Wang, and Jianfeng Gao. EMNLP 2023 Findings. Singapore, Singapore. Weakly Supervised Multi-Label Classification of Full-Text Scientific Papers [PDF] [arXiv] [code] Yu Zhang, Bowen Jin, Xiusi Chen, Yanzhen Shen, Yunyi Zhang, Yu Meng, and Jiawei Han. KDD 2023. Long Beach, CA, USA. The Effect of Metadata on Scientific Literature Tagging: A Cross-Field Cross-Model Study [PDF] [arXiv] [code] [dataset] Yu Zhang, Bowen Jin, Qi Zhu, Yu Meng, and Jiawei Han. WWW 2023. Austin, TX, USA. Effective Seed-Guided Topic Discovery by Integrating Multiple Types of Contexts [PDF] [arXiv] [code] Yu Zhang*, Yunyi Zhang*, Martin Michalski*, Yucheng Jiang*, Yu Meng*, and Jiawei Han. WSDM 2023. Singapore, Singapore. PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training [PDF] [arXiv] [code] Yunyi Zhang, Minhao Jiang, Yu Meng, Yu Zhang, and Jiawei Han. EMNLP 2023. Singapore, Singapore. Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks [PDF] [arXiv] [code] Bowen Jin, Yu Zhang, Qi Zhu, and Jiawei Han. KDD 2023. Long Beach, CA, USA. Patton: Language Model Pretraining on Text-Rich Networks [PDF] [arXiv] [code] Bowen Jin, Wentao Zhang, Yu Zhang, Yu Meng, Xinyang Zhang, Qi Zhu, and Jiawei Han. ACL 2023. Toronto, Canada. Chain-of-Skills: A Configurable Model for Open-Domain Question Answering [PDF] [arXiv] [code] Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, and Jianfeng Gao. ACL 2023. Toronto, Canada. Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning [PDF] [arXiv] [code] Yu Meng, Martin Michalski, Jiaxin Huang, Yu Zhang, Tarek Abdelzaher, and Jiawei Han ICML 2023. Honolulu, HI, USA. Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks [PDF] [arXiv] [code] Bowen Jin, Yu Zhang, Yu Meng, and Jiawei Han. ICLR 2023. Kigali, Rwanda. Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation [PDF] [arXiv] [code] Xiusi Chen, Yu Zhang, Jinliang Deng, Jyun-Yu Jiang, and Wei Wang. SDM 2023. Minneapolis, MN, USA. (Regular Paper, Best Poster Award Honorable Mention) 2022 Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds [PDF] [arXiv] [code] Yu Zhang, Yu Meng, Xuan Wang, Sheng Wang, and Jiawei Han. NAACL 2022. Seattle, WA, USA. Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification [PDF] [arXiv] [code] Yu Zhang, Zhihong Shen, Chieh-Han Wu, Boya Xie, Junheng Hao, Ye-Yi Wang, Kuansan Wang, and Jiawei Han. WWW 2022. Lyon, France. MotifClass: Weakly Supervised Text Classification with Higher-order Metadata Information [PDF] [arXiv] [code] Yu Zhang*, Shweta Garg*, Yu Meng, Xiusi Chen, and Jiawei Han. WSDM 2022. Tempe, AZ, USA. Heterogeneous Network Representation Learning: A Unified Framework with Survey and Benchmark [PDF] [arXiv] [code] Carl Yang*, Yuxin Xiao*, Yu Zhang*, Yizhou Sun, and Jiawei Han. TKDE. Volume 34, Issue 10. IEEE. Generating Training Data with Language Models: Towards Zero-Shot Language Understanding [PDF] [arXiv] [code] Yu Meng, Jiaxin Huang, Yu Zhang, and Jiawei Han. NeurIPS 2022. New Orleans, LA, USA. Topic Discovery via Latent Space Clustering of Pretrained Language Model Representations [PDF] [arXiv] [code] Yu Meng, Yunyi Zhang, Jiaxin Huang, Yu Zhang, and Jiawei Han. WWW 2022. Lyon, France. 2021 MATCH: Metadata-Aware Text Class",
  "content_length": 16708,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:07"
}