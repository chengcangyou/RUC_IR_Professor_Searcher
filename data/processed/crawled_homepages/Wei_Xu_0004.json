{
  "name": "Wei Xu 0004",
  "homepage": "https://cocoxu.github.io",
  "status": "success",
  "content": "Wei Xu - Georgia Tech - College of Computing Wei Xu [phonetic pronunciation: way shoo ] Associate Professor College of Computing Georgia Institute of Technology wei.xu@cc.gatech.edu @cocoweixu I am a faculty member of the School of Interactive Computing and Machine Learning Center at Georgia Tech. My research lies at the intersections of machine learning, natural language processing, and social media. I direct the NLP X Lab which currently focuses on (1) large language models, such as cultural bias, multilingual capability, temporal shifts, and personalization; (2) text generation, such as constrained decoding and learnable evaluation metric; and (3) interdisciplinary NLP applications that can make impact in education, security, accessibility, etc. I received the NSF CAREER Award, Faculty Research Awards from Google, Sony, and Criteo, CrowdFlower AI for Everyone Award, Paper Awards at COLING'18 and ACL'24, as well as research funds from DARPA and IARPA. I am a member of NAACL executive board. I was a postdoctoral researcher at the University of Pennsylvania. I received my PhD in Computer Science from New York University, BSMS from Tsinghua University. I plan to recruit 1-2 PhD students for 2026 admission (apply to Machine Learning or CS PhD program and list me as a potential advisor). I also recruit research MS students (apply to MSCS program) and undergraduates who have sufficient time and motivation. Given the number of applicants, I won't be able to reply to individual inquiries about admission, but a short email after submitting your application can help me locate it in the system. Research Publications Students Teaching CV Code & Data What's New Sep 2025, paper on LLM probabilistic reasoning accepted to NeurIPS 2025. Aug 2025, 4 papers accepted to EMNLP 2025 main conference Aug 2025, talk at Apple ML research (virtual) \"Probabilistic Reasoning and Multicultural Alignment in LLMs\" Jul 2025, talk at JPMorgan AI Research (virtual) May 2025, talk at Sungkyunkwan University, South Korea May 2025, keynote at PrivateNLP@NAACL \"Empowering Everyday Users to Protect Their Privacy in the Age of AI\". May 2025, co-organize the 10th Workshop for Noisy User-generated Text (WNUT) at NAACL 2025. Apr 2025, co-organize Human-centered Evaluation and Auditing of Language Models Workshop at CHI 2025. Mar 2025, talk at University of Pennsylvania Feb 2025, talk at University of Massachusetts, Lowell (virtual) Feb 2025, talk at Google Research, Mountain View Feb 2025, talk at University of California, Berkeley Dec 2024, Chao Jiang successfully defended his phd thesis and will join Apple AI/ML Research Oct 2024, received an NIH R01 grant! Oct 2024, talk at Bloomberg's CTO Data Science Speaker Series Oct 2024, talk at Stony Brook University, New York Oct 2024, received the Google Academic Research Award üèÜ ! Oct 2024, talk at Tokyo Institute of Technology on \"Enhancing Multilingual Capabilities in LLMs\" (slides) Sep 2024, 4 long papers and 1 short paper accepted to EMNLP main conference. Sep 2024, talk at MIT on \"Cultural Biases, World Languages, and Privacy in Large Language Models\" (slides). Sep 2024, talk at Northeastern on \"Human-AI Collaboration in Evaluating LLMs\". Aug 2024, üèÜ our paper on multicultural LLMs won the Best Social Impact Award at ACL 2024! Aug 2024, tutorial at ACL 2024 on \"Automatic and Human-AI Interactive Text Generation\" (slides) Aug 2024, my PhD advisor Ralph Grishman won the ACL Lifetime Achievement Award Aug 2024, talk at Megagon (virtual) July 2024, Yang Chen successfully defended his phd thesis, and will join NVIDIA as a research scientist. June 2024, talk at NSF workshop on AI Text Production (virtual) May 2024, 6 long papers accepted to ACL 2024 main conference! May 2024, keynote at CHI 2024 HEAL Workshop on \"Human-AI Collaboration in Evaluating LLMs\" (slides). May 2024, Yao Dou will start his summer internship at Microsoft Research; Chao Jiang will intern at Apple. Apr 2024, üèÜ David Heineman won the CoC Outstanding Undergraduate Research Award! Mar 2024, press coverage by VentureBeat on our new research about cultural biases in LLMs Mar 2024, talk at USC and UCLA on \"Amazing Multilingual Capabilities and Concerning Cultural Biases in LLMs\" Oct 2023, demo of Thresh üåæ has been accepted to EMNLP 2023 -- a customizable tool for fine-grained human evaluation of LLM generated texts (e.g., MT, summarization, text revision, + more) Aug 2023, I was quoted in Business Insider about AI-generated content online. Aug 2023, Mounica Maddela defended her PhD thesis and will join Bloomberg AI's LLM group July 2023, our paper on multilingual text simplification received Honorable Mention Award at ACL 2023! Research Highlights Multilingual Multicultural LLMs While LLMs have demonstrated impressive performance, their success is largely concentrated in English and other high-resource languages. In contrast, many non-English languages remain underrepresented and underserved. Moreover, these models often reflect Western cultural biases and struggle to capture the nuances of non-Western cultural contexts (Naous et al., ACL 2024; Naous et al., NAACL 2025). We work on identifying and closing these gaps in performance and cultural adaptation. Addressing these challenges calls for a deeper analysis of pre-training data to identify and mitigate representational gaps, as well as alignment (Guo et al., arXiv 2025) and inference-time algorithms (Le at al., ICLR 2024) that can dynamically adapt model behavior to diverse linguistic and cultural contexts. Robustness and Reasoning of LLMs Artificial General Intelligence (AGI) benchmarks seek to assess an AI system‚Äôs capacity to perform tasks that require human-level intelligence, including reasoning, learning, and adapting to novel situations (Zheng et al., ACL 2024; Mendes et al., EMNLP 2024). While current systems fall short of true AGI, there is growing interest in moving beyond static benchmarks toward more realistic, dynamic evaluations. Our research focuses on designing real-world tasks that better reflect practical challenges faced by LLMs, and on developing innovative methods (Zheng et al., arXiv 2025) to enhance their robustness and performance in these complex settings. Interdisciplinary NLP+X Research We actively collaborate with researchers to explore impactful real-world applications of large language models in Human-Computer Interaction, Security and Privacy, Healthcare, and Law (Jiang et al., EMNLP 2024; Dou et al., ACL 2024). As LLMs continue to advance, they offer exciting new capabilities across specialized domains. There are a lot of opportunities, as LLMs often exhibit promising but inconsistent performance in domain-specific tasks, where precision, context sensitivity, and domain knowledge are critical. NLP X Lab photos together with Alan Ritter's group Yao Dou (CS PhD student; human-centered LLM evaluation, generation) Tarek Naous (ECE ML PhD; multilingual multicultural LLM) Duong Minh Le (CS PhD; multilingual LLM -- co-advisor: Alan Ritter) Jonathan Zheng (ML PhD; reasoning, robustness of LLM -- co-advisor: Alan Ritter) Geyang Guo (CS PhD; LLM alignment -- co-advisor: Alan Ritter) Junmo Kang (CS PhD; efficiency -- co-advisor: Alan Ritter) Zirui Shao (visiting PhD student from Zhejiang University) Usneek Singh (MS, autumn 2025 -- ) Zicong He (ECE MS, summer 2025 -- ) Govind Ramesh (BSMS, winter 2022 -- ; LLM safety) Jerry Zheng (BSMS, autumn 2025 -- ) Julie Young (BSMS, autumn 2025 -- ) Rachel Choi (part-time, summer 2022 -- ) Oleksandr Lavreniuk (Undergrad, summer 2024 -- ) Sara Takagi (Undergrad, summer 2025 -- ) Katerina Addington (Undergrad, autumn 2025 -- ) Eric Kim (Undergrad, autumn 2025 -- ) Frank Chang (Undergrad, autumn 2025 -- ) Guanjun Yan (Undergrad, autumn 2025 -- ) Alexey Plagov (Undergrad, autumn 2025 -- ) Benjamin Mamut (Undergrad, autumn 2025 -- ) Jiayu Liu (Undergrad intern from UIUC, summer 2025 -- ) Alumni (with theses) Chao Jiang (PhD 2025 ‚Üí Apple AI/ML research) Yang Chen (PhD 2024, co-advisor: Alan Ritter ‚Üí Research Scientist at NVIDIA) Mounica Maddela (PhD 2023 ‚Üí Bloomberg AI) Wuwei Lan (PhD 2021 ‚Üí Applied Scientist at Amazon) Xiaofeng Wu (MS 2025 ‚Üí Baidu) Marcus Ma (MS 2024 ‚Üí PhD student at USC) Anton Lavrouk (MS 2024 ‚Üí Lockheed Martin) David Heineman (BS 2024, CoC Outstanding Undergrad Research Award ‚Üí Predoctoral young investigator at AI2) Jonathan Zheng (BS 2023 ‚Üí PhD student at Georgia Tech) Michael Ryan (BS 2023 ‚Üí PhD student at Stanford) Publications Preprints Flipping the Dialogue: Training and Evaluating User Language Models Tarek Naous, Philippe Laban, Wei Xu, Jennifer Neville arXiv, 2025 Camellia: Benchmarking Cultural Biases in LLMs for Asian Languages Tarek Naous, Anagha Savit, Carlos Rafael Catalan, Geyang Guo, Jaehyeok Lee, Kyungdon Lee, Lheane Marie Dizon, Mengyu Ye, Neel Kothari, Sahajpreet Singh, Sarah Masud, Tanish Patwa, Trung Thanh Tran, Zohaib Khan, Alan Ritter, JinYeong Bak, Keisuke Sakaguchi, Tanmoy Chakraborty, Yuki Arase, Wei Xu arXiv, 2025 Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges Xiaofeng Wu, Alan Ritter, Wei Xu arXiv, 2025 2025 Probabilistic Reasoning with LLMs for Privacy Risk Estimation Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu NeurIPS 2025 CARE: Multilingual Human Preference Learning for Cultural Awareness Geyang Guo, Tarek Naous, Hiromi Wakaki, Yukiko Nishimura, Yuki Mitsufuji, Alan Ritter, Wei Xu EMNLP 2025 SimulatorArena: Are User Simulators Reliable Proxies for Multi-Turn Evaluation of AI Assistants? Yao Dou, Michel Galley, Baolin Peng, Chris Kedzie, Weixin Cai, Alan Ritter, Chris Quirk, Wei Xu, Jianfeng Gao EMNLP 2025 What are Foundation Models Cooking in the Post-Soviet World? Anton Lavrouk, Tarek Naous, Alan Ritter, Wei Xu EMNLP 2025 How to Protect Yourself from 5G Radiation? Investigating LLM Responses to Implicit Misinformation Ruohao Guo, Wei Xu, Alan Ritter EMNLP 2025 Beyond the Reported Cutoff: Where Large Language Models Fall Short on Financial Knowle",
  "content_length": 26525,
  "method": "requests",
  "crawl_time": "2025-12-01 14:45:48"
}