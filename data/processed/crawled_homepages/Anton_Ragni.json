{
  "name": "Anton Ragni",
  "homepage": "https://www.sheffield.ac.uk/dcs/people/academic/anton-ragni",
  "status": "success",
  "content": "Dr Anton Ragni | Computer Science | The University of Sheffield Skip to main content Search sheffield.ac.uk Close menu × School of Computer Science School of Computer Science Menu Dr Anton Ragni BEng, MEng, PhD School of Computer Science Senior Lecturer in Speech and Language Technologies Assessments Lead Member of the Speech and Hearing (SpandH) research group Open staff member portrait in a modal window a.ragni@sheffield.ac.uk Regent Court (DCS) Full contact details Dr Anton Ragni School of Computer Science Regent Court (DCS) 211 Portobello Sheffield S1 4DP Orcid ID:https://orcid.org/0000-0003-0634-4456 Profile Dr Anton Ragni is a Senior Lecturer in Speech and Language Processing in the School of Computer Science at the University of Sheffield.He graduated with BEng and MEng degrees in Information Technology from the University of Tartu, Estonia, in 2005 and 2007 respectively. He was awarded his PhD from the University of Cambridge in 2013.From 2005 to 2008, he underwent graduate training at the Nordic Graduate School of Language Technology and from 2007 to 2008, he was an intern in the Speech Technology Group, Toshiba Research Europe Ltd, UK. From 2013 to 2018 and from 2018 to 2019, he was a Research Associate and Senior Research Associate, respectively, in Speech Processing at the University of Cambridge.His current research interest focuses on machine learning approaches for speech and language processing. Research interests Dr Anton Ragni's research interests include:Core automatic speech recognitionEfficient and expressive speech synthesisSpoken Language TranslationInformation RetrievalConversation Modelling Publications Books Young S, Evermann G, Gales M, Hain T, Kershaw D, Xunying L, Moore G, Odell J, Ollason D, Povey D , Ragni A et al () The HTK Book (for HTK Version 3.5, documentation alpha version). Cambridge University Engineering Department: Cambridge University Engineering Department. Journal articles Mogridge R & Ragni A (2026) Minerva 2 for speech and language tasks. Computer Speech & Language, 95. View this article in WRRO Sun W, Tu Z & Ragni A (2024) Energy-based models for speech synthesis. ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 12667-12671. View this article in WRRO Ma Y, Øland A, Ragni A, Sette BMD, Saitis C, Donahue C, Lin C, Plachouras C, Benetos E, Quinton E , Shatri E et al (2024) Foundation Models for Music: A Survey.. CoRR, abs/2408.14340. Cross M & Ragni A (2024) What happens to diffusion model likelihood when your model is conditional?. Proceedings of Machine Learning Research, 255, 1-14. View this article in WRRO Ragni A, Gales MJF, Rose O, Knill KM, Kastanos A, Li Q & Ness PM (2022) Increasing Context for Estimating Confidence Scores in Automatic Speech Recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 30, 1319-1329. Wang Z & Ragni A (2021) Approximate Fixed-Points in Recurrent Neural Networks. Jacobsen SA & Ragni A (2021) Continuous representations of intents for dialogue systems. Chen X, Liu X, Wang Y, Ragni A, Wong JHM & Gales MJF (2019) Exploiting future word contexts in neural network language models for speech recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 27(9), 1444-1454. Wu C, Gales MJF, Ragni A, Karanasou P & Sim KC (2018) Improving interpretability and regularization in deep learning. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 26(2), 256-265. Ragni A, Li Q, Gales MJF & Wang Y (2018) Confidence Estimation and Deletion Prediction Using Bidirectional Recurrent Neural Networks.. CoRR, abs/1810.13025. Shi-Xiong Zhang , Ragni A & Gales MJF (2010) Structured Log Linear Models for Noise Robust Speech Recognition. IEEE Signal Processing Letters, 17(11), 945-948. Flynn R & Ragni A () Self-Train Before You Transcribe. Interspeech 2024, 2840-2844. Book chapters Ma Y, Yuan R, Li Y, Zhang G, Chen X, Yin H, Lin C, Benetos E, Ragni A, Gyenge N , Liu R et al (2023) ON THE EFFECTIVENESS OF SPEECH SELF-SUPERVISED LEARNING FOR MUSIC, Proceedings of the International Society for Music Information Retrieval Conference (pp. 457-465). Nair S, Ragni A, Klejch O, Galuščáková P & Oard D (2020) Experiments with Cross-Language Speech Retrieval for Lower-Resource Languages, Lecture Notes in Computer Science (pp. 145-157). Springer International Publishing Conference proceedings Que S & Ragni A (2025) VisualSpeech: Enhancing Prosody Modeling in TTS Using Video. Proceedings of Interspeech 2025 (pp 3778-3782). Rotterdam, The Netherlands, 17 August 2025 - 17 August 2025. View this article in WRRO Leung W-Z, Cross M, Ragni A & Goetze S (2024) Training data augmentation for dysarthric automatic speech recognition by text-to-dysarthric-speech synthesis. Proceedings of Interspeech 2024 (pp 2494-2498). Kos island, Greece, 1 September 2024 - 1 September 2024. View this article in WRRO Mogridge R, Close G, Sutherland R, Hain T, Barker J, Goetze S & Ragni A (2024) Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users Using Intermediate ASR Features and Human Memory Models.. ICASSP (pp 306-310) Li Y, Yuan R, Zhang G, Ma Y, Chen X, Yin H, Xiao C, Lin C, Ragni A, Benetos E , Gyenge N et al (2024) MERT: ACOUSTIC MUSIC UNDERSTANDING MODEL WITH LARGE-SCALE SELF-SUPERVISED TRAINING. 12th International Conference on Learning Representations Iclr 2024 Sun W, Tu Z & Ragni A (2024) Energy-Based Models for Speech Synthesis.. ICASSP (pp 12667-12671) Leung W-Z, Cross M, Ragni A & Goetze S (2024) Training Data Augmentation for Dysarthric Automatic Speech Recognition by Text-to-Dysarthric-Speech Synthesis.. INTERSPEECH Flynn R & Ragni A (2024) Self-Train Before You Transcribe.. INTERSPEECH Yuan R, Ma Y, Li Y, Zhang G, Chen X, Yin H, Zhuo L, Liu Y, Huang J, Tian Z , Deng B et al (2023) MARBLE: Music Audio Representation Benchmark for Universal Evaluation. Advances in Neural Information Processing Systems (NeurIPS 2023), Vol. 36. New Orleans, USA View this article in WRRO Ma Y, Yuan R, Li Y, Zhang G, Lin C, Chen X, Ragni A, Yin H, Benetos E, Gyenge N , Liu R et al (2023) On the effectiveness of speech self-supervised learning for music.. ISMIR 2023: 24th International Society for Music Information Retrieval Conference proceedings (pp 457-465). Milan, Italy, 5 November 2023 - 5 November 2023. View this article in WRRO Nomo Sudro P, Ragni A & Hain T (2023) Adapting pretrained models for adult to child voice conversion. 2023 31st European Signal Processing Conference (EUSIPCO) Proceedings (pp 271-275). Helsinki, Finland, 4 September 2023 - 4 September 2023. View this article in WRRO Flynn R & Ragni A (2023) Leveraging cross-utterance context for ASR decoding. Proceedings of Interspeech 2023 (pp 1359-1363). Dublin, Ireland, 20 August 2024 - 20 August 2024. View this article in WRRO Nicholls D, Knill K, Gales MJF, Ragni A & Ricketts P (2023) Speak & improve: L2 English speaking practice tool. Proceedings of Interspeech 2023 (pp 3669-3670). Dublin, Ireland, 20 August 2024 - 20 August 2024. View this article in WRRO Mogridge R, Close G, Sutherland R, Goetze S & Ragni A (2023) Pre-Trained Intermediate ASR Features and Human Memory Simulation for Non-Intrusive Speech Intelligibility Prediction in the Clarity Prediction Challenge 2. he 4th Clarity Workshop on Machine Learning Challenges for Hearing Aids (Clarity-2023). https://claritychallenge.org/clarity2023-workshop/results.html, 19 August 2023 - 19 August 2023. Flynn R & Ragni A (2023) Leveraging Cross-Utterance Context For ASR Decoding.. INTERSPEECH (pp 1359-1363) Li Y, Yuan R, Zhang G, MA Y, Lin C, Chen X, Ragni A, Yin H, Hu Z, He H , Benetos E et al (2022) LV-49: MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning. 23rd International Society for Music Information Retrieval Conference (ISMIR 2022). Bengaluru, India, 4 December 2022 - 4 December 2022. View this article in WRRO Li Y, Zhang G, Yang B, Lin C, Ragni A, Wang S & Fu J (2022) HERB: Measuring hierarchical regional bias in pre-trained language models. Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022 (pp 334-346). Online, 20 November 2022 - 20 November 2022. View this article in WRRO Kastanos A, Ragni A & Gales MJF (2020) Confidence Estimation for Black Box Automatic Speech Recognition Systems Using Lattice Recurrent Neural Networks. ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp 6329-6333), 4 May 2020 - 8 May 2020. Li Q, Ness PM, Ragni A & Gales MJF (2019) Bi-directional lattice recurrent neural networks for confidence estimation. ICASSP 2019 (pp 6755-6759). Brighton, UK, 12 May 2019 - 12 May 2019. View this article in WRRO Ragni A, Li Q, Gales MJF & Wang Y (2019) Confidence estimation and deletion prediction using bidirectional recurrent neural networks. 2018 IEEE Spoken Language Technology Workshop (SLT) (pp 204-211). Athens, Greece, 18 December 2018 - 18 December 2018. View this article in WRRO Oard DW, Carpuat M, Galuscáková P, Barrow J, Nair S, Niu X, Shing H-C, Xu W, Zotkina E, McKeown KR , Muresan S et al (2019) Surprise Languages: Rapid-Response Cross-Language IR.. EVIA@NTCIR Li Q, Ness P, Ragni A & Gales MJF (2019) Bi-directional Lattice Recurrent Neural Networks for Confidence Estimation.. ICASSP (pp 6755-6759) Wang Y, Wong JHM, Gales MJF, Knill KM & Ragni A (2018) Sequence teacher-student training of acoustic models for automatic free speaking language assessment. 2018 IEEE Spoken Language Technology Workshop (SLT). Athens, Greece, 18 December 2018 - 21 December 2018. Wang Y, Chen X, Gales MJF, Ragni A & Wong JHM (2018) Phonetic and graphemic systems for multi-genre broadcast transcription. 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). Calgary, AB, Canada, 15 April 2018 - 20 April 2018. Chen O, Ragni A, Gales M & Chen X (2018) Active memory networks for language modeling. Proc",
  "content_length": 22647,
  "method": "requests",
  "crawl_time": "2025-12-01 12:59:53"
}