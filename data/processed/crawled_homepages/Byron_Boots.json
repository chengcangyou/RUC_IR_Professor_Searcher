{
  "name": "Byron Boots",
  "homepage": "https://homes.cs.washington.edu/~bboots",
  "status": "success",
  "content": "Byron Boots - University of Washington Byron Boots email: bbootscs.washington.edu office: Bill and Melinda Gates Center (CSE2) 210 telephone: (206) 616-8017 I am the Amazon Professor of Machine Learning in the Paul G. Allen School of Computer Science and Engineering (CSE) at the University of Washington where I direct the UW Robot Learning Laboratory. I am also a Principal Research Scientist in the Seattle Robotics Lab at NVIDIA Research, and I am co-chair of the IEEE Robotics and Automation Society Technical Committee on Robot Learning. My group performs fundamental and applied research in machine learning, artificial intelligence, and robotics with a focus on developing theory and systems that tightly integrate perception, learning, and control. Our work touches on a range of problems including computer vision, state estimation, localization and mapping, high-speed navigation, motion planning, and robotic manipulation. The algorithms that we develop use and extend theory from deep learning and neural networks, nonparametric statistics, graphical models, nonconvex optimization, quantum physics, online learning, reinforcement learning, and optimal control. (See Google Scholar and Publications below.) We have been honored with several awards for our work. Prior to joining the faculty at the University of Washington, I was an Assistant Professor in the School of Interactive Computing within the College of Computing at Georgia Tech, and, before that, I was a post-doc in the Robotics and State Estimation Lab directed by Dieter Fox at the University of Washington. I received my Ph.D. from the Machine Learning Department in the School of Computer Science at Carnegie Mellon University where I was a member of the Sense, Learn, Act (SELECT) Lab, which was co-directed by Carlos Guestrin and my advisor Geoff Gordon. Teaching CSE478: Autonomous Robotics -- Winter 2023 Previous Courses at UW: CSE/AMATH 579: Intelligent Control Through Learning and Optimization -- Fall 2022 CSE478: Autonomous Robotics -- Winter 2022 CSEP546: Machine Learning -- Fall 2021 CSE446: Machine Learning -- Winter 2021 CSE599U: Reinforcement Learning -- Fall 2020 CSE599W: Reinforcement Learning -- Spring 2020 CSE446: Machine Learning -- Winter 2020 Previous Courses at Georgia Tech: CS8803: Adaptive Control and Reinforcement Learning -- Spring 2019 CS4641/7641: Machine Learning -- Fall 2018 CS8803: Statistical Techniques in Robotics -- Spring 2018 CS8803: Statistical Techniques in Robotics -- Spring 2017 CS4641: Machine Learning -- Fall 2016 CS8803: Statistical Techniques in Robotics -- Spring 2016 CS8803: Statistical Techniques in Robotics -- Spring 2015 CS4001: Computing, Society, and Professionalism -- Fall 2014 Refereed Conference & Journal Publications Authors Title Year Journal/Proceedings J. Sacks & B. Boots. Learning to Optimize in Model Predictive Control. [Abstract] [BibTeX] [PDF Coming Soon] 2022 Proceedings of the 2022 IEEE Conference on Robotics and Automation (ICRA-2022) Abstract: Sampling-based Model Predictive Control (MPC) is a flexible control framework that can reason about non-smooth dynamics and cost functions. Recently, significant work has focused on the use of machine learning to improve the performance of MPC, often through learning or fine-tuning the dynamics or cost function. In contrast, we focus on learning to optimize more effectively. In other words, to improve the update rule within MPC. We show that this can be particularly useful in sampling-based MPC, where we often wish to minimize the number of samples for computational reasons. Unfortunately, the cost of computational efficiency is a reduction in performance; fewer samples results in noisier updates. We show that we can contend with this noise by learning how to update the control distribution more effectively and make better use of the few samples that we have. Our learned controllers are trained via imitation learning to mimic an expert which has access to substantially more samples. We test the efficacy of our approach on multiple simulated robotics tasks in sample-constrained regimes and demonstrate that our approach can outperform a MPC controller with the same number of samples. BibTeX: @inproceedings{Sacks-ICRA-22, Author = \"{Sacks, Jacob and Boots, Byron}\", booktitle = \"{IEEE} International Conference on Robotics and Automation ({ICRA}) \", Title = \"{Learning to Optimize in Model Predictive Control}\", year = {2022}} S. Adhikary & B. Boots. Sampling Over Riemannian Manifolds Using Kernel Herding. [Abstract] [BibTeX] [PDF Coming Soon] 2022 Proceedings of the 2022 IEEE Conference on Robotics and Automation (ICRA-2022) Abstract: Kernel herding is a deterministic sampling algorithm designed to draw `super samples' from probability distributions when provided with their kernel mean embeddings in a reproducing kernel Hilbert space (RKHS). Empirical expectations of functions in the RKHS formed using these super samples tend to converge even faster than random sampling from the true distribution itself. Standard implementations of kernel herding have been restricted to sampling over flat Euclidean spaces, which is not ideal for applications such as robotics where more general Riemannian manifolds may be appropriate. We propose to adapt kernel herding to Riemannian manifolds by (1) using geometry-aware kernels that incorporate the appropriate distance metric for the manifold and (2) using Riemannian optimization to constrain herded samples to lie on the manifold. We evaluate our approach on problems involving various manifolds commonly used in robotics including the SO(3) manifold of rotation matrices, the spherical manifold used to encode unit quaternions, and the manifold of symmetric positive definite matrices. We demonstrate that our approach outperforms existing alternatives on the task of resampling from an empirical distribution of weighted particles, a problem encountered in applications such as particle filtering. We also demonstrate how Riemannian kernel herding can be used as part of the kernel recursive approximate Bayesian computation algorithm to estimate parameters of black-box simulators, including inertia matrices of an Adroit robot hand simulator. Our results confirm that exploiting geometric information through our approach to kernel herding yields better results than alternatives including standard kernel herding with heuristic projections. BibTeX: @inproceedings{Adhikary-ICRA-22, Author = \"{Adhikary, Sandesh and Boots, Byron}\", booktitle = \"{IEEE} International Conference on Robotics and Automation ({ICRA}) \", Title = \"{Sampling Over Riemannian Manifolds Using Kernel Herding}\", year = {2022}} A. Lambert, B. Hou, R. Scalise, S. Srinivasa, & B. Boots. Stein Variational Probabilistic Roadmaps. [Abstract] [BibTeX] [PDF Coming Soon] [arXiv] 2022 Proceedings of the 2022 IEEE Conference on Robotics and Automation (ICRA-2022) Abstract: Efficient and reliable generation of global path plans are necessary for safe execution and deployment of autonomous systems. In order to generate planning graphs which adequately resolve the topology of a given environment, many sampling-based motion planners resort to coarse, heuristically-driven strategies which often fail to generalize to new and varied surroundings. Further, many of these approaches are not designed to contend with partial-observability. We posit that such uncertainty in environment geometry can, in fact, help \\textit{drive} the sampling process in generating feasible, and probabilistically-safe planning graphs. We propose a method for Probabilistic Roadmaps which relies on particle-based Variational Inference to efficiently cover the posterior distribution over feasible regions in configuration space. Our approach, Stein Variational Probabilistic Roadmap (SV-PRM), results in sample-efficient generation of planning-graphs and large improvements over traditional sampling approaches. We demonstrate the approach on a variety of challenging planning problems, including real-world probabilistic occupancy maps and high-dof manipulation problems common in robotics. BibTeX: @inproceedings{Lambert-ICRA-22, Author = \"{Lambert, Alexander, and Hou, Brian and Scalise, Rosario and S. Srinivasa, Siddhartha and Boots, Byron}\", booktitle = \"{IEEE} International Conference on Robotics and Automation ({ICRA}) \", Title = \"{Stein Variational Probabilistic Roadmaps}\", year = {2022}} H. Nichols, M. Jimenez, Z. Goddard, M. Sparapany, B. Boots, & A. Mazumdar. Adversarial Sampling-Based Motion Planning. [Abstract] [BibTeX] [PDF] 2022 IEEE Robotics and Automation Letters (Presented at ICRA-2022) Abstract: There are many scenarios in which a mobile agent may not want its path to be predictable. Examples include preserving privacy or confusing an adversary. However, this desire for deception can conflict with the need for a low path cost. Optimal plans such as those produced by RRT* may have low path cost, but their optimality makes them predictable. Similarly, a deceptive path that features numerous zig-zags may take too long to reach the goal. We address this trade-off by drawing inspiration from adversarial machine learning. We propose a new planning algorithm, which we title Adversarial RRT*. Adversarial RRT* attempts to deceive machine learning classifiers by incorporating a predicted measure of deception into the planner cost function. Adversarial RRT* considers both path cost and a measure of predicted deceptiveness in order to produce a low-cost trajectory that still has deceptive properties. We demonstrate the performance of Adversarial RRT*, with entropy as a measure of deception, using a Dubins car and show how percent of paths misclassified is increased from 18% to 53% while keeping path cost within 21% of the optimal planner. In addition, Adversarial RRT* is able to deceive a separate classifier that was designed independently. The reduction in classification accuracy from 48% to 30% for this separate classifier il",
  "content_length": 283451,
  "method": "requests",
  "crawl_time": "2025-12-01 13:07:06"
}