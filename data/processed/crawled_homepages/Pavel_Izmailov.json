{
  "name": "Pavel Izmailov",
  "homepage": "https://izmailovpavel.github.io",
  "status": "success",
  "content": "Pavel Izmailov Pavel Izmailov Contact: pi390@nyu.edu, Twitter I am an Assistant Professor in the NYU Tandon CSE department, and Courant CS department by courtesy. I am also a member of the NYU CILVR Group. I am also a Researcher at Anthropic. I am primarily interested in reinforcement learning, reasoning, AI for science and AI alignment. Previously, I worked on reasoning and superintelligent AI alignment at OpenAI. My research interests are broadly in understanding how deep neural networks work. I am excited about a broad array of topics in core machine learning, including: ‚Ä¢ Problem-solving and reasoning in AI ‚Ä¢ Reinforcement learning, planning and search ‚Ä¢ Interpretability of deep learning models ‚Ä¢ AI for scientific discovery and math ‚Ä¢ Generalization and robustness of AI models ‚Ä¢ Technical AI alignment ‚Ä¢ Probabilistic deep learning, uncertainty estimation and Bayesian methods You can see some of my representative publications below. Highlights ‚Ä¢ I contributed to the Anthropic Claude 3.7 Sonnet and Claude 4, state-of-the art reasoning and coding models. ‚Ä¢ I contributed to OpenAI o1, a new state-of-the-art in LLM reasoning. ‚Ä¢ Our work on weak-to-strong generalization was covered by a WIRED, MIT Technology Review and others. ‚Ä¢ Our work on Bayesian model selection was recognized with an Outstanding Paper Award üèÜ at ICML 2022! Links [Home, Bio, Publications, Talks, Group, Teaching, CV, GitHub, Google Scholar, Semantic Scholar] Selected Papers *Equal first authorship. Full list of papers available here. Learning to Reason with LLMs OpenAI Technical Post (contributor) 2024 [OpenAI blog] Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision C. Burns*, P. Izmailov*, J. H. Kirchner*, B. Baker*, L. Gao*, L. Aschenbrenner*, Y. Chen*, A. Ecoffet*, M. Joglekar*, J. Leike, I. Sutskever, J. Wu* 2023 [PDF, ArXiv, OpenAI blog, Code] [WIRED, TechCrunch, MIT Technology Review, IEEE Spectrum] FlexiViT: one model for all patch sizes L. Beyer, P. Izmailov, A. Kolesnikov, M. Caron, S. Kornblith, X. Zhai, M. Minderer, M. Tschannen, I. Alabdulmohsin, F. Pavetic Conference on Computer Vision and Pattern Recognition (CVPR), 2023 [PDF, ArXiv, Code] Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations Polina Kirichenko*, Pavel Izmailov*, Andrew Gordon Wilson International Conference on Learning Representations (ICLR), 2023 üåü Spotlight Presentation [PDF, ArXiv, Code] On Feature Learning in the Presence of Spurious Correlations Pavel Izmailov*, Polina Kirichenko*, Nate Gruver*, Andrew Gordon Wilson Neural Information Processing Systems (NeurIPS), 2022 [PDF, ArXiv, Code] Bayesian Model Selection, the Marginal Likelihood, and Generalization Sanae Lotfi, Pavel Izmailov, Gregory Benton, Micah Goldblum, Andrew Gordon Wilson International Conference on Machine Learning (ICML), 2022 üèÜ Outstanding Paper Award, üì¢ Long Talk (Oral) [PDF, ArXiv, Code] Dangers of Bayesian Model Averaging under Covariate Shift Pavel Izmailov, Patrick Nicholson, Sanae Lotfi, Andrew Gordon Wilson Neural Information Processing Systems (NeurIPS), 2021 [PDF, ArXiv, Poster, Code] What Are Bayesian Neural Network Posteriors Really Like? Pavel Izmailov, Sharad Vikram, Matthew D. Hoffman, Andrew Gordon Wilson International Conference on Machine Learning (ICML), 2021 üì¢ Long Talk (Oral) [PDF, ArXiv, Code, HMC samples, Poster, NeurIPS competition] Why Normalizing Flows Fail to Detect Out-of-Distribution Data Polina Kirichenko*, Pavel Izmailov*, Andrew Gordon Wilson Neural Information Processing Systems (NeurIPS), 2020 [PDF, ArXiv, Code] Bayesian Deep Learning and a Probabilistic Perspective of Generalization Andrew Gordon Wilson, Pavel Izmailov Neural Information Processing Systems (NeurIPS), 2020 [PDF, ArXiv, Code] A Simple Baseline for Bayesian Uncertainty in Deep Learning Wesley Maddox*, Timur Garipov*, Pavel Izmailov*, Dmitry Vetrov, Andrew Gordon Wilson Neural Information Processing Systems (NeurIPS), 2019 [PDF, ArXiv, Code, Poster, Video] Averaging Weights Leads to Wider Optima and Better Generalization Pavel Izmailov*, Dmitry Podoprikhin*, Timur Garipov*, Dmitry Vetrov, Andrew Gordon Wilson Uncertainty in Artificial Intelligence (UAI), 2018 üì¢ Oral Presentation [PDF, ArXiv, Code, Poster, Slides, PyTorch Blogpost, Towards Data Science Blogpost, fast.ai Blogpost] Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs Timur Garipov*, Pavel Izmailov*, Dmitry Podoprikhin*, Dmitry Vetrov, Andrew Gordon Wilson Neural Information Processing Systems (NeurIPS), 2018 üåü Spotlight Presentation [PDF, ArXiv, Code, Poster, Slides, Video, Blogpost]",
  "content_length": 4611,
  "method": "requests",
  "crawl_time": "2025-12-01 14:10:24"
}