{
  "name": "Vincent Sitzmann",
  "homepage": "https://www.vincentsitzmann.com",
  "status": "success",
  "content": "Vincent Sitzmann Vincent Sitzmann Assistant Professor, MIT EECS Research Blog Teaching Talks Bio Hi, I'm Vincent! I lead the Scene Representation Group at MIT CSAIL, where we build machines that learn to understand and interact with our world autonomously. Email Twitter Scholar CV Highlighted Work See our group website for more publications. Generative View Stitching Chonghyuk Song, Michal Stary, Boyuan Chen, George Kopanas, Vincent Sitzmann arXiv preprint 2025 Website Code Twitter arXiv True Self-Supervised Novel View Synthesis is Transferable Thomas W. Mitchel*, Hyunwoo Ryu*, Vincent Sitzmann arXiv 2025 Website Code Twitter arXiv Selective Underfitting in Diffusion Models Kiwhan Song, Jaeyeon Kim, Sitan Chen, Yilun Du, Sham Kakade, Vincent Sitzmann arXiv 2025 Website Twitter arXiv Locality in Image Diffusion Models Emerges from Data Statistics Artem Lukoianov, Chenyang Yuan, Justin Solomon, Vincent Sitzmann Spotlight • NeurIPS 2025 Website Code arXiv Meschers: Geometry Processing of Impossible Objects Ana Dodik, Isabella Yu, Kartik Chandra, Jonathan Ragan-Kelley, Joshua Tenenbaum, Vincent Sitzmann, Justin Solomon SIGGRAPH 2025 Paper Website Controlling diverse robots by inferring Jacobian fields with deep networks Sizhe Li, Annan Zhang, Boyuan Chen, Hanna Matusik, Chao Liu, Daniela Rus, Vincent Sitzmann Nature Journal Article • Nature 2025 Paper Website Code Twitter arXiv History-Guided Video Diffusion Kiwhan Song*, Boyuan Chen*, Max Simchowitz, Yilun Du, Russ Tedrake, Vincent Sitzmann ICLR 2025 Website Code Twitter arXiv Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion Boyuan Chen, Diego Marti Monso, Yilun Du, Max Simchowitz, Russ Tedrake, Vincent Sitzmann NeurIPS 2024 Website Code Twitter arXiv pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction David Charatan, Sizhe Li, Andrea Tagliasacchi, Vincent Sitzmann Best Paper Runner-Up • CVPR 2023 Website Code Twitter arXiv Decomposing NeRF for Editing via Feature Field Distillation Sosuke Kobayashi, Eiichi Matsumoto, Vincent Sitzmann NeurIPS 2022 Website Code Twitter arXiv Blog Thoughts on research, teaching, and AI. View all posts Sep 24, 2025 Make It Work, Then Prove It Works: A Framework for Research There are two disparate skillsets required for good research: moving fast to find what works, then slowing down to prove it. Knowing when to switch between them is crucial. Teaching Courses I have taught at MIT. Advances in Computer Vision Spring 2025 • 6.8300 Recent Talks Selected talks and presentations. Modeling the world (and yourself) from vision Toronto's Vision Group Lecture Series Short Biography Vincent Sitzmann is an Assistant Professor at MIT where he leads the Scene Representation Group. He received his PhD at Stanford University with Gordon Wetzstein and his Bachelor's degree from the Technical University of Munich. Vincent's research goal is to build machines that learn to understand and interact with the world autonomously by building ``world models'' - mental simulators that enable an agent to simulate what will happen next in their environment and as a consequence of their actions, a critical piece of AI and key in downstream applications in graphics, vision, and robotics.",
  "content_length": 3257,
  "method": "requests",
  "crawl_time": "2025-12-01 14:44:06"
}