{
  "name": "Tobias Glasmachers",
  "homepage": "https://www.ini.rub.de/the_institute/people/tobias-glasmachers",
  "status": "success",
  "content": "Prof. Dr. Tobias Glasmachers | People | Institut für Neuroinformatik RUB INI People Prof. Dr. Tobias Glasmachers tobias.glasmachers@ini.rub.de (+49) 234-32-25558 Prof. Dr. Tobias Glasmachers Theory of Machine Learning Theory of Machine Learning Ruhr-Universität Bochum Institut für Neuroinformatik Universitätsstraße 150 Building NB, Room NB 3/27 D-44801 Bochum, Germany tobias.glasmachers@ini.rub.de (+49) 234-32-25558 About Me Research Software Publications Teaching Supervised Theses Projects About Me I am a professor for theory of machine learning at the Institut für Neuroinformatik, Ruhr-Universität Bochum, Germany. I am heading the Optimization of Adaptive Systems group. My research interests are optimization, and machine learning / artificial intelligence. Short CV 2004-2008: Ph.D. candidate in Christian Igel's group at the Institut für Neuroinformatik in Bochum. I received my Ph.D. in 2008 from the Faculty of Mathematics, Ruhr-Universität Bochum, Germany. 2008-2009: Post-doc in the same group. 2009-2011: Post-doc in Jürgen Schmidhuber's group at IDSIA, Lugano, Switzerland. 2012-2018: Junior professor for theory of machine learning at the Institut für Neuroinformatik, Ruhr-Universität Bochum, Germany. I am the head of the optimization of adaptive systems group. 2018: Promotion to full professor. Research My research is located in the area of machine learning, a modern branch of artificial intelligence research. This is an interdisciplinary research topic in between computer science, statistics, and optimization, with connections to the neurosciences and applications in robotics, engineering, medicine, economics, and many more disciplines. Within this wide area I am focusing on three aspects: supervised learning and reinforcement learning (including modern deep learning), and optimization with simple gradient-based methods and with evolutionary algorithms. Supervised Machine Learning Supervised learning is a learning paradigm with endless (mostly technical) applications. A learning machine (algorithm) builds a predictive model from data provided in the form of input/output pairs. This allows for the automated solution of classification and regression problems. A primary example is classification of objects in images, a classic computer vision task. I have recently started to reach out to reinforcement learning problems in 3D environments for fully autonomous behavior learning of robots or computer game agents (bots). My research activities include both theoretical and practical aspects. Reinforcement Learning Among all machine learning paradigms, reinforcement learning is closest to our intuitive idea of behavior learning. An agent interacts with an environment and learns by trial and error. Robotics in full of extremely challenging examples of this type. I mostly deal with computer game environments. Learning complex behaviors for 3D ego perspective games like DooM or Minecraft is one of the long-term goals of my research. Optimization Gradient-based optimization, particularly relatively simple first order methods like (stochastic) gradient descent and coordinate descent, are at the heart of many modern training procedures for learning machines, in particular for (possibly regularized) empirical risk minimization. This includes backpropagation based training of (deep) neural networks, as well as convex (primal or dual) optimization, e.g., for support vector machine training. Evolutionary Algorithms (EAs) are a class of nature-inspired algorithms that mimic the process of Darwinian evolution. This process is resolved into the components inheritance, variation, and selection. It has been widely recognized that EAs are useful for search and optimization, in particular when derivatives are not available. Formally they can be understood as randomized direct search heuristics. They are suitable for tackling black-box optimization problems. I focus on evolution strategies, a class of optimization algorithms for continuous variables, and on multi-objective optimization. Network For meachine learning ralated research at RUB please check this website: https://ml-ai.rub.de/ (1+1) Limited Memory Matrix Adaptation Evolution Strategy Code Variable Metric Evolution Strategies for High-dimensional Multi-Objective Optimization Code Challenges of Convex Quadratic Bi-objective Benchmark Problems Code for reproducing the experiments in the paper. Python version of the code The Hessian Estimation Evolution Strategy Python code The Quasi-Newton Evolution Strategy Python code LM-MA-ES (large-scale variable metric evolution strategy) Python code BBComp (archive) Mirror of the (now shut-down) bbcomp server Precomputed Merging of Support Vectors budgeted stochastic gradient Descent with fast merging of support vectors Asynchronous ES An asynchronous natural evolution strategy. Adaptive Coordinate Frequencies Coordinate Descent Coordinate descent with online adaptation of coordinate frequencies for fast training of linear models. LASSO-code, modified liblinear. Hypervolume Maximization Maximization of dominated hypervolume for multi-objective benchmark problems. HMO-CMA-ES (hybrid multi-objective covariance matrix adaptation evolution strategy) Code xCMA-ES CMA-ES with multiplicative covariance update. Pareto Archive An efficient archiving algorithm for non-dominated solutions in multi-objective optimization. Stochastic Gradient Optimization Comparison of SGD, SAG, SVRG, and ADAM for training kernel machines on a budget. Limits of End-to-end Learning Code for reproducing the experiments in the paper. 2025 Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial ControlMaus, T., Atamna, A., & Glasmachers, T. Bibtex APA Downloads Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control @article{MausAtamnaGlasmachers2025b, author\t\t=\t{Maus, Tom and Atamna, Asma and Glasmachers, Tobias}, title\t\t=\t{Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control}, month\t\t=\t{October}, year\t\t=\t{2025}, doi\t\t=\t{10.48550/ARXIV.2510.20408}, } Maus, T., Atamna, A., & Glasmachers, T.. (2025). Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control. http://doi.org/10.48550/ARXIV.2510.20408 Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and AdamAtamna, A., Maus, T., Kievelitz, F., & Glasmachers, T. Bibtex APA Downloads Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam @misc{AtamnaMausKievelitzEtAl2025, author\t\t=\t{Atamna, Asma and Maus, Tom and Kievelitz, Fabian and Glasmachers, Tobias}, title\t\t=\t{Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam}, year\t\t=\t{2025}, } Atamna, A., Maus, T., Kievelitz, F., & Glasmachers, T.. (2025). Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam. Retrieved from https://arxiv.org/abs/2508.05408 Deep Reinforcement Learning Based Navigation with Macro Actions and Topological MapsHakenes, S., & Glasmachers, T. arXiv, Accepted for LOD 2025 Bibtex APA @misc{HakenesGlasmachers2025, author\t\t=\t{Hakenes, Simon and Glasmachers, Tobias}, title\t\t=\t{Deep Reinforcement Learning Based Navigation with Macro Actions and Topological Maps}, year\t\t=\t{2025}, doi\t\t=\t{10.48550/ARXIV.2504.18300}, } Hakenes, S., & Glasmachers, T.. (2025). Deep Reinforcement Learning Based Navigation with Macro Actions and Topological Maps. arXiv, Accepted for LOD 2025. http://doi.org/10.48550/ARXIV.2504.18300 Additive Drift as an Optimization Problem for the (1 + 1)-ESJungeilges, A., & Glasmachers, T.In Proceedings of the 18th ACM/SIGEVO Conference on Foundations of Genetic Algorithms (pp. 130–141) Leiden, Netherlands: Association for Computing Machinery Bibtex APA Downloads pdf @inproceedings{JungeilgesGlasmachers2025, author\t\t=\t{Jungeilges, Alexander and Glasmachers, Tobias}, title\t\t=\t{Additive Drift as an Optimization Problem for the (1 + 1)-ES}, booktitle\t=\t{Proceedings of the 18th ACM/SIGEVO Conference on Foundations of Genetic Algorithms}, pages\t\t=\t{130–141}, publisher\t=\t{Association for Computing Machinery}, series\t\t=\t{FOGA ′25}, address\t\t=\t{New York, NY, USA}, year\t\t=\t{2025}, doi\t\t=\t{10.1145/3729878.3746612}, } Jungeilges, A., & Glasmachers, T.. (2025). Additive Drift as an Optimization Problem for the (1 + 1)-ES. In Proceedings of the 18th ACM/SIGEVO Conference on Foundations of Genetic Algorithms (pp. 130–141). Leiden, Netherlands: Association for Computing Machinery. http://doi.org/10.1145/3729878.3746612 Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning EnvironmentsMaus, T., Atamna, A., & Glasmachers, T. Bibtex APA Downloads Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning Environments @article{MausAtamnaGlasmachers2025, author\t\t=\t{Maus, Tom and Atamna, Asma and Glasmachers, Tobias}, title\t\t=\t{Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning Environments}, year\t\t=\t{2025}, doi\t\t=\t{10.48550/ARXIV.2507.00762}, } Maus, T., Atamna, A., & Glasmachers, T.. (2025). Leveraging Genetic Algorithms for Efficient Demonstration Generation in Real-World Reinforcement Learning Environments. http://doi.org/10.48550/ARXIV.2507.00762 SortingEnv: An Extendable RL-Environment for an Industrial Sorting ProcessMaus, T., Zengeler, N., & Glasmachers, T. Bibtex APA Downloads SortingEnv: An Extendable RL-Environment for an Industrial Sorting Process @article{MausZengelerGlasmachers2025, author\t\t=\t{Maus, Tom and Zengeler, Nico and Glasmachers, Tobias}, title\t\t=\t{SortingEnv: An Extendable RL-Environment for an Industrial Sorting Process}, year\t\t=\t{2025}, doi\t\t=\t{10.48550/ARXIV.2503.10466}, } Maus, T., Zengeler, N., & G",
  "content_length": 93700,
  "method": "requests",
  "crawl_time": "2025-12-01 14:39:24"
}