{
  "name": "Ranjay A. Krishna",
  "homepage": "http://www.ranjaykrishna.com/index.html",
  "status": "success",
  "content": "Ranjay Krishna - Home Ranjay Krishna I teach machines to see like people and interact with people. As modern machines struggle to fully conceptualize the visual world, my research bootstraps machine learning  using frameworks from behavioral and social sciences. Bio: Ranjay Krishna is an Assistant Professor at the Allen School of Computer Science & Engineering. He co-directs the RAIVN lab at UW and directs the PRIOR team at Ai2. His research lies at the intersection of computer vision, natural language processing, robotics, and human computer interaction. This research has received best paper, outstanding paper, and orals at CVPR, ACL, CSCW, NeurIPS, UIST, and ECCV, and has been reported by Science, Forbes, the Wall Street Journal, and PBS NOVA. His research has been supported by Google, Apple, Ai2, Amazon, Cisco, Toyota Motor Inc, Toyota Research Institute, NSF, ONR, and Yahoo. He holds a bachelor's degree in Electrical & Computer Engineering and in Computer Science from Cornell University, a master's degree in Computer Science from Stanford University and a Ph.D. in Computer Science from Stanford University. RECENT ​PAPER HIGHLIGHTS[Oct 2025] Our Latte paper received Oral award at EMNLP 2025, awarded to top 1.5% of submissions.[Oct 2025] Our TrajVIT paper received Highlight award at ICCV 2025, awarded to top 5% of submissions.[Jun 2025] Our Molmo paper received Best Paper Honorable Mention at CVPR 2025.[Jun 2025] Our Molmo paper will appear as a Oral at CVPR 2025, awarded to top 0.7% of submissions.[Apr 2025] Our interleaved scene graph paper will appear as a Spotlight at ICLR 2025, awarded to top 5% of submissions ​[Dec 2024] Our Multilingual diversity for LLMs paper will appear as an Spotlist at NeurIPS 2024, awarded to top 5% of submissions.​[June 2024] Our Visual Program Distillation paper will appear as an Oral at CVPR 2024, awarded to top 5% of submissions.​[May 2024] Our Selective Visual Representations paper will appear as a Spotlight at ICLR 2024, awarded to top 5% of submissions.​[Dec 2023] Our DataComp paper will appear as an Oral at NeurIPS 2023, awarded to top (0.6%) submissions.​[Dec 2023] Our Quilt-1M will appear as an Oral at NeurIPS 2023, awarded to top (0.6%) submissions.​[Oct 2023] Our paper on Explanations and human-AI decision making got awarded a Best Paper Honorable Mention at CSCW 2023​[Mar 2023] Our CREPE paper was recognized as a Highlight at CVPR 2023, awarded to top 2.5% of submissions.RECENT TALKS @ CONFERENCES[Jul 2025] Invited talk at CogSci 2025 workshop on Minds in the Making[Jun 2025] Keynote at CVPR 2025 workshop on Harnessing Generative Models for Synthetic Visual Datasets[Jun 2025] Keynote at CVPR 2025 workshop on Generalization in Robotics Manipulation[Jun 2025] Keynote at CVPR 2025 workshop on 3D Vision Language Models for Robotic Manipulation[Jun 2025] Keynote at CVPR 2025 workshop on Demographic Diversity in Computer Vision[Mar 2025] Invited talk at RAISE 2025 seminar series at the University of Washington[Dec 2024] Invited talk at IndoML 2024 Symposium[Dec 2024] Keynote at NeurIPS 2024 workshop on Multimodal Algorithmic Reasoning[Oct 2024] Keynote at ECCV 2024 workshop on Efficient Deep Learning for Foundation Models[Oct 2024] Keynote at ECCV 2024 workshop on Green Foundation Models[Jun 2024] Invited talk at DUB 2024 speaker series at the University of Washington[Jun 2024] Keynote at CVPR 2024 workshop on Evaluation of Generative Foundation Models[Jun 2024] Keynote at CVPR 2024 workshop on Computer Vision with Humans in the Loop[April 2023] Invited DUB seminar talk at the University of Washington[Oct 2023] Keynote at ICCV 2023 workshop on Scene Graphs and Graph Representation Learning[Oct 2023] Keynote at ICCV 2023 workshop on On Closing The Loop Between vision an language[Aug 2023] Distinguished researcher talk on Compositionally at Salesforce AI[July 2023] Talk on Embodied Intelligence at the AAAI 2023 Inaugural Summer Symposium on Embodied Intelligence​​[Jun 2023] Keynote at CVPR 2023 workshop on New Frontiers in Vision and Language Reasoning.​RECENT WORKSHOPS​​[Jun 2025] Synthetic Data for Computer Vision at CVPR 2025​​[Jun 2024] Synthetic Data for Computer Vision at CVPR 2024​​[Oct 2023] International Challenge on Compositional and Multimodal Perception at ICCV 2023 ​[Jul 2023] Artificial Intelligence and Human-Computer Interaction at ICML 2023 ACademic Publications Convergent Functions, Divergent FormsHyeonseong Jeon, Ainaz Eftekhar, Aaron Walsman, Kuo-Hao Zeng, Ali Farhadi, Ranjay KrishnaNeurIPS 2025[pdf] [website] [code] Reinforcing Visual State Reasoning for Multi-Turn VLM AgentsKangrui Wang, Pingyue Zhang, Zihan Wang, Yaning Gao, Linjie Li, Qineng Wang, Hanyang Chen, Yiping Lu, Zhengyuan Yang, Lijuan Wang, Ranjay Krishna, Jiajun Wu, Li Fei-Fei, Yejin Choi, Manling Li NeurIPS 2025[pdf] [website] [docs] [code] Seeking and Updating with Live Visual KnowledgeMingyang Fu, Yuyang Peng, Dongping Chen, Zetong Zhou, Benlin Liu, Yao Wan, Zhou Zhao, Philip S. Yu, Ranjay KrishnaNeurIPS 2025[pdf] [website] [code] [data] MedicalNarratives: Connecting Medical Vision and Language with Localized NarrativesWisdom O. Ikezogwo, Kevin Zhang, Mehmet Saygin Seyfioglu, Fatemeh Ghezloo, Linda Shapiro, Ranjay KrishnaNeurIPS 2025[pdf] [website] LATTE: Learning to Think with Vision SpecialistsZixian Ma, Jianguo Zhang, Zhiwei Liu, Jieyu Zhang, Juntao Tan, Manli Shu, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Caiming Xiong, Ranjay Krishna, Silvio SavareseEMNLP 2025 [EMNLP Oral awarded to top 1.5% of submissions][pdf] Wait, Do We Really Need to \"Wait\"? Towards Training-Free Efficient Reasoning in R1-style ModelsChenlong Wang, Yuanning Feng, Dongping Chen, Zhaoyang Chu, Ranjay Krishna, Tianyi ZhouEMNLP 2025[pdf] GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data GenerationAbhay Deshpande, Yuquan Deng, Arijit Ray, Jordi Salvador, Winson Han, Jiafei Duan, Kuo-Hao Zeng, Yuke Zhu, Ranjay Krishna, Rose HendrixCoRL 2025[pdf] ManiFlow: A Dexterous Manipulation Policy using Flow MatchingGe Yan, Jiyue Zhu, Yuquan Deng, Shiqi Yang, Ri-Zhao Qiu, Xuxin Cheng, Marius Memmel, Ranjay Krishna, Ankit Goyal, Xiaolong Wang, Dieter FoxCoRL 2025[pdf] [website] MultiRef: Controllable Image Generation with Multiple Visual ReferencesRuoxi Chen, Dongping Chen, Siyuan Wu, Sinan Wang, Shiyun Lang, Petr Sushko, Gaoyang Jiang, Yao Wan, Ranjay KrishnaACM MM 2025[pdf] [website] [data] [benchmark] Visual Representations inside the Language ModelBenlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han, Ranjay KrishnaCoLM 2025[pdf] The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong GainsScott Geng, Hamish Ivison, Chun-Liang Li, Maarten Sap, Jerry Li, Ranjay Krishna, Pang Wei Koh CoLM 2025[pdf] SAT: Dynamic Spatial Aptitude Training for Multimodal Language ModelsArijit Ray, Jiafei Duan, Ellis L Brown II, Reuben Tan, Dina Bashkirova, Rose Hendrix, Kiana Ehsani, Aniruddha Kembhavi, Bryan A. Plummer, Ranjay Krishna, Kuo-Hao Zeng, Kate SaenkoCoLM 2025[pdf] One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object TrajectoryChenhao Zheng, Jieyu Zhang, Mohammadreza Salehi, Ziqi Gao, Vishnu Iyengar, Norimasa Kobori, Quan Kong, Ranjay KrishnaICCV 2025 [ICCV Highlight awarded to top 5% of submissions][pdf] Contrastive Flow MatchingGeorge Stoica, Vivek Ramanujan*, Xiang Fan*, Ranjay Krishna, Judy HoffmanICCV 2025[pdf] PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to HistopathologyMehmet Saygin Seyfioglu*, Fatemeh Ghezloo*, Rustin Soraki*, Wisdom O. Ikezogwo*, Beibin Li*, Tejoram Vivekanandan, Joann G. Elmore, Ranjay Krishna, Linda ShapiroICCV 2025[pdf] [website] CoSyn: Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data GenerationYue Yang*, Ajay Patel*, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris Callison-Burch, Ranjay Krishna, Aniruddha Kembhavi, Christopher ClarkACL 2025[pdf] [data] [code] [website] SAM2Act: Integrating Visual Foundation Model with A Memory Architecture for Robotic ManipulationHaoquan Fang, Markus Grotz, Wilbert Pumacay, Yi Ru Wang, Dieter Fox, Ranjay Krishna, Jiafei DuanICML 2025[pdf] [benchmark] [code] [website] [mentioned in AI Index] Unsettling the Hegemony of Intention: Agonistic Image GenerationAndre Ye, Andrew Shaw, Ranjay Krishna, Amy ZhangFaact 2025[pdf] Improving Interpersonal Communication by Simulating Audiences with Language ModelsRyan Liu, Howard Yen, Raja Marjieh, Thomas L. Griffiths, Ranjay KrishnaCogSci 2025[pdf] [code] Perception Tokens Enhance Visual Reasoning in Multimodal Language ModelsMahtab Bigverdi, Zelun Luo, Cheng-Yu Hsieh, Ethan Shen, Dongping Chen, Linda G. Shapiro, Ranjay KrishnaCVPR 2025[pdf] [website] Synthetic Visual GenomeJae Sung Park, Zixian Ma, Linjie Li, Chenhao Zheng, Cheng-Yu Hsieh, Ximing Lu, Khyathi Chandu, Quan Kong, Norimasa Kobori, Ali Farhadi, Yejin Choi, Ranjay KrishnaCVPR 2025[pdf] [website] [dataset] [model] [code] Eval3D: Interpretable and Fine-grained Evaluation for 3D GenerationShivam Duggal, Yushi Hu, Oscar Michel, Aniruddha Kembhavi, William T. Freeman, Noah A. Smith, Ranjay Krishna, Antonio Torralba, Ali Farhadi, Wei-Chiu MaCVPR 2025[pdf] RealEdit: Reddit Edits As a Large-scale Empirical Dataset for Image TransformationsPetr Sushko, Ayana Bharadwaj, Zhi Yang Lim, Vasily Ilin, Ben Caffee, Dongping Chen, Mohammadreza Salehi, Cheng-Yu Hsieh, Ranjay KrishnaCVPR 2025[pdf] NVILA: Efficient Frontier Visual Language ModelsZhijian Liu, Ligeng Zhu, Baifeng Shi, Zhuoyang Zhang, Yuming Lou, Shang Yang, Haocheng Xi, Shiyi Cao, Yuxian Gu, Dacheng Li, Xiuyu Li, Haotian Tang, Yunhao Fang, Yukang Chen, Cheng-Yu Hsieh, De-An Huang, An-Chieh Cheng, Jinyi Hu, Sifei Liu, Ranjay Krishna, Pavlo Molchanov, Jan Kautz, Hongxu Yin, Song Han, Yao LuCVPR 2025[pdf] [website] [code] [demo] One Diffusion to Generate Them AllDuong H. Le, Tuan Pham, Sangho Lee, Christopher Clark, Aniruddha Kembhavi, S",
  "content_length": 33429,
  "method": "requests",
  "crawl_time": "2025-12-01 14:15:44"
}