{
  "name": "Yue Zhao 0016",
  "homepage": "https://yzhao062.github.io",
  "status": "success",
  "content": "Yue Zhao Yue Zhao Assistant Professor Thomas Lord Department of Computer Science School of Advanced Computing University of Southern California Los Angeles, CA, USA Email: Google Scholar | Short Bio | GitHub | LinkedIn | Áü•‰πé (ÂæÆË∞É) | Â∞èÁ∫¢‰π¶ | ÂæÆ‰ø° | 300k+ followers in total 22k+ GitHub ‚≠ê Top 700 Worldwide External Collaboration and Employment. I am open to external opportunities for invited talks, research collaborations, and employment (only on the part-time/advising/visiting basis). Let us connect by email. I frequently visit major cities, e.g., Seattle, NYC, Chicago, Boston, Atlanta, and Bay Area to meet people, give talks, and host social events. Lab Openings. We are warmly welcoming new members to the FORTIS Lab! Ph.D. Students (0 or 1 Ph.D. student for Fall 2026 with prerequisite): Future Ph.D. students should be comparable to our 1st year Ph.D. students -- see FORTIS Lab. We prioritize the students who I have worked with. I am unlikely to hire Ph.D. students if not receiving new funding by Feb 2026; please use your valuable quota carefully. Research Collaborators/Interns (Any Time, All Year Round): We welcome both undergraduate and graduate interns from USC and other institutions. We will provide GPUs/API keys for the project. Preferred candidates are located in North America for time zone compatibility. I do not hire in-person summer interns -- I am enjoying summer and working remotely :) Application Process: To apply for either opportunities, complete the Application Form, email fortis@usc.edu after submitting the form, and review the FORTIS Lab website for more information before reaching out. Research Interests: My research builds reliable, robust, and scalable AI that advances science and benefits society. I focus on developing rigorous algorithmic foundations, advancing safety and interpretability in large models, and creating open systems that connect research with real-world impact. Reliable AI Foundations: Detecting the Unexpected. I develop fundamental algorithms and benchmarks for detecting rare, unseen, or abnormal patterns across modalities. This work unifies anomaly detection, out-of-distribution (OOD) detection, and automated model selection to ensure that AI systems remain reliable and predictable under uncertainty. Keywords: Anomaly Detection, OOD Detection, Model Selection, Robust Learning Trust & Safety in Large Language Models and Agents. I study how to make large models and agentic systems safe, interpretable, and aligned under real-world conditions. My work investigates hallucination mitigation, privacy and security safeguards, jailbreak prevention, and dynamic evaluation frameworks for trustworthy reasoning and decision-making. Keywords: LLM Safety, Hallucination Mitigation, Privacy & Security, Trust Evaluation Foundation Models for Science & Society. I apply foundation models and generative AI to scientific and societal domains, addressing challenges in climate forecasting, healthcare, and political or social decision-making. These efforts combine domain knowledge with foundation model reasoning to accelerate discovery and policy insights. Keywords: AI for Science, Generative AI, Decision Modeling, Computational Social Science Scalable, Automated & Open AI Systems. I create efficient and reproducible machine learning systems that enable large-scale, open, and automated deployment of AI. My open-source work emphasizes distributed inference, workflow automation, and user-centric design, promoting transparent and accessible AI research for academia and industry alike. Keywords: ML Systems, Automated ML, Open-source AI, Distributed Computing Biography. ‚úà News and Travel [Nov 2025] üéâOur work on explainability‚Äìextractability tradeoffs in MLaaS wins the Second Prize CCC Award at the IEEE ICDM 2025 BlueSky Track!. [Nov 2025] Our paper on mitigating hallucinations in LLMs using causal reasoning has been accepted to AAAI 2026! See our Preprint. [Nov 2025] üéâLLM-augmented transformers (TyphoFormer) for typhoon forecasting wins the Best Short Paper Award at ACM SIGSPATIAL 2025; see our Preprint! [Oct 2025] Two new papers accepted to IJCNLP-AACL 2025 Findings ‚Äî AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection and LLM-Empowered Patient-Provider Communication (a data-centric survey on clinical applications of LLMs). Congratulations to all! [Oct 2025] üéâCongratulations to our Ph.D. students Yuehan Qin and Haoyan Xu for successfully passing their qualifying exams! Both of them achieved this after 1.5 years transferring to our group. We are so proud of their accomplishments and excited for their continued research journeys and graduation! [Sep 2025] üéâCongratulations to Shawn Li for being selected as an Amazon ML Fellow (2025‚Äì2026). The fellowship recognizes his strong research achievements as a PhD student and will further accelerate his work in secure and trustworthy machine learning. [Sep 2025] New collaborative NeurIPS 2025 paper ‚ÄúDyFlow‚Äù proposes a dynamic workflow framework for agentic reasoning with LLMs. [Aug 2025] We have two new papers accepted to EMNLP Findings 2025: one on causal methods for hallucination mitigation (Treble Counterfactual VLMs) and another introducing a benchmark for NLP anomaly detection (NLP-ADBench). See our Treble Preprint and NLP-ADBench Preprint! üèÖ Awards and Grants As Principal Investigator (August 2023 onwards) Second Prize CCC Award, IEEE ICDM BlueSky Track, 2025 Best Short Paper, ACM SIGSPATIAL, 2025 Capital One Research Awards, 2024 Amazon Research Awards, 2024 Best Paper, KDD Resource-Efficient Learning Workshop, 2024 NSF Award 1, NSF Award 2, 2024, NSF Award 3, 2025 Google Cloud Research Innovators, 2024 AAAI New Faculty Highlights, 2024 Prior to Principal Investigator Role (Before August 2023) Meta AI4AI Research Award (student co-PI), 2022 Norton Labs Graduate Fellowship, 2022 CMU Presidential Fellowship, 2019-2020 Mantei/Mae Academic Achievement Award, 2011-2015",
  "content_length": 5937,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:31"
}