{
  "name": "Alexey Tumanov",
  "homepage": "https://www.cc.gatech.edu/~atumanov",
  "status": "success",
  "content": "Alexey Tumanov Skip to: Site menu | Main content Alexey Tumanov Associate Professor School of Computer Science College of Computing Georgia Institute of Technology KACB 3346 atumanov[at]gatech[dot]edu [Google Scholar] [arXiv] [DBLP] [GitHub] [Twitter] [ACM] Brief Bio Alexey Tumanov is a tenured Associate Professor of Computer Science at Georgia Tech, where he directs the Systems for Artificial Intelligence Lab ( SAIL ), which has consistently produced graduates going to NVIDIA, Meta, Microsoft, Apple, Google, Cisco, OpenAI. The lab’s research agenda broadly focuses on distributed systems support for soft real-time Machine Learning (SRTML) as well as Large Foundation Model inference and reasoning support. Tumanov obtained his PhD from Carnegie Mellon University in 2016, where he developed the first theoretical framework for declarative spatio-temporal resource allocation with support for combinatorial soft constraints, funded by a highly selective NSERC (Canadian NSF) Alexander Graham Bell Canada Graduate Scholarship (NSERC CGS-D3) , the ISTC-CC Fellowship, and the Parallel Data Lab (PDL) Consortium. Alexey completed his Postdoctoral Fellowship at UC Berkeley RiseLab , contributing to the design, architecture, and development of several successful open source platforms, including Ray, and Ray Serve. Tumanov is a recipient of the Best Student Paper Award for his dissertation work published in EuroSys 2016, the Test of Time Award at the ACM Symposium on Cloud Computing (SoCC’21). Georgia Tech’s College of Computing Outstanding Junior Faculty Teaching Award in 2024, and Junior Faculty Research Award in 2025. Research Synopsis My current research interest is in systems support and resource management for distributed machine learning frameworks and applications. Specifically, I am currently working on distributed systems and scheduling algorithms for soft-real time Machine Learning inference and co-scheduling ML inference and online training. This builds on the body of research and development at Carnegie Mellon modeling, designing, and developing abstractions, primitives, algorithms and systems for a general resource management framework with support for static and dynamic heterogeneity, hard and soft placement constraints, time-varying resource capacity guarantees, and combinatorial constraints in heterogeneous resource contexts. Cost- and latency-efficient resource management is fundamental to commoditizing Machine Learning. [ Back to top ] SAIL: Systems for Artificial Intelligence Lab @ GT CURRENT PhD Students Payman Behnam : ECE PhD student, MLCommons Rising Star'25, NGF'24, QIF'23 Amey Agrawal : SCS PhD student Debopam Sanyal : SCS PhD student Dhruv Garg : SCS PhD student, co-advised with Ada Gavrilovska Elton Pinto : SCS PhD student Anirudha Agrawal : SCS PhD student Masters Students Please see the SAIL Lab Team for most up-to-date details. Undergraduate Superstars Please see the SAIL Lab Team for most up-to-date details. SAIL ALUMNI PhD Students Alind Khare : SCS PhD, Senior Research Scientist, M365 Research, Microsoft Yanbo Xu : CSE PhD, co-advised with Chao Zhang, Microsoft HealthAI Masters Students Aditya Annavajjala : MSCS GRA Animesh Agrawal : BSMS CS student Monish Ramadoss : MSCS student Sameer Reddy : MSCS student Pranav Gadikar : MSCS student Anshul Ahluwalia : MSCS student Rohit Das : MSCS student Srihas Yarlagadda : MSCS student Brian Model : BSMS CS student Snigdha Grandhi : MSCS with SAIL, now SDE-3, cloud tech division with Adobe Pranavi Bajjuri : MSCS GRA with SAIL, now SWE@Confluent Irene Lee : Software Engineering Intern at AnyScale Meghavarnika Budati : MSCS, now a Software Engineer at Snowflake Manas Sahni : MSCS, now at NVIDIA, Systems for ML Software Engineer Shreya Varshini : MSCS, now at Facebook, Hardware Insights Engineer Luis Pastrana : MSCS, now at Citadel Securities Undergraduate Students Varun Mehrotra : Undergraduate Research Assistant Aditi Arun : Undergraduate Research Assistant, ML 4 Health Khang Vu : Undergrad, now EW/Avionics Software Researcher at Georgia Tech Research Institute Shiva Devarajan : Undergrad Shreyas Casturi : Undergrad [ Back to top ] Publications [EuroSys26] Maya: Optimizing Deep Learning Training Workloads using GPU Runtime Emulation Srihas Yarlagadda*, Amey Agrawal*, Elton Pinto, Hakesh Darapaneni, Mitali Meratwal, Shivam Mittal, Pranavi Bajjuri, Srinivas Sridharan, Alexey Tumanov To appear in Proc. of the 21st ACM European Conference on Computer Systems (EuroSys'26), April 2026. [Abstract] [PDF] [arXiv] [BibTeX] @misc{maya-eurosys26, title={Maya: Optimizing Deep Learning Training Workloads using Emulated Virtual Accelerators}, author={Srihas Yarlagadda and Amey Agrawal and Elton Pinto and Hakesh Darapaneni and Mitali Meratwal and Shivam Mittal and Pranavi Bajjuri and Srinivas Sridharan and Alexey Tumanov}, year={2025}, eprint={2503.20191}, archivePrefix={arXiv}, primaryClass={cs.LG}, url={https://arxiv.org/abs/2503.20191}, } [CCS25] VillainNet: Targeted Poisoning Attacks Against SuperNets Along the Accuracy-Latency Pareto Frontier D. Oygenblik, A. Vemulapalli, A. Agrawal, D. Sanyal, Alexey Tumanov, Brendan Saltaformaggio To appear in Proc. of the 32nd ACM Conference on Computer and Communications Security (ACM CCS 2025) [Abstract] [PDF] [BibTeX] TBD [OpSysRev25] EMPIRIC: Exploring Missing Pieces in KV Cache Compression for Reducing Computation, Storage, and Latency in Long-Context LLM Inference Payman Behnam, Yaosheng Fu, Ritchie Zhao, Po-An Tsai, Zhiding Yu, Alexey Tumanov ACM SIGOPS Operating Systems Review, Volume 59, Issue 2, July 2025. [Abstract] [PDF] [DOI] [BibTeX] @article{sigops-osr25-empiric, author = {Behnam, Payman and Fu, Yaosheng and Zhao, Ritchie and Tsai, Po-An and Yu, Zhiding and Tumanov, Alexey}, title = {EMPIRIC: Exploring Missing Pieces in KV Cache Compression for Reducing Computation, Storage, and Latency in Long-Context LLM Inference}, year = {2025}, issue_date = {July 2025}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {59}, number = {2}, issn = {0163-5980}, url = {https://doi.org/10.1145/3759441.3759448}, doi = {10.1145/3759441.3759448}, journal = {SIGOPS Oper. Syst. Rev.}, month = aug, pages = {46–54}, numpages = {9} } [OpSysRev25] Efficient LLM Inference via Chunked Prefills Amey Agrawal, Nitin Kedia, Ashish Panwar, Jayashree Mohan, Nipun Kwatra, Bhargav S. Gulavani, Alexey Tumanov, Ramachandran Ramjee ACM SIGOPS Operating Systems Review, Volume 59, Issue 2, July 2025. [Abstract] [PDF] [DOI] [BibTeX] @article{sigops-osr25-sarathi, author = {Agrawal, Arney and Kedia, Nitin and Panwar, Ashish and Mohan, Jayashree and Kwatra, Nipun and Gulavani, Bhargav S. and Tumanov, Alexey and Ramjee, Ramachandran}, title = {Efficient LLM Inference via Chunked Prefills}, year = {2025}, issue_date = {July 2025}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {59}, number = {2}, issn = {0163-5980}, url = {https://doi.org/10.1145/3759441.3759444}, doi = {10.1145/3759441.3759444}, journal = {SIGOPS Oper. Syst. Rev.}, month = aug, pages = {9–16}, numpages = {8} } [OpSysRev25] Toward Weight Sharing Paradigm for Efficient AI: Training and Inference Serving Payman Behnam, Alind Khare, Dhruv Garg, Alexey Tumanov ACM SIGOPS Operating Systems Review, Volume 59, Issue 2, July 2025. [Abstract] [PDF] [DOI] [BibTeX] @article{sigops-osr25-wsdnn, author = {Behnam, Payman and Khare, Alind and Garg, Dhruv and Tumanov, Alexey}, title = {Toward Weight Sharing Paradigm for Efficient AI: Training and Inference Serving}, year = {2025}, issue_date = {July 2025}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {59}, number = {2}, issn = {0163-5980}, url = {https://doi.org/10.1145/3759441.3759447}, doi = {10.1145/3759441.3759447}, journal = {SIGOPS Oper. Syst. Rev.}, month = aug, pages = {34–45}, numpages = {12} } [ICML25] RocketKV: Accelerating Long-Context LLM Inference via Two-stage KV Cache Compression Payman Behnam*, Yaosheng Fu*, Ritchie Zhao, Po-An Tsai, Zhiding Yu, Alexey Tumanov In Proc. of 42nd International Conference on Machine Learning (ICML'25), Vancouver, 2025. [Abstract] [OpenReview] [PDF] [arxiv] [BibTeX] @inproceedings{rocketkv-icml25, title={Rocket{KV}: Accelerating Long-Context {LLM} Inference via Two-Stage {KV} Cache Compression}, author={Payman Behnam and Yaosheng Fu and Ritchie Zhao and Po-An Tsai and Zhiding Yu and Alexey Tumanov}, booktitle={Forty-second International Conference on Machine Learning}, year={2025}, url={https://openreview.net/forum?id=RyOpooIxDF} } [NSDI25] SuperServe: Fine-grained Inference Serving for Unpredictable Workloads Alind Khare, Dhruv Garg, Sukrit Kalra, Snigdha Grandhi, Ion Stoica, Alexey Tumanov In Proc. of the 22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI'25), Philadelphia, USA, 2025. [Abstract] [PDF] [arXiv] [video] [BibTeX] @inproceedings{superserve-nsdi25, author = {Alind Khare and Dhruv Garg and Sukrit Kalra and Snigdha Grandhi and Ion Stoica and Alexey Tumanov}, title = {{SuperServe}: {Fine-Grained} Inference Serving for Unpredictable Workloads}, booktitle = {22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25)}, year = {2025}, isbn = {978-1-939133-46-5}, address = {Philadelphia, PA}, pages = {739--758}, url = {https://www.usenix.org/conference/nsdi25/presentation/khare}, publisher = {USENIX Association}, month = {apr} } [TMLR25] ∇QDARTS: Quantization as an Elastic Dimension to Differentiable Neural Architecture Search Payman Behnam*, Uday Kamal*, Sanjana Vijay Ganesh, Zhaoyi Li, Michael Andrew Jurado, Alind Khare, Igor Fedorov, Gaowen Liu, Alexey Tumanov Transactions in Machine Learning Research (TMLR), 2025. [openreview] [pdf] [code] [BibTeX] @article{qdarts-tmlr25, title={\\ensuremath{\\nabla}{QDARTS}: Quantization as an Elastic Dimension to Differentiable {NAS}}, author={Payman Behnam and Uday Kamal and Sanjana Vijay Ganesh an",
  "content_length": 49550,
  "method": "requests",
  "crawl_time": "2025-12-01 12:54:09"
}