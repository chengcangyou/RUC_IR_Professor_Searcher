{
  "name": "HeuiSeok Lim",
  "homepage": "http://nlp.korea.ac.kr",
  "status": "success",
  "content": "NLP&AI Lab - NLP&AI Lab News Highlights K-AI 연구실 선정 본 연구실이 과학기술정보통신부 주관 ‘독자 AI 파운데이션 모델’ 개발 사업에서 K‑AI 타이틀이 부여된 5대 정예 연구실 중 하나로 선정되었습니다. (https://n.news.naver.com/article/018/0006081401?sid=105) KULLM3 공개 본 연구실이 한국어 생성 능력에 특화된 KULLM3 모델을 공개했습니다.(https://www.aitimes.kr/news/articleView.html?idxno=30926) EMNLP 2025 논문 11편 채택 본 연구실의 논문 11편이 자연어처리 분야 최상위 국제 학술대회인 EMNLP 2025에 최종 채택되었습니다. (https://www.newsis.com/view/NISX20241202_0002980099) Latest News 한글 및 한국어 정보처리 학술대회 (HCLT) 2025 최우수 논문상 수상 본 연구실의 이정섭, 김민혁, 윤정호, 홍성태, 장영준, 이승윤 연구원, 서재형, 박찬준 박사의 “KULLM-RAG: 지능형 자가 검증 기반 RAG 특화 대규모 언어 모델” 논문이 HCLT 2025에서 최우수 논문상을 수상했습니다. EMNLP 2025 13편 게재 본 연구실의 서재형 박사, 문현석 연구원의 “The Impact of Negated Text on Hallucination with Large Language Models” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 어수경 연구원, 박찬준 연구교수의 “Mixture-of-Clustered-Experts: Advancing Expert Specialization and Generalization in Instruction Tuning” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 김진성, 구선민 연구원의 “Semantic Inversion, Identical Replies: Revisiting Negation Blindness in Large Language Models” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 문현석, 홍성태 연구원, 서재형 박사의 “Metric Calculating Benchmark: Complicate Instruction Following Benchmark for Large Language Models” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 김동준, 심규호, 전용찬, 김민혁 연구원, 박찬준 연구교수의 “Benchmark Profiling: Mechanistic Diagnosis of LLM Benchmarks” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 김민혁, 이승윤 연구원의 “TORSO: Template-Oriented Reasoning Towards General Tasks” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 박찬준 연구교수, 서재형 박사의 “MultiDocFusion : Hierarchical and Multimodal Chunking Pipeline for Enhanced RAG on Long Industrial Documents” 논문이 EMNLP 2025 Main에 Accept 되었습니다. 본 연구실의 서재형 박사, 정다현, 이재욱, 전용찬, 김동준 연구원의 “KoLEG: On-the-Fly Korean Legal Knowledge Editing with Continuous Retrieval” 논문이 EMNLP 2025 Findings에 Accept 되었습니다. 본 연구실의 문현석 연구원, 서재형 박사, 구선민, 김진성 연구원의 “LimaCost: Data Valuation for Instruction Tuning of Large Language Models” 논문이 EMNLP 2025 Findings에 Accept 되었습니다. 본 연구실의 구선민, 김진성 연구원, 박찬준 연구교수의 “HAWK: Highlighting Entity-aware Knowledge for Alleviating Information Sparsity in Long Contexts” 논문이 EMNLP 2025 Findings에 Accept 되었습니다. 본 연구실의 이재욱, 정다현 연구원의 “StepKE: Stepwise Knowledge Editing for Multi-Hop Question Answering” 논문이 EMNLP 2025 Findings에 Accept 되었습니다. 본 연구실의 박찬준 연구교수의 “ZEBRA: Leveraging Model-Behavioral Knowledge for Zero-Annotation Preference Dataset Construction” 논문이 EMNLP 2025 Findings에 Accept 되었습니다. 본 연구실의 박찬준 연구교수의 “Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching” 논문이 EMNLP 2025 Findings에 Accept 되었습니다. ICLR 2025 1편 게재 본 연구실의 서재형 연구원의 “K-HALU: Multiple Answer Korean Hallucination Benchmark for Large Language Models” 논문이 \bICLR 2025에 Accept 되었습니다. ACL 2025 5편 게재 본 연구실의 이정섭, 홍성태, 문현석 연구원의 “Cross-Lingual Optimization for Language Transfer in Large Language Models” 논문이 \bACL 2025 Main에 Accept 되었습니다. 본 연구실의 박찬준 연구교수의 “Rethinking KenLM: Good and Bad Model Ensembles for Efficient Text Quality Filtering in Large Web Corpora” 논문이 ACL 2025 Main에 Accept 되었습니다. 본 연구실의 문현석, 서재형 연구원의 “Call for Rigor in Reporting Quality of  Instruction Tuning Data” 논문이 ACL 2025 Main에 Accept 되었습니다. 본 연구실의 이승윤, 홍성태, 문현석 연구원의 “Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer” 논문이 ACL 2025 Findings에 Accept 되었습니다. 본 연구실의 전용찬, 김민혁, 김동준 연구원, 박찬준 연구교수의 “Enhancing Automatic Term Extraction in Large Language Models via Syntactic Retrieval” 논문이 ACL 2025 Findings에 Accept 되었습니다. NAACL 2025 Industry 4편 게재 본 연구실의 박찬준 연구교수의 “Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs” 논문이 NAACL 2025 \bIndustry Track에 Accept 되었습니다. 본 연구실의 박찬준 연구교수의 “Understanding LLM Development Through Longitudinal Study: Insights from the Open Ko-LLM Leaderboard” 논문이 NAACL 2025 \bIndustry Track에 Accept 되었습니다. 본 연구실의 박제윤 석사, 박찬준 연구교수의 “CharacterGPT: A Persona Reconstruction Framework for Role-Playing Agents” 논문이 NAACL 2025 \bIndustry Track에 Accept 되었습니다. 본 연구실의 박찬준 연구교수의 “Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models” 논문이 NAACL 2025 \bDemo Track에 Accept 되었습니다. ACL 2025 Industry 2편 게재 본 연구실의 심규호, 홍성태 연구원의 “REVISE: A Framework for Revising OCRed text in Practical Information Systems with Data Contamination Strategy” 논문이 \bACL 2025 Industry-Oral Track에 Accept 되었습니다. 본 연구실의 장영준, 홍성태, 손준영, 박찬준 연구교수의 “From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems” 논문이 \bACL 2025 SRW Track에 Accept 되었습니다. COLING 2025 Industry 1편 게재 본 연구실의 박찬준 연구교수의 “sDPO: Don’t Use Your Data All at Once” 논문이 COLING 2025 \bIndustry Track에 Accept 되었습니다. NAACL 2025 5편 게재 본 연구실의 박찬준 연구교수의 “LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs” 논문이 NAACL 2025 \bMain에 Accept 되었습니다. 본 연구실의 정다현, 서재형, 이재욱 연구원, 박찬준 연구교수의 “CoME: A Unlearning-based Approach to Conflict-free Model Editing” 논문이 NAACL Main에 Accept 되었습니다. 본 연구실의 문현석, 서재형, 이승윤 연구원, 박찬준 연구교수의 “Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models” 논문이 NAACL 2025 \bFindings에 Accept 되었습니다. 본 연구실의 정다현, 이승윤, 문현석 연구원, 박찬준 연구교수의 “FLEX: A Benchmark for Evaluating Robustness of Fairness in Large Language Models” 논문이 NAACL 2025 Findings에 Accept 되었습니다. 본 연구실의 박찬희, 문현석 연구원, 박찬준 연구교수의 “MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation” 논문이 NAACL 2025 Findings에 Accept 되었습니다. 박찬준 박사 숭실대학교 교수 임용 본 연구실의 박찬준 박사가 우수한 연구 업적을 인정받아 2025년 9월부로 숭실대학교 소프트웨어학과 교수로 임용되었습니다. COLING 2025 2편 게재 본 연구실의 홍성태, 이승윤, 문현석 연구원의 “MIGRATE: Cross-Lingual Adaptation of Domain-Specific LLMs through Code-Switching and Embedding Transfer” 논문이 COLING 2025에 Accept 되었습니다. 박찬준 연구교수의 “Representing the Under-Represented: Cultural and Core Capability Benchmarks for Developing Thai Large Language Models” 논문이 COLING 2025에 Accept 되었습니다. Expert Systems With Applications 1편 게재 본 연구실의 손수현 연구원, 박찬준 연구교수, 이정섭 연구원, 이찬희 박사, 장윤나, 서재형 연구원, 임정우 박사의 “An Analysis on Language Transfer of Pre-trained Language Model with Cross-lingual Post-training” 논문이 Top-tier 저널인 Expert Systems with Applications에 Accept 되었습니다. See More EMNLP 2024 Industry 3편 게재 본 연구실의 박찬준 박사의 “Evalverse: Unified and Accessible Library for Large Language Model Evaluation” 논문이 EMNLP 2024 Demo Track에 Accept 되었습니다. 본 연구실의 박찬준 박사의 “SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models” 논문이 EMNLP 2024 Industry Track에 Accept 되었습니다. 본 연구실의 홍성태, 신중민, 서재형, 이태민 연구원의 “Intelligent Predictive Maintenance RAG framework for Power Plants: Enhancing QA with StyleDFS and Domain Specific Instruction Tuning” 논문이 EMNLP 2024 Industry Track에 Accept 되었습니다. Applied Intelligence 1편 게재 본 연구실의 손수현, 임정우, 구선민, 김진성 연구원의 “A Large-Scale Dataset for Korean Document-level Relation Extraction from Encyclopedia Texts” 논문이 Applied Intelligence에 Accept 되었습니다. 고려대학교 정보대학 컴퓨터학과 우수논문상 3장 수상 본 연구실의 어수경 연구원이 고려대학교 정보대학 컴퓨터학과 우수 논문상을 수상하였습니다. 본 연구실의 구선민 연구원이 고려대학교 정보대학 컴퓨터학과 우수 논문상을 수상하였습니다. 본 연구실의 임정우 연구원이 고려대학교 정보대학 컴퓨터학과 우수 논문상을 수상하였습니다. LREC-COLING 2024 2편 게재 본 연구실 및 연구실 출신의 어수경, 임정우, 박찬준 박사 (Upstage), 문현석, 서재형, 연구원의 “KNOTICED: A Dataset for Critical Error Detection in English-Korean Machine Translation” 논문이 LREC-COLING 2024에 Accept 되었습니다. 본 연구실 및 연구실 출신의 이승윤, 박찬준 박사 (Upstage), 정다현, 문현석, 서재형, 어수경 연구원의 “Leveraging Pre-existing Resources for Data-Efficient Counter-Narrative Generation in Korean” 논문이 LREC-COLING 2024에 Accept 되었습니다. 한글 및 한국어 정보처리 학술대회 (HCLT) 2022 19편 게재 본 연구실의 어수경, 구선민, 정다현 연구원, 박찬준 박사, 서재형, 문현석 연구원의 “KoCED: 윤리 및 사회적 문제를 초래하는 기계번역 오류 탐지를 위한 학습 데이터셋” 논문이 제34 회 한글 및 한국어 정보처리 학술대회 (HCLT 2022)의 우수논문상으로 선정되었습니다. 본 연구실의 임정우, 손준영, 김진성, 허윤아, 서재형, 장윤나 연구원의 “상호참조 정보와 대화 그래프를 활용한 대화 관계추출 모델” 논문이 제34회 한글 및 한국어 정보 처리 학술대회 (HCLT 2022)의 우수논문상으로 선정되었습니다. EMNLP 2023 6편 게재 본 연구실의 서재형, 문현석, 이재욱, 어수경, 박찬준 연구원의 “CHEF in the Language Kitchen: A Generative Data Augmentation Leveraging Korean Morpheme Ingredients” 논문이 자연어처리 Top-tier conference인 EMNLP 2023 Main에 Accept 되었습니다. 본 연구실의 손준영, 김진성, 임정우, 장윤나 연구원의 “Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction” 논문이 자연어처리 Top-tier conference인 EMNLP 2023 Findings에 Accept 되었습니다. 본 연구실의 장윤나, 손수현, 이정우, 손준영, 임정우, 문현석, 양기수 연구원의 “Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations” 논문이 자연어처리 Top-tier conference인 EMNLP 2023 Main에 Accept 되었습니다. 본 연구실의 천창우, 서재형 연구원의 “CReTIHC: Designing Causal Reasoning Tasks about Temporal Interventions and Hallucinated Confoundings” 논문이 자연어처리 Top-tier conference인 EMNLP 2023 Findings에 Accept 되었습니다. 본 연구실의 임정우, 강명훈, 김진성, 김정욱, 허윤아 연구원의 “Beyond Candidates: Adaptive Dialogue Agent Utilizing Persona and Knowledge” 논문이 자연어처리 Top-tier conference인 EMNLP 2023 Findings에 Accept 되었습니다. 본 연구실의 구선민, 박찬준, 김진성, 서재형, 어수경, 문현석 연구원의 “KEBAP: Korean Error Explainable Benchmark Dataset for ASR and Post-processing” 논문이 자연어처리 Top-tier conference인 EMNLP 2023 Main에 Accept 되었습니다. Transactions on Audio, Speech and Language Processing 1편 게재 본 연구실 임정우, 황태선, 이동엽 연구원의 “Adaptive Multi-Domain Dialogue State Tracking on Spoken Conversations” 논문이 Transactions on Audio, Speech and Language Processing에 Accept 되었습니다. COLING 2022 Workshop 개최 본 연구실의 장윤나, 임정우, 허윤아, 손수현 연구원 및 임희석 교수님, 김승룡 교수님의 주도하에 “The 1st Workshop on Customized Chat Grounding Persona and Knowledge”를 성공적으로 개최하였습니다. EMNLP 2022 1편 게재 본 연구실의 임정우, 강명훈, 허윤아, 김진성, 장윤나 연구원의 “You Truly Understand What I Need: Intellectual and Friendly Dialog Agents grounding Persona and Knowledge” 논문이 자연어처리 Top-tier conference인 EMNLP2022의 findings에 Accept되었습니다. 한글 및 한국어 정보처리 학술대회 (HCLT) 2024 20편 게재 본 연구실의 정다현 연구원, 박찬준 박사의 “대규모 언어 모델의 지식 편집을 위한 지식 삭제 기반 접근법 연구” 논문이 제36 회 한글 및 한국어 정보처리 학술대회 (HCLT 2024)의 우수논문상으로 선정되었습니다. 본 연구실의 서재형 연구원의 “부정형 텍스트와 거대언어모델의 새로운 환각 현상” 논문이 제36 회 한글 및 한국어 정보처리 학술대회 (HCLT 2024)의 우수논문상으로 선정되었습니다. 본 연구실의 김민혁 연구원의 “SelQ: 한국어 Instruction-tuned 모델의 선택적 양자화” 논문이 제36 회 한글 및 한국어 정보처리 학술",
  "content_length": 16582,
  "method": "requests",
  "crawl_time": "2025-12-01 13:20:17"
}