{
  "name": "Shiry Ginosar",
  "homepage": "https://shiry.ttic.edu",
  "status": "success",
  "content": "Shiry Ginosar - Homepage shiry at ttic dot edu Google Scholar / Twitter / BlueSky Shiry Ginosar I am an Assistant Professor at TTIC where I work at the intersection of computer vision, machine learning, and artificial intelligence. I hold a part-time faculty position at the University of Chicago's CS department, and I am a member of the Global Research Centre for Diverse Intelligences. Most recently, I spent a couple of years at Google DeepMind as a Visiting Faculty Researcher. Previously, I was a postdoctoral fellow at the Simons Institute for the Theory of Computing and a Computing Innovation postdoctoral fellow at UC Berkeley, advised by Jitendra Malik. I completed my Ph.D. in Computer Science at UC Berkeley under the supervision of Alyosha Efros. Before joining the Computer Vision group, I was part of Bjoern Hartmann's Human-Computer Interaction lab at Berkeley. Earlier in my career, I was a Visiting Scholar at the CS Department of Carnegie Mellon University with Luis von Ahn and Manuel Blum in Human Computation. Between my academic roles, I spent four years at Endeca as a Senior Software Engineer. My research explores grounded visual understanding. I have worked on conditional video synthesis in its very early days, introduced data-driven methods to artifical social intelligence, and developed several visual data mining methods. My work has been covered by The New Yorker, The Wall Street Journal, and the Washington Post, amongst others. My work has been featured on PBS NOVA, exhibited at the Israeli Design Museum and is part of the permanent collection of the Deutsches Museum. My research work inspired the founding of Sway, a startup acquired by Roblox. See here for an official bio. News üí´ Recruting students! üí´ I am recruiting exceptional Ph.D. students & postdocs with an adventurous soul for my lab. We aim to understand intelligence one pixel at a time, inspired by psychology, neuroscience, language, robotics, and the arts. If joining a small elite force of advanced computer science research in a friendly and welcoming environment is what you are looking for, please apply! I am actively looking for exceptional undergraduate students in their second and third year of the U Chicago CS/Math/Stats programs who have excelled in the Machine Learning and/or Computer Vision classes. If you are interested in a research position and think you are qualified, do send me a note! I recently organized and chaired a Summer Cluster at the Simons Institute for the Theory of Computing at UC Berkeley on studying intelligence from a fundamental scientific viewpoint, bringing together top AI, Psychology, and Neuroscience researchers. Talk recordings: workshop 1 on lower-level capabilities workshop 2 on higher-level capabilities Artificial Social Intelligence involves the data-driven predictive modeling of social situations. I initiated a series of workshops on this emerging area at leading computer vision conferences: CVPR 2022 ICCV 2023 ECCV 2024 ICCV 2025 Research Group Our work is driven by a central question: how can we understand human and artificial intelligence one pixel at a time? While rooted in machine perception, our approach is deeply interdisciplinary, drawing from Psychology, Neuroscience, and the arts. Affiliated Research Assistant Professors Kaylene Stocking Graduate Students Uriel Barron Affiliated Graduate Students Eunice Yiu, Neerja Thakkar Former Affiliates and Visitors Sanjay Subramanian (PhD), Evonne Ng (PhD, Now @ Facebook Reality Labs), Jasmine Collins (PhD), Vivien Nguyen (MA, Now @ Princeton), Varsha Ramakrishnan (Undergrad), Gefen Kohavi (Undergrad), Amir Bar (MA, PhD TAU+UC Berkeley, Now @ MetaAI), Caroline Mai Chan (Undergrad, Now @ MIT), Hemang Jeetendra Jangle (Undergrad), Daniel Tsai (Undergrad), Crystal Lee (Undergrad), Kate Rakelly (Undergrad, PhD UC Berkeley), Brian Yin (Undergrad), Sarah Sachs (Undergrad), Timothy Brown (Undergrad), Luis Fernando de Pombo (Undergrad) Teaching TTIC 31270: Generative Models, Art, and Perception (Fall 2025) Recent Talks What Do Vision and Vision-Language Models Really Know About the World?, ICML 2025. What is the right \"token\" for next-token visual prediction? (Recorded), Simons Institute for the Theory of Computing, June 2024. Social behavior prediction from video observations. (Recorded), Simons Institute for the Theory of Computing, June 2024. Selected Publications See Google Scholar for the full list. Evaluating Video Models on Forecasting Tasks The future is not certain! How should we properly evaluate forecasting? Evaluating whether models can predict future states of the world under uncertainty and across multiple levels of abstraction requires a stochastic approach. We propose a unified evaluation framework for frozen video understanding and synthesis models that takes the uncertainty of the future into account via a diffusion forecasting module. Jacob C Walker, Pedro V√©lez, Luisa Polania Cabrera, Guangyao Zhou, Rishabh Kabra, Carl Doersch, Maks Ovsjanikov, Jo√£o Carreira, Shiry Ginosar. Generalist Forecasting with Frozen Video Models via Latent Diffusion In submission. PDF. Empowerment gain and causal model construction Children & adults don't just explore‚Äîthey seek empowerment: controllable and variable interventions. When it comes to goal-directed work, people prioritize controllable variability (a.k.a. empowerment). But in undirected play, we shift toward embracing pure variability. Eunice Yiu, Kelsey Allen, Shiry Ginosar, Alison Gopnik. Empowerment gain and causal model construction: Children and adults are sensitive to controllability and variability in their causal generalization and interventions., World models, A(G)I, and the Hard problem(s) of life-mind continuity: Towards a unified understanding of natural and artificial intelligence‚Äù issue of Philosophical Transactions A., 2026 (In Press). PDF. Mapping social perception to social behavior using artificial neural networks ANN approach for uncovering representations in social brain nodes By training a set of neural networks to embed and reconstruct videos from neural activity, we surprisingly observe that neural responses in OFC and aIC support astonishingly accurate reconstructions of social videos. We further extend this approach to generate optimal stimuli for neurons from each region and identify interpretable axes of neural responses like social partner angle and distance. Finally, we identify a subset of neurons predicting social behavioral responses and observe a causal role of activity in aIC and OFC in social behavior production, with electrical microstimulation evoking gaze shifts and facial movements. These results suggest that these frontal brain regions contain a surprisingly rich code for social scenes and play a critical role in transforming social perception into behavior, positioning them as central nodes in social cognition. Nate Dolensek, Shi Chen, Shiry Ginosar, and Doris Tsao. Mapping social perception to social behavior using artificial neural networks, Cosyne 2025 Poster. PDF Gaussian Splatting for Masked Autoencoders 3D Gaussians as a learned mid-level image representation. We present the first method to employ 3D Gaussian primitives in an image representation learning framework trained on large image datasets. Our learning-based method starkly contrasts with the current usage of Gaussian splatting, which is restricted to optimization-based single-scene reconstructions. Jathushan Rajasegaran, Xinlei Chen, Ruilong Li, Christoph Feichtenhofer, Jitendra Malik, and Shiry Ginosar. Gaussian Splatting for Masked Autoencoders. PDF, Project Page, The talk I gave at the Simons Institute at Berkeley. Poly-Autoregression A general framework for behavior prediction in multi-agent settings. We demonstrate that we can formulate a wide range of problems as social behavior prediction. We present a simple framework for predicting agent behavior in multi-agent settings, unifying human action forecasting, car trajectory prediction, and hand-object interaction forecasting. Neerja Thakkar, Tara Sadjadpour, Jathushan Rajasegeran, Shiry Ginosar, and Jitendra Malik. Poly-Autoregressive Prediction for Modeling Interactions, CVPR 2025. PDF, Project Page Pose Priors from Language Models Improving pose estimates involving physical contact using LMMs. Central insight: An LLM can tell you, e.g., that to hug someone, your arm should go on their neck, shoulder, waist, or bottom‚Äîbut probably not on their knee... And all of this knowledge comes from detailed descriptions of physical contact in books! We leverage this insight to improve pose estimation by converting natural language descriptors, generated by a large multimodal model (LMM), into tractable losses to constrain 3D pose optimization. Sanjay Subramanian, Evonne Ng, Lea M√ºller Dan Klein, Shiry Ginosar, and Trevor Darrell. Pose Priors from Language Models, CVPR 2025. PDF, Project Page KiVA: Kid-inspired Visual Analogies for LMMs A benchmark for visual analogies inspired by developmental psychology. We present a benchmark that closes a critical gap in current benchmarks for foundational models - visual analogical reasoning, which even young children can do but in which large multimodal models perform poorly. Eunice Yiu, Maan Qraitem, Anisa Noor Majhi, Charlie Rose Wong, Yutong Bai, Shiry Ginosar, Alison Gopnik, and Kate Saenko. KiVA: Kid-inspired Visual Analogies for Large Multimodal Models, ICLR 2025. PDF, Project Page, Benchmark Data, Colab Synergy and Synchrony in Couple Dances How does social interaction influence one's behavior? We focus our analysis on motion behavior during Swing, a couples-dance genre with tight physical coupling, for which we present an in-the-wild video dataset. We demonstrate that single-person future motion prediction in this context is challenging. Instead, we observe that prediction greatly benefits from considering the interaction partners' behavior. Vongani Maluleke, Lea M√ºller, Jathushan Rajasegaran, Georgios Pav",
  "content_length": 25673,
  "method": "requests",
  "crawl_time": "2025-12-01 14:27:32"
}