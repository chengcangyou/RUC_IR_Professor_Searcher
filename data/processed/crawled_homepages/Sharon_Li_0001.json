{
  "name": "Sharon Li 0001",
  "homepage": "https://pages.cs.wisc.edu/~sharonli",
  "status": "success",
  "content": "Sharon Li - UW Madison Computer Sciences Sharon Li - UW Madison Computer Sciences Sharon Li [CV] Associate Professor Department of Computer Sciences University of Wisconsin-Madison Office: CS5393 G. Scholar LinkedIn Github Twitter e-Mail Everyday human conversation can be filled with intent that goes unspoken, feelings implied but never named.How can AI ever really understand that?â¨ Weâre excited to share our new work MetaMind â just accepted to #NeurIPS2025 as a Spotlight paper!A thread ð1ï¸â£ Humanâ¦ pic.twitter.com/xCJrl4QfAe— Sharon Y. Li (@SharonYixuanLi) September 26, 2025 Multi-Agent Debate (MAD) has been hyped as a collaborative reasoning paradigm â but let me drop the bomb: majority voting, without any debate, often performs on par with MAD.This is what we formally prove in our #NeurIPS2025 Spotlight paper: âDebate or Vote: Which Yieldsâ¦ pic.twitter.com/aSNx8euToe— Sharon Y. Li (@SharonYixuanLi) September 27, 2025 Excited to share our #NeurIPS2025 paper: Visual Instruction Bottleneck Tuning (Vittle)Multimodal LLMs do great in-distribution, but often break in the wild. Scaling data or models helps, but itâs costly.ð¡ Our work is inspired by the Information Bottleneck (IB) principle,â¦ pic.twitter.com/rUdCYJtavT— Sharon Y. Li (@SharonYixuanLi) October 3, 2025 Collecting large human preference data is expensiveâthe biggest bottleneck in reward modeling.In our #NeurIPS2025 paper, we introduce latent-space synthesis for preference data, which is 18Ã faster and uses a network thatâs 16,000Ã smaller (0.5M vs 8B parameters) thanâ¦ pic.twitter.com/sKzV0W4zq5— Sharon Y. Li (@SharonYixuanLi) October 5, 2025 Your LVLM says: âThereâs a cat on the table.âButâ¦ thereâs no cat in the image. Not even a whisker.This is object hallucination â one of the most persistent reliability failures in multi-modal language models. Our new #NeurIPS2025 paper introduces GLSim, a simple butâ¦ pic.twitter.com/iJ310e8gme— Sharon Y. Li (@SharonYixuanLi) October 11, 2025 We hear increasing discussion about aligning LLM with âdiverse human values.âBut whatâs the actual price of pluralism? ð§®In our #NeurIPS2025 paper (with @shawnim00), we move this debate from the philosophical to the measurable â presenting the first theoretical scaling lawâ¦ pic.twitter.com/dzEEe2oImL— Sharon Y. Li (@SharonYixuanLi) October 12, 2025 Human preference data is noisy: inconsistent labels, annotator bias, etc. No matter how fancy the post-training algorithm is, bad data can sink your model. ð¥ @Samuel861025 and I are thrilled to release PrefCleanBench â a systematic benchmark for evaluating data cleaningâ¦ pic.twitter.com/TN7gVEGPVw— Sharon Y. Li (@SharonYixuanLi) October 18, 2025 Deception is one of the most concerning behaviors that advanced AI systems can display. If you are not concerned yet, this paper might change your view.We built a multi-agent framework to study:ð How deceptive behaviors can emerge and evolve in LLM agents during realisticâ¦ pic.twitter.com/2XHyLCBUmR— Sharon Y. Li (@SharonYixuanLi) October 25, 2025 About I am an Associate Professor in the Department of Computer Sciences at the University of Wisconsin-Madison. I am a member of machine learning@uw-madison and a faculty affiliate with the Data Science Institute. Previously, I was a postdoc researcher in the Computer Science department at Stanford University, working with Christopher RÃ©. I completed my PhD from Cornell University in 2017, where I was advised by Turing laureate John E. Hopcroft. My research focuses on the foundations of safe and reliable AI systems, addressing challenges that arise in both model development and deployment in the wild. We are building towards LLM systems that are reliable by design, with behaviors that can be rigorously understood and reasoned about. This enables principled control throughout the model lifecycle, from training to deployment. Our current research investigates core questions around: Reliable agentic LLM systems: Coordinated decision-making across interacting language models, emergent strategies and collective reasoning, and uncertainty quantification for agentic LLMs. Reliable inference-time compute: Understanding and detecting hallucinations, deception, and unfaithful reasoning. Advancing steering mechanisms and socially aligned reasoning. Reliable post-training methodologies: Developing new reinforcement learning and reward modeling techniques to enhance alignment and reasoning capabilities. My research has been recognized by the Alfred P. Sloan Fellowship (2025), MIT Innovators Under 35 Award (2023), NSF CAREER Award (2023), AFOSR Young Investigator (YIP) Award (2022), Forbes 30 Under 30 in Science (2020), and multiple faculty research awards from Google, Meta, and Amazon. I was named the \"Innovator of the Year\" by MIT Technology Review in 2023. Our research has also won the Outstanding Paper Award at NeurIPS 2022 and ICLR 2022. [Openings]: In an effort to maintain a healthy group size, I have very limited PhD openings for the Fall 2026 admission cycle and will only consider applicants with an exceptional research fit. For questions regarding the application process, please see the FAQ. I strongly recommend reading my [Advising Statement] before applying or contacting me. Updates 9/2025: 11 papers accepted by NeurIPS. 7/2025: Promoted to tenured professor. 7/1/2025: Received Google ML and Systems Faculty Award. 6/15/2025: Shawn received the NSF Graduate Research Fellowship. 5/16/2025: Xuefeng defended his Ph.D. thesis - congratulations Dr. Du! 5/1/2025: 5 papers accepted by ICML 2025. 3/3/2025: Will serve as the Program Chair for ICML 2026 in Seoul, South Korea. 12/3/2024: I will be co-organizing two workshops at ICLR 2025 on responsible AI and uncertainty quantification for LLM. 11/1/2024: Will be presenting 6 works at NeurIPS - see you in Vancouver! 5/1/2024: 4 papers accepted by ICML 2024. 1/16/2024: 4 papers accepted by ICLR 2024. 7/19/2023: Yiyou defended his Ph.D. thesis - congratulations Dr. Sun! 6/26/2023: Received funding from ONR to support OOD detection research - thanks ONR! 6/21/2023: Received NSF CAREER Award. 2/11/2023: Xuefeng received the inaugural Jane Street Graduate Research Fellowship. 11/21/2022: Received NeurIPS Outstanding Paper Award. 11/2022: Received Google-Initiated Research Grant. 9/14/2022: 4 papers accepted to NeurIPS 2022 and 1 paper accepted to NeurIPS 2022 Datasets and Benchmarks Track. Congrats to the team and co-authors! 5/15/2022: 4 papers accepted by ICML, congratulations to the team! 4/15/2022: Received ICLR Outstanding Paper Award Honorable Mention. [Services]: Program chair: ICML 2026 Area chair and senior program committee: NeurIPS, ICLR, ICML and AAAI. Asscociate editor: ACM Transactions on Knowledge Discovery from Data (TKDD), Transactions on Machine Learning Research (TMLR) Program chair and founding organizer: ICML Workshop on Uncertainty and Robustness in Deep Learning (UDL) 2019 & 2020. Co-organizer: ICML Workshop on Uncertainty and Robustness in Deep Learning (UDL), 2021. Co-organizer: ICML Workshop on Distribution-free Uncertainty Quantification (DFUQ), 2021. Co-organizer: WiML Un-Workshop on Uncertainty Estimation, 2021. Co-organizer: ICML Workshop on Distribution-free Uncertainty Quantification (DFUQ), 2022. Co-organizer: NeurIPS Workshop on Robustness in Sequence Modeling, 2022. Co-organizer: ICCV Tutorial on Reliability of Deep Learning for Real-World Deployment, 2023. Co-organizer: CVPR Workshop on Prompting in Vision, 2024. Co-organizer: DCAI: Data-centric Artificial Intelligence Workshop at WWW, 2024. Co-organizer: ICLR Workshop on Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI, 2025. Co-organizer: ICLR Workshop on Advances in Financial AI: Opportunities, Innovations, and Responsible AI, 2025. [Teaching]: Fall 2025: CS762 Advanced Deep Learning Spring 2025: CS540 Introduction to Artificial Intelligence Fall 2023: CS762 Advanced Deep Learning Fall 2022: CS762 Advanced Deep Learning Spring 2022: CS540 Introduction to Artificial Intelligence Fall 2021: CS762 Advanced Deep Learning Spring 2021: CS540 Introduction to Artificial Intelligence Fall 2020: CS839 Advanced Topics in Deep Learning. Misc I travel and occasionally take photos. Here is my pictorial Travel Memo. This is the treasure I shoot with. Sponsors We are thankful for the generous funding award and gift from the following sponsors:",
  "content_length": 8487,
  "method": "requests",
  "crawl_time": "2025-12-01 14:26:36"
}