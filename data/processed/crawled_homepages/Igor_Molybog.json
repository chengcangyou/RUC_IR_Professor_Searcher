{
  "name": "Igor Molybog",
  "homepage": "https://igormolybog.github.io",
  "status": "success",
  "content": "Igor Molybog Menu Home Research Group CV Publications GitHub Schedule Meeting Teaching ECE405 (2026) seminar (s2026) ECE605 (2025) ECE491B (2025) ECE491B/693B EE417/617 EE650 IEOR169 IEOR240 Igor Molybog Igor Molybog Researcher in the domains of AI, ML and Optimization Assistant Professor at the University of Hawai'i at Manoa Department of Electrical and Computer Engineering Department of Information and Computer Sciences Office: POST 205H Email: igormolybog AT gmail.com I am looking for exceptional students and postdocs to join my research group! If you are a prospective or admitted graduate student interested in joining my group, please submit the form. About me I am an AI researcher specializing in large language models (LLM), focusing on the efficient development and robust evaluation of computer systems that automate economically viable yet tedious tasks typically requiring human intervention. My current areas of interest include: Expanding AI's Impact: Identifying novel use cases for automation with LLM and novel tasks for increasing professionals’ productivity. Developing frameworks for robust evaluation of AI agents. Sourcing diverse data to address unique challenges in emerging applications. Multimodal Modeling: Integrating video and other sensory modalities into AI reasoning to advance robotics and other cyber-physical systems applications. Enhancing large language models’ capabilities in computer programming and mathematical problem-solving. Core Machine Learning and Scaling: Addressing efficiency challenges and fundamental obstacles to expand the computational resources available to AI systems. Optimizing the design of modeling experiments and developing predictable training processes. I teach courses and supervise projects on language modeling and associated topics within ECE and ICS departments of UH Manoa. Previously, I worked on the large-scale distributed computing experiments and training codebase for large language modeling within Meta AI, which contributed to the release of the famous LLaMa models. My background is in Applied Mathematics and Operations Research. In 2022, I graduated with a Ph.D. in Engineering from UC Berkeley, where I worked on learning algorithms for data analysis and control of complex safety-critical systems. My dissertation under the supervision of Professor Javad Lavaei spans the theory of non-convex and conic optimization, stochastic control, machine learning, focusing on computational and sampling complexity of learning algorithms. I designed data processing algorithms that are robust to noise and highly scalable with the amount of available computational resources. News Subscribe November 2025: HawAII is happy to host Alex Avdoshkin from MIT Physics who will deliver a talk on training transformers with data from condensed matter physics simulations. Please join us in Holmes Hall 411 at 13:30 on 13 of November! November 2025: Congratulations to Yosub Shin, Michael Buriek, Boris Sobolev, Pavel Bushuyeu, Vikas Kumar, Haoyang Xu and Samuel Watson for winning the First Place at the DCVLR NeurIPS 2025 challenge with their class project for ECE 605. November 2025: The pre-print for our new paper SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations led by Amila Indika is available online. October 2025: At 13:30 on 23 of October, HawAII is happy to host David Bau from Northeastern University in Boston who will deliver a talk on Mechanistic Interpretability of large neural networks. Please join us in Holmes Hall 411! October 2025: At 15:30 on Oct 8, I am giving a talk on Empirical Sequence Modeling at the Applied Math Seminar of the Department of Mathematics at UH Manoa. slides are available September 2025: The closed beta of our AI class companion (tutor, customizable by the instructor) is now hosted at alu.institute. It is being served for the students enrolled in the pilot UH Manoa classes (ECE345, BUS619, ECON336) and whitelisted individuals. Please reach out if you want to try it in your class! August 2025: I am honored to deliver the keynote address on the state of AI at the SCV x SBI venture capital annual conference on Aug 13. The slides can be found here. July 2025: We are assembling a cross-institutional team to participate in the ARC Institute Virtual Cell Challenge. This challenge focuses on predicting cellular responses to genetic or chemical perturbations using AI models. Please reach out if you are interested in participation or collaboration! June 2025: We are releasing a preprint of our paper on the pitfalls of vision-based video synchronization: “Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization”. June 2025 Our paper REAL: Response Embedding-based Alignment for LLMs will be presented at IJCAI2025 workshop on Causal Learning for Recommendation Systems. June 2025: We are releasing a public demo version of Roughcut - a video editing AI agent developed by Yosub Shin in our lab. This MacOS app is focused on speech-heavy video and capable of conditional highlight extraction and conversational editing via a chat interface. We are actively sourcing feedback and encourage everyone to try it out! May 2025: Congratulations to Honggen Zhang for passing his dissertation defense! He is going to join XtalPi and contribute to AI drug development. April 2025: A new permanent graduate-level course ECE 605 on large-scale AI development and deployment will be taught in Fall 2025. It will include a series of paper-reading seminars where we will go over the most pressing technincal engineering challenges in the field and approaches to their solution. March 2025: Amila Indika, a talented Master's student under my co-supervision, is graduating this year and entering the job market! January 2025: I am visiting the Center for Language and Speech Processing (CLSP) at Johns Hopkins Computer Science with a brand new talk on scaling properties of LLM inference systems scheduled on February 21, 2025 (12:00-13:15). December 2024: We are delighted to kick off Spring 2025 HawAII AI paper reading seminar. Please see flyer for the schedule and other details. November 2024: I presented the REAL: Response Embedding-based Alignment for LLMs at the UHM ICS seminar! The slides and recording are available. October 2024: Honggen Zhang, an LLM expert working with my group is entering the job market this year! September 2024: We welcome Yosub Shin as a full-time Graduate Researcher to our research group, working on advanced models for video processing and multimodal understanding. September 2024: We developed REAL - a simple algorithm for efficient high-quality preference data generation. The preprint is available online: REAL: Response Embedding-based Alignment for LLMs. August 2024: I am participating in the AI Panel on October 11, 2024. July 2024: At noon on 1 Aug, I am giving a talk “Scaling generative modeling across model sizes and data modalities” at the lab meeting of New York Genome Center. July 2024: At noon on 26 July, HawAII is happy to host Nikita Zhivotovsky from UC Berkeley who will deliver a talk on Improving Risk Bounds with Unbounded Losses via Data-Dependent Priors. Join us in POST 302! June 2024: Our paper on the economic trajectory of AI development “What if synthetic data is all you need” is available online! May 2024: A new HawAII reading group just started! Please join us on Fridays 12:00-13:05 in POST 302 or reach out for a Zoom link. April 2024: Our paper Effective Long-Context Scaling of Foundation Models will be presented at NAACL 2024 conference! March 2024: We are thrilled to announce an upcoming collaboration with Epoch AI on the technical and economical aspects of scaling Artificial Intelligence systems. March 2024: At 4 PM on 24 Apr, HawAII is happy to host Daniel Abramovitch (Agilent Labs), Richard Braatz (MIT), and Kam Leang (U. Utah) in Webster Hall 203 with a talk on automatic control! zoom link; recording; . February 2024: Our research group has been awarded compute resources by the Google Cloud Research Credits Program February 2024: Our paper HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding has been accepted at The Web Conference 2024 January 2024: Our research group has been awarded compute resources by the ACCESS Allocations program. January 2024: I am presenting the overview of my research to the Department of Information and Computer Sciences at UH Manoa on Tuesday, Jan 9, 2024, 12:00-13:00, in Keller Hall 103. (recording) January 2024: We are delighted to announce the Hawai'i Artificial Intelligence Initiative aiming to accelerate AI research at UHM by fostering collaboration December 2023: On 18 Dec, we are happy to host Prof. Xiao Li from CUHK with a talk on Convergence Guarantees for SGD with Random Reshuffling. Please join us at HH 386 at 11 am! (recording) October 2023: I am chairing session WA67 “Challenges in the Large-scale Model Training” at INFORMS Annual Meeting 2023! October 2023: I have presented a talk on the Large Language Modeling practice at the CS Department seminar of UH Manoa: recording, slides September 2023: A new paper on extending the context length of a trained RoPE transformer: Effective Long-Context Scaling of Foundation Models July 2023: Our paper Llama 2: Open Foundation and Fine-Tuned Chat Models landed with a splash, making it to the top of hackernews. May 2023: I will present the paper A Theory on Adam Instability in Large-Scale Machine Learning at the FAIR <> GenAI Workshop. slides April 2023: Our paper Over-parametrization via Lifting for Low-rank Matrix Sensing: Conversion of Spurious Solutions to Strict Saddle Points got accepted at the 2023 International Conference on Machine Learning (ICML). March 2023: New paper A Theory on Adam Instability in Large-Scale Machine Learning is accessible online. January 2023: New paper Over-parametrization via Lifting for Low-rank Matrix Sensing: Conversion of Spurious Solutions to Strict Saddle Points is acce",
  "content_length": 14390,
  "method": "requests",
  "crawl_time": "2025-12-01 13:22:42"
}