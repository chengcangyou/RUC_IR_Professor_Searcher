{
  "name": "Daniel M. Roy 0001",
  "homepage": "http://danroy.org",
  "status": "success",
  "content": "Daniel Roy Dan Roy aka daniel roy, daniel m roy, droy Research Director, CIFAR Canada AI Chair, and Founding Faculty, Vector Institute Professor Department of Statistical Sciences Department of Computer Science  (cross-appointment) University of Toronto Department of Computer and Mathematical Sciences University of Toronto Scarborough Editorial Boards Action Editor, Journal of Machine Learning Research Jump to:   Teaching | Research Articles | Group Members | Probabilistic Programming | Contact Note: I will not be taking any new students or postdocs this year. news JUL 2024.My joint work with Idan Attias, Gintare Karolina Dziugaite, Mahdi Haghifam, Roi Livni on \"Information Complexity of Stochastic Convex Optimization\" won a best paper award at ICML 2024 (given to 10 out of ~10,000 submissions). APR 2024.I've been promoted to Full Professor. SEP 2023.I've been named Research Director of the Vector Institute. research My research is focused on the foundational principles underlying prediction, inference, and decision making under uncertainty. This focus on foundations ties together multiple lines of work, which span machine learning, statistics, mathematical logic, applied probability, and computer science. My group has made significant contributions to learning theory, statistical network analysis, decision theory, probabilistic programming, Bayesian nonparametric statistics. More recently, my group has come to focus on information theories of learning, online learning, and nonstandard analytic foundations for decision theory. Want to hear more about our research? Watch a recent talk at ETH Zurich, summarizing some recent research on \"removing assumptions from statistics\". joining my group I am seeking students at all levels with strong quantitative backgrounds interested in foundational problems at the intersection of machine learning, statistics, and computer science. I am also seeking qualified postdoctoral researchers for two- and three- year positions. Click to read instructions before contacting me, or your email is likely to be deleted. I value people who are attentive to details. Undergraduates at Toronto: I welcome these emails, but they should include a c.v., lists of relevant course work, and a transcript. The subject line should contain the word \"consideration\" to indicate these instructions have been read. Students seeking short-term research opportunities: Other than in exceptional cases (listed in next paragraph), I do not take students for internships, summer research, or short term visits. Prospective graduate students: I receive emails everyday from prospective graduate students. Other than in exceptional cases, students who are not already admitted to Toronto should NOT email me directly. Instead, they should first apply to and gain admission to the graduate program in Statistics or Computer Science. Do not email me about the admission process—google and figure it out yourself. In your research statement, you should mention my name and state clearly how your research interests align with my research program. If you are admitted, then I'm happy to discuss supervision. Exceptional cases include: you have publications already at NIPS, ICML, UAI, ICLR, COLT, ALT, similar conferences, or in a top statistics journal; you have competed at the highest levels of math or computing olympiads; you have done something truly exceptional relative to the resources available to you. In these cases, students are encouraged to email me before applying and include the phrase \"special consideration\" in their email's subject line to indicate they have read my webpage. Postdocs should send me their c.v. and best papers as PDFs and should include the word \"consideration\" in their subject line to indicate they have read my website. Hide instructions. group members Ziyi Liu, Ph.D. candidate, Stats Irfan Alam, Postdoc, Math (Nonstandard analysis) Tosca Lechner, Vector Distinguished Postdoctoral Fellow group alumni Ekansh Sharma, Ph.D. CS → Google Thibault Randrianarisoa, Postdoc, Statistics →Asst. Prof, Univ. Toronto, Scarborough Mahdi Haghifam, Ph.D., ECE → Distinguished Postdoctoral Fellow, Northeastern University → Research Asst. Prof, TTIC & Simons Fellow Mufan Li, Ph.D., Stats → Postdoctoral Research Associate, Princeton University → Assistant Prof., Dept. of Statistics and Actuarial Sciences, University of Waterloo David Schrittesser, Postdoc, Math →Full Prof., Institute for Advanced Study and Mathematics, Harbin Inst. Technology, China Blair Bilodeau, Ph.D. candidate, Stats → Voleon Group Yanbo Tang, Ph.D., Statistics → Chapman Fellow, Imperial College London → Lecturer, Dept. of Statistics, Imperial College London Jeffrey Negrea, Ph.D., Statistics → Postdoctoral Fellow, Data Science Institute, University of Chicago → Assistant Prof., Dept. of Statistics and Actuarial Science, Waterloo Yasaman Mahdaviyeh, Ms.C., CS → Ph.D., CS Columbia University Ali Ramezani-Kebrya, Postdoctoral Fellow → Senior Postdoctoral Associate, EPFL → Associate Prof., Dept. of Informatics, University of Oslo, Norway Jun Yang, Ph.D., Statistics → Florence Nightingale Fellow, Oxford University → Assistant Prof., Dept. Mathematical Sciences, University of Copenhagen Zacharie Naulet, Postdoctoral Fellow → Assistant Prof., Université Paris-Sud Alexander Edmonds, M.Sc., CS → Ph.D., CS, UofT Haosui (Kevin) Duanmu, Ph.D., Statistics (Dissertation; Departmental Thesis Award) → NSERC Postdoctoral Fellow, Dept. Economics, UC Berkeley → Full Professor, Institute for Advanced Study in Mathematics, Harbin Institute of Technology Victor Veitch, Ph.D., Statistics (Dissertation; Departmental Thesis Award, Stat. Soc. of Canada (SSC) Pierre Robillard Award) → Distinguished Postdoctoral Researcher at Columbia → Asst. Prof., University of Chicago, Statistics Siddharth Ancha M.Sc., CS → Ph.D., CS, CMU → Postdoc, MIT Pablo García Moreno Postdoc → Machine Learning Scientist, Amazon teaching STA3000  (Fall 2017) Advanced Theory of Statistics, Part I STA4516  (Fall 2017) Nonstandard Analysis and Applications to Statistics and Probability STAD68   (Fall 2017) Advanced Machine Learning and Data Mining STAD68   (Fall 2016) Advanced Machine Learning and Data Mining STA4516  (Fall 2015) Topics in Probabilistic Programming STAC63  (Fall 2015) Probability Models STAD68   (Winter 2015) Advanced Machine Learning and Data Mining STA4513  (Fall 2014) Statistical models of networks, graphs, and other relational structures probabilistic programming Programs can be used to give compact representations of distributions: in order to represent a distribution, one simply gives a program that would generate an exact sample were the random number generator to produce realizations of independent and identically distributed random variables. This approach to representing distributions by probabilistic programs works not only for simple distributions on numbers like Poissons, Gaussians, etc., and combinations thereof, but also for more exotic distributions on, e.g., phrases in natural language, rendered 2D images of 3D scenes, and climate sensor measurements. Probabilistic programming systems support statistical inference on models defined by probabilistic programs. By constraining some variables of a program (e.g., simulated sensor readings in some climate model) and studying the conditional distribution of other variables (e.g., the parameters of the climate model), we can identify plausible variable settings that agree with the constraints. Conditional inferences like this would allow us to, e.g., build predictive text systems for mobile phones, guess the 3D shape of an object from only a photograph, or study the underlying mechanisms driving observed climate measurements. Probabilistic programming systems for machine learning and statistics are still in their infancy, and there are many interesting theoretical and applied problems yet to be tackled. My own work focuses on theoretical questions around representing stochastic processes and the computational complexity of sampling-based approaches to inference. I was involved in the definition of the probabilistic programming language Church, and its first implementation, MIT-Church, a Markov Chain Monte Carlo algorithm operating on the space of execution histories of an interpreter. Some of my key theoretical work includes a study of the computability of conditional probability and de Finetti measures, both central notions in Bayesian statistics. Readers looking for an overview of these results are directed to the introduction of my doctoral dissertation. A less technical description of a probabilistic programming approach to artificial intelligence can be found in a recent book chapter on legacies of Alan Turing, co-authored with Freer and Tenenbaum. More information on probabilistic programming can be found on probabilistic-programming.org, a wiki that I maintain. In particular, look at the list of research articles and papers on probabilistic programming and the tutorials. NIPS Workshop on Probabilistic Programming I co-organized the first workshop on probabilistic programming for statistics and machine learning at NIPS*2008 (with Vikash Mansinghka, John Winn, David McAllester and Josh Tenenbaum). Four years later, I co-organized the second workshop on probabilistic programming at NIPS*2012 (with Vikash Mansinghka and Noah Goodman). academic Hello, my name is Daniel M. Roy (or simply, Dan) and I am a Professor of Statistics at the University of Toronto, with cross appointments in Computer Science and in Electrical and Computer Engineering. I received all three of my degrees in (Electrical Engineering and) Computer Science from MIT. As a doctoral student, I was member of the Computer Science and Artificial Intelligence Laboratory (CSAIL), where I was advised by Leslie Kaelbling. I also collaborated with members of Josh Tenenbaum's Computational Cognitive Science group. After my doctorate, I was a Newton International Fellow of th",
  "content_length": 33411,
  "method": "requests",
  "crawl_time": "2025-12-01 12:57:23"
}