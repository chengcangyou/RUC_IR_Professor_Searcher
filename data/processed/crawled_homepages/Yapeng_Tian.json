{
  "name": "Yapeng Tian",
  "homepage": "http://www.yapengtian.com",
  "status": "success",
  "content": "Yapeng Tian | Home Yapeng Tian Assistant Professor, The University of Texas at Dallas yapeng.tian@utdallas.edu ECSS 4.211 Bio I am an Assistant Professor in the Computer Science Department of UT Dallas and lead the Computer Vision and Multimodal Computing (CVMC) Lab. Before coming to UTD, I finished my PhD at University of Rochester, advised by Chenliang Xu, my master degree at Tsinghua University working with Wenming Yang, and B.E degree at Xidian University. I was a visiting student at SIAT advised by Yu Qiao. I did internships at Adobe Research with Dingzeyu Li and Meta with Alexander Richard. I am interested in solving core computer vision, computer audition, and machine learning problems and applying the developed learning approaches to broad AI applications, such as multisensory perception, computational photography, AR/VR, accessibility, and healthcare. My work has been recognized with awards including the AAAI New Faculty Highlights, Cisco Faculty Research Award, and Amazon Research Award. ICCV 2025 Workshop Call for Papers: We are excited to announce the CV4A11y, KnowledgeMR, and MCL Workshops at ICCV 2025. We invite paper submissions. üìç CV4A11y: Workshop on Vision Foundation Models and Generative AI for Accessibility üìç KnowledgeMR: Workshop on Knowledge-Intensive Multimodal Reasoning üìç MCL: Workshop on Multimodal Continual Learning Research Highlights Audio-Visual Scene Understanding: To achieve truly intelligent systems, we must move beyond scene understanding that relies solely on individual senses like sight or sound. Our research pioneers a multimodal approach, integrating computer vision and audition to unlock the rich information available through combined audio-visual perception. We tackle fundamental challenges in this emerging field, developing unified, explainable, and robust multimodal models for video understanding. Audio-Visual Scene Generation: We're pushing beyond scene perception to content creation, developing audio-visual intelligent systems that can generate realistic sounds and videos from diverse multimodal inputs. Our work includes joint audio-visual generation, spatial audio generation, and video and text guided audio generation models. AI for Accessibility and Healthcare: We develop computer vision and AI models to empower individuals with disabilities and improve healthcare. Our work spans: (a) Assistive Technologies: Creating systems to aid those with autism, blind or low vision, and hearing impairments. (b) Medical Imaging: Developing AI to enhance medical images for improved diagnosis and treatment. Image and Video Processing: I enjoy building computer vision algorithms to improve image and video quality in both automated and creative ways. My research involves developing a range of image and video restoration models capable of generating photorealistic outputs. This work has also been applied to medical imaging, including MRI data. News 11/2025: One paper accepted at AAAI 2026. 11/2025: Our autism gaze target detection paper, led by Shijian in collaboration with Dr. Rollins‚Äôs lab accepted at AAAI 2026 (AI for Social Impact Track). 10/2025: One paper accepted at TMLR. 10/2025: I will be serving as an Area Chair for ACL ARR. 09/2025: One paper accepted at NeurIPS 2025 (DB Track). 09/2025: One paper accepted at IJCV. 09/2025: One paper accepted at NeurIPS GenProCC Workshop. The project was led by Michael, a K‚Äì12 student advised by Shijian. 08/2025: I will be serving as an Area Chair for AAAI/CVPR/ICLR 2026. 08/2025: One paper accepted at EMNLP 2025 Findings. 07/2025: Received an NSF grant. 07/2025: One paper accepted at COLM 2025. 07/2025: Our AV-DiT paper accepted at ACM MM 2025. 07/2025: Two papers conditionally accepted at UIST 2025. 07/2025: One paper accepted at BMVC 2025. 06/2025: Two papers accepted at ICCV 2025. 05/2025: One paper accepted at ACL 2025 (main conference). 04/2025: I will be serving as an Area Chair for NeurIPS 2025. 04/2025: We are excited to announce the CV4A11y, MCL, and KnowledgeMR workshops at ICCV 2025. More details coming soon. Stay tuned! 04/2025: Guest lecture at Texas A&M. 02/2025: Two papers accepted at CVPR 2025. 02/2025: Our Multimodal Large Language Model Pruning paper accepted at PAKDD 2025. 01/2025: Invited talk at UNT Artificial Intelligence (AI) Seminar. 12/2024: Our spatial audio generation paper accepted at ICASSP 2025. 12/2024: emoji_eventsDAVIS won the ACCV Best Paper Award, Honorable Mention! 11/2024: One paper accepted at WACV 2025 and one journal article accepted by IEEE TPAMI. 10/2024: Our Audio-Visual Dataset Distillation paper accepted at TMLR journal. 10/2024: I will be serving as an Area Chair for CVPR 2025. 10/2024: emoji_eventsARSports won IEEE ISMAR'24 IDEATExR workshop Best Paper Award! 10/2024: Invited talk at UTSW. 09/2024: Our Continual Audio-Visual Sound Separation paper accepted at NeurIPS 2024. 09/2024: emoji_eventsCookAR received UIST'24 Belonging & Inclusion Best Paper Award! 09/2024: Received an NIH R01 grant! This exciting project will focus on AI/AR-assisted Vision for people with low vision. We're excited to collaborate with Prof. Yuhang Zhao at UW-Madison (lead institute) and Prof. Jon E. Froehlich at UW. Check out our preliminary work: CookAR. 09/2024: Our audio-visual question answering paper accepted at EMNLP 2024. 09/2024: Two papers accepted at ACCV 2024. One on audio-visual sound separation and another on language-guided audio-visual editing. 09/2024: Our Audio-Visual Autism Behavior Recognition paper acceted at IEEE TMM. 08/2024: I will be serving as an Area Chair for ICLR 2025 and a SPC for AAAI 2025. 08/2024: William received the Jonsson School of Engineering and Computer Science Award for his Undergraduate Research Project! 07/2024 Our CookAR paper accepted at UIST 2024. 07/2024: We will be organizing an Audio Imagination workshop at NeurIPS 2024. More details coming soon! 07/2024: Our mentored high school students received the Best Science Education Award at the 2024 CAST-STEM Bridge Summer Camp. 07/2024: One paper accepted at BMVC 2024. 06/2024: Our EgoVSR paper accepted at IEEE TCSVT. 05/2024: One paper accepted at ACM TOMM. 05/2024: One paper accepted at ACM C&C. 05/2024: Seven papers accepted at CVPR Workshops. 04/2024: Dr. Rollins and I received a UTD SPIRe grant. 04/2024: Received an Amazon Research Award. 03/2024: Congrats to Zeke Barnett, a K12 student in the lab! He will be joining CMU for his undergraduate study. 03/2024: One paper accepted at NAACL 2024. 03/2034: One journal article accepted at Medical Image Analysis. 03/2024: One journal article accepted at IEEE TMM. 03/2024: Received UTD Undergraduate Research Apprenticeship Program (URAP) award. 02/2024: We are organizing an ELVM: Efficient Large Vision Models workshop at CVPR 2024. 02/2024: One paper accepted at CVPR 2024. 02/2024: One paper accepted at CHI 2024. 10/2023: Invited talk at UTD-DFWCSTA Battle of the Brains - Conference & Contest for K12 students. 10/2023: Invited lightning talk at Workshop on Imaging and Data Science. 10/2023: One paper accepted at WACV 2024. 10/2023: Listed in 2022 World's Top 2% Scientists by Stanford University. 10/2023: Invited talk at Do Good with Data Webinar for K12 students. 09/2023: Two papers accepted at NeurIPS 2023. 09/2023: One paper accepted at UIST 2023. 09/2023: Five papers accepted at ICCV AV4D workshop. 07/2023: Three papers accepted at ICCV 2023. 06/2023: One paper accepted at MICCAI 2023. We are organizing a Cardiac MRI Reconstruction Challenge in conjunction with MICCAI 2023. 06/2023: Invited talk at Sight and Sound Workshop @ CVPR 2023. 06/2023: I will serve as a SPC for AAAI 2024. 06/2023: Received an Adobe Research Gift. 06/2023: One journal paper accepted at IEEE Transactions on Image Processing. 05/2023: Three papers accepted at CVPR Sight and Sound Workshop. 03/2023: I will serve as an Execution Area Chair for VALSE. 03/2023: Received an inaugural Undergraduate Research Apprenticeship Program (URAP) award. 03/2023: Received a Cisco Faculty Research Award. 03/2023: I will be co-organizing a Cardiac MRI Reconstruction Challenge in conjunction with MICCAI 2023. 02/2023: Three papers accepted at CVPR 2023. 02/2023: Please check out our new AV-NeRF paper. In this work, we pose and tackle a Real-World Audio-Visual Scene Synthesis problem. 02/2023: One journal paper accepted at IEEE Signal Processing Letters. 02/2023: One journal paper accepted at IEEE Transactions on Neural Networks and Learning Systems. 01/2023: Two papers accepted at ICLR 2023. 11/2022: Selected for the 2023 AAAI New Faculty Highlights Program. 10/2022: Invited talk at AV4D Workshop @ ECCV 2022. 09/2022: One paper accepted at NeurIPS 2022. Congratulations to Shentong! 09/2022: Two papers accepted at ECCV@AV4D 2022 . 08/2022: Please check out our new article \"Learning in Audio-visual Context: A Review, Analysis, and New Perspective.\" 08/2022: I start as an assistant professor in CS at UTD. 07/2022: I will serve as a Senior Program Committee (SPC) Member for AAAI 2023. 07/2022: One paper accepted at ECCV 2022. 06/2022: One paper accepted at MICCAI 2022. 06/2022: Successfully defended my dissertation! Thanks to everyone who supported me and helped me along the way. 04/2022: I will attend CVPR'22 Doctoral Consortium. 03/2022: Two works: audio-visual question answering and MRI SR are accepted by CVPR 2022. 12/2021: Two papers are accepted by AAAI 2022. 10/2021: One paper on sounding object localization is accepted by BMVC 2021! 07/2021: One paper on video matting is accepted by ICCV 2021! 03/2021: Our two works: co-learn sounding object visual grounding and sound separation and audio-visual robustness are accepted by CVPR 2021! 02/2021: We will co-organize a CVPR 2021 Tutorial on Audio-visual Scene Understanding! 01/2021: Co-organized the WACV 2021 Tutorial on Audio-visual Scene Understanding. More details can be found in our website. 10/2020: I was in the top 10% of high-scoring reviewers for NeurIPS 2020! 07/2020:",
  "content_length": 61967,
  "method": "requests",
  "crawl_time": "2025-12-01 14:50:36"
}