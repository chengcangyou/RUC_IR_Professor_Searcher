{
  "name": "Kevin Skadron",
  "homepage": "http://www.cs.virginia.edu/skadron",
  "status": "success",
  "content": "Professor Kevin Skadron \"Sequentiality is an illusion\" Kevin Skadron Harry Douglas Forsyth Professor of Computer Science Department of Computer Science School of Engineering and Applied Science University of Virginia 85 Engineer's Way, Rice Hall, Box 400740 Charlottesville, VA 22904-4740 Office: Rice 421 Phone: (434) 982-2042 Fax: (434) 982-2214 skadron (ampersand) virginia.edu (classes | bio | note to grad-student/summer-intern applicants | research summary | selected publications | software) Areas of Interest Computer architecture, especially pertaining to novel heterogeneous processor organizations, accelerator architecture, processing in memory, and automata processing. Biographical Sketch evin Skadron has been on the faculty at University of Virginia since 1999. He received his B.S. in Electrical and Computer Engineering and B.A. in Economics from Rice University in 1994, and his Ph.D. in Computer Science from Princeton University in 1999. He spent the 2007-08 academic year on sabbatical at NVIDIA Research. He served as department chair from 2012-2021. He also helped found and serves as director for the UVA Center for Automata Processing (CAP) and served as the SRC/DARPA-funded Center for Research on Intelligent Storage and Processing in Memory (CRISP), part of the JUMP 1.0 program. He is also a member of the Center for Research on Processing in Storage and Memory (PRISM), part of the JUMP 2.0 program. Skadron is the recipient of the 2023 SRC/SIA University Research Award for lifetime research contributions to the U.S. semiconductor industry, the 2011 ACM SIGARCH Maurice Wilkes Award, a Fellow of the IEEE and ACM, and a member of the Virginia Academy of Science, Engineering, and Medicine (VASEM).   For the year 2003-04, he was named a University of Virginia Teaching Fellow.  Among other professional activities, he is co-founder and editorial board member of  IEEE Computer Architecture Letters, for which he served as associate editor-in-chief from 2001-2009 and editor-in chief from 2010-2012, and as associate editor from 2012-2016.  He served on the editorial board of IEEE Micro from 2004-2012 and as co-founder/co-editor (with Kevin Rudd) of its \"Prolegomena\" column, as secretary-treasurer of ACM's SIGARCH from 2007-2011, as technical program co-chair of PACT 2006, general co-chair for PACT 2002 and MICRO-37, and on numerous technical program committees. Note to postdoc, graduate student and summer-intern applicants International summer-intern requests: Due to visa complexities, undergraduate summer interns from outside the US are typically not feasible.  I get a very large number of these requests; please understand that I generally cannot respond personally. Inquiries from prospective graduate students: Due to the large number of these inquiries, please understand that I am not able to respond to form letters.  But I am always happy to discuss mutual research interests!  Potential applicants may also want to read more about my advising philosophy. Teaching Over the last several semesters I have taught: Spring 2025: CS 6501, Special Topics in Computer Architecture: CPU/GPU Memory Systems and Near-Data Processing Spring 2024, Spring 2023: CS 6501: Special Topics in Computer Architecture: Hardware Accelerators Fall 2024: CS 3130: Computer Systems and Organizaiton 2 (CSO2) (with Prof. Reiss, who served as lead instructor) Fall 2023, Fall 2022: CS 4414: Operating Systems Research My research currently focuses on specialized and heterogeneous architectures and how to design architectures in the presence of severe physical constraints, especially thermal, power delivery, process variations, and wear-out. We are chiefly focusing on these issues in the context of asymmetric and heterogeneous designs, which provide the best balance between high single-thread performance, high throughput for parallel tasks, and high performance on critical functions. To address these challenges, we are taking a variety of approaches. Currently, our focus is in these areas: New processing-in-memory architectures, including Fulcrum in HPCA'20, Gearbox in ISCA'22, Sieve in ISCA'21, DRAM-CAM in CAL'22, DRAM-AP (digital bit-serial PIM) in IISWC'24, our Sunder in-memory automata architecture in MICRO'21; and our PIMeval simulation framework, PIMbench benchmark suite, and PIM programming API, in IISWC'24 New capabilities and programming models for regular-expression and automata processing, including runtime monitoring using temporal logic, as part of the UVA Center for Automata Processing (CAP).  We have developed novel architectures (e.g. Sunder, in MICRO'21, Impala, in HPCA'20), FPGA implementations (eg., Grapefruit, in FCCM'20), new applications (e.g., frequent-itemset mining in IPDPS'15 and sequential pattern mining in CF'16), a new benchmark suite (AutomataZoo), new modeling tools (e.g., MNCaRT) , a  new programming language  for inexact pattern matching (RAPID, in ASPLOS'16), a new automata-based method for string kernels on FPGAs (IEEE Micro, Sep.-Oct. 2023), acceleration for LTLf specifications (FMCAD'20), and new debugging support (in ASPLOS'19). New heterogeneous architectures, including accelerators and reconfigurable units (e.g., our work on crypto processors), and new design-space exploration tools such as Lumos to help understand the right mixture of heterogeneous units Developing new programming abstractions to simplify programming for heterogeneous systems, such as our ICS'09/IJPP'11, JPDC'13-Trellis, and ASPLOS'16-RAPID papers, and our PIM API in IISWC'24 We also continue to maintain several research tools we developed, including: The MNCaRT automata and regular expression processing toolset The Rodinia benchmark suite of applications with both optimized GPU and multicore-CPU implementations of a diverse set of applications  (see our IISWC'10, IISWC'09 and JPDC'08 papers and ASPLOS 2010 tutorial) -- also support for the SPECaccel benchmark suite, which incorporates over half of the Rodinia suite. HotSpot (e.g. our IEEE. Trans. Computers'08 and ISPASS'09 papers), and most recently HotSpot 7.0. In prior work, my group has: Explored scaling implications for power delivery (e.g., our ISCA'14 paper) and fault tolerance (e.g., our IEEE Micro'13 paper),  explored new runtime reliability management techniques to balance performance and wear-out (e.g. our IEEE Micro'05 paper), and cope with transient faults (e.g. our GH'06 and GH'07 papers for GPUs) and take advantage of coarse-grained reconfigurable resources (e.g., our DATE'11 and CASES'11 papers). We also evaluated technology scaling limits and implications (e.g., 2007 presentation to the NRC CSTB study on \"Sustaining Growth in Computing Performance,\" our paper in IEEE Micro on scaling with design constraints (preprint pdf), and our \"Implications of Dim Silicon paper (preprint pdf)). Developed new power delivery modeling capabilities (e.g., see our VoltSpot ISCA'14 paper) and exploring new optimization techniques (e.g., our ASP-DAC'14 and DAC'14 papers) Developed new, efficient cryptography accelerators (e.g., in the VLSI Journal) Developed new design-space exploration capabilities that reduce simulation requirements, such as genetically programmed response surfaces (e.g. our DAC'08 paper and software) and Lumos. New cache organizations for many cores (e.g., our SC'10 and ICCD'09 papers), cache-conscious thread scheduling (e.g., our IPDPS'10 paper), and cache-conscious data layout for heterogeneous systems (SC'11) Explored how to most effectively use texture, constant, per-block shared memory, and other features that GPUs and GPU languages such as CUDA provide (e.g., see our ACM Queue'08, JPDC'08, IPDPS'09, and ICS'09/IJPP'11 papers) Developed new techniques to make SIMD architectures more effective in the presence of irregular data structures or irregular parallelism (see our IPDPS'12, ISCA'10 and SC'09 papers) Developed the first publicly available architectural simulator for GPUs, Qsilver (see our GH'04 paper) Developed improved power map derivation using thermal maps (e.g., our ICCD'10 paper) A new, pre-RTL floorplanning algorithm (see our ArchFP software) New temperature sensing and thermal-management capabilities (e.g. our ITEHRM'06 and follow-on IEEE Trans. Computers papers; see also our ACM Computing Surveys paper on dynamic thermal management and \"prolegomenon\" in IEEE Micro), as well as novel temperature-aware design techniques (e.g. our HPCA'06, DAC'08, and SEMI-THERM'10 papers) Described new techniques for coherence, including bypassing coherence for private data and a simplified form of \"sharing tracker\" coherence for avoiding refetch of shared, read-only data Dynamic combination or \"federation\" of scalar cores to support runtime variations in ILP and DLP (e.g. our DAC'08 and follow-on ACM TACO papers) New, lightweight out-of-order execution techniques with much better performance/mm2 and performance/watt (see our ACM TACO paper - lightweight OO was an enabling technique for federation) Described new power management techniques, especially in the context of real-time constraints, spanning a variety of application types from multimedia (e.g. our Asilomar'06 paper) to multi-tier e-commerce workloads (e.g. our PACT'08 paper) Described a new form of hybrid neural branch predictor Described power-management techniques for branch prediction that do not impede prediction accuracy or performance and shown the importance of branch prediction for energy efficiency Evaluated the optimal energy-efficient scaling of microarchitectural structure sizes for simultaneous multithreading (SMT) Evaluated whether trace caches are energy efficient Explored how current power and thermal management features may expose security vulnerabilities Developed new reliability modeling capabilities (e.g. our IEEE TVLSI'07 paper) Shown the value of control theory in managing adaptive hardware structures, including controlling the DVS setting for a multimedia workload; setting the decay interval f",
  "content_length": 48163,
  "method": "requests",
  "crawl_time": "2025-12-01 13:42:32"
}