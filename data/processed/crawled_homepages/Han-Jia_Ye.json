{
  "name": "Han-Jia Ye",
  "homepage": "http://www.lamda.nju.edu.cn/yehj",
  "status": "success",
  "content": "Han-Jia Ye Home Publications Teaching Students Code Han-Jia Ye (å¶ç¿°å) (Pre-Tenure) Associate Professor School of Artificial Intelligence, Nanjing University State Key Laboratory for Novel Software Technology 163 Xianlin Avenue, Qixia District, Nanjing, China Email: yehjxkxkxk@nju.edu.cn yehjxkxkxk@lamda.nju.edu.cn yhjyehanjiaxkxkxk@gmail.com Short Bio Han-Jia Ye is an Associate Professor (Pre-Tenure) in the School of Artificial Intelligence at the Nanjing University (NJU). His major research focuses on machine learning and its applications to data mining and computer vision, including representation learning, meta-learning, model reuse, and tabular machine learning. Han-Jia received his B.Sc. degree from Nanjing University of Posts and Telecommunications, China in June 2013. After that, he became an M.Sc. student in the LAMDA Group led by professor Zhi-Hua Zhou in Nanjing University. From Sept. 2015, Han-Jia started his Ph.D. degree in machine learning under the supervision of Prof. Yuan Jiang and Prof. De-Chuan Zhan. During 2017-2018, he visited Prof. Fei Sha's group in University of Southern California, LA. He received his PhD degree at May 2019. Latest News 09/2025: Will be hosting two tutorials on model reuse (with Da-Wei Zhou and Zhenguo Li) and tabular representation learning (with Jun-Peng Jiang) at AAAI 2026. 05/2025: 6 papers have been accepted by ICML 2025, and 1 paper has been accepted by ACL 2025. 05/2025: 1 survey paper on model reuse has been accepted by IJCAI 2025. 04/2025: 1 arXiv paper on efficient evaluation of LLM. 04/2025: Release the Tabular Data Github Organization, including our new survey on tabular data. 03/2025: 1 arXiv paper on time series forecasting with model zoo. 02/2025: 1 arXiv paper on analyzing the tabular foundation model TabPFN. 01/2025: 2 papers have been accepted by ICLR 2025. 12/2024: 3 papers have been accepted by AAAI 2025. 09/2024: 3 papers have been accepted by NeurIPS 2024. 06/2024: Release the Tabular Data Learning Toolbox TALENT, a baseline ModernNCA, as well as the benchmark. 06/2024: Release the Multilingual Multimodal Large Language Model Parrot. 06/2024: 1 arXiv paper on Multimodal LLMs Learning without Text-only Forgetting. 06/2024: Release the OVIS Multimodal Large Language Model [Paper]. 05/2024: 4 papers have been accepted by ICML 2024. 05/2024: 1 paper revisiting the channel independent strategy for multivariate time series forecasting has been accepted by TKDE 2024. 04/2024: 1 paper on continual learning with pre-trained model has been accepted by IJCAI 2024 (survey track). 03/2024: 2 papers have been accepted by CVPR 2024. 02/2024: Glad to host a tutorial with Yao-Xiang Ding on model reuse at AAAI 2024. Slides: [Part1][Part2] 12/2023: 2 papers have been accepted by AAAI 2024. 09/2023: 2 papers have been accepted by NeurIPS 2023. 09/2023: Release the Pre-Trained Model-Based Continual Learning Toolbox PILOT [Report][Survey]. 09/2023: 1 paper on contextualized meta-learning has been accepted by TPAMI. 08/2023: Release the Model Reuse toolbox ZhiJian [Report][Documents]. 08/2023: Glad to host a tutorial with Ying Wei and Da-Wei Zhou on continual learning at IJCAI 2023. Slides: [Part1][Part2] 06/2023: 1 arXiv paper on pre-trained model selection/ranking. 02/2023: 1 survey paper on deep class-incremental learning. 01/2023: 3 papers have been accepted by ICLR 2023. 04/2022: 1 papers on unsupervised meta-learning has been accepted by TPAMI. 03/2022: 2 papers on meta-learning and heterogeneous model reuse have been accepted by TPAMI. Show older news Selected Publications [Google scholar] [DBLP] Ting-Ji Huang, Jia-Qi Yang, Chunxu Shen, Kai-Qi Liu, De-Chuan Zhan, Han-Jia Ye. Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens. In: Proceedings of the 42nd International Conference on Machine Learning (ICML) 2025. Vancouver, Canada. [pdf] Hao-Run Cai, Han-Jia Ye. Understanding the Limits of Deep Tabular Methods with Temporal Shift. In: Proceedings of the 42nd International Conference on Machine Learning (ICML) 2025. Vancouver, Canada. [pdf][code] Si-Yang Liu, Han-Jia Ye. TabPFN Unleashed: A Scalable and Effective Solution to Tabular Classification Problems. In: Proceedings of the 42nd International Conference on Machine Learning (ICML) 2025. Vancouver, Canada. [pdf] Han-Jia Ye, Huai-Hong Yin, De-Chuan Zhan, Wei-Lun Chao. Revisiting Nearest Neighbor for Tabular Data: A Deep Tabular Baseline Two Decades Later. In: The 13th International Conference on Learning Representations (ICLR) 2025. Singapore. [pdf][code] Yi-Kai Zhang, Shiyin Lu, Qing-Guo Chen, De-Chuan Zhan, Han-Jia Ye. ZooProbe: A Data Engine for Evaluating, Exploring, and Evolving Large-scale Training Data for Multimodal LLMs. In: The 13th International Conference on Learning Representations (ICLR) 2025. Singapore. [pdf] Yi-Kai Zhang, De-Chuan Zhan, Han-Jia Ye. Capability Instruction Tuning. In: Proceedings of the 39th AAAI Conference on Artificial Intelligence (AAAI) 2025: 25958--25966. Philadelphia, PA. [pdf] [code] Chao Yi, Yu-Hang He, De-Chuan Zhan, Han-Jia Ye. Bridge the Modality and Capability Gaps in Vision-Language Model Selection. Advances in Neural Information Processing Systems 37 (NeurIPS). 2024. [pdf] [code] Lu Han, Han-Jia Ye, De-Chuan Zhan. The Capacity and Robustness Trade-Off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting. IEEE Transactions on Knowledge and Data Engineering. 36(11): 7129-7142, 2024. [pdf] [code] Han-Jia Ye, Da-Wei Zhou, Lanqing Hong, Zhenguo Li, Xiu-Shen Wei, De-Chuan Zhan. Contextualizing Meta-Learning via Learning to Decompose. IEEE Transactions on Pattern Analysis and Machine Intelligence. 46(1): 117-133, 2024. [pdf] [code] Han-Jia Ye, Lu Ming, De-Chuan Zhan, Wei-Lun Chao. Few-Shot Learning with a Strong Teacher. IEEE Transactions on Pattern Analysis and Machine Intelligence. 46(3): 1425-1440, 2024. [pdf] [code] Yi-Kai Zhang, Ting-Ji Huang, Yao-Xiang Ding, De-Chuan Zhan, Han-Jia Ye. Model Spider: Learning to Rank Pre-Trained Models Efficiently. Advances in Neural Information Processing Systems 36 (NeurIPS). 2023. [pdf] [code] Han-Jia Ye, Lu Han, De-Chuan Zhan. Revisiting Unsupervised Meta-Learning via the Characteristics of Few-Shot Tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence. 45(3): 3721-3737, 2021. [pdf] [code] Han-Jia Ye, Su Lu, De-Chuan Zhan. Generalized Knowledge Distillation via Relationship Matching. IEEE Transactions on Pattern Analysis and Machine Intelligence. 45(2): 1817-1834, 2023. [pdf] [code] Lu Han, Han-Jia Ye, De-Chuan Zhan. Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps. In: The 11th International Conference on Learning Representations (ICLR) 2023. Kigali, Rwanda. [pdf] [code] Da-Wei Zhou, Qi-Wei Wang, Han-Jia Ye, De-Chuan Zhan. A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning. In: The 11th International Conference on Learning Representations (ICLR) 2023. Kigali, Rwanda. [pdf] [code] Han-Jia Ye, Le Gan, De-Chuan Zhan. How to Train Your MAML to Excel in Few-Shot Classification. In: The 10th International Conference on Learning Representations (ICLR) 2022. Virtual. [pdf] [code] Han-Jia Ye, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou. Heterogeneous Few-Shot Model Rectification with Semantic Mapping. IEEE Transactions on Pattern Analysis and Machine Intelligence. 43(11): 3878-3891, 2021. [pdf] [code] Xiu-Shen Wei*, Han-Jia Ye*, Xin Mu, Jianxin Wu, Chunhua Shen, Zhi-Hua Zhou. Multi-Instance Learning With Emerging Novel Class. IEEE Transactions on Knowledge and Data Engineering. 33(5): 2109-2120, 2021. [pdf] Su Lu, Han-Jia Ye, Le Gan, De-Chuan Zhan. Towards Enabling Meta-Learning from Target Models. In: Advances in Neural Information Processing Systems 34 (NeurIPS) 2021: 8060--8071. Virtual. [pdf] [code] Han-Jia Ye, Xin-Chun Li, De-Chuan Zhan. Task Cooperation for Semi-Supervised Few-Shot Learning. In: Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI) 2021: 10682-10690. Virtual. [pdf][code] Han-Jia Ye, De-Chuan Zhan, Wei-Lun Chao. Procrustean Training for Imbalanced Deep Learning. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) 2021: 92--102. Montreal, Canada. [pdf] Han-Jia Ye, Hong-You Chen, De-Chuan Zhan, Wei-Lun Chao. Identifying and Compensating for Feature Deviation in Imbalanced Deep Learning. CoRR abs/2001.01385. 2020. [pdf] Han-Jia Ye, De-Chuan Zhan, Nan Li, Yuan Jiang. Learning Multiple Local Metrics: Global Consideration Helps. IEEE Transactions on Pattern Analysis and Machine Intelligence. 42(7): 1698-1712, 2020. [pdf] Han-Jia Ye, Xiang-Rong Sheng, De-Chuan Zhan. Few-shot learning with adaptively initialized task optimizer: a practical meta-learning approach. Machine Learning. 109(3): 643-664, 2020. [pdf] [code] Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, Fei Sha. Few-Shot Learning via Embedding Adaptation With Set-to-Set Functions. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020: 8805--8814. Seattle, WA. [pdf] [code] Han-Jia Ye, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou. What Makes Objects Similar: A Unified Multi-Metric Learning Approach. IEEE Transactions on Pattern Analysis and Machine Intelligence. 41(5): 1257-1270, 2019. [pdf] [supp] [code] Wei-Lun Chao*, Han-Jia Ye*, De-Chuan Zhan, Mark Campbell, Kilian Q. Weinberger. A Meta Understanding of Meta-Learning. In: The Adaptive and Multitask Learning (AMTL) 2019 Workshop 2019. Long Beach, CA. [pdf] Han-Jia Ye, De-Chuan Zhan, Yuan Jiang. Fast generalization rates for distance metric learning. Machine Learning. 108(2): 267-295, 2019. [pdf] Han-Jia Ye, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou. Rectify Heterogeneous Models with Semantic Mapping. In: Proceedings of the 35th International Conference on Machine Learning (ICML) 2018: 1904-1913. Stockholm, Sweden. [pdf] [code] Han-Jia Ye, De-Chuan Zhan, Xue-Min Si, Yuan Jiang. Learning Mahalanobis Distance Metric: Consi",
  "content_length": 13401,
  "method": "requests",
  "crawl_time": "2025-12-01 13:17:47"
}