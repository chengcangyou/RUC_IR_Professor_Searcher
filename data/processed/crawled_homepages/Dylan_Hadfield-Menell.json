{
  "name": "Dylan Hadfield-Menell",
  "homepage": "https://people.csail.mit.edu/dhm",
  "status": "success",
  "content": "Dylan Hadfield-Menell I am an Associate Professor of EECS at MIT. I run the Algorithmic Alignment Group in the Computer Science and Artificial Intelligence Laboratory (CSAIL). My research develops methods to ensure that AI systems behavior aligns with the goals and values of their human users and society as a whole, a concept known as 'AI alignment'. My group and I work to address alignment challenges in multi-agent systems, human-AI teams, and societal oversight of machine learning. Our goal is to enable the safe, beneficial, and trustworthy deployment of AI in real-world settings. Dylan Hadfield-Menell dhm at csail.mit.edu Associate Professor of EECS Faculty of Artificial Intelligence and Decision-Making Computer Science and Artificial Intelligence Laboratory Dept. of Electrical Engineering and Computer Science Massachusetts Institute of Technology 44 Vassar St., 45-701D Cambridge, MA 02139 United States Google Scholar Twitter LinkedIn Publications Journal Publications Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities. Zora Che, Stephen Casper, Robert Kirk, Anirudh Satheesh, Stewart Slocum, Lev McKinney, Rohit Gandikota, Aidan Ewart, Domenic Rosati, Zichu Wu, Zikui Cai, Bilal Chughtai, Yarin Gal, Furong Huang, Dylan Hadfield-Menell. Transactions on Machine Learning Research (TMLR). 2025. Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs Abhay Sheshadri, Aidan Ewart, Phillip Guo, Aengus Lynch, Cindy Wu, Vivek Hebbar, Henry Sleight, Asa Cooper Stickland, Ethan Perez, Dylan Hadfield-Menell, Stephen Casper. Transactions on Machine Learning Research (TMLR). 2025. Defending Against Unforeseen Failure Modes with Latent Adversarial Training Stephen Casper, Lennart Schulze, Oam Patel, Dylan Hadfield-Menell. Transactions on Machine Learning Research (TMLR). 2025. Building Human Values into Recommender Systems: An Interdisciplinary Synthesis Jonathan Stray, Alon Halevy, Parisa Assar, Dylan Hadfield-Menell, Craig Boutilier, Amar Ashar, Chloe Bakalar, Lex Beattie, Michael Ekstrand, Claire Leibowicz, Connie Moon Sehat, Sara Johansen, Lianne Kerlin, David Vickrey, Spandana Singh, Sanne Vrijenhoek, Amy Zhang, McKane Andrus, Natali Helberger, Polina Proutskova, Tanushree Mitra, Nina Vasan. ACM Transactions on Recommender Systems. 2024. Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert, JÃ©rÃ©my Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, Tony Wang, Samuel Marks, Charbel-RaphaÃ«l Segerie, Micah Carroll, Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman Anwar, Anand Siththaranjan, Max Nadeau, Eric J Michaud, Jacob Pfau, Dmitrii Krasheninnikov, Xin Chen, Lauro Langosco, Peter Hase, Erdem BÄ±yÄ±k, Anca Dragan, David Krueger, Dorsa Sadigh, Dylan Hadfield-Menell. Transactions on Machine Learning Research (TMLR). 2023. Judging Facts, Judging Norms: Training Machine Learning Models to Judge Humans Requires a Modified Approach to Labeling Data Aparna Balagopalan, David Madras, David H Yang, Dylan Hadfield-Menell, Gillian K Hadfield, Marzyeh Ghassemi. Science Advances. 2023. Spurious Normativity Enhances Learning of Compliance and Enforcement Behavior in Artificial Agents. Raphael Koster, Dylan Hadfield-Menell, Richard Everett, Laura Weidinger, Gillian K. Hadfield, and Joel Z. Leibo. Proceedings of the National Academy of Sciences of the United States (PNAS). 2022. When Curation Becomes Creation: Algorithms, Microcontent, and the Vanishing Distinction Between Platforms and Creators. Liu Leqi, Dylan Hadfield-Menell, Zachary C. Lipton. Communications of the ACM. 2021. Conference Publications Randomness, Not Representation: The Unreliability of Evaluating Cultural Alignment in LLMs. Ariba Khan, Stephen Casper, Dylan Hadfield-Menell. Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT). 2025. Diverse Preference Learning for Capabilities and Alignment. Stewart Slocum, Asher Parker-Sartori, Dylan Hadfield-Menell. The Thirteenth International Conference on Learning Representations (ICLR). 2025. Pitfalls of Evidence-Based AI Policy. Stephen Casper, David Krueger, Dylan Hadfield-Menell. ICLR Blogpost Track. 2025. Melting Pot Contest: Charting the Future of Generalized Cooperative Intelligence. Rakshit Trivedi, Akbir Khan, Jesse Clifton, Lewis Hammond, Edgar A DuÃ©Ã±ez-GuzmÃ¡n, John P Agapiou, Jayd Matyas, Sasha Vezhnevets, Dipam Chakraborty, Yue Zhao, Marko Tesic, Barna PÃ¡sztor, Yunke Ao, Omar G. Younis, Jiawei Huang, Benjamin Swain, Haoyuan Qin, Mian Deng, Ziwei Deng, Utku Erdoganaras, Natasha Jaques, Jakob Nicolaus Foerster, Vincent Conitzer, Jose Hernandez-Orallo, Dylan Hadfield-Menell, Joel Z Leibo. Advances in Neural Information Processing Systems (NeurIPS), Competition Track. 2024. The Concordia Contest: Advancing the Cooperative Intelligence of Language Agents. Chandler Smith, Rakshit Trivedi, Jesse Clifton, Lewis Hammond, Akbir Khan, Marwa Abdulhai, Alexander Sasha Vezhnevets, John P Agapiou, Edgar A DuÃ©Ã±ez-GuzmÃ¡n, Jayd Matyas, Danny Karmon, Oliver Slumbers, Minsuk Chang, Dylan Hadfield-Menell, Natasha Jaques, Tim Baarslag, Joel Z. Leibo. Advances in Neural Information Processing Systems (NeurIPS), Competition Track. 2024. Black-Box Access is Insufficient for Rigorous AI Audits. Stephen Casper, Carson Ezell, Charlotte Siegmann, Noam Kolt, Taylor Lynn Curtis, Benjamin Bucknall, Andreas Haupt, Kevin Wei, JÃ©rÃ©my Scheurer, Marius Hobbhahn, Lee Sharkey, Satyapriya Krishna, Marvin Von Hagen, Silas Alberti, Alan Chan, Qinyi Sun, Michael Gerovitch, David Bau, Max Tegmark, David Krueger, Dylan Hadfield-Menell. Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT). 2024. Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF. Anand Siththaranjan, Cassidy Laidlaw, Dylan Hadfield-Menell. Proceedings of the 12th International Conference on Learning Representations (ICLR). 2024. The SaTML 24 CNN Interpretability Competition: New Innovations for Concept-Level Interpretability. Stephen Casper, Jieun Yun, Joonhyuk Baek, Yeseong Jung, Minhwan Kim, Kiwan Kwon, Saerom Park, Hayden Moore, David Shriver, Marissa Connor, Keltin Grimes, Angus Nicolson, Arush Tagade, Jessica Rumbelow, Hieu Minh Nguyen, Dylan Hadfield-Menell. roceedings of the 2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 2024. Red Teaming AI: The Devil Is In The Details. Sina Fazelpour, Dylan Hadfield-Menell, Luca Belli. Tech Policy Press. 2024. Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness? Kevin Liu, Stephen Casper, Dylan Hadfield-Menell, Jacob Andreas. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2023. Get It in Writing: Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL. Phillip JK Christoffersen, Andreas A Haupt, Dylan Hadfield-Menell. Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems (AAMAS). 2023. Red Teaming Deep Neural Networks with Feature Synthesis Tools. Stephen Casper, Yuxiao Li, Jiawei Li, Tong Bu, Kevin Zhang, Kaivalya Hariharan, Dylan Hadfield-Menell. Advances in Neural Information Processing Systems (NeurIPS). 2023. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. Tilman RÃ¤uker, Anson Ho, Stephen Casper, Dylan Hadfield-Menell. 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). 2023. Estimating and Penalizing Induced Preference Shifts in Recommender Systems. Micah D Carroll, Anca Dragan, Stuart Russell, Dylan Hadfield-Menell. International Conference on Machine Learning (ICML). 2022. A Penalty Default Approach to Preemptive Harm Disclosure and Mitigation for AI Systems. Rui-Jie Yew, Dylan Hadfield-Menell. Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES). 2022. Robust Feature-Level Adversaries are Interpretability Tools. Stephen Casper, Max Nadeau, Dylan Hadfield-Menell, Gabriel Kreiman. Advances in Neural Information Processing Systems (NeurIPS). 2022. How to Talk so AI will Learn: Instructions, Descriptions, and Autonomy. Theodore R Sumers, Robert D Hawkins, Mark K Ho, Thomas L Griffiths, Dylan Hadfield-Menell. Advances in Neural Information Processing Systems (NeurIPS). 2022. Towards Psychologically-Grounded Dynamic Preference Models. Mihaela Curmei, Andreas A Haupt, Dylan Hadfield-Menell, Benjamin Recht. Proceedings of the 16th ACM Conference on Recommender Systems (RecSys). 2022. Guided Imitation of Task and Motion Planning. Michael J. McDonald, Dylan Hadfield-Menell. Proceedings of the 5th Conference on Robot Learning (CoRL). 2021. Consequences of Misaligned AI. Simon Zhuang, Dylan Hadfield-Menell. Proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS). 2020. Conservative Agency via Attainable Utility Preservation. Alexander M. Turner, Dylan Hadfield-Menell, Prasad Tadepalli. Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES). 2020. The Assistive Multi-Armed Bandit. Lawrence Chan, Dylan Hadfield-Menell, Siddartha S. Srinivasa, Anca D. Dragan. Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI). 2019. Human-AI Learning Performance in Multi-Armed Bandits. Ravi Pandya, Sandy H. Huang, Dylan Hadfield-Menell, Anca D. Dragan. Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES). 2019. Legible Normativity for AI Alignment: The Value of Silly Rules. Dylan Hadfield-Menell, McKane Andrus, Gillian K. Hadfield. Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES). 2019. Incomplete Contracting and AI Alignment. Dylan Hadfield-Menell, Gillian K. Hadfield. Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES). 2019",
  "content_length": 15429,
  "method": "requests",
  "crawl_time": "2025-12-01 13:04:16"
}