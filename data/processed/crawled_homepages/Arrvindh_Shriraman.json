{
  "name": "Arrvindh Shriraman",
  "homepage": "http://www.cs.sfu.ca/~ashriram",
  "status": "success",
  "content": "Arrvindh Shriraman · SFU CS Associate Professor (since Sep'16) School of Computing Science Simon Fraser University Email: ac.ufs.sc.@marirhsa Gmail: moc.liamg@krow.marirhsa Google Scholar Github Linkedin Group Github Arrvindh Shriraman School of Computing Science ASB 9241, 8888 University Drive Simon Fraser University Burnaby, BC V5A 1S6, Canada Tel: I prefer email contact. perm_contact_calendarCalendar directions_carDirections Teaching 295: Intro to Computer Systems Posts Accelerator Benchmarks If you are interested in working with me, before you email me, please read my First Contact guide. Active Research (more-) NEEDLE Vendors have closely integrated reconfigurable logic (e.g., FPGAs) into multicores that enable the software community to realize accelerators for specific program regions. We propose a methodical LLVM-based compiler approach to answer the question, what is acceleratable? and help software developers with early stage exploration of acceleration targets. Our hypothesis is that an entirely new program execution-based abstraction is needed to extract acceleratable regions from programs to help hardware synthesis tools. [IISWC'16,HPCA'16] FUSION Chip designers have shown increasing interest in integrating specialized fixed-function coprocessors. With increasing energy cost of wires and caches relative to compute operations, it is imperative to optimize data movement to retain the energy benefits of accelerators. We have developed a lightweight coherent cache hierarchy for accelerators to optimize the data movement. We are studying coherence based memory models for both GPUs [HPCA'13] and fixed-function coprocessors [ISCA'15]. Recent Publications and Talks All publications . . , () : URL PDF BibTeX Abstract Abstract: Bibtex: Software All software µIR - Microarchitecture Intermediate Representation (MICRO'19) High-level synthesis and Accelerator generation tool [More] Deepframe (PACT'19) Deep-learning based trace compiler for constructing accelerator offload [More] Service (more-) Program committee members, ASPLOS 2017, MICRO 2016, HPCA 2015, Local Arrangements Chair, MICRO 2012. Recently Graduated Students All students and postdocs Student theses Postdoc (Total: 1) Guha, Apala. Deep learning paths and traces. (Spring 2016 - Fall 2019). First Job: Startup Phd (Total: 7) Vedula, Naveen. Running deep learning applications on resource constrained devices. (Fall 2014 - Summer 2021). First Job: Huawei Reza Hojabr. High-Performance Interconnection Networks for Neural Network Accelerators. (Fall 2019 - Spring 2021). First Job: Untether AI MSc (Total: 7) Sedaghati, Ali. X-Cache: A Modular Architecture for Domain-Specific Caches. ( Fall 2019 - Spring 2022). First Job: Huawei Bui, Minh. Hardware and Software Acceleration for Hamilton-Jacobi Reachability Analysis. ( Fall 2019 - Summer 2021). First Job: Phd at SFU",
  "content_length": 2865,
  "method": "requests",
  "crawl_time": "2025-12-01 13:01:21"
}