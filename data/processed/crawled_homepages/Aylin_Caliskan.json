{
  "name": "Aylin Caliskan",
  "homepage": "https://faculty.washington.edu/aylin/index.html",
  "status": "success",
  "content": "Aylin Caliskan - University of Washington Home Publications Advising Teaching Talks Press Service Bio Aylin Caliskan My first name is pronounced as /aÉªËlin/ Associate ProfessorThe Information School Paul G. Allen School of Computer Science & Engineering (courtesy) Co-director â¢ Tech Policy Lab Faculty Affiliate â¢ UW NLP RAISE, VSD Lab University of Washington Nonresident Senior Fellow in Governance Studies Center for Technology Innovation - Brookings Institution aylin@uw.edu I am a computer scientist with additional formal training in information systems engineering and robotics, specializing in artificial intelligence (AI) and its societal impacts. More specifically, I focus on technical and empirical AI ethics in natural language processing, multimodal machine learning, and human-AI collaboration. My work was among the first to rigorously show that machine learning models trained on language corpora encode human-like biases. I investigate the underpinning mechanisms of information transfer between human society and AI.Â To analyze and control AI representations, reasoning, and outputs, I develop evaluation methods, transparency enhancing approaches, and mitigation techniques that detect, quantify, characterize, and steer biases, errors, and potential harms of AI.Â I study human-AI interaction to uncover how machines impact humans and society.Â As AI co-evolves with society, my work advances the responsible development and deployment of AI by integrating societal considerations to benefit everyone. News Iâm honored to be promoted to Associate Professor with tenure at the University of Washington! This milestone was made possible thanks to my brilliant mentees, students, collaborators, mentors, and the Tech Policy Lab for advancing artificial intelligence & ethics together. In 2024, I received the NSF CAREER Award for my research on the Societal Impact of Generative AI and Aligning AI with Ethical Principles. In 2023, I was recognized as one of the 100 Brilliant Women in AI Ethics and honored with an IJCAI Early Career Spotlight. In 2024, I will participate in an expert conversation at Johns Hopkins University on Gender, Data & Equity. I have been invited to deliver a talk on the Societal Impact of Generative AI and Ethics at the Stanford Center for AI Safety Annual Meeting and another on Fairness, Bias, and Factuality in Generative AI at NYU. I will give keynotes at UCSF School of Medicine and AIBSD AAAI, and a Seminal Presentation on Bias and Fairness in Artificial Intelligence at Howard University. I am teaching Generative AI in Autumn 2024. My paper on implicit bias in AI is published in Science. Semantics derived automatically from language corpora contain human-like biases. source code Aylin Caliskan, Joanna J. Bryson, and Arvind Narayanan.A Story of Discrimination and Unfairness: Implicit Bias Embedded in Language Models. 9th Hot Topics in Privacy Enhancing Technologies Accepted on 5/20/2016 Research Anna-Maria Gueorguieva and Aylin Caliskan Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation accepted, The 40th Annual AAAI Conference on Artificial Intelligence, Alignment Track (AAAI 2026) Yuchen Wu, Edward Sun, Kaijie Zhu, Jianxun Lian, Jose Hernandez-Orallo, Aylin Caliskan, and Jindong Wang Personalized Safety in LLMs: A Benchmark and A Planning-Based Agent Approach The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025) Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, and Aylin Caliskan No Thoughts Just AI: Biased LLM Hiring Recommendations Alter Human Decision Making and Limit Human Autonomy AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2025) Mattea Sim, Natalie Grace Brigham, Tadayoshi Kohno, Tessa E. S. Charlesworth, and Aylin Caliskan Biased AI Outputs Can Impact Humans' Implicit Bias: A Case Study of the Impact of Gender-Biased Text-to-Image Generators AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2025) Gandalf Nicolas and Aylin Caliskan What Are Chatbotsâ Stereotypes About? A Data-Driven Analysis of Large Language Modelsâ Content Associations with Social Categories AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2025) Kyra Wilson, Sourojit Ghosh, and Aylin Caliskan Bias Amplification in Stable Diffusionâs Representation of Stigma Through Skin Tones and Their Homogeneity AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2025) Saloni Dash, AmÃ©lie Reymond, Emma S. Spiro, and Aylin Caliskan Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning Social Simulation with LLMs at Conference on Language Modeling (COLM 2025), arXiv 2025 Kshitish Ghate, Tessa Charlesworth, Mona Diab, and Aylin Caliskan Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes In Findings of the Association for Computational Linguistics: ACL 2025 Kyra Wilson and Aylin Caliskan Gender, Race, and Intersectional Bias in AI Resume Screening via Language Model Retrieval Brookings 2025 Kshitish Ghate*, Isaac Slaughter*, Kyra Wilson, Mona Diab, and Aylin Caliskan (*denotes equal contributions) Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders North American Chapter of the Association for Computational Linguistics (NAACL 2025) Yuyang Jiang, Longjie Guo, Yuchen Wu, Aylin Caliskan, Tanushree Mitra, Hua Shen Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions 2025 Chahat Raj, Bowen Wei, Aylin Caliskan, Antonios Anastasopoulos, and Ziwei Zhu VIGNETTE: Socially Grounded Bias Evaluation for Vision-Language Models arXiv 2025 Chahat Raj, Mahika Banerjee, Aylin Caliskan, Antonios Anastasopoulos, and Ziwei Zhu Talent or Luck? Evaluating Attribution Bias in Large Language Models arXiv 2025 Kshitish Ghate, Andy Liu, Devansh Jain, Taylor Sorensen, Atoosa Kasirzadeh, Aylin Caliskan, Mona T. Diab, and Maarten Sap EVALUESTEER: Measuring Reward Model Steerability Towards Values and Preference arXiv 2025 Gandalf Nicolas and Aylin Caliskan Directionality and Representativeness are Differentiable Components of Stereotypes in Large Language Models PNAS Nexus, 2024 Gandalf Nicolas and Aylin Caliskan A Taxonomy of Stereotype Content in Large Language Models arXiv 2024 Kyra Wilson and Aylin Caliskan Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2024) Sourojit Ghosh*, Nina Lutz*, and Aylin Caliskan (*denotes equal contributions) \"I don't see myself represented here at all\": User Experiences of Stable Diffusion Outputs Containing Representational Harms across Gender Identities and Nationalities AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2024) Sourojit Ghosh*, Pranav Narayanan Venkit*, Sanjana Gautam*, Shomir Wilson, and Aylin Caliskan (*denotes equal contributions) Do Generative AI Models Output Harm while Representing Non-Western Cultures: Evidence from A Community-Centered Approach AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2024) Chahat Raj, Anjishnu Mukherjee, Aylin Caliskan, Antonios Anastasopoulos, and Ziwei Zhu Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AAAI/ACM AIES 2024) Aylin Caliskan and Kristian Lum Effective AI regulation requires understanding general-purpose AI Brookings 2024 Steven A. Lehr, Aylin Caliskan, Suneragiri Liyanage, and Mahzarin R. Banaji ChatGPT as Research Scientist: Probing GPT's Capabilities as a Research Librarian, Research Ethicist, Data Generator and Data Predictor Proceedings of the National Academy of Sciences (PNAS 2024) Chahat Raj, Anjishnu Mukherjee, Aylin Caliskan, Antonios Anastasopoulos, and Ziwei Zhu BiasDora: Exploring Hidden Biased Associations in Vision-Language Models In Findings of the Association for Computational Linguistics: EMNLP 2024 Amanda Alvarez, Aylin Caliskan, M. J. Crockett, Shirley S. Ho, Lisa Messeri, and Jevin West (alphabetical order) Science communication with generative AI Nature Human Behaviour, 2024 Tessa Elizabeth Sadie Charlesworth, Kshitish Ghate, Aylin Caliskan, and Mahzarin R. Banaji Extracting intersectional stereotypes from embeddings: Developing and validating the Flexible Intersectional Stereotype Extraction procedure PNAS Nexus, 2024 Anjishnu Mukherjee, Aylin Caliskan, Ziwei Zhu, Antonios Anastasopoulos Global Gallery: The Fine Art of Painting Culture Portraits through Multilingual Instruction Tuning North American Chapter of the Association for Computational Linguistics (NAACL 2024) Inyoung Cheong, Aylin Caliskan, and Tadayoshi Kohno Safeguarding Human Values: Rethinking US Law for Generative AI's Societal Impacts AI and Ethics 2024 Yiwei Yang, Anthony Zhe Liu, Robert Wolfe, Aylin Caliskan, Bill Howe Label-Efficient Group Robustness via Out-of-Distribution Concept Curation Conference on Computer Vision and Pattern Recognition (CVPR 2024) Aylin Caliskan Artificial Intelligence, Bias, and Ethics The 32nd International Joint Conference on Artificial Intelligence (IJCAI 2023) IJCAI Early Career Spotlight Paper Federico Bianchi, Pratyusha Kalluri, Esin Durmus, Faisal Ladhak, Myra Cheng, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin Caliskan Demographic Stereotypes in Text-to-Image Generation Stanford University Human-Centered Artificial Intelligence Policy Brief 2023 Isaac Slaughter, Craig Greenberg, Reva Schwartz, and Aylin Caliskan Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition In Findings of the Associ",
  "content_length": 16172,
  "method": "requests",
  "crawl_time": "2025-12-01 13:02:26"
}