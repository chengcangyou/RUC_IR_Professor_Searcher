{
  "name": "Stella X. Yu",
  "homepage": "https://web.eecs.umich.edu/~stellayu",
  "status": "success",
  "content": "Stella Yu Stella Yu stellayu @ umich . edu, 734-647-1761 Stella Yu received her Ph.D. from Carnegie Mellon University, where she studied robotics at the Robotics Institute and cognitive neuroscience at the Center for the Neural Basis of Cognition. Before joining the University of Michigan as a Full Professor of Electrical Engineering and Computer Science in Fall 2022, she was the Director of Vision Group at the International Computer Science Institute, a Senior Fellow at the Berkeley Institute for Data Science, and an Adjunct Professor in Computer Science, Vision Science, Cognitive and Brain Sciences at UC Berkeley. She is a recipient of the NSF CAREER Award and the Clare Boothe Luce Professorship. Teaching 2026 WUMEECS 442 Computer Vision 2025 FUMEECS 542 Advanced Topics in Computer Vision 2025 FUMCSE 598 Action and Perception 2025 WUMEECS 442 Computer Vision 2024 FUMEECS 542 Advanced Topics in Computer Vision 2024 WUMEECS 598 Action and Perception 2023 FUMEECS 542 Advanced Topics in Computer Vision 2023 WUMEECS 598 Action and Perception Research Google Scholar Papers Talks Services My research lies at the intersection of computer vision, human vision, machine learning, and robotics. Visual perception is not only a fascinating computational challenge, but more importantly, an intelligent solution to large-scale pattern recognition and adaptive decision-making in complex environments. Human vision is a universal sensing system like no other: a flexible light meter, an instant geometer, a versatile material comparator, and a holistic parser. What fascinates me most is that infants with normal vision all learn to see -- beginning with a nebulous blur and gradually shaped by diverse, iterative interactions with the world. This developmental process produces a profound integration of action and perception, such that seeing becomes believing, and visual reality becomes the reality. My research explores this phenomenon through four interconnected themes. 1. Actionable Representation Learning from Natural Data I attribute our fast, effortless vision to actionable representation learning driven by natural data, where mid-level visual elements can be flexibly recomposed to support generalization. My work seeks to uncover these internal compositional structures that make recognition and adaptation in humans so efficient, and to build models that do the same. Recent works: Test-Time Canonicalization, Open Ad-hoc Recognition, Concurrent Segmentation and Recognition, Unsupervised Hierarchical Semantic Segmentation, The Emergence of Objectness, SegSort, Scalable NCA, Instance-Group Discrimination, Instance Discrimination, Open Compound Domain Adaptation, Open Long-Tailed Recognition, Unsupervised Selective Labeling. 2. Integrative Perception-Action Learning for Embodied Autonomy I study vision as integral to how an agent achieves autonomy and understands the world through interaction. Traditional vision research often defines perception tasks in isolation, e.g., recognition, detection, segmentation, as if perception were an end in itself. In contrast, I view perception as fundamentally shaped by its role in agent autonomy and world understanding. This broader perspective is rooted in human development, where vision emerges not as a separate module, but through its continuous coupling with bodily action and environmental feedback. My research explores this coupling through computational models and embodied learning systems that treat perception and action as inseparable components of autonomy. Recent work: Integrative Skill Development in Humanoids 3. Efficient Structure-Aware Machine Learning Models I view a computational model as dual to the data it takes in. Because natural visual data are inherently structured - spatially, temporally, and semantically - models that reflect these structures can achieve greater efficiency, robustness, and interpretability. My work incorporates structural inductive biases such as symmetry, part-whole hierarchies, and geometric constraints to accelerate learning and improve generalization. Recent works: Visually Consistent Hierarchical Recognition, Unsupervised Pose-Aware Feature Learning, Emergent Data-Driven Prototypicality, Co-Domain Symmetry, SurReal: Complex-Valued Learning, Recurrent Parameter Generator, Orthogonal CNN, Clipped Hyperbolic Classifiers and CO-SNE. 4. Application to Science, Medicine, and Engineering I am interested in applying computer vision and machine learning to capture and exceed human expertise, enabling automatic data-driven discoveries in science, medicine, and engineering. Recent works: Coordinate-Based Neural Representations for Computational Adaptive Optics, Unsupervised Phenotyping of Retinal Fundus Images and Demographics Prediction from Meibography, High Fidelity MRI Reconstruction, BatVision, Regional Scale Building Information Modeling, Iterative Human and Automated Identification of Wildlife Images, Dental Restoration. Advisees Ph.D. Students: Utkarsh Singhal, Alfredo De Goyeneche, Ryan Feng, Zilin Wang, Jerry Zhengjie Xu, Yixing Wang, Seung Hyun Lee, Andrew Christopher Scheffer, Stanley Cheng-Lin Hsieh, Ye Li, Sihan Xu Postdocs: Kwan-Yee Lin, Seulki Park, Gustavo Perez, Osher Azulay Note: I look for motivated and thoughtful postdocs and Ph.D. students in computer vision, robotics, and machine learning. Strong math / debugging / communication skills are desired. Please read my papers to see whether we can develop a shared vision. Alumni Ph.D. Students Peter Zhihang Ren: Serial Dependence Study in Medical Image Perception via Generative Models Peter Jiayun Wang: Structure-Aware Representation Learning and Its Medical Applications Ke Wang: Magnetic Resonance Image Reconstruction with Greater Fidelity and Efficiency Tsung-Wei Ke: Learning Visual Groupings and Representations with Minimal Human Labels Ke Wang: Magnetic Resonance Imaging with Greater Fidelity and Efficiency Zhongqi Miao: Deep Learning Applications in Wildlife Recognition Baladitya Yellapragada: Insights and Applications from Data-driven Representation Learning Jyh-Jing Hwang: Learning Image Segmentation with Relation-centric Loss and Representation Pat Virtue: Complex-valued Deep Learning with Applications to Magnetic Resonance Image Synthesis Elena Bernardis: Finding Dots in Microscopic Images Weiyu Zhang Postdocs: Yan Xu, Iksung Kang, Amir Rahimi, Sangwoo Mo, Fei Pan, Sangryul Jeon, Dong-Jin Kim, Nils-Steffen Worzyk, Yunhui Guo, Saeed Seyyedi, Sascha Hornauer, Rudrasis Chakraborty, Qian Yu, Zhirong Wu, Ziwei Liu, Caigui Jiang, Matthias Demant, Seyed Ali Amirshahi, Dimitri Lisin, Christina Pavlopoulou Graduate Students: Anna Kay, Brian Wang, Saicharan Bandikallu, Youren Zhang, Oliver Wang, Gaurav Kaul, Daniel Chun-Hsiao Yeh, Tony Long Lian, Girish Chandar Ganesan, Ge Zhang, Qingyi Chen, Frank Xudong Wang, Naren Doraiswamy, Xinlei Pan, Daniel Lin, Haoran Guo, Galen Chuang, Yifei Xing, Arian Ranjbar, Jesper Haahr Christensen, Jianqiao Ni, Michele Winter, Sebastian Palacio, Undergraduate Students: Leon Maksin, Qianqi Yan, Matthew Wang, Tejasvi Kothapalli, Joshua Levine, Daniel Zeng, Ke Li, Runtao Liu, Shuai Liu, Emily Hsiao, Alice Duan, Lu Yu, Pengyuan Chen, Wayne Li, Lucy Yang, Borong Zhang, Vinay Ramasesh, Noah Golmant, Renee Sweeney, Riley Edmunds, William Guss, Asha Anoosheh Links Wolverine, HR, MCommunity, M-Reports, Compute Usage, MIDAS, MICDE Faculty Dashboard, CSE Intranet, Student Applications, CSE Courses Enrollment CoE Rooms, Online Purchase System, M-Market, GET, Faculty Meal, Group Meeting UCB EECS, Redwood Seminar CLIMB, CITRIS, Brilliance New Yorker, New York Times, Economist, Adobe Stock, OED Power School, Parks & Recreation, Ann Arbor Corridor, Rec & Ed, Art Center, Ann Arbor Family Portal, YMCA, Bluelake, Greenhills schedule, GryphOn, Qustodio, Smash Boom Best, UMS, Michigan Sports Camps, UM Youth Hub, UM PPLP, 2023 I1 I2 I3, 2024 PPLP UM Health, UofM, My Chart, BCBS, Dental, Delta, FSA Native Landscape, Google Calendar Sync",
  "content_length": 8010,
  "method": "requests",
  "crawl_time": "2025-12-01 14:31:34"
}