{
  "name": "Marco Mondelli",
  "homepage": "http://marcomondelli.com",
  "status": "success",
  "content": "Marco Mondelli I am a Professor at the Institute of Science and Technology Austria (ISTA), see also my ISTA webpage. I have been at ISTA since 2019 and was an Assistant Professor until 2025. In 2017-2019, I was a Postdoctoral Research Scholar in the Department of Electrical Engineering at Stanford University, where I have worked with Andrea Montanari. I was a Research Fellow at the Simons Institute for the Theory of Computing for the program Foundations of Data Science held in 2018. In 2016, I received my Ph.D. in Computer and Communication Sciences at the Ãcole Polytechnique FÃ©dÃ©rale de Lausanne (EPFL), Switzerland, under the supervision of Prof. RÃ¼diger Urbanke. My current research interests include machine learning, high-dimensional statistics, data science, information theory, and modern coding theory. My research was/is/will be generously supported by an ERC Starting Grant, a Lopez-Loreta Prize, the FWF Cluster of Excellence BILAI, and Google. Contact: marco.mondelli@ist.ac.at Google Scholar             LinkedIn             ResearchGate IEEE BITS special issue Together with Ahmad Beirami (Google), Samet Oymak (University of Michigan), Vatsal Sharan (University of Southern California) and Ananda Theertha Suresh (Google), I am editing a Special Issue on Generative Models of IEEE BITS, The Information Theory Magazine. The topics span alignment, compression, in-context learning, data efficiency and more, see the Call for Paper here. You are encouraged to submit an expository paper intended for a broad audience! Open Positions I have open postdoctoral, PhD, and internship positions. I am actively looking for candidates with strong mathematical background and interest in (at least one of) the broad areas of machine learning, high-dimensional statistics, information theory and quantitative genetics. I have multiple open positions in the context of an ERC Starting Grant awarded for the project \"Inference in High Dimensions: Light-speed Algorithms and Information Limits\". Prospective interns are encouraged to contact me directly via email. Prospective PhD students are encouraged to apply to the IST Austria graduate school and via ELLIS. Prospective postdocs are encouraged to contact me directly via email with a CV, a publication list and a research statement; reference letters will be requested at a later stage. IST Austria also offers attractive postdoctoral positions via the IST-BRIDGE program and the NOMIS program. Ph.D. Students and Postdocs I am extremely lucky to be able to work with the following Ph.D. students and postdocs. Simone Bombari (Ph.D. student) Kevin KÃ¶gler (Ph.D. student) Al Depope (Ph.D. student co-advised with Matthew Robinson) Peter Sukenik (Ph.D. student co-advised with Christoph Lampert) Diyuan Wu (Ph.D. student) Filip KovaÄeviÄ (Ph.D. student) Edwige Cyffers (Postdoc co-advised with Christoph Lampert) ClÃ©mentine DominÃ© (Postdoc co-advised with Francesco Locatello) ...and to have worked with the following alumni! Aleksandr Shevchenko, former Ph.D. student → Postdoc at ETH Amedeo Esposito, former Postdoc → tenure-track Assistant Professor at the Okinawa Institute of Science and Technology (OIST) Yihan Zhang, former Postdoc → Lecturer at the University of Bristol Selected Recent/Future Service I am currently serving in the editorial board of the following journals: IEEE Transactions on Information Theory (Associate Editor, since 2025) Information and Inference: A Journal of the IMA (Associate Editor, since 2025) Mathematical Foundations of Machine Learning (Editor, since 2025) Transactions on Machine Learning Research (Action Editor, since 2024) I am/have been involved in the program committees of the following conferences: ICML 2026 (Senior Area Chair), ICLR 2026 (Area Chair), Youth in High Dimensions 2026 (Co-organizer) NeurIPS 2025 (Senior Area Chair), ICML 2025 (Area Chair), ICLR 2025 (Area Chair), ITW 2025 (TPC Member), Youth in High Dimensions 2025 (Co-organizer) NeurIPS 2024 (Senior Area Chair), ISIT 2024 (Data Set Competition Chair), ICML 2024 (Area Chair), ITW 2024 (TPC Member), Youth in High Dimensions 2024 (Co-organizer) NeurIPS 2023 (Area Chair), ICML 2023 (Area Chair), COLT 2023 (General PC), ISIT 2023 (TPC Member), ITW 2023 (TPC Member), ISTC 2023 (TPC Member), Youth in High Dimensions 2023 (Co-organizer) NeurIPS 2022 (Area Chair), ICML 2022 (Area Chair), ITW 2022 (TPC Member), Youth in High Dimensions 2022 (Co-organizer) ISIT 2021 (TPC Member), ISTC 2021 (TPC Member), Youth in High Dimensions 2021 (Co-organizer) ITW 2020 (TPC Member), ISTC 2020 (TPC Member), ISIT 2019 (TPC Member), ISIT 2018 (TPC Member) Latest Updates November 2025: Three papers accepted at EurIPS workshops: \"Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping\" (joint with Simone and Inbar) has been selected for a contributed talk at the Privacy-Preserving Machine Learning Workshop, where we will also present \"A Law of Data Reconstruction for Random Features (and Beyond)\" (joint with Leonardo, Simone and Tatiana); \"High-dimensional Analysis of Synthetic Data Selection\" (joint with Parham, Filip and Francesco) will be presented at the Workshop on Principles of Generative Modeling. Congratulations Simone, Leonardo, Parham and Filip! October 2025: Our TMLR paper \"Improved Convergence of Score-Based Diffusion Models via Prediction-Correction\" (joint with Francesco and Jan) has been awarded a J2C Certification. October 2025: New paper on arXiv: \"Optimal Regularization for Performative Learning\" (joint with Edwige and Alireza). September 2025: Two papers accepted at the 2025 Conference on Neural Information Processing Systems (NeurIPS'25): \"Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers\" (joint with Peter and Christoph), and \"Attention with Trained Embeddings Provably Selects Important Tokens\" (joint with Diyuan, Alex and Samet). Congratulations Peter and Diyuan! June 2025: Excited that our paper \"Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing\" (joint with Yihan, Hong Chang and Ramji) has been accepted to Mathematical Statistics and Learning (MSL). An extended abstract of this work appeared also at the 2024 Conference on Learning Theory (COLT'24). May 2025: Paper \"Spectral Estimators for Multi-Index Models: Precise Asymptotics and Optimal Weak Recovery\" (joint with Filip and Yihan) accepted at the 2025 Conference on Learning Theory (COLT'25). Congratulations Filip and Yihan! May 2025: Three papers accepted at the 2025 International Conference on Machine Learning (ICML'25), including a spotlight: \"Neural Collapse Beyond the Unconstrainted Features Model: Landscape, Dynamics, and Generalization in the Mean-Field Regime\" (joint with Diyuan, spotlight), \"Spurious Correlations in High Dimensional Regression: The Roles of Regularization, Simplicity Bias and Over-Parameterization\" (joint with Simone), and \"Test-Time Training Provably Improves Transformers as In-context Learners\" (joint with Alperen, Emrullah, Xuechen, Mahdi and Samet). Congratulations Diyuan and Simone! April 2025: Our paper \"Spurious Correlations in High Dimensional Regression: The Roles of Regularization, Simplicity Bias and Over-Parameterization\" (joint with Simone) received the Best Paper Award at the Workshop on Spurious Correlation and Shortcut Learning held at the 2025 International Conference on Learning Representations (SCSL @ICLR'25). April 2025: Thrilled that our paper \"Privacy for Free in the Over-Parameterized Regime\" (joint with Simone) has been accepted to the Proceedings of the National Academy of Sciences (PNAS). Simone gave an oral presentation of this work at DeepMath 2024. February 2025: One paper accepted as an oral and one paper as a spotlight at the 2025 International Conference on Learning Representations (ICLR'25). Oral: \"Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural Collapse\" (joint with Arthur, Peter and Zihan). Spotlight: \"High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws\" (joint with Emrullah, Alperen, Onur and Samet). Congratulations Peter! February 2025: Paper \"Efficient identification of wide shallow neural networks with biases\" (joint with Massimo, Timo and Michael) accepted to Applied and Computational Harmonic Analysis (ACHA). January 2025: Paper \"Information limits and Thouless-Anderson-Palmer equations for spiked matrix models with structured noise\" (joint with Jean, Francesco and Yizhou) accepted to Physical Review Research (PRR). November 2024: Congratulations to Simone for receiving a Google PhD Fellowship! September 2024: Thrilled to be a recipient of an ERC Starting Grant for my project \"Inference in High Dimensions: Light-speed Algorithms and Information Limits\". I will be hiring soon at all levels (postdocs, PhD students and interns). September 2024: Three papers accepted at the 2024 Conference on Neural Information Processing Systems (NeurIPS'24): \"Average gradient outer product as a mechanism for deep neural collapse\" (joint with Daniel, Peter and Misha), \"Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really Optimal?\" (joint with Peter and Christoph), and \"Matrix Denoising with Doubly Heteroscedastic Noise: Fundamental Limits and Optimal Spectral Methods\" (joint with Yihan). Congratulations Peter and Yihan! August 2024: Congratulations Dr. Aleksandr Shevchenko on defending your Ph.D.! July 2024: We just updated our preprint on \"Joint modelling of whole genome sequence data for human height via approximate message passing\" (joint with Al, Jakub and Matt). A preliminary version (\"Inference of Genetic Effects via Approximate Message Passing\") was accepted at the 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP'24). This work was accepted as an oral presentation at the 52nd European Mathematical Genetics Meeting (Best student presentation award to Al), at the ",
  "content_length": 10210,
  "method": "requests",
  "crawl_time": "2025-12-01 13:51:40"
}