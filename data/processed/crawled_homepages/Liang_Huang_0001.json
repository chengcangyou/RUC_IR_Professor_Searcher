{
  "name": "Liang Huang 0001",
  "homepage": "http://eecs.oregonstate.edu/~huanlian",
  "status": "success",
  "content": "Liang Huang's Oregon State Homepage Liang Huang Professor of Computer Science, School of EECS Professor (by courtesy) of Biochemistry & Biophysics Faculty, Bioengineering Graduate Program Affiliated Faculty, Center for Quantitative Life Sciences (CQLS) Oregon State University (official profile) I am a computational linguist and computational biologist, most fascinated by the shared mathematical foundations between the two. Research Areas: NLP (simultaneous translation, parsing), compbio (RNA folding, RNA design, homologous folding, protein design), ML (structured prediction, weakly-supervised learning). Research Focus: efficient algorithms and provable theory in the above areas. News Research Publications Teaching Group Bio/CV Software Funding Media Misc Contact 2025/10: The SamplingDesign paper by undergraduate student Wei Yu Tang (now PhD student at USC) has been accepted by Nature Communications. 2024/03: My Nature paper was featured in this College of Engineering story. 2024/02: We (PI Huang, co-PI Mathews) were one of the 9 teams nationwide to receive major funding for interdisciplinary RNA research. See news release from NSF/NIH. 2023/11: I gave a Distinguished Lecture at UW Paul Allen School of CSE (video). 2023/10: I gave an invited talk at the 11th mRNA Health Conference, co-organized by 2023 Nobel Laureate Katalin Kariko. Dr. Kariko commented on my work in her keynote. 2023/05: Landmark Nature paper (pre-)published (as an accelerated article preview); see also Nature news. I reduced mRNA design to lattice parsing (1961, Bar-Hillel construction, i.e., \"the intersection of context-free and regular languages is still context-free\"). 2023/03: My first PhD student Ashish Vaswani (1st-author of the Transformer paper) was featured in this USC story about ChatGPT. 2022/11: LinearSampling published by Nucleic Acids Research. 2021/11: LinearTurboFold published by PNAS. First PNAS paper from OSU College of Engineering. 2021/07: Delivered ISMB 2021 Integrative RNA COSI Keynote. 2021/06: Delivered CVPR 2021 Invited Talk. 2020/04: two ACL 2020 papers and one ISMB 2020 paper (linearpartition) accepted. 2019/06: Delivered ACL 2019 Keynote Speech (attended by 2000+ researchers). 2019/05: We have 3 ACL 2019 papers accepted. 2019/05: LinearFold is accepted by ISMB 2019 (top conference in bioinformatics and comp. bio.) and will appear in Bioinformatics in July. 2019/04: I was recognized as one of the most influential NLP researchers in the past ten years (2007-2017) by the CS citation index Aminer from Tsinghua University. 2018/10: groundbreaking work in simultaneous translation -- first practical system that achieves high quality and low latency (done at Baidu Research). Media coverage by IEEE Spectrum, MIT Technology Review, FORTUNE, etc. Also covered by two podcasts: Data Skeptic and Eye on AI. 2018/09: Ph.D. student Mingbo Ma defended (4th PhD graduate) and will become a Research Scientist at Baidu Research (Silicon Valley). 2018/08: 4 papers (3 long, 1 short) in EMNLP 2018. 2018/07: Funded by NSF, NIH, and Intel. 2018/05: SIGMOD 2018 Best Paper Finalist. 2018/03: csrankings.org ranks OSU 15th in NLP (mostly our group), 20th in broad AI, and 36th in CS (in the US). 2018/02: We released the world's fastest RNA secondary structure prediction server, powered by the first linear-time prediction algorithm, based on our earlier work in computational linguistics. It is orders of magnitude faster than existing ones, with comparable or even higher accuracy. Code on Github. 2017/10: Serving as an Senior Area Chair (syntax/parsing) for ACL 2018. 2017/09: I'm giving an invited talk at EMNLP 2017 Workshop on Structured Prediction. [slides] 2017/07: three papers accepted by EMNLP 2017. I had my first first-author paper after a 5-year gap; it feels great getting back to real work! 2017/06: Ph.D. alumni Ashish Vaswani's recent work on attention received a lot of attention itself, bringing a revolution in deep learning for NLP. 2017/06: Ph.D. student Mingbo Ma participated in the WMT 2017 competition on multimodal translation, and achieved the best TER score among 15 systems on the English+Image->German COCO task (the hardest task in that competition, since it's into German rather than French, and tested on out of domain images). 2017/05: Ph.D. student Kai Zhao successfully defended and accepted a rare Research Scientist offer from Google Research (NYC). 2017/05: We were part of the OSU team in the DARPA Explanable AI (XAI) grant ($6.5M total). 2017/01: We are hosting Oregon's first and only University site for North American Computational Linguistics Olympiad (NACLO)! 2016/12: Ph.D. student James Cross successfully defended, and joined Facebook as a Research Scientist. 2016/11: James's EMNLP 2016 paper received an Honorable Mention for Best Paper (and unanimous full-score reviews). 2016/07: Ph.D. alumni (USC) Ashish Vaswani joined Google Brain as a Research Scientist. 2015/09: Postdoc Feifei Zhai joined IBM T. J. Watson as a Research Staff Member. 2015/09: Our group moved to Oregon State University after three years at the City University of New York. 2015/07: We received a Yahoo! Faculty Engagement Award. I was trained as a computational linguist (parsing, translation, algorithms and theory), but in recent years I became more interested in adapting my NLP algorithms to computational biology, thanks to the shared mathematical foundations between the two seemingly distant fields. In particular, I have been working on efficient (mostly linear-time) algorithms for RNA folding, mRNA design, homologous folding, and RNA design. More interestingly, when COVID-19 hit, this line of work became much more relevant because SARS-CoV-2 is the longest RNA virus known today (~30,000 nucleotides) which requires linear runtime, and because mRNA vaccine is the best way to prevent it but mRNA design is computationally challenging. Therefore, my work has made impact on the fight against COVID-19, and has resulted in high-profile papers such as LinearTurboFold (PNAS 2021) and LinearDesign (Nature 2023). I am most interested in the theoretical and algorithmic aspects of biology and language, and many of my NLP/bio papers draw unexpected connections from theoretical computer science, e.g., my synchronous binarization algorithm (binarizing a synchronous context-free grammar in linear-time) was inspired by Graham Scan for Convex Hull, my LinearDesign algorithm (optimal mRNA design) uses the intersection between context-free and regular languages, and my k-best parsing algorithms are often featured in my Algorithms courses. On the other hand, my recent work in NLP pioneered the field of simultaneous translation, turning it from obscurity to spotlight. See my ACL 2019 Keynote and CVPR 2021 Invited Talk. Listing of my papers on Google Scholar, Semantic Scholar, and a subset (top conferences) in csrankings.org. Recent and Past Talks [playlist] Linear-Time Algorithms for RNA Folding and mRNA Design to Fight COVID-19. U. of Washington Allen School of Computer Science (UW/CSE), Distinguished Lecture Series (Nov. 2023). [youtube] Allen Inst. of AI (AI2) (Nov. 2023) [youtube] 11th mRNA Health Conference (co-organized by Nobel Laureate Katalin Kariko) (Oct. 2023). [youtube] Dr. Kariko's comment on my work in her keynote (she referred to me as \"the mathematician\") Tsinghua University AIR (in Chinese) (Sep. 2022). [youtube] [bilibili] Bayer (Aug. 2022). Columbia University NLP Seminar (Apr. 2022). [youtube (missing the first 5 minutes)] Pfizer (Nov. 2021). University of Edinburgh Inst. for Language, Cognition and Computation (ILCC) Seminar (Nov. 2021). ISMB 2021 iRNA COSI Keynote (July 2021). [youtube] Simultaneous Translation: Recent Advances and Remaining Challenges. ACL 2019 Keynote. [slides (keynote)] [slides (pdf)] [video (livecongress)] [youtube] Updated version: CVPR 2021 Invited Talk [youtube]. Linguistis Meets Biology: LinearFold: Linear-Time Prediction of RNA Secondary Structures. Invited talk at Univ. of Rochester Medical School (Bioinfo. Cluster), Stanford Medical School (EternaCon 2018), and 2nd Southern California NLP Symposium. [slides] Human-Inspired Structured Prediction for Language and Biology. Invited talk at UC Santa Cruz. [slides] Breakthrough in Simultaneous Translation. Invited talk at Stanford and Google. [slides] Marrying Dynamic Programming with Recurrent Neural Nets for Structured Prediction. Invited talk at EMNLP 2017 Workshop on Structured Prediction. [slides] Scalable Large-Margin Structured Prediction: Theory and Algorithms. ACL 2014/2015 Tutorials. slides. Structured Learning with Inexact Search. Talks given at UMass Amherst, IBM, Columbia, Rochester, etc. slides. Dynamic Programming for Incremental Parsing. Talks given at UCSD, Google, JHU, MIT, IBM, etc. slides and video from the talk at JHU CLSP Seminar (Sep 2010). Tree-based and Forest-based Translation. Talks given at BBN, CUHK, Berkeley, Pomona, etc. slides. Forest-based Algorithms in NLP (thesis work). Talks given at MIT, Google, Stanford, CMU, etc. version 1 (includes cube pruning, but no forest-based translation): video from the CLSP seminar talk at JHU (on vimeo) (April 2008). video from the Google techtalk (on youtube) (March 2008). slides. version 2 (includes forest-based translation but no cube pruning; â‰ˆthesis defense): slides from the LTI seminar talk at CMU (May 2009). Selected Recent Work (for the full list please visit my Google Scholar page) Preprints under review Wei Yu Tang, Ning Dai, Tianshuo Zhou, David H. Mathews, Liang Huang (2024). Sampling-based Continuous Optimization with Coupled Variables for RNA Design. 2025 Ning Dai, Tianshuo Zhou, Wei Yu Tang, David H. Mathews, Liang Huang (2025). Messenger RNA Design for Ensemble Free Energy via Probabilistic Lattice Parsing. In Proceedings of ISMB 2025. Tianshuo Zhou, Apoorv Malik, Wei Yu Tang, David H. Mathews, Liang Huang (2025). Scalable and Interpretable Identification of Minimal Undesignable RNA Structure Motifs ",
  "content_length": 54380,
  "method": "requests",
  "crawl_time": "2025-12-01 13:47:05"
}