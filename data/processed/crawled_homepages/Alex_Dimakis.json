{
  "name": "Alex Dimakis",
  "homepage": "http://users.ece.utexas.edu/~dimakis",
  "status": "success",
  "content": "Alexandros G. Dimakis (Alex Dimakis) Home Main Bio and CV Research Projects Group Papers By Type Scholar Profile Courses Teaching Activities Service and TPCs Fun Artistic Attempts Alexandros G. Dimakis (Alex Dimakis) Professor, EECS Department, UC Berkeley Co-Founder BespokeLabs.ai Co-Director of the National AI Institute for Foundations of Machine Learning Twitter Office: 269 Cory Hall, Berkeley, CA 94720 alexdimakis at berkeley.edu I am interested in Generative AI, Information Theory and Machine Learning. Resume. Google Scholar Profile. News Co-founded BespokeLabs.ai a startup working on data curation and data centric AI. We are hiring. DeepSeek-R1 did not release its reasoning data. We are curating a reasoning dataset in OpenThoughts and training OpenThinker aiming to make the best open-source (open-weights and open-data) reasoning models. N. Raoof, L. Rout, G. Daras, S. Sanghavi, C. Caramanis, S. Shakkottai, A.G. Dimakis, \"Infilling Score: A Pretraining Data Detection Algorithm for Large Language Models,\" ICLR 2025, (Paper) (Code). S. Gadre, G. Smyrnis, V. Shankar, et al. \"Language models scale reliably with over-training and on downstream tasks,\" ICLR 2025, (Arxiv) (Code). A. Aali, G. Daras, B. Levac, S. Kumar, A. G. Dimakis, J. Tamir \"Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data,\" ICLR 2025, (Arxiv) (Code). Datacomp-LM released: DCLM. This is the largest public dataset for LLM training and includes 300T tokens, effective LLM per-training code based on Open_LM and 53 evaluations. Also we release truly open-source pretrained DCLM LMs of sizes up to 7B with excellent performance, full training data and source code. D.J. Diaz, C. Gong, J.Ouyang-Zhang, J.M. Loy, J. Wells, D. Yang, A. D. Ellington, A. G. Dimakis and A. R. Klivans Stability Oracle: a structure-based graph-transformer framework for identifying stabilizing mutations Nature Communications bioarxiv Four papers accepted to NeurIPS 2023 S. Gadre, G. Ilharco, A. Fang, J. Hayase, G. Smyrnis, T. Nguyen, R. Marten, M. Wortsman, D. Ghosh, J. Zhang, E. Orgad, R. Entezari, G. Daras, S. M. Pratt, V. Ramanujan, Y. Bitton, K. Marathe, S. Mussmann, R. Vencu, M. Cherti, R. Krishna, P. W. Koh, O. Saukh, A. Ratner, S. Song, H. Hajishirzi, A. Farhadi, R. Beaumont, S. Oh, A.G. Dimakis, J. Jitsev, Y. Carmon, V. Shankar, L. Schmidt, âDataComp: In search of the next generation of multimodal datasetsâ Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. Datasets and Benchmarks Track, Selected for Oral presentation. https://www.datacomp.ai/ (Project Page) G. Daras, K. Shah, Y. Dagan, A. Gollakota, A. G. Dimakis, A. R. Klivans, âAmbient Diffusion: Learning Clean Distributions from Corrupted Data,â Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. (Project Page) (Arxiv), (Code). L. Rout, N. Raoof, G. Daras, C. Caramanis, A. G. Dimakis, S. Shakkottai, âSolving Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models,â Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. (Project Page), (Arxiv),(Code) G. Daras, Y. Dagan, A.G. Dimakis, C. Daskalakis, âMartingale Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent, â Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2023. (Project Page) Our paper on deep learning for time-series modeling used for electronic system design and electromagnetic (EM) interconnect analysis for signal integrity, accepted to ICCAD: S. Ravula, V. Gorti, B. Deng, S. Chakraborty, J. Pingenot, B. Mutnury, D. Wallace, D. Winterberg, A. R. Klivans, A. G. Dimakis, âOne-Dimensional Deep Image Prior for Curve Fitting of S-Parameters from Electromagnetic Solvers,â 2023 International Conference on Computer-Aided Design (ICCAD 2023) (Project Page) T. Chen, C. Gong, D. J. Diaz, X. Chen, J. T. Wells, Q. Liu, Z. Wang, A. D. Ellington, A.G. Dimakis, A. R. Klivans, âHotProtein: A Novel Framework for Protein Thermostability Prediction and Editing,â Proceedings on the International Conference on Representation Learning (ICLR 2023). Elected IEEE Fellow for contributions to distributed coding and learning, 2022. Selected as Commissioner. Artificial Intelligence Commission on Competition, Inclusion, and Innovation by the US Chamber of Commerce to provide a roadmap for tech leadership to US policy makers. Faculty of the year award (for 2022). MS Program in Information Technology Management, (Voted by students). Keynote speaker, 14th IEEE Image and Multidimensional Signal Processing Workshop (IVMSP) 2022. Plenary speaker, 13th International Conference on the Image, 2022. Best Paper Award at UAI 2021 Workshop on Tractable Probabilistic Modeling. Recent talk: Generative models are the new sparsity Recent Berkeley Simons talk on deep generative models and how they can be used to solve inverse problems including Denoising, Missing data, Compressed Sensing and MRI. G. Daras, N. Raoof, Z. Gkalitsiou and A.G. Dimakis ââMultitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve,ââ Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2022. (Project Page) arxiv M. Jordan, J. Hayase, A. G. Dimakis, S. Oh ââZonotope Domains for Lagrangian Neural Network Verification,ââ Proc. of Neural Information Processing Systems (NeurIPS), Dec. 2022. (Arxiv) G. Daras, Y. Dagan, A. G. Dimakis, C. Daskalakis ââScore-Guided Intermediate Level Optimization: Fast Langevin Mixing for Inverse Problems.ââ International Conference on Machine Learning (ICML), 2022. (Project Page) J. Whang, M. Delbracio, H. Talebi, C. Saharia, A. G. Dimakis, P. Milanfar, ââDeblurring via Stochastic Refinement.ââ Computer Vision and Pattern Recognition (CVPR) June 2022. (Oral Presentation) (Arxiv) Two papers accepted to NeurIPS 2021 Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G. Dimakis and Jonathan I. Tamir, Robust Compressed Sensing MRI with Deep Generative Priors, (Project Page), (Arxiv) Sriram Ravula, Georgios Smyrnis ,Matt Jordan, Alexandros G. Dimakis Inverse Problems Leveraging Pre-trained Contrastive Representations (Project Page) (Arxiv) Six papers accepted to ICML 2021 Ajil Jalal, Sushrut Karmalkar, A.G. Dimakis and E. Price, Instance-Optimal Compressed Sensing via Posterior Sampling, (Project Page) Ajil Jalal, Jessica Hoffmann, Sushrut Karmalkar, A.G. Dimakis and E. Price, Fairness for Image Generation with Uncertain Sensitive Attributes (Project page) Giannis Daras, Joseph Dean, Ajil Jalal, and A.G. Dimakis, Intermediate Layer Optimization for Inverse Problems using Deep Generative Models (Project Page) Matt Jordan, A.G. Dimakis, Provable Lipschitz Certification for Generative Models (Arxiv), (Code) Jay Whang, Qi Lei, A.G. Dimakis Solving Inverse Problems with a Flow-based Noise Model (Arxiv) Jay Whang, Erik Lindgren, A.G. Dimakis, Composing Normalizing Flows for Inverse Problems (Arxiv) Best Paper Award at UAI 2021 Workshop on Tractable Probabilistic Modeling Congratulations to Qi Lei for winning the Oden Institute Outstanding Dissertation Award for her awesome Phd dissertation Recent service: TPC chair for MLSys 2021 AAAI 2021 Area chair, NeurIPS 2020 Area chair New paper: Intermediate Layer Optimization for Inverse Problems using Deep Generative Models by G. Daras, J. Dean, A. Jalal and A.G. Dimakis. (Code) (Paper) Four papers accepted to NeurIPS 2020 A. Jalal, L. Liu, A.G. Dimakis and C. Caramanis, Robust compressed sensing of generative models, (arxiv) M. Jordan and A.G. Dimakis, Exactly Computing the Local Lipschitz Constant of ReLU Networks, (arxiv) I. Daras, N. Kitaev, A. Odena and A.G. Dimakis SMYRF - Efficient attention using asymmetric clustering (arxiv) M. Kocaoglu, S. Shakkottai, A.G. Dimakis, C. Caramanis and S. Vishwanath Applications of Common Entropy in Causal Inference (pdf) New Survey: Deep Learning Techniques for Inverse Problems in Imaging G. Ongie, A. Jalal, C. A. Metzler, R. G. Baraniuk, A. G. Dimakis and R. Willett Journal on Selected Areas in Information Theory, May 2020. (arxiv), ieeeXplore Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models Giannis Daras, Augustus Odena, Han Zhang, Alexandros G. Dimakis, CVPR 2020. (arxiv) | Code | Colab Notebook | Twitter Thread Deep Generative models and Inverse Problems, talk at 2019 Texas AI summit (Slides.pdf) (Slides.pptx) Related Video: GANs and Compressed Sensing talk Gradient Coding from Cyclic MDS Codes and Expander Graphs N. Raviv, I. Tamo, R. Tandon and A. G. Dimakis, IEEE Transactions on Information Theory (arxiv) Five papers accepted to NeurIPS 2019 Matt Jordan , Justin Lewis, Alexandros G. Dimakis Provable Certificates for Adversarial Examples: Fitting a Ball in the Union of Polytopes (pdf) Qi Lei, Ajil Jalal, Inderjit S. Dhillon, and Alexandros G. Dimakis Inverting Deep Generative models, One layer at a time. (pdf) Qi Lei, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis Primal-Dual Block Frank-Wolfe (pdf) Shanshan Wu, Sujay Sanghavi, Alexandros G. Dimakis Sparse Logistic Regression Learns All Discrete Pairwise Graphical Models (Spotlight) (pdf) Shanshan Wu, Alexandros G. Dimakis, Sujay Sanghavi Learning Distributions Generated by One-Layer ReLU Networks (pdf) SysML 2019 paper on adversarial attacks on text classifiers Q. Lei, L. Wu, P. Chen, A.G. Dimakis, I.S. Dhillon and M. Witbrock, Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification Systems and Machine Learning (SysML), April 2019. (pdf) slides code Press coverage: Nature News, VentureBeat, TechTalks ICML 2019 paper on learned compressed sensing matrices S. Wu, A.G. Dimakis, S. Sanghavi, F.X. Yu, D. Holtmann-Rice, D. Storcheus, A. Rostamizadeh, S. Kumar, Learning a Compressed Sensing Measurement Matrix via Gradient Unrolling International Conference on Machine Learning (ICML), ",
  "content_length": 17154,
  "method": "requests",
  "crawl_time": "2025-12-01 12:53:10"
}