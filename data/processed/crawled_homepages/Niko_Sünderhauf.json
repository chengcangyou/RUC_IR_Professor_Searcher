{
  "name": "Niko Sünderhauf",
  "homepage": "https://research.qut.edu.au/qcr/people/niko-suenderhauf",
  "status": "success",
  "content": "Niko Suenderhauf - QUT Centre for Robotics Skip to content Prof Niko Suenderhauf Home Our People Prof Niko Suenderhauf Please enable JavaScript Please enable JavaScript Find Niko Suenderhauf onNiko Suenderhauf's full profile, contact information and publications are available on:Recent tweetsFollow @nikosuenderhauf Deputy Centre Director, Program Lead Visual Learning and Understanding (Robotic Vision, Simultaneous Localisation and Mapping (SLAM), Reinforcement Learning, Machine Learning, AI) PhD (Chemnitz University Of Technology)Professor Niko Suenderhauf is Deputy Director (Research) of the ARC Research Hub (ITRH) in Intelligent Robotic Systems for Real-Time Asset Management, and lead-CI for an ARC Discovery Project (2022-25). He is Chief Investigator and member of the Executive Committee of the QUT Centre for Robotics (QCR) and leads the Visual Learning and Understanding program. He has been Acting Joint Director of the QUT Centre for Robotics between October 2022 and March 2023. He was QCR's acting Deputy Director Feb-July 2021. Between 2017 and 2020 Niko was Chief Investigator and Project Leader of the Australian Centre of Excellence for Robotic Vision (ACRV).Niko conducts research in robotic vision and robotic learning, at the intersection of robotics, computer vision, machine learning and AI. His research is driven by the question of how robots can learn to perform complex tasks. Solving this problem requires robust perception, scene understanding, high-level planning and reasoning, and the capability to interact with objects and humans.Niko's research group develops innovative ways of incorporating Large Language Models into robotics, leveraging their abilities for high-level planning and common-sense reasoning. His group also explores the utility of other foundation models, such as vision-language models, for robotic perception, scene understanding, learning, and mapping.Niko is very interested in questions about the reliability, safety and robustness  of machine learning for real-world applications.Prof Suenderhauf regularly organises workshops at leading robotics and computer vision conferences. He was was co-chair of the IEEE Robotics and Automation Society Technical Committee on Robotic Perception (2020-2022), was a member of the editorial board for the International Journal of Robotics Research (IJRR, 2019-2022), and Associate Editor for the IEEE Robotics and Automation Letters journal (RA-L) from 2015 to 2019. Niko served as AE for the IEEE International Conference on Robotics and Automation (ICRA) 2018 and 2020.As an educator at QUT, Niko teaches Robotic Vision (ENN583) and Advanced Machine Learning (ENN585) in the Master's of Robotics and AI. He previously enjoyed teaching Introduction to Robotics (EGB339), Mechatronics Design 3 (EGH419), as well as Digital Signals and Image Processing (EGH444) to the undergraduate students in the Electrical Engineering degree.Niko received his PhD from Chemnitz University of Technology, Germany in 2012. In his thesis, Niko focused on robust factor graph-based models for robotic localisation and mapping, as well as general probabilistic estimation problems, and developed the mathematical concepts of Switchable Constraints. After two years as a Research Fellow in Chemnitz, Niko joined QUT as a Research Fellow in March 2014, before being appointed to a tenured Lecturer position in 2017. Projects (Chief investigator)Australian Robotic Inspection and Asset Management HubDeep Learning for Robotics in Open-World Conditions: Uncertainty, Continuous Learning, Active LearningFrom Chat to Chores: The Future of LLM-Powered Service RobotsGeometric-Semantic Representations for Infrastructure Monitoring and MaintenanceImplicit representations for place recognition and robot localisationLearning Robotic Navigation and Interaction from Object-based Semantic MapsReinforcement Learning for Robot Navigation and InteractionReliability in Deep Machine Learning and Uncertainty for Object DetectionRobot Learning for Everyday Tasks with Large Language Models, Imitation Learning and NeRFsScene Understanding and Semantic SLAMSemantic Mapping for Robotic MaintenanceSpace Robotics: Scene Understanding for Lunar/Mars RoverTowards Resilient Cyberphysical Systems ProjectsAmazon Picking Challenge (2016)LunaRoo - A hopping Lunar science platformWeakly Supervised Segmentation of Underwater Imagery Additional information Experience Research Project Leadership I am a Chief Investigator of the Australian Centre for Robotic Vision. In this role, I lead the project on Robotic Vision Evaluation and Benchmarking, and am deputy project leader for the Centre's Scene Understanding project. Robotic Vision Evaluation and Benchmarking (2018 – Present) Big benchmark competitions like ILSVRC or COCO fuelled much of the progress in computer vision and deep learning over the past years. We aim to recreate this success for robotic vision. To this end, we develop a set of new benchmark challenges for robotic vision that evaluate probabilistic object detection, scene understanding, uncertainty estimation, continuous learning for domain adaptation, continuous learning to incorporate previuosly unseen classes, active learning, and active vision. We combine the variety and complexity of real-world data with the flexibility of synthetic graphics and physics engines. See projectScene Understanding and Semantic SLAM (2017 – Present) Making a robot understand what it sees is one of the most fascinating goals in my current research. To this end, we develop novel methods for Semantic Mapping and Semantic SLAM by combining object detection with simultaneous localisation and mapping (SLAM) techniques. We furthermore work on Bayesian Deep Learning for object detection, to better understand the uncertainty of a deep network’s predictions and integrate deep learning into robotics in a probabilistic way. See projectBayesian Deep Learning and Uncertainty for Object Detection (2017 – Present) In order to fully integrate deep learning into robotics, it is important that deep learning systems can reliably estimate the uncertainty in their predictions. This would allow robots to treat a deep neural network like any other sensor, and use the established Bayesian techniques to fuse the network’s predictions with prior knowledge or other sensor measurements, or to accumulate information over time. We focus on Bayesian Deep Learning approaches for the specific use case of object detection on a robot in open-set conditions. See projectReinforcement Learning for Robot Navigation and Complex Task Execution (2017 – Present) How can robots best learn to navigate in challenging environments and execute complex tasks, such as tidying up an apartment or assist humans in their everyday domestic chores? Often, hand-written architectures are based on complicated state machines that become intractable to design and maintain with growing task complexity. I am interested in developing learning-based approaches are effective and efficient, and scale better to complicated tasks. See projectVisual Place Recognition in Changing Environments (2012 – Present) An autonomous robot that operates on our campus should be able to recognize different places when it comes back to them after some time. This is important to support reliable navigation and localisation and therefore enable the robot to perform a useful task. The problem of visual place recognition gets challenging if the visual appearance of these places changed in the meantime. This usually happens due to changes in the lighting conditions (think day vs. night or early morning vs. late afternoon), shadows, different weather conditions, or even different seasons. We develop algorithms for vision-based place recognition that can deal with these changes in visual appearance. See projectOrganised Research Workshops Dedicated workshops are a great way of getting in contact with fellow researchers from around the world that are working on similar scientific questions. Over the past years I was lead organiser or co-organiser for these workshops at leading international conferences:The Importance of Uncertainty in Deep Learning for Robotics (IROS 2019)Robotic Vision Probabilistic Object Detection Challenge (CVPR 2019)Deep Learning for Semantic Visual Navigation (CVPR 2019)New Benchmarks, Metrics, and Competitions for Robotic Learning (RSS 2018)Real-World Challenges and New Benchmarks for Deep Learning in Robotic Vision (CVPR 2018)Long-term autonomy and deployment of intelligent robots in the real-world (ICRA 2018)Learning for Localization and Mapping (IROS 2017)New Frontiers for Deep Learning in Robotics (RSS 2017)Deep Learning for Robotic Vision (CVPR 2017)Are the Sceptics Right? - Limits and Potentials of Deep Learning in Robotics (RSS 2016)Visual Place Recognition: What is it good for? (RSS 2016)Visual Place Recognition in Changing Environments (ICRA 2015)Visual Place Recognition in Changing Environments (CVPR 2015)Visual Place Recognition in Changing Environments (ICRA 2014)Robust and Multimodal Inference in Factor Graphs (ICRA 2013) Awards TypeAcademic Honours, Prestigious Awards or PrizesReference year2020DetailsAmazon Research Award for the project \"Learning Robotic Navigation and Interaction from Object-based Semantic Maps\". This internationally competitive and prestigious award supports my research towards intelligent robots operating alongside humans in domestic environments with $120,000AUD.TypeAcademic Honours, Prestigious Awards or PrizesReference year2018DetailsGoogle Faculty Research Award for the project \"The Large Scale Robotic Vision Perception Challenge\". This award \"recognises and supports world-class faculty pursuing cutting-edge research\". My proposal was selected after expert reviews out of 1033 proposals from 360 universities in 46 countries. The acceptance rate was only 14.7%.The award sum of over $74,000AUD supported my research activities of creating new robotic vision research c",
  "content_length": 12645,
  "method": "requests",
  "crawl_time": "2025-12-01 14:06:01"
}