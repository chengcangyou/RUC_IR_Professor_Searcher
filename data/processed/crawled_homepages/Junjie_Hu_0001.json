{
  "name": "Junjie Hu 0001",
  "homepage": "https://junjiehu.github.io",
  "status": "success",
  "content": "Junjie Hu About I am an Assistant Professor jointly in the Department of Computer Science and Department of Biostatistics at the University of Wisconsin-Madison. I am a faculty affiliate with Data Science Institute. I obtained my Ph.D. from School of Computer Science at Carnegie Mellon University, where I worked with Jaime Carbonell and Graham Neubig. I have a broad interest in natural language processing and machine learning. My research goal is to build robust intelligent AI agents that adapt rapidly to dynamic environments and communicate effectively with people speaking different languages. In particular, my research focuses on algorithmic design and fundamental understanding of machine learning models in NLP that enable safe deployment in the wild. Most recently, I’m fascinated by understanding behaviors of large language models (LLMs), adapting them effectively to knowledge-intensive reasoning tasks, and aligning them safely with users from diverse backgrounds. My specific topics of interest include the following aspects of LLMs: Multilingual NLP and Cultures: Democratizing inclusive LLMs across languages and cultures while enhancing pluralistic alignment. Efficient Multimodal LLMs: Developing efficient multimodal LLMs for high-stakes applications in education and healthcare. Cognitive Language Agents: Unifying cognitive concepts and languages to enable complex reasoning, planning and human behavior simulation. Evaluation and Mechanistic Interpretation: Exploring robust methods for evaluating and interpreting black-box foundation models. Our research has been supported by National Science Foundation, National Institutes of Health, Department of Defense, UW ICTR, Wisconsin Alumni Research Foundation, American Family Insurance, Microsoft, NVIDIA, etc. Prospective PhD students (Updated on Aug 8 2025): Thanks for your interest! I may not be able to reply to all inqueries due to the large amounts of emails. If you still want to bring my attention to your papers by email, please add “[prospective student to Hulab]” in the email subject. I’ll update hiring information on my website. I am looking for 1 or 2 creative and curiosity-driven PhD students to join our lab in the fall of 2025. The admission decision at UW-Madison is committee-based. Please apply to the CS program, and mention my name in your application and research statement. UW-Madison is an excellent place for research, and Madison is a wonderful city to live in. Please check out these videos (Why UW-Madison, Madison). Prospective MS/BS students and interns: I’m also happy to work with master’s or undergraduate students at UW-Madison. If you are a currently UW student, please email me your CV. At the beginging of some semesters, I typically send an email to the CS mailing list to find students for research projects. Selected candidates will participate in a brief interview and will be paired with one of my PhD students. For international students, I consider only exceptional candidates with closely aligned research interests. Please contact me at least 5 months before your onsite internship to allow time for paperwork and review the J-1 student internship program requirements. Research Group I am really fortunate to work with a group of excellent students at UW-Madison. Stay tuned for our latest works! Graduate Students Rheeya Uppaal (PhD in CS, Spring 2022-) Tim Ossowski (PhD in CS, Fall 2022-) Binwei Yao (PhD in CS, Fall 2023-) Zefan Cai (PhD in CS, Fall 2024-) Ishita Kakkar (PhD in CS, Fall 2025-) Alumni Himanshu Chaudhary (MS in CS) Tara Bobinac (MS in CS) Karthik Suresh (MS in CS) Shan Leng (MS in Stats, now PhD in BDS at UW-Madison) Agam Goyal (BS in CS, now PhD in CS at UIUC) Samarth Mathur (MS in ECE, now software engineer at Supernova Technology) Yuye Jiang (MS in CS, now software engineer at Oracle) Gowtham Ramesh (MS in CS, now applied research scientist at AMD) Jack Ziyang Cai (BS in ECE/Math -> MS in ECE) Ruixue Lian (PhD in ECE, co-advised w/ Prof. William Sethares, now applied scientist at Amazon AWS) Makesh Narsimhan Sreedhar (MS in CS, now research engineer at NVIDIA) Shilu He (MS in Math, now software engineer at Amazon Alexa) Shanchao Liang (BS in CS/Math, now PhD in CS at Purdue) Shunchi Zhang (Exchange student from XJTU, now MS in CS at JHU) Recent Preprints 2025 arXiv Scaling Up Audio-Synchronized Visual Animation: An Efficient Training Paradigm Lin Zhang, Zefan Cai, Yufan Zhou, Shentong Mo, Jinhong Lin, Cheng-En Wu, Yibing Wei, Yijing Zhang, Ruiyi Zhang, Wen Xiao, and others arXiv preprint arXiv:2508.03955 2025 arXiv MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models Haozhe Zhao, Zefan Cai, Shuzheng Si, Liang Chen, Jiuxiang Gu, Wen Xiao, and Junjie Hu arXiv preprint arXiv:2507.09574 2025 arXiv Headinfer: Memory-efficient llm inference by head-wise offloading Cheng Luo, Zefan Cai, Hanshi Sun, Jinqi Xiao, Bo Yuan, Wen Xiao, Junjie Hu, Jiawei Zhao, Beidi Chen, and Anima Anandkumar arXiv preprint arXiv:2502.12574 2025 arXiv VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection Zeyi Huang, Yuyang Ji, Anirudh Sundara Rajan, Zefan Cai, Wen Xiao, Junjie Hu, and Yong Jae Lee arXiv preprint arXiv:2505.20289 2025 2024 arXiv Large Language Models Are Active Critics in NLG Evaluation Shuying Xu, Junjie Hu, and Ming Jiang arXiv preprint arXiv:2410.10724 2024 arXiv Prompting Large Vision-Language Models for Compositional Reasoning Timothy Ossowski, Ming Jiang, and Junjie Hu arXiv preprint arXiv:2401.11337 2024 Publications 2025 COLM PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling Zefan Cai, Yichi Zhang, Bofei Gao, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Junjie Hu, and Wen Xiao In The Second Conference of Language Modeling 2025 [Code] EMNLP V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models Qidong Wang, Junjie Hu, and Ming Jiang In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP) 2025 EMNLP Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding Yun-Shiuan Chuang, Nikunj Harlalka, Sameer Narendran, Alexander Cheung, Sizhe Gao, Siddharth Suresh, Junjie Hu, and Timothy T Rogers In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP) 2025 ICLR Model Editing as a Robust and Denoised variant of DPO: A Case Study on Toxicity Rheeya Uppaal, Apratim Dey, Yiting He, Yiqiao Zhong, and Junjie Hu In The Thirteenth International Conference on Learning Representations 2025 ICLR No Preference Left Behind: Group Distributional Preference Optimization Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, and Junjie Hu In The Thirteenth International Conference on Learning Representations 2025 ICML MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving Ruida Wang, Rui Pan, Yuxin Li, Jipeng Zhang, Yizhen Jia, Shizhe Diao, Renjie Pi, Junjie Hu, and Tong Zhang In The Forty-Second International Conference on Machine Learning 2025 NeurIPS R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration Zefan Cai, Wen Xiao, Hanshi Sun, Cheng Luo, Yikai Zhang, Ke Wan, Yucheng Li, Yeyang Zhou, Li-Wen Chang, Jiuxiang Gu, Zhen Dong, Anima Anandkumar, Abedelkadir Asi, and Junjie Hu In Proceedings of the Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS) 2025 TMLR COMMA: A Communicative Multimodal Multi-Agent Benchmark Timothy Ossowski, Danyal Maqbool, Jixuan Chen, Zefan Cai, Tyler J. Bradshaw, and Junjie Hu Transactions on Machine Learning Research (Accepted) 2025 2024 ACL OLIVE: Object Level In-Context Visual Embeddings Timothy Ossowski, and Junjie Hu In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics 2024 ACL Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges Bosheng Ding, Chengwei Qin, Ruochen Zhao, Tianze Luo, Xinze Li, Guizhen Chen, Wenhan Xia, Junjie Hu, Anh Tuan Luu, and Shafiq Joty In Findings of the 62nd Annual Meeting of the Association for Computational Linguistics 2024 COLM How Well Do LLMs Identify Cultural Unity in Diversity? Jialin Li, Junli Wang, Junjie Hu, and Ming Jiang In The first Conference of Language Modeling 2024 CSCW MetaWriter: Exploring the Potential and Perils of AI Writing Support in Scientific Peer Review Lu Sun, Stone Tao, Junjie Hu, and Steven Dow In Proceedings of The 26th ACM Conference on Computer-Supported Cooperative Work and Social Computing 2024 CVPR Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation Zihan Wang, Xiangyang Li, Jiahao Yang, Yeqi Liu, Junjie Hu, Ming Jiang, and Shuqiang Jiang In The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024 CogSci Evaluating LLM Agent Group Dynamics against Human Group Dynamics: A Case Study on Wisdom of Partisan Crowds Yun-Shiuan Chuang, Siddharth Suresh, Nikunj Harlalka, Agam Goyal, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy T Rogers In The Annual Conference of the Cognitive Science Society (CogSci). 2024 EACL Learning Label Hierarchy with Supervised Contrastive Learning Ruixue Lian, William A. Sethares, and Junjie Hu In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics 2024 EMNLP Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks Yun-Shiuan Chuang, Zach Studdiford, Krirk Nirunwiroj, Agam Goyal, Vincent V. Frigo, Sijia Yang, Dhavan V. Shah, Junjie Hu, and Timothy T. Rogers In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP Findings) 2024 EMNLP Benchmarking Machine Translation with Cultural Awareness Binwei Yao, Ming Jiang, Diyi Yang, and Junjie Hu In Proceedings of the 2024 Conference on Empirica",
  "content_length": 57446,
  "method": "requests",
  "crawl_time": "2025-12-01 13:38:13"
}