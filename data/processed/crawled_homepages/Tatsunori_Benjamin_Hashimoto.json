{
  "name": "Tatsunori Benjamin Hashimoto",
  "homepage": "https://thashim.github.io",
  "status": "success",
  "content": "Tatsunori Hashimoto | Home Tatsunori Hashimoto Assistant Professor, Stanford thashim [AT] stanford.edu Bio I am currently an assistant professor at the computer science department in Stanford university. My research uses tools from statistics to make machine learning systems more robust and trustworthy — especially in complex systems such as large language models. The goal of my research is to use robustness and worst-case performance as a lens to understand and make progress on several fundamental challenges in machine learning and natural language processing. A few topics of recent interest are, Long-tail behavior How can we ensure that a machine learning system won't fail catastrophically in the wild under changing conditions? Understanding A system which understands how to answer questions or generate text should also do so robustly out-of-domain. Fairness Machine learning systems which rely on unreliable correlations can result in spurious and harmful predictions. Previously, I was a post-doc at Stanford working for John C. Duchi and Percy Liang on tradeoffs between the average and worst-case performance of machine learning models. Before my post-doc, I was a graduate student at MIT co-advised by Tommi Jaakkola and David Gifford and a undergraduate student at Harvard in statistics and math advised by Edoardo Airoldi. Advisees Yu Sun (2023-) Postdoc (w/ Sanmi Koyejo and Carlos Guestrin) Ian Covert (2023-) Postdoc (w/ James Zou) Lisa Li (2021-) Graduate Student (w/ Percy Liang) Tianyi Zhang (2021-) Graduate Student Yann Dubois (2022-) Graduate Student (w/ Percy Liang) Neil Band (2023-) Graduate Student (w/ Tengyu Ma) Nicole Meister (2023-) Graduate Student (w/ Carlos Guestrin) Zitong Yang (2024-) Graduate Student (w/ Emmanuel Candes) Chenglei Si (2024-) Graduate Student (w/ Diyi Yang) Christopher Mohri (2024-) Graduate Student (w/ John Duchi) Tristan Thrush (2024-) Graduate Student (w/ Chris Potts) Publications Most recent publications on Google Scholar. Selected and Recent Papers All Stats+ML NLP Comp Bio Observational Scaling Laws and the Predictability of Language Model Performance PDF Yangjun Ruan, Chris J Maddison, Tatsunori Hashimoto ArXiv preprint Length-controlled AlpacaEval: A simple way to debias automatic evaluators PDF Yann Dubois, Balázs Galambosi, Percy Liang, Tatsunori B Hashimoto ArXiv preprint Linguistic Calibration of Language Models PDF Neil Band, Xuechen Li, Tengyu Ma, Tatsunori Hashimoto International Conference on Machine Learning (ICML 2024) Language Models with Conformal Factuality Guarantees PDF Christopher Mohri, Tatsunori Hashimoto International Conference on Machine Learning (ICML 2024) Proving test set contamination in black box language models PDF Yonatan Oren, Nicole Meister, Niladri Chatterji, Faisal Ladhak, Tatsunori B Hashimoto International Conference on Learning Representations (ICLR 2024) Benchmarking and improving generator-validator consistency of language models PDF Xiang Lisa Li, Vaishnavi Shrivastava, Siyan Li, Tatsunori Hashimoto, Percy Liang International Conference on Learning Representations (ICLR 2024) Identifying the risks of lm agents with an lm-emulated sandbox PDF Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao Zhou, Jimmy Ba, Yann Dubois, Chris J Maddison, Tatsunori Hashimoto International Conference on Learning Representations (ICLR 2024) Robust Distortion-free Watermarks for Language Models PDF Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang Transactions on Machine Learning Research (TMLR 2024) Likelihood-Based Diffusion Language Models PDF Ishaan Gulrajani, Tatsunori B. Hashimoto Advances in Neural Information Processing Systems (NeurIPS 2023) AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback PDF Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto Advances in Neural Information Processing Systems (NeurIPS 2023) Whose Opinions Do Language Models Reflect? PDF Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, Tatsunori Hashimoto International Conference on Machine Learning (ICML 2023, oral) Data Feedback Loops: Model-driven Amplification of Dataset Biases PDF Rohan Taori, Tatsunori B Hashimoto International Conference on Machine Learning (ICML 2023, oral)\" Foundation Models and Fair Use PDF Peter Henderson, Xuechen Li, Dan Jurafsky, Tatsunori Hashimoto, Mark A Lemley, Percy Liang Journal of Machine Learning Research (JMLR 2024) Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models PDF Kaitlyn Zhou, Dan Jurafsky, Tatsunori Hashimoto Conference on Empirical Methods in Natural Language Processing (EMNLP 2023) Benchmarking Large Language Models for News Summarization PDF Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, Tatsunori B Hashimoto Transactions of the Association of Computational Linguistics (TACL, presented at EMNLP 2023) Tracing and Removing Data Errors in Natural Language Generation Datasets PDF Faisal Ladhak, Esin Durmus, Tatsunori Hashimoto Annual Meeting of the Association of Computational Linguistics (ACL 2023) Diffusion-LM Improves Controllable Text Generation PDF Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, Tatsunori B Hashimoto Advances in Neural Information Processing Systems 31 (NeurIPS 2022) Identifiability Conditions for Domain Adaptation PDF Ishaan Gulrajani, Tatsunori B Hashimoto International Conference on Machine Learning (ICML 2022) Emergent abilities of large language models PDF Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus Transactions on Machine Learning Research (2022) Jury learning: Integrating dissenting voices into machine learning models PDF Mitchell Gordon, Michelle Lam, Joon Park, Kayur Patel, Jeff Hancock, Tatsunori B Hashimoto, Michael Bernstein Conference on Human Factors in Computing Systems (CHI 2022, Best paper) Spurious Correlations in Reference-Free Evaluation of Text Generation PDF Esin Durmus, Faisal Ladhak, Tatsunori B Hashimoto Annual Meeting of the Association of Computational Linguistics (ACL 2022) Large Language Models Can Be Strong Differentially Private Learners PDF Xuechen Li, Florian Tramer, Percy Liang, Tatsunori B Hashimoto International Conference on Learning Representations (ICLR 2022 Oral) Is Importance Weighting Incompatible with Interpolating Classifiers? PDF Ke A Wang, Niladri S Chatterji, Saminul Haque, Tatsunori B Hashimoto International Conference on Learning Representations (ICLR 2022) Model Performance Scaling with Multiple Data Sources PDF Tatsunori B Hashimoto International Conference on Machine Learning (ICML 2021) Improved Natural Language Generation via Loss Truncation PDF Daniel Kang, Tatsunori B Hashimoto Annual Meeting of the Association of Computational Linguistics (ACL 2020) Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-case Generalization PDF Shiori Sagawa*, Pang Wei Koh*, Tatsunori B Hashimoto, Percy Liang International Conference on Learning Representations (ICLR 2020) Distributionally Robust Language Modeling PDF Yonatan Oren*, Shiori Sagawa *, Tatsunori B Hashimoto *, Percy Liang Empirical Methods in Natural Language Processing (EMNLP 2019) Distributionally Robust Losses For Latent Covariate Mixtures PDF John C Duchi, Tatsunori B Hashimoto, Hongseok Namkoong Operations Research (2022) Unifying Human and Statistical Evaluation for Natural Language Generation PDF Tatsunori B Hashimoto*, Hugh Zhang*, Percy Liang Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2019) Generating Sentences by Editing Prototypes PDF Kelvin Guu*, Tatsunori B Hashimoto*, Yonatan Oren, Percy Liang Transactions of the Association of Computational Linguistics (TACL, presented at ACL 2018) Fairness Without Demographics in Repeated Loss Minimization PDF Tatsunori B Hashimoto, Megha Srivastava, Hongseok Namkoong, Percy Liang Proceedings of the 35th International Conference on Machine Learning (ICML 2018, Best paper runner up) Word embeddings as metric recovery in semantic spaces PDF Tatsunori B Hashimoto, David Alvarez-Melis, Tommi S Jaakkola Transactions of the Association for Computational Linguistics 4 (TACL, presented at ACL 2016) Metric recovery from directed unweighted graphs PDF Tatsunori B Hashimoto, Yi Sun, Tommi S Jaakkola Artificial Intelligence and Statistics (AISTATS 2015), (best poster at NeurIPS 2014 workshop on networks) Observational Scaling Laws and the Predictability of Language Model Performance PDF Yangjun Ruan, Chris J Maddison, Tatsunori Hashimoto ArXiv preprint Length-controlled AlpacaEval: A simple way to debias automatic evaluators PDF Yann Dubois, Balázs Galambosi, Percy Liang, Tatsunori B Hashimoto ArXiv preprint Trustless Audits without Revealing Data or Models PDF Suppakit Waiwitlikhit, Ion Stoica, Yi Sun, Tatsunori Hashimoto, Daniel Kang International Conference on Machine Learning (ICML 2024) Linguistic Calibration of Language Models PDF Neil Band, Xuechen Li, Tengyu Ma, Tatsunori Hashimoto International Conference on Machine Learning (ICML 2024) A Survey on Data Selection for Language Models PDF Alon Albalak, Yanai Elazar, Sang Michael Xie, Shayne Longpre, Nathan Lambert, Xinyi Wang, Niklas Muennighoff, Bairu Hou, Liangming Pan, Haewon Jeong, Colin Raffel, Shiyu Chang, Tatsunori Hashimoto, William Yang Wang ArXiv preprint Language Models with Conformal Factuality Guarantees PDF Christopher Mohri, Tatsunori Hashimoto International Conference on Machine Learning (ICML 2024) Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution PDF Ian Covert, Chanwoo Kim, Su-In Lee, James Zou, Tatsunori Hashimoto ArXiv preprint On the learnab",
  "content_length": 47398,
  "method": "requests",
  "crawl_time": "2025-12-01 14:36:21"
}