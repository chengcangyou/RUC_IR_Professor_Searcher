{
  "name": "Ana Klimovic",
  "homepage": "https://anakli.inf.ethz.ch",
  "status": "success",
  "content": "Ana KlimovicYou need to enable JavaScript to run this app.Ana Klimovićaklimovic@ethz.chCV | Google Scholar | Twitteraklimovic@ethz.chCV | Google Scholar | TwitterI am an Assistant Professor in the Department of Computer Science at ETH Zurich. I am a member of the ETH Systems Group, where I lead the Efficient Architectures and Systems Lab (EASL).I work on computer systems for large-scale applications such as cloud computing services, data analytics, and machine learning. The goal of my research is to improve the performance and resource efficiency of cloud computing while making it easier for users to deploy and manage their applications. My research interests span operating systems, computer architecture, and their intersection with machine learning.Before joining ETH, I spent a year as a Research Scientist at Google Brain. I completed my Ph.D. in Electrical Engineering at Stanford University, advised by Professor Christos Kozyrakis. My dissertation was on the design and implementation of fast, elastic storage for cloud computing. My Ph.D. was generously supported by the Microsoft Research PhD Fellowship and Stanford Graduate Fellowship. I earned my M.S. in Electrical Engineering at Stanford University in 2015. I graduated from the Engineering Science program at the University of Toronto in 2013, where I earned my Bachelor of Applied Science and Engineering.If you are interested in joining the EASL research group, please email me (aklimovic@ethz.ch) with your CV. See below for research focus areas.Research Focus AreasServerless Computing: A New Paradigm of Cloud ComputingStimulated by an exponential growth in data, users, and an increasing demand for elastic cloud services that automatically manage and scale computing resources, serverless computing has emerged as a new paradigm of cloud computing. The goal is for users to focus on writing code for their applications while cloud providers manage resources based on application demands. On serverless computing platforms, users can simultaneously launch thousands of tiny, short-lived tasks and pay only for the resources their tasks actually consume per millisecond time interval, as opposed to paying for pre-allocated virtual machines that have fixed ratios of compute, memory, and storage.Research topics: What should an operating system for serverless computing look like? Scheduling millions of short-lived tasks to satisfy performance requirements and achieve high resource utilization poses interesting challenges. Serverless computing encourages a high degree of resource sharing across tenants, which poses performance and security isolation concerns. What are the right abstraction for users to express their applications such that the platform can optimize their execution?Systems for Efficient AITraining and serving AI models requires large compute clusters, which have high cost and consuming significant energy. As models continue to grow in size to improve accuracy, scaling the underlying system infrastructure is challenging due to high cost and datacenter power limitations. Improving the resource efficiency and data efficiency of AI model training and serving is key to making AI more sustainable, scalable, and ubiquitous.Research topics: How can we improve AI serving latency and throughput per Watt, particularly as AI inference increasingly involves models interacting with databases (e.g., for retrieval augmented generation) and a variety of other tools (e.g., search engines and code interpreters)? How can we efficiently customize model inference for different users and types of requests in a multi-tenant setting while exposing an intuitive, declarative API to users? How can we make AI training more resource-efficient and elastic? How should we build distributed storage services to manage AI training data and enable efficient data selection and ingestion during training?Declarative Cloud Programming with AI Developing correct, high-performance, and scalable distributed cloud applications is notoriously difficult for programmers as it requires reasoning about parallelism, durability, and consistency. The code generation capabilities of large language models (LLMs) and AI agents offer exciting opportunities to automate the cloud application development process. Research topics: How to design programming abstractions for cloud application developers to specify their functionality, performance, consistency, and durability requirements in a declarative way? How to go from declarative specifications to correct and scalable implementations? How can we teach LLMs to generate code in new programming models or frameworks that offer performance and correctness benefits? Research Group PhD students:Tom KuchlerLazar CvetkovićFoteini StratiMaximilian BötherXiaozhe YaoPinghe LiTobias Stocker Postdocs:Yazhuo Zhang Masters students:Zhendong ZhangHao ZhuRahul SteigerAndrei ArnautuThomas LacknerAlumni Post-docs:Dmitrii Ustiugov, now Assistant Professor at Nanyang Technological University, Singapore PhD students:Dan Graur (primary advisor: Prof. Gustavo Alonso), now at GoogleMichael Wawrzoniak (primary advisor: Prof. Gustavo Alonso)Dimitris Koutsoukos (primary advisor: Prof. Gustavo Alonso), now at Apple Masters thesis students:Alessio RussoSimone KalbermatterHongshu (Hazel) YanGeorge ManosPaul ElvingerBoyko BorisovJohn StaibXianzhe MaIxeia Sánchez PérizJingyi ZhuEstella NegoitaFrancesco DeaglioOto MrazMihajlo DjokicElwin StephanDan Kluser Zak CookMuyu Li Zehao WeiHengxuan YingMalte BrodmannMohit KumarValentino FöhnAmory Hoste Bachelor thesis students: Leo StephanTim NotterRobin HolzingerJonathan SmithLeon ThommRobin OesterJoel AndréSimon Sommerhalder Research assistants: Antonio Andrea SalvalaggioBoris GoranovVictor VitezYushi LiuNeo LouJosef SchönbergerViktor GsteigerFrançois CostaEirini MilioriDohyun ParkHongyu HeKaishuo ZhangBowen WuJulia BazińskaTanguy AlbriciDamien AymonPublications [SOSP] Unlocking True Elasticity for the Cloud-Native Era with Dandelion Tom Kuchler, Pinghe Li, Yazhuo Zhang, Lazar Cvetković, Boris Goranov, Tobias Stocker, Leon Thomm, Simone Kalbermatter, Tim Notter, Andrea Lattuada, Ana Klimovic. To appear in the Proceedings of the ACM Symposium on Operating Systems Principles, 2025. [SOSP] Sailor: Automating Distributed Training over Dynamic, Heterogeneous, and Geo-distributed Clusters Foteini Strati, Zhendong Zhang, George Manos, Ixeia Sánchez, Qinghao Hu, Tiancheng Chen, Berk Buzcu, Song Han, Pamela Delgado, Ana Klimovic. To appear in the Proceedings of the ACM Symposium on Operating Systems Principles, 2025. [ICML] Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs Youhe Jiang*, Fangcheng Fu*, Xiaozhe Yao*, Guoliang He, Xupeng Miao, Ana Klimovic, Bin Cui, Binhang Yuan, Eiko Yoneki.Proceedings of the International Conference on Machine Learning (ICML), 2025. [ATC] Resource Multiplexing in Tuning and Serving Large Language Models Yongjun He, Haofeng Yang, Yao Lu, Ana Klimovic, Gustavo Alonso.Proceedings of the USENIX Annual Technical Conference (ATC), 2025. [MLSys] On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions Maximilian Böther, Abraham Sebastian, Pranjal Awasthi, Ana Klimovic, Srikumar Ramalingam.Proceedings of the Conference on Machine Learning and Systems (MLSys), 2025. [MLSys] ThunderServe: High-performance and Cost-efficient LLM Serving in Cloud Environments Youhe Jiang*, Fangcheng Fu*, Xioazhe Yao*, Taiyi Wang, Bin Cui, Ana Klimovic, Eiko Yoneki.Proceedings of the Conference on Machine Learning and Systems (MLSys), 2025. [EuroSys] DeltaZip: Efficient Serving of Multiple Full-Model-Tuned LLMs Xiaozhe Yao, Qinghao Hu, Ana Klimovic. Proceedings of the European Conference on Computer Systems (EuroSys), 2025. [SIGMOD] Modyn: Data-Centric Machine Learning Pipeline Orchestration Maximilian Böther, Ties Robroek, Viktor Gsteiger, Robin Holzinger, Xianzhe Ma, Pinar Tözün, Ana Klimovic. Proceedings of the International Conference on Management of Data (SIGMOD), 2025. [ASPLOS] PCcheck: Persistent Concurrent Checkpointing for ML Foteini Strati*, Michal Friedman*, Ana Klimovic. Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), 2025. [CIDR] Adaptive Data Transformations for QaaS Dimitrios Koutsoukos, Renato Marroquín, Ingo Müller, Ana Klimovic. Proceedings of the Conference on Innovative Data Systems Research (CIDR), 2025. [HotInfra] Decluttering the data mess in LLM training Maximilian Böther, Dan Graur, Xiaozhe Yao, Ana Klimovic. Proceedings of the Workshop on Hot Topics in System Infrastrcutrue, co-located with SOSP, 2024. [SOSP] Dirigent: Lightweight Serverless Orchestration Lazar Cvetković, François Costa, Mihajlo Djokic, Michal Friedman, Ana Klimovic. Proceedings of the ACM Symposium on Operating Systems Principles, 2024. [ICML] DéjàVu: KV-cache Streaming for Fast, Fault-tolerant Generative LLM Serving Foteini Strati, Sara McAllister, Amar Phanishayee, Jakub Tarnawski, Ana Klimovic.Proceedings of the International Conference on Machine Learning (ICML), 2024. [ATC] Pecan: Cost-Efficient ML Data Preprocessing with Automatic Transformation Ordering and Hybrid Placement Dan Graur*, Oto Mraz*, Sepehr Pourghannad, Muyu Li, Chandramohan A. Thekkath, Ana Klimovic.Proceedings of the USENIX Annual Technical Conference (ATC), 2024. [CIDR] Off-the-shelf Data Analytics on Serverless Michael Wawrzoniak, Gianluca Moro, Rodrigo Bruno, Ana Klimovic, Gustavo Alonso. Proceedings of the Conference on Innovative Data Systems Research (CIDR), 2024. [EuroSys] Orion: Interference-aware, Fine-grained GPU Sharing for ML Applications Foteini Strati, Xianzhe Ma, Ana Klimovic. Proceedings of the European Conference on Computer Systems (EuroSys), 2024. [SoCC] Function as a Function Tom Kuchler, Michael Giardino, Timothy Roscoe, Ana Klimovic. Proceedings of the ACM Symposium on Cloud Computing (SoCC), 2023. [SoCC] tf.data service: A Case for Disaggregatin",
  "content_length": 21073,
  "method": "requests",
  "crawl_time": "2025-12-01 12:56:09"
}