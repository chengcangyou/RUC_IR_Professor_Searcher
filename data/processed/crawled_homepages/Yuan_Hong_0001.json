{
  "name": "Yuan Hong 0001",
  "homepage": "https://yhongcs.github.io",
  "status": "success",
  "content": "Welcome to Yuan Hong's Homepage Dr. Yuan Hong School of Computing, University of Connecticut Home Publications People Services Address: 371 Fairfield Way Unit 4155, Storrs, CT 06269 Office: ITE-265 Email: yuan.hong AT uconn.edu Short Bio Dr. Yuan Hong is a Collins Aerospace Endowed Associate Professor in the School of Computing at University of Connecticut (UConn) and affiliated with the Connecticut Advanced Computing Center (CACC). Prior to joining UConn, he was an Assistant Professor in Computer Science and Cybersecurity Program Director at Illinois Institute of Technology between 2017 and 2022. He received his Ph.D degree from Rutgers University, M.Sc degree from Concordia University, Montreal, Canada, and B.Sc degree from Beijing Institute of Technology, respectively. He is a recipient of the NSF CAREER Award (2021), CCS Distinguished Paper Award (2024), CCS Top Reviewer Award (2025), USENIX Security Notable Reviewer Award (2025), and multiple Cisco Research Awards, and was also recognized as the finalist of the Meta Research Award (2021). He also received a National Physics Olympiad Prize in China. His research spans Security, Privacy, and Trustworthy Machine Learning, with a focus on differential privacy, secure computation, applied cryptography, adversarially robust learning in the context of computer vision, (large) language models, and cyber-physical systems (CPS). His research has been published in premier venues across Security, Databases, Machine Learning, Computer Vision, and NLP, such as S&P, CCS, USENIX Security, NDSS, CSF, PETS, SIGMOD, VLDB, NeurIPS, CVPR, ECCV, EMNLP, KDD, and AAAI, as well as leading interdisciplinary journals (e.g., multiple IEEE/ACM Transactions, and TR_C). He is a Senior Member of the ACM and IEEE. We have Ph.D. openings available for Spring/Fall 2026. If you are interested in our research, please email your application materials to Dr. Yuan Hong. UConn@CSRankings: Security & Crypto (28th), Overall (62th) News [Recent Conference TPC] CCS'26, USENIX Security'26, S&P'26, NDSS'26, CCS'25, USENIX Security'25, NDSS'25 [10/2025] Our SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models and the Dataset (the largest annotated dataset of jailbreaking and benign prompts to date) are online. A comprehensive evaluation platform and leaderboard will be released soon! [10/2025] Our Laplace DP-SGD for high dimensions via majorization theory is accepted to CSF'26 after shepherding (a prestigious venue for computer security foundation). Congrats to Meisam, Qin and the team! [10/2025] Yuan received the CCS'25 Top Reviewer Award and Nima received the CCS'25 Distinguished Artifact Evaluation Award, Thanks and Congrats! [10/2025] Our two CCS'25 papers got three (Available, Functional/Reusable, Results Reproduced) badges for the artifacts Congrats! [09/2025] Our work on certified robustness with universal asymmetric randomization is accepted to CSF'26 (a prestigious venue for computer security foundation). Congrats to Hanbin! [08/2025] Our patent on differentially private outsourcing system on anomaly detection is official (US Patent US12399985B2). Congrats to Meisam, Han and the team! [08/2025] Our work on differentially private embedding distillation is accepted to EMNLP'25 (Main Conference, Acceptance Rate: 22.16%). Congrats to Shuya! [08/2025] Yuan is recognized as the Notable Reviewer by USENIX Security'25, Thanks! [08/2025] Hanbin has successfully defended his doctoral dissertation. He will join TikTok as a Research Scientist, Congrats! [07/2025] Congrats to Nima for receiving the USENIX Security'25 Student Travel Award. Thanks for the generous support! [07/2025] Our work on optimizing DP for deep learning (including ViT and Language Model Fine-tuning) is accepted to CCS'25 (Acceptance Rate: 316/2,278=13.87%). Congrats to Qin, Nicholas, Meisam and the team! [07/2025] Our work on safeguarding graph neural networks against topology inference attacks is accepted to CCS'25 (Acceptance Rate: 316/2,278=13.87%). Congrats to Jie and the team! [06/2025] Our patent on utility-optimized differential privacy system is official (US Patent US12321478B2). Congrats to Meisam, Shangyu and the team! [06/2025] Shuya has successfully defended her doctoral dissertation. She will join University of Alabama at Birmingham as a Tenure-Track Assistant Professor, Congrats! [06/2025] Our work on rectifying machine unlearning measurements is accepted to USENIX Security'25 (Acceptance Rate: 407/2385=17.1%). Congrats to Nima, Shenao and the team! [05/2025] Thrilled to lead the NSF CSR project on building secure and real-time multi-camera surveillance systems (very grateful to NSF for the generous support!) [05/2025] Congrats to Shuya for receiving the Taylor L. Booth Graduate Fellowship (SoC's highest honor for Ph.D. students). Also, congrats to other students who received the Predoctoral Fellowships! [04/2025] Congrats to Shuya for receiving the ACM Student Travel Award. Thanks for the generous support! [04/2025] Hanbin will continue to do research internship in LLM Security at TikTok in Summer 2025. Congrats! [02/2025] Shenao will do research internship at VISA Research in Summer 2025. Congrats! [02/2025] Two works are accepted to CODASPY'25 (Acceptance Rate: 31/148=20.9%). Congrats to Shuya, Bingyu and the team! [12/2024] Xinyu has successfully defended her doctoral dissertation. She will join Alibaba Group as a Researcher in LLMs and Robustness, Congrats! [12/2024] Our work on information-theoretic robust and privacy-preserving representations learning is accepted to AAAI'25 (Acceptance Rate: 3032/12957=23.4%). Congrats to Ben, Leila and the team! [10/2024] Our work on the distributed backdoor attacks and certified defenses on FedGL recieved the CCS'24 Distinguished Paper Award. Congrats to all the co-authors! [09/2024] Our provably robust watermark for FedGL is accepted to NeurIPS'24 (Acceptance Rate: 25.8%). Congrats to Yuxin and the team! [08/2024] Media report for our CodeBreaker (USENIX Security'24): Researchers Highlight How Poisoned LLMs Can Suggest Vulnerable Code. [07/2024] Congrats to Shenao for receiving the USENIX Security'24 Student Travel Award. Thanks for the generous support! [07/2024] Our optimization-based atttack (breaking SOTA poisoning defenses to federated learning) is accepted to CIKM'24 (Acceptance Rate: 347/1531=23%). Congrats to Yuxin and the team! [07/2024] Our certified black-box attack (breaking SOTA defenses with provable confidence and limited resources) is accepted to CCS'24 (Acceptance Rate: 331/1964=16.9%). Congrats to Hanbin, Xinyu and the team! [07/2024] Our certified defenses for distributed backdoor attacks on federated graph learning is accepted to CCS'24 (Acceptance Rate: 331/1964=16.9%). Congrats to Yuxin and the team! [06/2024] Our DP data streaming mechanism under the delay-allowed framework is accepted to NDSS'25 (Acceptance Rate: 211/1311=16.1%). Congrats to Xiaochen, Shuya and the team! [06/2024] Our LLM-assisted backdoor attack to LLM-fine-tuned code generation/completion models is accepted to USENIX Security'24 (Acceptance Rate: 417/2276=~18%). Congrats to Shenao, Hanbin and the team! Selected Recent Publications SoK: SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models [Code Available Soon, Dataset (Largest Annotated Jailbreaking and Benign Prompts)] Crypto ePrint: KPIR-C: Keyword PIR with Arbitrary Server-side Computation [Code Available Soon] CSF'26: Lap2: Revisiting Laplace DP-SGD for High Dimensions via Majorization Theory [Code Available Soon] CSF'26: Towards Strong Certified Defense with Universal Asymmetric Randomization [Code] EMNLP'25: DPED: Multi-Layer Noise Distillation for Privacy-Preserving Text Embeddings [Code] CCS'25: PLRV-O: Advancing Differentially Private Deep Learning via Privacy Loss Random Variable Optimization [Code] CCS'25: Safeguarding Graph Neural Networks against Topology Inference Attacks [Code] USENIX Security'25: Rectifying Privacy and Efficacy Measurements in Machine Unlearning: A New Inference Attack Perspective [Code] AAAI'25: Learning Robust and Privacy-Preserving Representations via Information Theory [Code] NDSS'25: Delay-Allowed Differentially Private Data Stream Release [Code] NeurIPS'24: FedGMark: Certifiably Robust Watermarking for Federated Graph Learning [Code] CCS'24: Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence [Code] CCS'24: Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses [Code] USENIX Security'24: An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection [Code, Dataset] USENIX Security'24: Inf2Guard: An Information-Theoretic Framework for Learning Privacy-Preserving Representations against Inference Attacks [Code] CVPR'24: On the Faithfulness of Vision Transformer Explanations [Code] SIGMOD'24: Local Differentially Private Heavy Hitter Detection in Data Streams with Bounded Memory [Code] S&P'24: DPI: Ensuring Strict Differential Privacy for Infinite Data Streaming [Code] S&P'24: Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks [Code] AAAI'24: Task-Agnostic Privacy-Preserving Representation Learning for Federated Learning Against Attribute Inference Attacks [Code] VLDB'23: OpBoost: A Vertical Federated Tree Boosting Framework Based on Order-Preserving Desensitization [Code] CCS'22: L-SRR: Local Differential Privacy for Location-Based Services with Staircase Randomized Response [Code] KDD'22: A Model-Agnostic Approach to Differentially Private Topic Mining [Code] ECCV'22: UniCR: Universally Approximated Certified Robustness via Randomized Smoothing [Code] S&P'22: Universal 3-Dimensional Perturbations for Blackbox Attacks on Video Recognition Systems [Code] Teaching Principles of Databases: Fall 25 Cybersecurity Lab: Fall 23, Spring 24, Fall 24 Computer Security: Spring ",
  "content_length": 10312,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:13"
}