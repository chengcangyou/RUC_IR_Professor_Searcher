{
  "name": "Kai Ming Ting",
  "homepage": "https://ai.nju.edu.cn/KaiMingTing",
  "status": "success",
  "content": "Kai Ming Ting 陈开明 (Kai Ming Ting) Professor National Key Laboratory for Novel Software Technology & School of Artificial Intelligence Xianlin Campus, Nanjing University Email: tingkm at nju.edu.cn Post-doctoral position Research Interests · Isolation kernel and Isolation Distributional Kernel · Mass-based similarity · Mass estimation and mass-based approaches · Ensemble approaches · Data stream data mining · Machine learning Short Biography After receiving his PhD from the University of Sydney, Australia, Kai Ming Ting worked at the University of Waikato (NZ), Deakin University, Monash University and Federation University in Australia. He joined Nanjing University in 2020. Research grants received include those from National Natural Science Foundation of China, US Air Force of Scientific Research (AFOSR/AOARD), Australian Research Council, Toyota InfoTechnology Center and Australian Institute of Sport. He is the principal driver of isolation-based methods. The first of its kind is Isolation Forest which is one of the most effective and efficient anomaly detectors created thus far. Since its creation in 2008, it has been widely used by academia as well as industry with close to 10,000 citations recorded by Google Scholar. He is also the principal creator of Isolation Kernel (IK) and Isolation Distributional Kernel (IDK). Shown in AI Journal 2024, IK is the only measure which can break the curse of dimensionality since the inception of the field. This has wide-changing implications on all fields of applications which employ similarity/distance measures. Since its introduction in KDD2020, IDK has significant changed the landscape of data mining methods, enabling anomaly detection, clustering and retrieval tasks to be accomplished more effectively in applications such as Spatial Transcriptomics (in bio-informatics),  trajectories, time series and graphs. The IDK-based methods have been shown to outperform SOTA methods; in addition, they are able to run faster in CPU than deep learning methods running in GPU. Qualifications · Graduate Certificate of Higher Education - Monash University 2004 · Ph.D, Basser Department of Computer Science - University of Sydney 1996 · Master of Computer Science - University of Malaya 1992 · Bachelor of Electrical Engineering- University of Technology Malaysia 1986 Selected Program Committees • Area Chair: International Joint Conference on Artificial Intelligence, 2021 • Program Co-chairs: The Twelfth Pacific-Asia Conference on Knowledge Discovery and Data Mining, Osaka, Japan, 2008. • Tutorial Co-chair: The Eighth Pacific-Asia Conference on Knowledge Discovery and Data Mining, Sydney, Australia, 2004. • Senior PC member: AAAI Conference on Artificial Intelligence, 2019,2023. • Senior PC member: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2021-2023. • Senior PC member: Pacific Asia Conference on Knowledge Discovery and Data Mining, 2016, 2017, 2021. • Program committee member (since 2014) • KDD 2015-2018: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. • ICDM 2014-2016, 2018-2020: IEEE International Conference on Data Mining. • IJCAI 2017: International Joint Conference on Artificial Intelligence. • ECML 2016: European Conference on Machine Learning. • PAKDD 2015: Pacific-Asia Conf. on Knowledge Discovery and Data Mining. • AISTATS 2021: International Conference on Artificial Intelligence and Statistics. Tutorial Presentation · “Which Anomaly Detector should I use?” in 2018 International Conference on Data Mining. · “Mass Estimation: Enabling density-based or distance-based algorithms to do what they cannot do” in 2016 Asian Conference on Machine Learning. · “BIG DATA MINING” in Big Data School, 2013 Pacific-Asia Conference on Knowledge Discovery and Data Mining. Software Downloads · Isolation Kernel and Isolation Distributional Kernel · Isolation Nearest Neighbour Ensemble · Isolation Forest: A fast and effective anomaly detector · Mass Estimation and its suite of software · Feating: an ensemble that works with SVM Selected Publications (Full publication list see here) Kai Ming Ting, Zong-you Liu, Lei Gong, Hang Zhang, and Ye Zhu (2024). A new distributional treatment for time series anomaly detection. The VLDB Journal: 1-28. Yang Cao, Ye Zhu, Kai Ming Ting, Flora D. Salim, Hong Xian Li, Luxing Yang, and Gang Li (2024). Detecting Change Intervals with Isolation Distributional Kernel. Journal of Artificial Intelligence Research. 79 : 273-306. Kai Ming Ting, Takashi Washio, Ye Zhu, Yang Xu, and Kaifeng Zhang (2024). Is it possible to find the single nearest neighbor of a query in high dimensions? Artificial Intelligence. 336: 104206. Yufan Wang, Zijing Wang,Kai Ming Ting, and Yuanyi Shang (2024). A Principled Distributional Approach to Trajectory Similarity Measurement and its Application to Anomaly Detection. Journal of Artificial Intelligence Research. 79: 865-893. Ye Zhu, and Kai Ming Ting (2023). Kernel-based clustering via isolation distributional kernel. Information Systems. 117: 102212. Kai Ming Ting, Takashi Washio, Jonathan Wells, Hang Zhang, and Ye Zhu (2023). Isolation Kernel Estimators. Knowledge and Information Systems. 65(2): 759-787. Xin Han, Ye Zhu, Kai Ming Ting, and Gang Li (2023). The impact of isolation kernel on agglomerative hierarchical clustering algorithms. Pattern Recognition. 139: 109517. Kai Ming Ting, Bi-Cun Xu, Takashi Washio, and Zhi-hua Zhou (2023). Isolation Distributional Kernel: A New Tool for Point & Group Anomaly Detection. IEEE Transactions on Knowledge and Data Engineering. 35(3): 2697-2710. Kai Ming Ting, Jonathan R. Wells, Ye Zhu (2023). Point-Set Kernel Clustering. IEEE Transactions on Knowledge and Data Engineering. 35(5): 5147-5158. Ye Zhu, Kai Ming Ting, Yuan Jin, and Maia Angelova (2022). Hierarchical clustering that takes advantage of both density-peak and density-connectivity. Information Systems. 103: 101871. Xiang-yu Song, Sunil Aryal, Kai Ming Ting, Zhen Liu, and Bin He (2022). Spectral–spatial anomaly detection of hyperspectral data based on improved isolation forest. IEEE Transactions on Geoscience and Remote Sensing. 60: 1-16. Ming Pang, Kai Ming Ting, Peng Zhao, and Zhi-hua Zhou (2022). Improving deep forest by screening. IEEE Transactions on Knowledge and Data Engineering. 9: 4298-4312. Kai Ming Ting, Jonathan R. Wells, and Takashi Washio (2021). Isolation kernel: the X factor in efficient and effective large scale online kernel learning. Data Mining and Knowledge Discovery. 35(6): 2282-2312. Ye Zhu, and Kai Ming Ting (2021). Improving the effectiveness and efficiency of stochastic neighbour embedding with isolation kernel. Journal of Artificial Intelligence Research. 71: 667-695. Ye Zhu, Kai Ming Ting, Mark J. Carman, and Maia Angelova (2021). CDF Transform-and-Shift: An effective way to deal with datasets of inhomogeneous cluster densities. Pattern Recognition. 117: 107977. Ming Pang, Kai Ming Ting, Peng Zhao, Zhi-hua Zhou (2020). Improving deep forest by screening. IEEE Transactions on Knowledge and Data Engineering. 34(9), 4298-4312. Jonathan R. Wells, Sunil Aryal and Kai Ming Ting (2020). Simple supervised dissimilarity measure: Bolstering iForest-induced similarity with class information without learning. Knowledge and Information Systems. 62(8): 3203-3216. Sunil Aryal, Kai Ming Ting, Takashi Washio, Gholamreza Haffari (2020). A comparative study of data-dependent approaches without learning in measuring similarities of data objects. Data Mining and Knowledge Discovery. 34: 124–162. Jonathan R. Wells and Kai Ming Ting (2019). A simple efficient density estimator that enables fast systematic search. Pattern Recognition Letters. 122: 92-98. Kai Ming Ting, Ye Zhu, Mark James Carman, Yue Zhu, Takashi Washio and Zhi-hua Zhou (2019). Lowest Probability Mass Neighbour Algorithms: Relaxing the metric constraint in distance-based neighbourhood algorithms. Machine Learning. 108(2): 331-376. Ye Zhu, Kai Ming Ting, Mark James Carman (2018). Grouping points by shared subspaces for effective subspace clustering. Pattern Recognition. 83: 230-244. Bo Chen, Kai Ming Ting and Takashi Washio (2018). Local Contrast as an effective means to robust clustering against varying densities. Machine Learning. 107: 1621-1645. Yue Zhu, Kai Ming Ting, Zhi-hua Zhou (2018). Multi-Label Learning with Emerging New Labels. IEEE Transactions on Knowledge and Data Engineering. 30(10): 1901-1912. Tharindu R. Bandaragoda, Kai Ming Ting, David Albrecht, Fei Tony Liu and Jonathan R. Wells (2018). Isolation-based Anomaly Detection using Nearest Neighbour Ensembles. Computational Intelligence. 34(4): 968-998. Kai Ming Ting, Takashi Washio, Jonathan R. Wells and Sunil Aryal (2017). Defying the gravity of learning curve: a characteristic of nearest neighbour anomaly detectors. Machine Learning. 106(1): 55-91. Sunil Aryal, Kai Ming Ting, Takashi Washio, Gholamreza Haffari (2017). Data-dependent dissimilarity measure: an effective alternative to geometric distance measures. Knowledge and Information Systems. 34(4): 968-998. Mu Xin, Kai Ming Ting and Zhi-hua Zhou (2017). Classification under Streaming Emerging New Classes: A Solution using Completely-random Trees. IEEE Transactions on Knowledge and Data Engineering. 29: 1605-1618. Guan-song Pang, Kai Ming Ting, David Albrecht, Huidong Jin (2016). ZERO++: Harnessing the power of zero appearances to detect anomalies. Journal of Artificial Intelligence Research. 57: 593-620. Ye Zhu, Kai Ming Ting, Mark James Carman (2016). Density-ratio based clustering for discovering clusters with varying densities. Pattern Recognition. 60(C): 983-997. Sunil Aryal and Kai Ming Ting (2016). A generic ensemble approach to estimate multi-dimensional likelihood in Bayesian classifier learning. Computational Intelligence. 32(3): 458-479. Bo Chen, Kai Ming Ting, Takashi Washio and Gholamreza Haffari (2015). Half-Space Mass: A maximally robust and efficient data depth method. Machine Lear",
  "content_length": 23961,
  "method": "requests",
  "crawl_time": "2025-12-01 13:39:22"
}