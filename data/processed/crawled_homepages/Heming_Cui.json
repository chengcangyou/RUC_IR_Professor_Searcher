{
  "name": "Heming Cui",
  "homepage": "https://i.cs.hku.hk/~heming",
  "status": "success",
  "content": "Heming Cui Department of Computer Science The University of Hong Kong (HKU) Room 421, Chow Yei Ching Building, HKU, Pok Fu Lam Road, Hong Kong [ Resume | Publication | Research Lab | Admitting New Students ] I am an associate professor in HKU CS. I got my bachelor and master degrees from Tsinghua University; I joined HKU in January 2015 right after I got my PhD degree from Columbia University (my PhD supervisor is Prof. Junfeng Yang). I lead the HKU Systems Software Lab. I am interested in building parallel and distributed systems, including blockchain systems, distributed AI training/serving systems, distributed big-data and parallel computing systems, and cloud computing systems. I have a particular focus on improving the reliability, security, and performance of these systems. I publish papers in broad areas of systems, security, and networking, including SOSP, NSDI, ASPLOS, ATC, EuroSys, DSN, TPDS, and TDSC. In recent three years, I serve on the program committees of international systems/networking conferences, including OSDI, NSDI, ATC, DSN, EuroSys, SOCC, and ICDCS. I also serve as constant reviewers for international systems/networking/software/security journals, including TPDS, TOCS, TSE, TON, TMC, and TDSC. I receive several world-wide competative research awards, including a Croucher Innovation Award in 2016 (HK $5 million), an outstanding (best) paper award from ACSAC '17, two Huawei flagship research grants in 2018 (blockchain and security) and 2021 (AI), and the Best Collaborating Scientist Medal from the Huawei Theory Lab in 2021, and the RGC Research Impact Fund (RIF) in 2023 (HK $4.3 million). He is the project leader of a National Key R&D Program of China 2030 (the project topic is about building new parallel training systems for large AI models). As (one of) the project leaders or principle investigators, Dr. Cui's total amount of competative research grants in Hong Kong and mainland China has reached about HK $90 million. My recent research papers have led to commercial software releases with global leading IT industries. For instance, My secure system papers (e.g., [Uranus AsiaCCS 2020] and [DAENet TDSC 2021]) on Trusted Execution Environments have become a core component of Huawei's Trusted and Intelligent Cloud Services (see the UTEE component in TICS). In addition, my students and I are actively collaborating with industries to jointly publish research papers and to transfer the resultant systems from these papers into commercial software of broad areas, including distributed AI training systems, permissioned blockchain systems, security and privacy preserving systems, and geo distributed transaction systems. I admit several PhD students every year. I expect my students to have good skills/experience on hacking systems software (e.g., Linux kernel, LLVM, or distributed protocols) or AI frameworks, and have strong motivation on research. If you are interested, please directly apply here and select \"systems and networking research\" as your interested field during the application. If you also want to talk with me individually, please read my recent papers (at least several times for each paper), understand how they work deeply, compile and run them, and then email me what new research topics you can think of (e.g., new applications or significant improvments of my systems, or some other relevant and crazy ideas). I will reply your email quickly if your ideas make sense. I also recruit postdoc of broad systems and networking areas. Please read my papers, form a few short research proposals (ideas/plans) within the intersections of your work and my work, and send me your CV with the proposals. I have several well funded research grants that can support student Research Assistants (RAs) and summer research interns for students around the world. If you are interested and you can work full-time in HKU for a few months, you can send me emails with your CV and thoughts on my papers. Selected Publication (\"*\" means corresponding author) BIDL: A High-throughput, Low-latency Permissioned Blockchain Framework for Datacenter Networks [pdf | video | code] Ji Qi, Xusheng Chen, Yunpeng Jiang, Jianyu Jiang, Tianxiang Shen, Shixiong Zhao, Sen Wang, Gong Zhang, Li Chen, Man Ho Au, Heming Cui* Proceedings of the 28th ACM Symposium on Operating Systems Principles 2021 (SOSP '21). ACM results reproduced badge. Describe BIDL, a high-performance and BFT-compatible permissioned blockchain workflow that can parallelize the executions of smart contracts and their BFT ordering on dedicated datacenter networks; BIDL can also tackle aborts caused by concurrently contending smart contract transactions and non-determinism (e.g., multithreading races in transactions). Fold3D: Rethinking and Parallelizing Computational and Communicational Tasks in the Training of Large DNN Models [pdf | slides | code] Fanxin Li, Shixiong Zhao*, Yuhao Qing, Xusheng Chen, Xiuxian Guan, Sen Wang, Gong Zhang, and Heming Cui* IEEE Transactions on Parallel and Distributed Systems 2021 (TPDS '23) Describe Fold3D, a general pipepline parallel training system for big AI models (e.g., Transformer and GPT). Fold3D introduces a new scheduling algorithm that folds Data Parallel (DP), Pipeline Parallel (PP) and Tensor Parallel (TP) tasks in a highly parallel way. Compared to world's latest relevant training systems (e.g., Megatron), Fold3D improves all GPUs' utilization (training throughput) for training each big AI model significantly by about 40%. JITfuzz: Coverage-guided Fuzzing for JVM Just-in-Time Compilers Mingyuan Wu, Minghai Lu, Heming Cui, Yanwei Huang, Junjie Chen, Yuqun Zhang, and Lingming Zhang Proceedings of the 45th International Conference on Software Engineering (ICSE '23) CRONUS: Fault-isolated, Secure and High-performance Heterogeneous Computing for Trusted Execution Environments [pdf | slides | video | code] Jianyu Jiang, Qi Ji, Tianxiang Shen, Xusheng Chen, Shixiong Zhao, Sen Wang, Li Chen, Gong Zhang, Xiapu Luo, Heming Cui* Proceedings of the 55th ACM/IEEE International Symposium on Microarchitecture (MICRO '22). ACM results reproduced badge. ROG: A High Performance and Robust Distributed Training System for Robotic IoT [pdf | slides | video | code] Xiuxian Guan, Zekai Sun, Shengliang Deng, Xusheng Chen, Shixiong Zhao*, Zongyuan Zhang, Tianyang Duan, Yuexian Wang, Chenshu Wu, Yong Cui, Libo Zhang, Yanjun Wu, Rui Wang, Heming Cui Proceedings of the 55th ACM/IEEE International Symposium on Microarchitecture (MICRO '22). ACM results reproduced badge. A Geography-Based P2P Overlay Network for Fast and Robust Blockchain Systems [paper] Haoran Qiu, Tao Ji, Shixiong Zhao*, Xusheng Chen*, Ji Qi, Heming Cui, Sen Wang IEEE Transactions on Services Computing 2022 (TSC '22) SOTER: Guarding Black-box Inference for General Neural Networks at the Edge [pdf | slides | code] Tianxiang Shen, Ji Qi, Jianyu Jiang*, Xian Wang, Siyuan Wen, Xusheng Chen, Shixiong Zhao, Sen Wang, Li Chen, Xiapu Luo, Fengwei Zhang, Heming Cui Proceedings of the 2022 USENIX Annual Technical Conference (ATC '22) Describe SOTER, a system for enforcing the confidentiality and integrity of a trained DNN model's parameters for inference tasks on end devices by automatically splitting, transforming, recovering a part of the model's neuron layers within and outside a trusted execution environment (e.g., an Intel SGX CPU). SOTER incurs no inference precision loss for an DNN model and incurs only moderate performance overhead compared to the execution time of insecure inference tasks. NASPipe: High Performance and Reproducible Pipeline Parallel Supernet Training via Causal Synchronous Parallel [pdf | video | code] Shixiong Zhao, Fanxin Li, Xusheng Chen, Tianxiang Shen, Li Chen Sen Wang, Gong Zhang, Cheng Li, Heming Cui* The 2022 Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS '22). ACM results reproduced badge. Describe NASPipe, the first pipeline parallel (PP) training system for training multiple subnets concurrently in NAS (Neural Arch Search) based big AI models. vPipe: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel DNN Training [pdf | code] Shixiong Zhao, Fanxin Li, Xusheng Chen, Xiuxian Guan, Jianyu Jiang, Dong Huang, Yuhao Qing, Sen Wang, Peng Wang, Gong Zhang, Cheng Li, Ping Luo, Heming Cui* IEEE Transactions on Parallel and Distributed Systems 2021 (TPDS '21) Describe vPipe, a general pipepline parallel training system for big AI models (e.g., Transformer, AboebaNet, GPT, and GNMT). vPipe tackles a severe load imbalance problem among the multi-GPU pipeline stages caused by inherent tensors accumulation in former stages, which can greatly downgrade training performance. vPipe's throughput and effective GPU ALU utilization are higher than existing premier pipepline parallel training systems (e.g., GPipe and Pipedream). vPipe is also the first pipeline parallel training system that supports NAS (Neural Arch Search) during the training of a big AI model. COORP: Satisfying Low-Latency and High-Throughput Requirements of Wireless Network for Coordinated Robotic Learning [pdf | code] Shengliang Deng, Xiuxian Guan, Zekai Sun, Shixiong Zhao, Tianxiang Shen, Xusheng Chen, Tianyang Duan, Yuexuan Wang, Jia Pan, Yanjun Wu, Libo Zhang, Heming Cui* IEEE Internet of Things Journal 2022 (IOT-J '22) Describe Coorp, a wireless and distributed scheduling system for robots which conduct high-throughput distributed online learning as well as low-latency wireless coordinating operations. Evaluating and Improving Neural Program-Smoothing-based Fuzzing [pdf] Mingyuan Wu, Jing Liang, Jiahong Xiang, Yuqun Zhang, Guowei Yang, Huixin Ma, Sen Nie, Shi Wu, Heming Cui, Lingming Zhang Proceedings of the 44th International Conference on Software Engineering (ICSE '22) Evaluate the coverage limitations of existing program smoothing fuzzing techniques and introduce our optimizations on these techniques. One Fuzzing Strategy",
  "content_length": 23615,
  "method": "requests",
  "crawl_time": "2025-12-01 13:19:48"
}