{
  "name": "Xiangyu Zhang 0001",
  "homepage": "https://www.cs.purdue.edu/homes/xyzhang",
  "status": "success",
  "content": "Xiangyu Zhang Search Xiangyu Zhang Samuel Conte Professor of Computer SciencePurdue University BiographyXiangyu Zhang is a professor specializing in AI security, software analysis and cyber forensics. His work involves developing techniques to detect bugs, including security vulnerabilities, in traditional software systems as well as AI models and systems, and to diagnose runtime failures. He has served as the Principal Investigator (PI) for numerous projects funded by organizations such as DARPA, IARPA, ONR, NSF, AirForce, and industry. Many of the techniques developed by his team have successfully transitioned into practical applications. His research outcome has been published on top venues in the areas of Security, AI, Software Engineering, and Programming Languages, and recognized by various distinguished paper awards including the prestigious ACM Distinguished Dissertation Awards. He has mentored over 30 PhD students and post-docs, with fifteen of them securing academic positions in various universities. Many of them have been honored with NSF Career Awards or comparable recognitions.Interests Artificial Intelligence Security Program Analysis Cyber forensicsOngoing ProjectsDetecting Deception in Natural Language Processing Applications by Model InterpretationGood Ventures Foundation Feb 2023The goal of that project is to develop principled techniques that can detect deceptive contents in natural language conversions. These contents could be generated by humans or by Large Language Models (LLMs). These techniques are based on interpreting conversation contents (e.g., using another LLM) and analyzing model internals (e.g., using gradient-based optimizations).On-the-fly Cyber Crime Scene TranscriptionONR Jan 2023There has been an upsurge of cybercrime in recent years. The number of cybercrime in 2022 has increased by 600% compared to before pandemic, and the annual damage hits 6 trillion dollars. On the other hand, attack investigation is becoming increasingly challenging. It takes 228 days on average to identify an attack and 80 more days to investigate one. In industries that face more attacks, such as healthcare, the detection of an attack takes 329 days on average. Such lengthy dwell-time, i.e., the time an attack remains undetected leads to substantial monetary loss and institutional sabotage. In this project, we aim to develop an AI-based log transcribing technique. We will first define a universal behavior description language that can describe high level system/user behaviors that are forensics relevant, such as opening a URL, saving an attachment, playing a video, and chatting with a remote agent. This language will be so general that it can describe behaviors of all popular applications. We will then formulate the problem as a machine translation problem that translates audit logs generated by the unlying operating systems (in a very low level language) to descriptions in the human understandable high level language.Program Analysis for Domain Specific Language Extraction of Legacy SoftwareDARPA Jul 2021As part of the DARPA V-SPELLS program, this project aims to automate domain specific program analysis. There are inherently hard challenges in general program analysis, such as handling pointers, indirect calls, constructing loop invariants, and decompilation, despite the steady progress the community has been making. Fuzzing techniques and bug finding tools are still limited to finding low level bugs such as memory bugs, and formal methods often require substantial human efforts to translate domain specific and application specific properties down to annotations to implementation artifacts. The project focuses on lifting implementation to post hoc domain specific models, providing a new perspective to these hard problems. Instead of dealing with the low level implementation details, we abstract them away such that their high-level semantics become clean and easy to reason. With lifted domain models, domain specific properties can be easily checked. This allows existing fuzzers to find complex logical bugs, formal methods can be substantially simplified and automated. We are interested in lifting implementations in various domains such as parsers, network protocols, robotic systems, smart contracts, and even binary executables.Scanning AI Models for Backdoors by Artificial Brain SimulationIARPA Jul 2020As part of the IARPA TrojAI program, this project aims to develop techniques to scan backdoors injected into AI models of varius modalities such as Computer Vision, Object Detection, Natural Language Processing, and Cyber Security. AI backdoor attacks leverage vulnerabilities in pre-trained models such that inputs stamped with a specific (small) input pattern (e.g., a polygon patch) or undergone some fixed transformation (e.g., applying a filter) induce intended model misbehaviors, such as misclassification to a target label. The misbehavior-inducing input patterns/transformations are called backdoor triggers. The vulnerabilities are usually injected through various data poisoning methods. Some even naturally exist in normally trained models. The attack model of AI backdoors becomes increasingly similar to that of traditional cyber attacks (on software), and in the meantime AI models have more and more applications in critical tasks such as autonomous driving and ID recognition (for access control). Defending model backdoors hence becomes a pressing need. In this project, we develop novel analytic techniques to scan AI models for Trojans. Our approach analyzes inner neuron behaviors by determining how output activations change when we introduce different stimulations to a neuron. This is analogous to Electrical Brain Stimulation (EBS), a technique invented in the 19th century, and widely used ever since to study the functionalities/behaviors of human/animal brain neurons. EBS applies an electrical current of various strength to stimulate selected neurons, and then observes the external behavior, such as happiness or aversive reactions. Hence, we call our technique Artificial Brain Stimulation (ABS).TrojAI is a competition based program. Competitions are organized in rounds, each having a different focus such as Computer Vision (CV), Natural Language Processing (NLP), and Object Detection. In each round, hundreds of AI models are provided with half of them containing trojans. Performers are supposed identify the trojaned models. Team performance is recorded by a public leaderboard. A round ends once any team has reached the round target (and won the round), and the next round often starts immediately. Our team has been having top performance in the past three years (please refer to the TrojAI leaderboard)AI Model Debugging by Analyzing Model Internals with Python Program AnalysisNSF Oct 2019Just like software inevitably contains bugs and software debugging is a key step in software development, AI models may have undesirable behaviors, which we call model bugs, and model debugging IS an essential step in intelligent software engineering. Model bugs are different from traditional coding bugs. They are misconducts in the model engineering process, such as biased training data and problematic model structure, that lead to undesirable consequences such as low model accuracy and vulnerabilities to adversarial sample attacks, in which normal inputs are mutated (e.g., by perturbations not human perceptible) to induce mis-classification. We observe that AI models, especially neural network models, are essentially programs (e.g., in Python) that compute state variable values (called neurons) through multiple program phases (called layers). The values of neurons in a layer are computed from those of the previous layer through matrix multiplication and activation function, which is some kind of thresholding function to determine if values shall be used in the computation of next layer (called neuron activated). Intuitively, each neuron is considered denoting some abstract feature(s). The computation from a layer to the next is a further step of feature abstraction. The knowledge acquired in training is encoded in the weight values of the matrices. As such, AI model debugging can substantially benefit from analyzing these programs and their execution states. Hence, we propose to learn from the substantial experience of software debugging that is built up by the software engineering and program analysis community over decades of intensive research and develop novel analyses to inspect model internals for diagnosis and repair of model defects.Principled Co-Reasoning of Software and Natural-Language ArtifactsNSF Jul 2019The goal of that project is to develop principled co-analysis of code and natural language (NL) artifacts, including code comments, change logs, manual pages, constant strings in code, and variable and function names. That proposed research treats NL artifacts as first-class objects, instead of simple sources for additional information, to take full advantage of software NL artifacts. For example, a comment made by the developer at a code location can be propagated to other correlated code locations to help understanding and maintenance.Research GroupCurrent StudentsGuanhong Tao (expected 2024, on market ð¥)Zhiyuan Cheng (expected 2024)Shengwei An (expected 2025)Le Yu (expected 2025)Sayali KateYi SunYu ShiGuangyu ShenXuwei LiuYunshu MaoSiyuan ChengFrank FengXiangzhe XuKaiyuan Zhang (co-advised with Ninghui Li)Xuan ChenLu YanMingwei ZhengZhou XuanHanxi GuoSyed Yusuf AhmedXiaolong JinJiasheng JiangCurrent PostdocsZhuo Zhang, previously PhD from PurdueStephen Wang, previously PhD from HKUSTCurrent VisitorsWuqi Zhang, PhD student from HKUSTJunmin Zhu, previously MS from SJTUFormer StudentsYapeng Ye, 2024 PhD graduation, GoogleI Luk Kim, 2023 PhD graduation, Senior Computational Scientist at PurdueQiuling Xu, 2023 PhD graduation, NetflixYingqi Liu, 2023 PhD graduation, Research Scientist at MicrosoftHo",
  "content_length": 14654,
  "method": "requests",
  "crawl_time": "2025-12-01 14:48:12"
}