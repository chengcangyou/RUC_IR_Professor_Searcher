{
  "name": "Erhan Öztop",
  "homepage": "https://robotics.ozyegin.edu.tr/members/erhan-oztop",
  "status": "success",
  "content": "Erhan Öztop | Robotics Lab Skip to main content AboutResearchPublicationsCVContact I am a professor at Ozyegin University Computer Science Department where I co-direct Ozu Robotics Laboratory, and I am also a Specially Appointed Professor at Osaka University in the  Symbiotic Intelligent Systems Research Center (SISReC) of Institute for Open and Transdisciplinary Research Initiatives (OTRI). Before joining OzU, I was conducting research at the Cognitive Mechanisms Laboratories of the Advanced Telecommunications Research Institute (ATR) as the vice head of the Communication and Cognitive Cybernetics (CCC) Department. My research interests include computational modeling intelligent behavior, machine learning, cognitive and developmental robotics, and cognitive neuroscience and human-robot adaptation. In general, I am interested in the question of how humans and other biological systems process information and solve problems, and how this knowledge can be used for desiging intelligent learning systems. Research Please follow the links for brief descriptions Convergent Human and Robot Learning for Effective Robot Skill Generation Computational Modeling of Mirror Neurons Sign-Representation of Boolean Functions Dexterous Manual Manipulation Previous Projects Gifu Hand III Human visuomotor learning for robot skill synthesis : Dexterous manipulationThis study explores how the human visuomotor learning ability can be utilized for obtaining dexterous manipulation and movement capabilities on robots (see also item 4 below). For example an effortless ball manipulation via realtime control of the Gifu Hand can be seen here . A more challenging task is to rotate the so called Chinese healing balls without dropping them. With training, the robot hand is integrated into human ‘body schema’ allowing the subject to perform this task with the robot hand. Here is a movie or this showing the obtained skill with this paradigm. This basic skill then can be tuned to improve performance (e.g. speed) as shown here . Self-observation and auto-association as route to simple imitationIn the previous years, we have explored the associative memory hypothesis of imitation bootstrapping with the Gifu Hand. Click for a demo movie. Application to Brain Machine InterfaceCollaborating with Honda and neuroscientists at ATR/CNS, we employed the Gifu Hand in a brain-machine-interface (BMI) project. Using fMRI, human subjects’ brain activity are mapped to one of rock/scissors/paper hand postures that are replicated on the Gifu Hand in near real-time.Take a Google search on the project. Realtime full body robot control of HOAP-II Human visuomotor learning for robot skill synthesis: Reaching while keeping static balanceThis is the extension of the ‘human visuomotor learning for robot skill synthesis’ paradigm to full body humanoid robots. This is a collaborative work with Jan Babic at Jozef Stefan Institute, Slovenia and Joshua Hale at ATR, Japan. Here is the human human control of the robot, where the subject was asked to keep the robot balanced while tracing a trajectory with his finger. The data collected is used to derive a balanced reaching skill. Here this skill is used to have the robot trace an elliptical trajectory. Improving the human visuomotor learning for robot skill synthesis paradigmThis platform can carry a human. The idea is this: the subject controlling a humanoid robot will ‘ride’ the platform and ‘feel’ how the robot feels in terms of the dynamics of the center of mass of the robot. Here the force control of the platform can be seen. The separation induced by a higher order neuron (a polynomial) for a dichotomy of the corners of the 3 dimensional cube. Representation of Boolean functions (dichotomies over the n-cube) using polynomials (higher order neurons) with a small number of monomials (fan-in).Higher-order neurons or sigma-pi units are extensions of linear neuron models, which capture the nonlinearity in the input-output relation of a mapping using products of input variables, called the monomials. The net input to a higher-order unit is the sum of the monomials weighted by adjustable parameters. The output is obtained by the application of a predefined activation function, usually a sigmoidal function, or a threshold function to the net input. There are many aspects of this powerful model that deserves attention. My main interest is to study the number of monomials that a higher order neuron would require to solve a given classification. More generally; given a set of classification problems what is the minimum number of monomials that can solve the given problem set? Recently, I have showed that any dichotomy of the n-cube can be realized with 0.75*2n or less monomials. This is the best bound known so far. Here is the reprint that has the proof of this claim. DB, the robot used in human-robot interaction experiments Motor interference: an objective tool to test the extent that a robot is perceived as human-likeIt is generally accepted that (humanoid) robots will become part of out daily lives. So it is important to understand how well they will be accepted as social partners. In this direction, we have adopted the motor interference effect observed in human-human interactions to study study the human perception of robots as social partners. Motor interference refers to the differential effect of observing an action while performing a compatible or an incompatible action. An example of a compatible and incompatible movement pair is the vertical and. lateral hand movements. We have recently shown that a humanoid robot (DB) moving similar to a human elicits motor interference. We now are conducting experiments to tease apart the contribution of motion and form to this reaction. To get idea of the experiment setup click here. Activity maps of the units that model the AIP neurons Grasp Affordance LearningGrasp Affordance refers to the intrinsic features of an object that are relevant for grasping. For example the color of pen, in general, is not part of its grasp affordance because it does not guide the grasping behavior. In macaque monkeys the parietal area AIP appears to be involved in affordance extraction. AIP with the ventral premotor cortex (F5) forms the core of the monkey grasping circuit. Recently I developed a model for AIP neurons which is based on the hypothesis that early grasping of infants (being mediated by other mechanisms) provide the learning data points for F5-AIP complex to learn a mapping from visual->motor representation. The critical test is then to see whether this visuo-motor learning leads to the emergence of unit responses that are comparable to actual AIP neurons. The simulation results show that this is correct. The future research plan is to compare the modeled AIP unit activities with AIP neuron discharge profiles in a quantitative way. The cortical grasp planning and execution circuit of macaque monkeys. Mirror Neurons and ImitationAccording to the general opinion, high level functions such as imitation, action understanding and (precursors of) language are attributed to mirror neurons. However it is not clear how much the human mirror system has evolved to support imitation and language, if indeed there is a connection between these skills and the mirror neurons. Furthermore the number of studies that take a computational viewpoint to study these hypothesis is limited. Recently, guided by my earlier modeling of mirror neurons and mental state inference mechanisms I have made a meta-analysis of the computational models (that can be seen as models of mirror neurons) and current opinions about mirror neuron function. Here is the reprint. Older projects and links AppletsPhD Related links Publications International Journal Publications Sener M, Nagai Y, Oztop E, Ugur E (2021) Exploration with Intrinsic Motivation using Object-Action-Outcome Latent Space. IEEE Transactions on Cognitive and Developmental Systems. doi: 10.1109/TCDS.2021.3062728 Kirtay M, Vannucci L, Albanese U, Laschi C, Oztop E, Falotico E (2019) Emotion as an emergent phenomenon of the neuro-computational energy regulation mechanism of a cognitive agent in a decision-making task, Adaptive Behavior. doi:10.1177/1059712319880649 Bugur S, Oztop E, Nagai Y, Ugur E (2019) Effect regulated projection of robot's action space for production and prediction of manipulation primitives through learning progress and predictability based exploration, IEEE Transactions on Cognitive and Developmental Systems. doi: 10.1109/TCDS.2019.2933900 Amirshirzad N, Asiye K, Oztop E (2019) Human Adaptation to Human-Robot Shared Control. IEEE Transactions on Human-Machine Systems, Early access doi: 10.1109/THMS.2018.2884719 Imre M, Oztop E, Nagai Y, Ugur E (2019) Affordance-Based Altruistic Robotic Architecture for Human-Robot Collaboration. Adaptive Behavior, Early access doi:10.1177/1059712318824697 Teramae T, Ishira K, Babic J, Morimoto J, Oztop E (2018) Human-in-the-loop control and task learning for pneumatically actuated muscle based robots. ontiers in Neurorobotics, doi: 10.3389/fnbot.2018.00071 Taniguchi T, Ugur E, Hoffman M, Jamone L, Nagai T, Rosman B, Matsuka T, Iwahashi N, Oztop E, Piater J, Florentin W (2018) Symbol Emergence in Cognitive Developmental Systems: a Survey. IEEE Transactions on Cognitive and Learning Systems. Early access doi: 10.1109/TCDS.2018.2867772 Ersen M, Oztop E, Sariel S (2017) Enabling Cognition for Robot Manipulation in Human Environments: Requirements, Recent Work and Open Problems. The IEEE Robotics and Automation Magazine 24 (3), pp. 108-122 Babic J, Oztop E, Kawato M (2016) Human motor adaptation in full body movements: squat-to-stand under postural perturbations. Nature Scientific Reports 6: 32868 (doi:10.1038/srep32868) Sezener E, Oztop E (2015) Minimal sign representation of Boolean functions: algorithms and exact results for low dimensions. Neural Computation 27(8):1796-823 Ugur E, Sahin E, Nagai Y, Oztop E (2015) Stag",
  "content_length": 25245,
  "method": "requests",
  "crawl_time": "2025-12-01 13:06:54"
}