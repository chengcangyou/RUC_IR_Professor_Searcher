{
  "name": "Peter Dayan [KYB]",
  "homepage": "https://www.kyb.tuebingen.mpg.de/computational-neuroscience",
  "status": "success",
  "content": "Department for Computational Neuroscience Computational Neuroscience Decision-making in the brain The main focus of the department is building and testing theories and computational models of neural processing, with a particular emphasis on decision-making, learning and representation. This covers the ways that humans and other animals come to choose appropriate and sometimes inappropriate actions in the face of rewards and punishments, and the ways and goals of the process by which they come to form neural representations of the world. The models are informed and constrained by neurobiological, psychological and ethological data. We also study the consequences for neurological and psychiatric disease when these mechanisms, or their embedding in their environment, break down. These areas are developing and expanding very quickly because of technical innovations in cognitive science, artificial intelligence, neuroscience, psychiatry and in large-scale natural experiments. We perform behavioural and neuroimaging experiments of our own, and work in close collaborations with a panoply of other experimental and theoretical groups.There are three main current directions: neuromodulation, neural reinforcement learning and computational psychiatry.NeuromodulationThe neuromodulators dopamine, serotonin, acetylcholine and norepinephrine powerfully regulate a host of critical functions in the brain, and are involved or therapeutically manipulated in many diseases. Ideas abound about the functional associates of these substances - their representation of computationally meaningful quantities such as predictions of, and prediction errors for, affectively important outcomes, and different sorts of uncertainty. New technologies for recording and manipulating these neuromodulators are being developed; we exploit these to address critical questions about their function.Neural Reinforcement LearningNeural reinforcement learning covers the core theory, algorithms and implementations of adaptive decision-making. These include meta-control, which is the control of control - the way that decision-making systems in the brain are themselves regulated online and offline in order to generate adaptive behaviour in the face of substantial real and opportunity costs for the engagement of the neural machinery involved. We also study ways of creating and adapting representations, aspects of the utility afforded to states and the associated risk-sensitivity; the nature and effect of the social environments of decision-makers. We develop new, computationally-informed, behavioural tasks, and adopt new imaging analysis methods to examine these processes in functional and temporal detail.Computational PsychiatryOur understanding of decision-making in the healthy population has now advanced to the point that we can use it to investigate characteristic modes of failure. This provides precise, process- and circuit-oriented hypotheses for understanding symptoms and causes of mental dysfunction. In turn, this richly couples notionally organic and psychological concerns, and provides new methods for classification and prediction. In turn, as we deepen our understanding of failure modes, an important window is opened onto normal cognition. Team Alumni Publications Join the lab Contact Dr. Peter Dayan Geschäftsführender Direktor +49 7071 601 900 +49 7071 601 616 dayan@tue.mpg.de Bianca Gäßler Secretary +49 7071 601 901 +49 7071 601 616 bianca.gaessler@tuebingen.mpg.de Susan Fischer Coordinator Alexander von Humboldt Professorship +49 7071 601 1638 +49 7071 601 616 susan.fischer@tuebingen.mpg.de More Information Theoretical Neuroscience Textbook by Peter Dayan and LF Abbott Computational Neuroscience of Vision For a book on the computational neuroscience of vision, see Understanding Vision by Li Zhaoping Web-View Print Page Open in new window Estimated DIN-A4 page-width Go to Editor View",
  "content_length": 3915,
  "method": "requests",
  "crawl_time": "2025-12-01 14:11:19"
}