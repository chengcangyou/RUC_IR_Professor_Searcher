{
  "name": "Shubham Tulsiani",
  "homepage": "https://shubhtuls.github.io",
  "status": "success",
  "content": "Shubham Tulsiani - Home Shubham Tulsiani I am an Assistant Professor at Carnegie Mellon University in the Robotics Institute, where I am a part of the Computer Vision group. I am interested in building perception systems that can infer the spatial and physical structure of the world they observe. Please see these recent talks for an overview. Prior to joining CMU, I was a Research Scientist at FAIR, Pittsburgh working with Abhinav Gupta. I previously graduated from UC, Berkeley where I was advised by Jitendra Malik, and also frequently collaborated with Alyosha Efros. contact | google scholar | twitter email: shubhtuls AT cmu.edu Office: Smith Hall 230 Research Group Our group is interested in inferring physically and spatially grounded representations from perceptual input, and leveraging these for advances in fundamental problems in computer vision and robot manipulation. We believe that to enable machines to understand the physical world, we should reduce the reliance on supervision by annotation, and instead develop learning mechanisms informed by the real, physical world we live in â€“ by incorporating our knowledge about its structure and laws as a 'meta-supervisory' signal. We are always looking for strongly motivated PhD and MS students. If you are interested in joining our group, please read this. Dear Prospective Students, Thanks for the interest in being a part of our group! Unfortunately, I am unable to reply to individual emails, but hope you find the following helpful: I am a CMU student. How do I join your group? Send me an email and/or drop by my office - I'd be happy to chat! If you are an undergraduate, also consider reaching out to the PhD students in our group if their projects align with your interests. I want to join CMU. What graduate programs should I apply to? PhD. Applicants: While I am primarily affiliated with RI, I can supervise students admitted in any SCS department (e.g. MLD, CSD) so apply to the department that best matches your interests and background. If you are interested in working with me, mention this in your application statement. MS Applicants: RI offers MSR (research focused) and MSCV (industry focused) MS programs among others. Please apply to the program most aligned with your future goals. Should I contact you before applying to CMU for admission? Admissions across all PhD/MS programs are done by department-level committees and I am unable to help with individual applications. Please do feel free to reach out after you are admitted. Are you accepting interns/visitors? We do not have any short-term positions at this time. PhD Students Hanzhe Hu Himangi Mittal Qitao Zhao Yehonathan Litman (co-advised with Fernando De la Torre) MS Students Clara Cong (MSCV) Lucas Wu (MSR) Rena Ju (MSCV) Sungjae Park (MSR) Undergraduate Students Isaac Lin Alumni PhD: Jason Zhang (co-advised with Deva Ramanan), Sparse-view 3D in the Wild, 2024. Google Yufei Ye (co-advised with Abhinav Gupta), Learning to Perceive and Predict Everyday Interactions, 2024. Postdoc at Stanford Homanga Bharadhwaj (co-advised with Abhinav Gupta), Watch, Predict, Act: Robot Learning meets Web Videos, 2025. Meta MSR: Yanbo Xu. PhD at Princeton Bharath Raj. PhD at Cornell Zhizhuo (Z) Zhou. PhD at Stanford MSCV: Qitao Zhao, Poorvi Hebbar, Naveen Venkat, Mayank Agarwal, Yen-Chi Cheng, Paritosh Mittal Undergraduate: Amy Lin Teaching 16-822: Geometry-based Methods in Vision. Fall 2024, 2023, 2022 16-824: Visual Learning and Recognition. Spring 2025 16-825: Learning for 3D Vision. Spring 2025, 2024, 2023, 2022 Publications (all | selected) 2025 [New] DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion Qitao Zhao, Amy Lin, Jeff Tan, Jason Y. Zhang, Deva Ramanan, Shubham Tulsiani CVPR, 2025 pdf project page bibtex code @inproceedings{zhao2025diffusionsfm, title={DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion}, author={Qitao Zhao and Amy Lin and Jeff Tan and Jason Y. Zhang and Deva Ramanan and Shubham Tulsiani}, booktitle={CVPR}, year={2025} } [New] UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation Himangi Mittal, Peiye Zhuang, Hsin-Ying Lee, Shubham Tulsiani CVPR, 2025 pdf project page bibtex code @inproceedings{mittal2025uniphy, title={UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation}, author={Mittal, Himangi and Zhuang, Peiye and Lee, Hsin-Ying and Tulsiani, Shubham}, booktitle={CVPR}, year={2025} } [New] AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis Khiem Vuong, Anurag Ghosh, Deva Ramanan*, Srinivasa Narasimhan*, Shubham Tulsiani* CVPR, 2025 pdf project page bibtex code @inproceedings{vuong2025aerialmegadepth, title={AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis}, author={Vuong, Khiem and Ghosh, Anurag and Ramanan, Deva and Narasimhan, Srinivasa and Tulsiani, Shubham}, booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, year={2025}, } [New] Turbo3D: Ultra-fast Text-to-3D Generation Hanzhe Hu, Tianwei Yin, Fujun Luan, Yiwei Hu, Hao Tan, Zexiang Xu, Sai Bi, Shubham Tulsiani*, Kai Zhang* CVPR, 2025 pdf project page bibtex @inproceedings{huturbo3d, title={Turbo3D: Ultra-fast Text-to-3D Generation}, author={Hanzhe Hu and Tianwei Yin and Fujun Luan and Yiwei Hu and Hao Tan and Zexiang Xu and Sai Bi and Shubham Tulsiani and Kai Zhang}, booktitle={CVPR}, year={2025} } [New] SceneFactor: Factored Latent 3D Diffusion for Controllable 3D Scene Generation Alexey Bokhovkin, Quan Meng, Shubham Tulsiani, Angela Dai CVPR, 2025 pdf project page bibtex code @inproceedings{bokhovkin2025scenefactor, title={SceneFactor: Factored Latent 3D Diffusion for Controllable 3D Scene Generation}, author={Bokhovkin, Alexey and Meng, Quan and Tulsiani, Shubham and Dai, Angela}, booktitle={CVPR}, year={2025} } [New] MaterialFusion: Enhancing Inverse Rendering with Material Diffusion Priors Yehonathan Litman, Or Patashnik, Kangle Deng, Aviral Agrawal, Rushikesh Zawar, Fernando De la Torre, Shubham Tulsiani 3DV, 2025 pdf project page bibtex code @inproceedings{litman2025materialfusion, author = {Yehonathan Litman and Or Patashnik and Kangle Deng and Aviral Agrawal and Rushikesh Zawar and Fernando De la Torre and Shubham Tulsiani}, title = {MaterialFusion: Enhancing Inverse Rendering with Material Diffusion Priors}, booktitle = {3DV}, year = {2025} } [New] DressRecon: Freeform 4D Human Reconstruction from Monocular Video Jeff Tan, Donglai Xiang, Shubham Tulsiani, Deva Ramanan, Gengshan Yang 3DV, 2025 pdf project page bibtex code @inproceedings{tan2024dressrecon, title={DressRecon: Freeform 4D Human Reconstruction from Monocular Video}, author={Tan, Jeff and Xiang, Donglai and Tulsiani, Shubham and Ramanan, Deva and Yang, Gengshan}, booktitle = {3DV}, year = {2025} } 2024 Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis Qitao Zhao, Shubham Tulsiani NeurIPS, 2024 pdf project page bibtex code @inproceedings{bharadhwaj2024track2act, author = {Homanga Bharadhwaj and Roozbeh Mottaghi and Abhinav Gupta and Shubham Tulsiani}, title = {Track2Act: Predicting Point Tracks from Internet Videos enables Diverse Zero-shot Robot Manipulation}, booktitle={European Conference on Computer Vision (ECCV)}, year = {2024} } Track2Act: Predicting Point Tracks from Internet Videos Enables Diverse Zero-shot Manipulation Homanga Bharadhwaj, Roozbeh Mottaghi*, Abhinav Gupta*, Shubham Tulsiani* ECCV, 2024 pdf project page bibtex code @inproceedings{bharadhwaj2024track2act, author = {Homanga Bharadhwaj and Roozbeh Mottaghi and Abhinav Gupta and Shubham Tulsiani}, title = {Track2Act: Predicting Point Tracks from Internet Videos enables Diverse Zero-shot Robot Manipulation}, booktitle={European Conference on Computer Vision (ECCV)}, year = {2024} } UpFusion: Novel View Diffusion from Unposed Sparse View Observations Bharath Raj Nagoor Kani, Hsin-Ying Lee, Sergey Tulyakov, Shubham Tulsiani ECCV, 2024 pdf project page bibtex code @inproceedings{kani24upfusion, author = {Nagoor Kani, Bharath Raj and Lee, Hsin-Ying and Tulyakov, Sergey and Tulsiani, Shubham}, title = {UpFusion: Novel View Diffusion from Unposed Sparse View Observations}, booktitle={European Conference on Computer Vision (ECCV)}, year = {2024} } G-HOP: Generative Hand-Object Prior for Interaction Reconstruction and Grasp Synthesis Yufei Ye, Abhinav Gupta, Kris Kitani, Shubham Tulsiani CVPR, 2024 pdf project page bibtex code @inproceedings{ye2024ghop, author = {Ye, Yufei and Gupta, Abhinav and Kitani, Kris and Tulsiani, Shubham} title = {G-HOP: Generative Hand-Object Prior for Interaction Reconstruction and Grasp Synthesis}, booktitle={CVPR}, year={2024} } MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation Hanzhe Hu*, Zhizhuo Zhou*, Varun Jampani, Shubham Tulsiani CVPR, 2024 pdf project page bibtex code @inproceedings{hu2024mvdfusion, title={MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation}, author={Hanzhe Hu and Zhizhuo Zhou and Varun Jampani and Shubham Tulsiani}, booktitle={CVPR}, year={2024} } Cameras as Rays: Pose Estimation via Ray Diffusion Jason Y. Zhang*, Amy Lin*, Moneish Kumar, Tzu-Hsuan Yang, Deva Ramanan, Shubham Tulsiani ICLR, 2024 pdf project page bibtex code @InProceedings{zhang2024raydiffusion, title={Cameras as Rays: Pose Estimation via Ray Diffusion}, author={Zhang, Jason Y and Lin, Amy and Kumar, Moneish and Yang, Tzu-Hsuan and Ramanan, Deva and Tulsiani, Shubham}, booktitle={International Conference on Learning Representations (ICLR)}, year={2024} } Towards Generalizable Zero-Shot Manipulation via Translating Human Interaction Plans Homanga Bharadhwaj, Abhinav Gupta*, Vikash Kumar*, Shubham Tulsiani* ICRA, 2024 (Finalist for Best Paper Award in Robot Manipulation) pdf project page bibtex @article{bharadhwaj2023towards, title={Towards Generalizable Zero-Shot Manipulation via Translating Human Interaction Plans},",
  "content_length": 30211,
  "method": "requests",
  "crawl_time": "2025-12-01 14:27:57"
}