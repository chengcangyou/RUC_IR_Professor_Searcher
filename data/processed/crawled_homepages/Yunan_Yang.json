{
  "name": "Yunan Yang",
  "homepage": "https://yunany.github.io",
  "status": "success",
  "content": "Yunan Yang | Cornell University GOOGLE SCHOLAR HOME RESEARCH PUBLICATION TEACHING MENTORSHIP NEWS YUNAN YANG ETH Zurich / Alessandro Della Bella I am a tenure-track Goenka Family Assistant Professor at the Department of Mathematics, Cornell University. I obtained my Ph.D. in 2018 from the Department of Mathematics, UT Austin, supervised by Prof. Björn Engquist. I was a Courant Instructor at Courant Institute of Mathematical Sciences, NYU, from 09/2018 to 08/2021, and a Simons-Berkeley Research Fellow at Simons Institute for the Theory of Computing in Fall 2021. I was an Advanced Fellow at the Institute for Theoretical Studies, ETH Zürich from 01/2022 to 06/2023. I am interested in Inverse Problems, Numerical Analysis, Nonconvex Optimization, Optimal Transport, and Machine Learning. Here is my Curriculum Vitae. Contact Information Office: Malott Hall 582, Tower Rd, Ithaca, NY 14853, USA Email: yunan.yang@cornell.edu Please do not hesitate to contact me if our paths may cross. RESEARCH is formalized curiosity. It is poking and prying with a purpose. — Zora Neale Hurston Extensions and Applications of Optimal Transport The optimal mass transport problem seeks the most efficient way of transforming one mass distribution to the other relative to a given cost function. It was first brought up by Monge in 1781 and later expanded by Kantorovich. The topic of optimal transportation has been a prominent subject of study for several decades, owing to the sound theoretical foundation established over the past two centuries through mathematical analysis. One of my main research interests is exploring the potential of optimal transport in Applied Mathematics. My PhD thesis work was on this topic. Here is a list of my work focusing on the application and extension on the topic of optimal transportation, especially on seismic inversion, e.g., Full-Waveform Inversion (FWI): Botvinick-Greenhouse, J., Yang, Y., Maulik, R., 2023. Generative Modeling of Time-Dependent Densities via Optimal Transport and Projection Pursuit. Chaos 33 (10): 103108. [pdf] Han, R., Slepčev, D., Yang, Y., 2023. HV Geometry for Signal Comparison. To Appear in Quarterly of Applied Mathematics. [pdf] Yang, Y., Nurbekyan, L., Negrini, E., Martin, R. and Pasha, M., 2023. Optimal transport for parameter identification of chaotic dynamics via invariant measures. SIAM Journal on Applied Dynamical Systems, 22(1):269–310, 2023. [pdf] Frederick, C. and Yang, Y., 2022. Snapshots of modern mathematics from Oberwolfach, Mathematisches Forschungsinstitut Oberwolfach, 2022-04. [pdf] Engquist, B. and Yang, Y., 2022. Optimal Transport Based Seismic Inversion: Beyond Cycle Skipping. Communications on Pure and Applied Mathematics. [pdf] Dunlop, M. and Yang, Y., 2021. Stability of Gibbs Posteriors from the Wasserstein Loss for Bayesian Full Waveform Inversion. SIAM/ASA Journal on Uncertainty Quantification, 9(4), pp.1499-1526. [pdf] Engquist, B., Ren, K. and Yang, Y., 2020. The quadratic Wasserstein metric for inverse data matching. Inverse Problems, 36(5), p.055001. [pdf] Engquist, B. and Yang, Y., 2019. Seismic imaging and optimal transport. Communications in Information and Systems, Vol. 19, No. 2 (2019), pp. 95-145 [pdf] Engquist, B. and Yang, Y., 2019. Seismic inversion and the data normalization for optimal transport. Methods and Applications of Analysis, Vol. 26, No. 2 (2019), pp. 133-148. [pdf] Yang, Y. and Engquist, B., 2018. Analysis of optimal transport and related misfit functions in full-waveform inversion. Geophysics, 83(1), pp.A7-A12. [pdf] Yang, Y., Engquist, B., Sun, J. and Hamfeldt, B.F., 2018. Application of optimal transport and the quadratic Wasserstein metric to full-waveform inversion. Geophysics, 83(1), pp.R43-R62. [pdf] Engquist, B., Froese, B.D. and Yang, Y., 2016. Optimal transport for seismic full waveform inversion. Communications in Mathematical Science, 14(8):2309-2330, 2016. [pdf] Inverse Problems Studying Inverse Problems is like solving a puzzle. You are given a partial clue about the ground truth (i.e., data and model), and you must figure out the answer following the clue. Sometimes, we are concerned about whether it is solvable or not (i.e., the problem's ill-/well-posedness). Sometimes, we are interested in developing a way to find the solution (computational inverse problem). Different inverse problems exhibit totally different properties, making the entire subject extremely fun to study! Here is a list of my related work on Inverse Problems (minus those solved using Optimal Transport): Einkemmer, L., Li, Q., Wang, L. and Yang, Y., 2023. Suppressing Instability in a Vlasov-Poisson System by an External Electric Field Through Constrained Optimization. Journal of Computational Physics, 498, p.112662. [pdf] Li, Q., Wang, L. and Yang, Y., 2023. Differential-Equation Constrained Optimization With Stochasticity. submitted; arXiv preprint arXiv:2305.04024. [pdf] Mahankali, S. and Yang, Y., 2023. Norm-dependent convergence and stability of the inverse scattering series for diffuse and scalar waves. Inverse Problems, 39(5), p.054005. [pdf] Zhu, B., Hu, J., Lou, Y. and Yang, Y., 2023. Implicit Regularization Effects of the Sobolev Norms in Image Processing. La Matematica (2023). [pdf] Optimization Algorithms Many challenging inverse problems, optimal control, and optimal design tasks are eventually translated into optimization problems to be solved on the computer. Most of them are nonlinear, and the resulting optimization problems suffer from severe nonconvexity, for example, PDE-constrained optimization problems and machine learning training. My interests in designing optimization algorithms originated from dealing with these challenges. The main ideas are to design algorithms (1) for global optimization (i.e., the iterates converge to the global minimizer), (2) for faster convergence with the minimal computational cost, and (3) to incorporate the special property of forward model (e.g., the modeling PDE, or specific NN architecture) into the choice of optimization algorithms. Here is a list of my related work: Engquist, B., Ren, K. and Yang, Y., 2024. Adaptive State-Dependent Diffusion for Derivative-Free Optimization. Commun. Appl. Math. Comput. (2024). [pdf] Engquist, B., Ren, K. and Yang, Y., 2022. An Algebraically Converging Stochastic Gradient Descent Algorithm for Global Optimization. submitted; arXiv preprint arXiv:2204.05923. [pdf] Nurbekyan, L., Lei, W. and Yang, Y., 2023. Efficient Natural Gradient Descent Methods for Large-Scale PDE-Based Optimization Problems. SIAM Journal on Scientific Computing, 45(4), pp.A1621-A1655. [pdf] Scientific Machine Learning Machine Learning has immense potential and is a crucial subject in today's world. There are many similarities between Machine Learning concepts and other areas of Applied Mathematics, and understanding these connections is key to a comprehensive understanding of Machine Learning. Additionally, Machine Learning can be utilized to tackle persistent challenges in various domains of Applied Mathematics. Here is a list of my related work on understanding and utilizing Machine Learning: Wu C., Song R., Liu C., Yang, Y., Li, A., Huang, M. Geng T., 2024. NP-GL: Extending Power of Nature from Binary Problems to Real-World Graph Learning. To appear in The 12th International Conference on Learning Representations (ICLR) 2024. Liu, Z., Yang, Y., Pan, Z., Sharma A., Hasan, A., Ding, C., Li A., Huang, M., and Geng, T., 2023. Ising-CF: A Pathbreaking Collaborative Filtering Method Through Efficient Ising Machine Learning. The 60th Design Automation Conference (DAC). [pdf] Molinaro, R., Yang, Y., Engquist, B. and Mishra, S., 2023. Neural Inverse Operators for Solving PDE Inverse Problems. Proceedings of the 40th International Conference on Machine Learning, PMLR 202:25105-25139, 2023. [pdf] Yu, A.,Yang, Y. and Townsend, A., 2023. Tuning Frequency Bias in Neural Network Training with Nonuniform Data. The 11th International Conference on Learning Representations (ICLR) 2023. [pdf] Engquist, B., Ren, K. and Yang, Y., 2022. A Generalized Weighted Optimization Method for Computational Learning and Inversion. The 10th International Conference on Learning Representations (ICLR) 2022. [pdf] Adjoint Monte Carlo Methods and Optimization In a sequence of works, I investigate how to mathematically \"differentiate\" a Monte Carlo method, which is random in nature, with respect to parameters of interest. In particular, I studied such Monte Carlo methods designed to solve certain Partial Differential Equations (PDEs), including the Radiative Transport Equation (RTE) and the Boltzmann Equation. Here is a list of my related work: Caflisch, R., and Yang, Y., 2024. Adjoint DSMC for nonlinear Boltzmann equation constrained optimization. submitted; arXiv preprint arXiv:2401.08361. [pdf] Li, Q., Wang, L., and Yang, Y., 2022. Monte Carlo Gradient in Optimization Constrained by Radiative Transport Equation. SIAM Journal on Numerical Analysis, 61(6), pp.2744-2774.[pdf] Yang, Y., Silantyev, D. and Caflisch, R., 2023. Adjoint DSMC for Nonlinear Spatially-Homogeneous Boltzmann Equation With a General Collision Model. Journal of Computational Physics, p.112247. [pdf] Caflisch, R., Silantyev, D. and Yang, Y., 2021. Adjoint DSMC for nonlinear Boltzmann equation constrained optimization. Journal of Computational Physics, 439, p.110404. [pdf] Dynamical System Working with dynamical systems is always a humbling experience as the complexity of the trajectory behavior is so rich and case-dependent. However, there are many aspects to explore, especially from a data-driven perspective. Here is list of my related work on data-driven approaches for learning dynamical systems: Botvinick-Greenhouse, J., Yang, Y., Maulik, R., 2023. Generative Modeling of Time-Dependent Densities via Optimal Transport and Projection Pursuit. Chaos 33 (10): 103108. [pdf] Botvinick-Greenhouse, J., Martin, R. and Yang, Y., 2023. Learning dynamics on invariant m",
  "content_length": 20286,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:52"
}