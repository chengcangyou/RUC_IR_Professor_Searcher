{
  "name": "Yuanyuan Shi",
  "homepage": "https://yyshi.eng.ucsd.edu",
  "status": "success",
  "content": "Yuanyuan ShiSearch this siteEmbedded FilesSkip to main contentSkip to navigation    [Google Scholar] | [LinkedIn] | [Email]Office hour for FA'25: 11am - noon, @FAH 0009 or by appointmentsBiographyYuanyuan Shi is an Assistant Professor at UC San Diego department of Electrical and Computer Engineering, with affiliations at the Center for Energy Research and the MICS. She received her Ph.D. in Electrical and Computer Engineering from the University of Washington in 2020, advised by Prof. Baosen Zhang, and was a Postdoctoral Fellow in the Computing and Mathematical Sciences Department at Caltech, working with Prof. Adam Wierman and Prof. Anima Anandkumar.Her research interests lie primarily in machine learning and control, with applications in power and energy systems, and broader intelligent systems. Her group develops theory and algorithms that integrate learning with control-theoretic guarantees, enabling reliable decision-making in complex dynamical systems. She is a recipient of the Anastasio LANL-UC Early Career Faculty Fellowship, NSF CAREER Award, Schmidt Sciences AI2050 Early Career Fellowship, and Hellman Fellowship.For more details, see Curriculum Vitae.Prospective StudentsPhD Applicants: We plan to recruit 1–2 Ph.D. students to join our group starting Fall 2026. We are looking for applicants with solid math backgrounds and programming skills, and are excited about research in machine learning and control for energy and/or robotics applications. Please apply through the UCSD ECE PhD program (Intelligent Systems Robotics and Control (EC80) or Machine Learning and Data Science (EC93) tracks) (Application Deadline: 2025/12/17). Current UCSD graduate and undergraduate students: If you are currently at UCSD, please first fill out the Application Form and send me an email with your resume and UCSD transcript once you filled out the application.News2025/11: Our project explores mobile battery systems for construction EV charging and grid resilience is on UCSD News.2025/10: Honored to receive the Michael R. Anastasio LANL-UC Early Career Faculty Fellowship to collaborate with Los Alamos National Laboratory.2025/09: Checkout recent journal papers from our group: IEEE Transactions on Smart Grids: Stability-constrained RL for Voltage Control under Arbitrary Communication InfrastructureIEEE Transactions on Energy Markets, Policy and Regulation: Improving Sequential Market Coordination via Value-oriented Renewable Energy Forecasting2025/07:  Honored to receive the NSF CAREER award!2025/06:  L4DC 2025 Neural Operators for Predictor Feedback Control of Nonlinear Delay Systems (⭐️Best Paper Finalist)2025/05:  ICML 2025 Analytical Lyapunov Function Discovery via Reinforcement LearningGuest co-editor for Applied Energy Special Issue on the topic of “Trustworthy Machine Learning for Power and Energy Systems”. Submissions are open until Nov. 30, 2025. Learn more and submit your work hereNews Archive2025/03: ICLR 2025 Planning Neural Operator (PNO)2025/02: Checkout recent papers from our group: IEEE Transactions on Power Systems: Stability-constrained RL for Frequency Control under Time-varying InertiaApplied Energy: PDE-based Building Airflow Modeling and Control2025/01: Honored to receive the AI2050 Early Career Fellowship from Schmidt Sciences!2024/12: Paper on value-oriented renewable energy forecasting to appear in IEEE Transactions on Smart Grid.2024/09: Awarded DOE neural operator learning and scientific foundation model project. Check out our project website!2024/07: New paper on PDE based models for building airflow modeling and control in Applied Energy.2024/05: New paper paper on neural operator learning for PDE system control in IEEE Transactions on Automatic Control.2024/01: Honored to receive the Jacobs School Early-Career Faculty Acceleration Award for our collaborative work with Prof. Jingbo Shang on building learning and control for health and sustainability.2023/12: Our lab and collaborators presented two papers at NeurIPS 2023!Neural-PI Control with End-to-End Stability and Output Tracking Guarantees (We design a multi-input multi-output monotone neural network structure that guarantee stability of multi-agent RL in networked systems with passivity. The monotone neural network design can flexibly handle different communication structures: decentralized, distributed, and centralized!)SustainGym: Reinforcement Learning Environments for Sustainability Applications (A suite of Gym environments designed to test Multi-agent RL algorithms on sustainability tasks, including EVChargingEnv, ElectricityMarketEnv, DatacenterEnv, CogenEnv, BuildingEnv, with real-world data)2023/12: Our lab and collaborators presented five papers at IEEE CDC 2023!Neural Operators for Hyperbolic PDE Backstepping Feedback LawsNeural Operators for Hyperbolic PDE Backstepping KernelsLeveraging Predictions in Power System Frequency Control: an Adaptive ApproachKCRL: Krasovskii-Constrained Reinforcement Learning with Guaranteed Stability in Nonlinear Discrete-Time SystemsBridging Transient and Steady-State Performance in Voltage Control: A Reinforcement Learning Approach With Safe Gradient Flow2023/10:  Our paper on \"Optimal Vehicle Charging in Bilevel Power-Traffic Networks via Charging Demand Function\" is accepted for publication in the IEEE Transactions on Smart Grid. The paper investigate the coordination of large-scale EV charging by considering both the transportation and power network physical constraints, via a novel design of EV charging demand function. Congrats Yufan! 2023/08: We released a new real-world multi-zone building dataset BEAR-Data (1 building, 80+ zones with detailed zonal temperature and 17 control commands data about 8 months) for smart building research. The accompanied paper is accepted to ACM BuildSys 2023.2023/08: Our paper Predicting Strategic Energy Storage Behaviors is accepted for publication in the IEEE Transactions on Smart Grid. Congrats Yuexin!2023/09: Invited speaker at the CDC 2023 Physics-informed Learning for Control and Optimization This workshop aims to provide insight into recent advances in the field of physics-informed machine learning for control and optimization. Please consider joining the workshop on December 12th, 2023 @CDC 2023, Singapore.2023/09: Invited speaker at the Sixth AES Workshop  organized by the National Renewable Energy Laboratory (NREL). I presented our recent line of work on stability-constrained RL for voltage control. Check out the presentation slides here.2023/07: Our paper on Bridging Transient and Steady-State Performance in Voltage Control: A Reinforcement Learning Approach With Safe Gradient Flow is accepted for publication in the IEEE Control Systems Letters and will also be presented at IEEE CDC 2023. Congrats Jie!2023/07: Yufan presented our work on Combining Data and Physics Knowledge for Demand Response Forecast in Energy Systems at the 2023 IEEE Power and Energy System General Meeting!2023/06: Our paper on Operator Learning for Nonlinear Adaptive Control is accepted and presented at the L4DC 2023. Congrats Luke! Check out our project website.2023/05: Invited speaker at the ACC 2023 Workshop on Physics-Informed System Identification2023/05: Invited speaker at the AFOSR Workshop on Intersection of Deep Learning and Computational Nonlinear Control2023/05: Honored to receive the Hellman Fellowship 2023/04: Invited speaker at the UCSD Control Systems & Dynamics Seminar. 2023/02: Invited speaker at ITA 2023 session in machine learning and control.2023/01: Honored to receive the Jacobs School Early Career Faculty Development Award for our collaborative work with Prof. Patricia Hidalgo-Gonzalez on reinforcement learning for microgrid controlI co-organized the Control Meets Learning online seminar series in 2020 - 2021. This repo contains many interesting talks on the intersection of control and learning and future outlooks. Please check out this website for the recordings.2022/10: Invited talks at Allerton 2022 and INFORMS 2022 about \"Stability Constrained Reinforcement Learning for Real-Time Voltage Control\" Check out our slides here2022/10: Invited talk at the Pacific Northwest National Laboratory about Learning and Control for Sustainable Energy Systems.2022/06: Our work on \"Demand Response Model Identification and Behavior Forecast with OptNet: a Gradient-based Approach\" at the ACM International Conference on Future Energy Systems (ACM e-Energy) conference.2022/06: Our paper Robust online voltage control with an unknown grid topology is presented at the ACM International Conference on Future Energy Systems (ACM e-Energy) and selected as Best Paper Finalist.Research Projects Highlight:Reinforcement Learning (RL) for Power Grid Control with Stability Guarantees: We design RL algorithms with transient stability and steady-state optimality guarantees, for distribution grid voltage control and transmission grid frequency control under uncertainties. [Read more→]Stability constrained reinforcement learning for decentralized real-time voltage control, Jie Feng, Yuanyuan Shi, Guannan Qu, Steven H Low, Anima Anandkumar, Adam Wierman, IEEE Transactions on Control of Network Systems, 2024. [Paper] [Code]Online event-triggered switching for frequency control in power grids with variable inertia, Jie Feng, Wenqi Cui, Jorge Cortés, Yuanyuan Shi, IEEE Transactions on Power Systems, 2025. [Paper] [Code]Neural Operator Learning for Control: We develop novel neural operator learning methods for control of PDE-governed systems, delay systems, and robot motion planning, which can accelerate classic controller designs by 10-1000x while maintaining critical stability and (sub-)optimality guarantees. [Read more→]Neural operators for predictor feedback control of nonlinear delay systems, Luke Bhan, Peijia Qin, Miroslav Krstic, Yuanyuan Shi, Annual Conference on Learning for Dynamics and Control (L4DC), 2025. (Best Paper Finalist) [Paper] [Code]Neural operators for bypassing gain and control",
  "content_length": 11030,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:22"
}