{
  "name": "Miroslaw Z. Bober",
  "homepage": "https://www.surrey.ac.uk/people/miroslaw-bober",
  "status": "success",
  "content": "Prof Miroslaw Bober | University of Surrey This website uses cookiesSome of these cookies are necessary and are used to help make our site work. With your consent, we will also use cookies to improve your experience, analyse site usage and assist in our marketing efforts. By clicking 'Accept all', you consent to our use of cookies.You can learn more about these cookies and manage your preferences at any time on our cookies page .Necessary Necessary These cookies enable essential website functions and ensure the site operates properly. They do not store personally identifiable information. While you can disable them in your browser settings, some features may not function correctly.Analytics Analytics These cookies help us understand how visitors interact with our website by collecting anonymous usage data. We use this information to improve website performance and enhance your experience.Personalisation Personalisation These cookies allow us to customise the content you see based on your activity, such as the courses you view, applications you make, or your location. This helps us provide a more relevant and tailored experience when using our site.Marketing Marketing These cookies deliver personalised ads based on your browsing activity and help us measure the effectiveness of our advertising campaigns. Accept all Manage preferences Save preferences Reject all Professor Miroslaw Bober Professor of Video Processing BSc, MSc, PhD, MIEEE +44 (0)1483 684724 m.bober@surrey.ac.uk29 BA 00Academic and research departments Centre for Vision, Speech and Signal Processing (CVSSP), School of Computer Science and Electronic Engineering. AboutBiographyMiroslaw Bober joined Surrey in 2011 as Professor of Video Processing. He is leading the Visual Media Analysis team within the Centre for Vision, Speech and Signal Processing (CVSSP).Prior to his appointment at Surrey Prof Bober was the General Manager of the Mitsubishi Electric R&D Centre Europe (MERCE-UK), and the Head of Research for its Visual & Sensing Division. He was leading this European Corporate R&D centre for 15 years. His technical achievements were recognized in numerous awards, including the Presidential Award for strengthening the TV business in Japan via an innovative “Visual Navigation” content access technology (2010) and the prestigious Mitsubishi Best Invention Award for his Image Signature Technology (2008-one winner selected globally).Prof Bober received a BSc and an MSc degree with distinction in electrical engineering from the AGH University of Science and Technology (Krakow, Poland) (1990), an MSc degree in Machine Intelligence (with distinction) from Surrey University (1991), and a PhD degree in computer vision from Surrey University (1995).Miroslaw has published over 60 peer-reviewed publications and is the named inventor on over 80 unique patent applications. He has held over 30 research and industrial grants, with the value exceeding £16M. He is a member of the British Standards Institution (BSI) committee IST/37, responsible for UK contributions into MPEG and JPEG and represents UK in the area of image and video analysis and associated metadata. Prof Bober is chairing MPEG technical work on Compact Descriptors for Visual Search (CDVS - standard ISO/IEC FDIS 15938-13) and Compact Descriptors for Video Analysis (CDVA - work in progress). Expand biography University roles and responsibilities Programme Director for MSc in Multimedia Signal Processing and Communications Industrial tutor for undergraduate industrial placement year Personal tutor for undergraduate students (L1, L2, L3, L4) MSc-level tutor Member of Faculty Research Degrees Committee (FRDC) Member of the Departmental Industrial Advisory Board (IAB)AffiliationsI have extensive collaboration links with universities and research institutions in Europe (UK, Switzerland, Germany, Poland, France, Spain), US, Japan and China.I have also worked with the following companies: the BBC (UK), Bang and Olufsen (DE), CEDEO (IT), Casio (JP), Ericsson (SE), Huawei (DE), Mitsubishi Electric (JP), RAI television (IT), Renesas Electronics (JP), Telecom Italia (IT), and Visual Atoms (UK). Expand about tab additional information News 13 FEB 2025Artificial intelligence system reshaping the UK's war against knife crime 10 MAY 2023AI developed in the UK is the world leader in identifying the location and expression of proteins 28 FEB 2019Surrey introduces world’s first AI-powered travel guide 09 OCT 2018Presenting the a-book Show all articlesResearchResearch interestsMy research focuses on novel techniques in signal processing, computer vision and machine learning and their applications in industry, healthcare, big-data and security.I have a particular interest in image and video analysis and retrieval (visual search, object recognition, analysis of motion, shape and texture). The broad research objective is to develop unique methods and technology solutions for visual content understanding that can dramatically improve on existing state-of-the art leading to new applications.My algorithms for shape analysis and image/video fingerprinting as well as visual search are considered world-leading and were selected for ISO International standards within MPEG and used by, e.g. Metropolitan Police. Expand research interests Research projectsI am the project coordinator and PI for the BRIDGET FP-7 project [5.28 M€], where my team is responsible for the development of ultra large-scale visual search and media analysis algorithms for the broadcast industry. The project aims to open new dimensions for multimedia content creation and consumption by bridging the gap between the Broadcast and Internet. Project partners include RAI television, Huawei, Telecom Italia and more.CODAM is my latest project (PI) and is funded by the TSB creative media call [£1.05 M]. My team is working with the BBC and Visual Atoms to develop an advanced video asset management system with unique visual fingerprinting and visual search capabilities. It will aid content creation and deployment by enabling visual content tracking, identification and searching across multiple devices and platforms, and across diverse digital media ecosystems and markets. Where is the original version of the low-quality clip? Which video clip has been used most often in BBC programmes? Is it a stock shot of a red double decker bus, or an excerpt from a royal wedding? Is there other footage in the archive that shows the same event but can provide a fresh viewpoint? The CODAM system will answer these questions, track the origins of video clips across multi-platform productions and search for related material. It will take the form of a modular software system that can identify individual video clips in edited programmes, and perform object or scene recognition to find similar footage in an archive without relying on manually entered and often incomplete metadata. Expand research projects TeachingEEE3034 - Media Casting (Module Coordinator)EEE3029 - Multimedia Systems and Component TechnologyEEEM001 - Image and Video CompressionEEE3035 - Engineering Professional Studies. Expand my teaching PublicationsEMILY MARY CORRIGAN-KAVANAGH, DAVID MARK FROHLICH, HAIYUE YUAN, MIROSLAW Z BOBER (2021)Designing for the Next Generation of Augmented Books, In: Journal of design research : JDR18(Nos. 5/6)pp. 356-374 InderscienceDOI: 10.1504/JDR.2020.118675This paper presents an advanced process for designing “a-books”; augmented printed books with multimedia links presented on a nearby device. Although augmented paper is not new, our solution facilitates mass market use through industry standard publishing software that generates the a-book, and regular smartphones that play related digital media by optically recognising its ordinary paper pages through the phone’s built-in camera. This augmented paper strategy informs new classifications of digital content within publication design, enabling new immersive reading possibilities. Complementary affordances of print and digital, and how these are combined and harnessed by a-books in comparison to previous augmented paper concepts are first discussed. Subsequently, an explanation of the workflow for designing a-books is described. The final discussion includes implications for content creators of paper-based publishing, and future research plans.David M. Frohlich, Haiyue Yuan, Emily Corrigan-Kavanagh, Elisa Mameli, Caroline Scarles, Radu Sporea, George Revill, Alan W. Brown, Miroslaw Bober (2024)A Market-Ready Ecosystem for Publishing and Reading Augmented Books, In: J Wei, G Margetis (eds.), HUMAN-CENTERED DESIGN, OPERATION AND EVALUATION OF MOBILE COMMUNICATIONS, PT II, MOBILE 202414738pp. 58-75 Springer NatureDOI: 10.1007/978-3-031-60487-4_5Many studies show the possibilities and benefits of combining physical and digital information through augmented paper. Furthermore, the rise of Augmented Reality hardware and software for annotating the physical world with information is becoming more commonplace as a new computing paradigm. But so far, this has not been commercially applied to paper in a way that publishers can control. In fact, there is currently no standard way for book publishers to augment their printed products with digital media, short of using QR codes or creating custom AR apps. In this paper we outline a new publishing ecosystem for the creation and consumption of augmented books, and report the lab and field evaluation of a first commercial travel guide to use this. This is based simply on the use of the standard EPUB3 format for interactive e-books that forms the basis of a new 'a-book' file format and app.MZ Bober, WJ Szajnowski (2017)Determining statistical descriptors of a signal from a set of its samplesAn entity is subjected to an interrogating signal, and the reflection from the entity is repeatedly sampled to obtain a first set of values each dependent on the intensity of the reflected signal. A logarithmic transformati",
  "content_length": 84743,
  "method": "requests",
  "crawl_time": "2025-12-01 14:00:43"
}