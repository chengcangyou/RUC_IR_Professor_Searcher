{
  "name": "Thomas Hain",
  "homepage": "https://www.sheffield.ac.uk/dcs/people/academic/thomas-hain",
  "status": "success",
  "content": "Professor Thomas Hain | Computer Science | The University of Sheffield Skip to main content Search sheffield.ac.uk Close menu × School of Computer Science School of Computer Science Menu Professor Thomas Hain School of Computer Science Professor of Speech and Audio Technology Director of CDT in Speech and Language Technologies Director of Liveperson Centre Member of the Speech and Hearing (SpandH) research group Open staff member portrait in a modal window t.hain@sheffield.ac.uk Regent Court (DCS) Full contact details Professor Thomas Hain School of Computer Science Regent Court (DCS) 211 Portobello Sheffield S1 4DP Orcid ID:0000-0003-0939-3464 Google Scholar Personal website Profile Thomas Hain obtained the degree 'Dipl.-Ing' in Electrical/Communication Engineering in 1994 from the University of Technology, Vienna. He joined the Speech Technology Group at Philips Speech Processing which he left in a senior position.In 1997 he joined the Speech, Vision and Robotics Group at the Cambridge University Engineering Department as Research Associate and PhD Student. He took up a Lectureship at the SVR group in 2001.In 2004 he joined the Speech and Hearing Group to work as Lecturer in Computer Science. He was promoted to Senior Lecturer in 2008 and Reader in 2011. Research interests Thomas' research interests cover many areas in natural language processing, speech, audio and multimedia technology, machine learning, and complex system optimisation and design.His interests include: large vocabulary continuous speech recognition, non-linear methods in speech processing, low bit-rate speech coding, machine learning, multi-modal systems, image classification, microphone arrays, system and resource optimisation. Publications Books Young SJ, Evermann G, Gales MJF, Hain T, Kershaw D, Moore GL, Odell JJ, Ollason D, Povey D, Valtchev V & Woodland PC (2004) The HTK Book. Cambridge, England: Cambridge University Engineering Department. Young S, Evermann G, Gales M, Hain T, Kershaw D, Xunying L, Moore G, Odell J, Ollason D, Povey D , Ragni A et al () The HTK Book (for HTK Version 3.5, documentation alpha version). Cambridge University Engineering Department: Cambridge University Engineering Department. Journal articles Farooq MU & Hain T (2025) Enhancing Low-Resource Speech Recognition With Non-Linear Cross-Lingual Mappings. IEEE Transactions on Audio, Speech and Language Processing, 33, 4653-4666. Song H, Zhang L, Gao M, Zhang H, Hain T & Shan L (2025) MS-EmoBoost: a novel strategy for enhancing self-supervised speech emotion representations. Scientific Reports, 15(1). View this article in WRRO Hasan M, Jefferson N, Hain T & Dawson J (2022) Automatic detection of behavioural codes in team interactions. Computer Speech & Language, 74, 101339-101339. Ravenscroft W, Goetze S & Hain T (2022) Att-TasNet: attending to encodings in time-domain audio speech separation of noisy, reverberant speech mixtures. Frontiers in Signal Processing, 2. View this article in WRRO Shi Y, Huang Q & Hain T (2021) H-VECTORS : improving the robustness in utterance-level speaker embeddings using a hierarchical attention model. Neural Networks, 142, 329-339. View this article in WRRO El Hannani A, Errattahi R, Salmam FZ, Hain T & Ouahmane H (2021) Evaluation of the effectiveness and efficiency of state-of-the-art features and models for automatic speech recognition error detection. Journal of Big Data, 8. Errattahia R, Hannani AEL, Hain T & Ouahmane H (2019) System-independent ASR error detection and classification using Recurrent Neural Network. Computer Speech and Language, 55, 187-199. View this article in WRRO Deena S, Hasan M, Doulaty M, Saz O & Hain T (2019) Recurrent neural network language model adaptation for multi-genre broadcast speech recognition and alignment. IEEE/ACM Transactions on Audio, Speech and Language Processing, 27(3), 572-582. View this article in WRRO Saz Torralba O, Deena S, Doulaty M, Hasan M, Khaliq B, Milner R, Ng RWM, Olcoz J & Hain T (2018) Lightly supervised alignment of subtitles on multi-genre broadcasts. Multimedia Systems, 77(23), 30533-30550. View this article in WRRO Ng W, Nicolao M & Hain T (2017) Unsupervised crosslingual adaptation of tokenisers for spoken language recognition. Computer Speech and Language, 46, 327-342. Saz O & Hain T (2017) Acoustic Adaptation to Dynamic Background Conditions with Asynchronous Transformations. Computer, Speech & Language, 41, 180-194. View this article in WRRO Kamper H, De Wet F, Hain T & Niesler T (2014) Capitalising on North American speech resources for the development of a South African English large vocabulary speech recognition system. Computer Speech and Language, 28(6), 1255-1268. Fox C & Hain T (2013) Lightly supervised learning from a damaged natural speech corpus. ICASSP IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, 8086-8090. Gibson M & Hain T (2012) Application of SVM-based correctness predictions to unsupervised discriminative speaker adaptation. ICASSP IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, 4341-4344. Lecorvé G, Dines J, Hain T & Motlicek P (2012) Supervised and unsupervised Web-based language model domain adaptation. 13th Annual Conference of the International Speech Communication Association 2012 Interspeech 2012, 1, 182-185. Gibson M & Hain T (2012) Correctness-adjusted unsupervised discriminative acoustic model adaptation. IEEE Transactions on Audio, Speech and Language Processing, PP(99). Furui S, Fiscus J, Friedland G & Hain T (2012) Introduction to the Special Section on New Frontiers in Rich Transcription. IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING, 20(2), 353-355. Alharbi G & Hain T (2012) Automatic transcription of academic lectures from diverse disciplines. 2012 IEEE Workshop on Spoken Language Technology Slt 2012 Proceedings, 398-403. ZHOU YAN, GRYGORASH O & HAIN TF (2011) CLUSTERING WITH MINIMUM SPANNING TREES. International Journal on Artificial Intelligence Tools, 20(01), 139-177. Hain T, Burget L, Dines J, Garner PN, Grezl F, el Hannani A, Huijbregts M, Karafiat M, Lincoln M & Wan V (2011) Transcribing meetings with the AMIDA systems. IEEE Transactions on Audio, Speech and Language Processing. El Hannani A & Hain T (2010) Automatic Optimization of Speech Decoder Parameters. IEEE SIGNAL PROC LET, 17(1), 95-98. Gibson M & Hain T (2010) Error approximation and minimum phone error acoustic model estimation. IEEE Transactions on Audio Speech and Language Processing, 18(6), 1269-1279. Karafiát M, Burget L, Hain T & Černocký J (2008) Discrimininative training of narrow band - Wide band adapted systems for meeting recognition. Proceedings of the Annual Conference of the International Speech Communication Association Interspeech, 1217-1220. Hain T, El Hannani A, Wrigley SN & Wan V (2008) Automatic speech recognition for scientific purposes - WebASR. Proceedings of the Annual Conference of the International Speech Communication Association Interspeech, 504-507. Karafiát M, Burget L, Hain T & Černocký J (2008) Discrimininative training of narrow band - Wide band adapted systems for meeting recognition. INTERSPEECH 2008 - 9th Annual Conference of the International Speech Communication Association, 1217-1220. Fife TD, Iverson DJ, Lempert T, Furman JM, Baloh RW, Tusa RJ, Hain TC, Herdman S, Morrow MJ & Gronseth GS (2008) Practice Parameter: Therapies for benign paroxysmal positional vertigo (an evidence-based review): [RETIRED]. Neurology, 70(22), 2067-2074. Karafiát M, Burget L, Černocký J & Hain T (2007) Application of CMLLR in narrow band wide band adapted systems. International Speech Communication Association 8th Annual Conference of the International Speech Communication Association Interspeech 2007, 4, 2860-2863. Renais S, Hain T & Boudard H (2007) Recognition and understanding of meetings the AMI and AMIDA projects. 2007 IEEE Workshop on Automatic Speech Recognition and Understanding Asru 2007 Proceedings, 238-247. Hain T, Burget L, Dines J, Garau G, Wan V, Karafiat M, Vepa J & Lincoln M (2007) The AMI system for the transcription of speech in meetings. ICASSP IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, 4, IV357-IV360. Wan V & Hain T (2006) Strategies for language model web-data collection. ICASSP IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, 1, I1069-I1072. Bauer JJ, Mittal J, Larson CR & Hain TC (2006) Vocal responses to unanticipated perturbations in voice loudness feedback: An automatic mechanism for stabilizing voice amplitude. The Journal of the Acoustical Society of America, 119(4), 2363-2371. Hain T, Woodland PC, Evermann G, Gales MJF, Liu X, Moore GL, Povey D & Wang L (2006) Corrections to \"Automatic Transcription of Conversational Telephone Speech\".. IEEE Trans. Speech Audio Process., 14, 727-727. Hain T, Woodland PC, Evermann G, Gales MJF, Liu XY, Moore GL, Povey D & Wang L (2005) Automatic transcription of conversational telephone speech. IEEE T SPEECH AUDI P, 13(6), 1173-1185. Hain TC & Yacovino D (2005) Pharmacologic Treatment of Persons with Dizziness. Neurologic Clinics, 23(3), 831-853. Gurses S, Dhaher Y, Hain TC & Keshner EA (2005) Perturbation parameters associated with nonlinear responses of the head at small amplitudes. Chaos: An Interdisciplinary Journal of Nonlinear Science, 15(2). Hain T (2005) Implicit modelling of pronunciation variation in automatic speech recognition. SPEECH COMMUNICATION, 46(2), 171-188. Moon IS & Hain TC (2005) Delayed Quick Spins after Vestibular Nerve Section Respond to Anticonvulsant Therapy. Otology & Neurotology, 26(1), 82-85. Yacovino DA & Hain TC (2004) Farmacología de las alteraciones vestibulares. Revista de Neurología, 39(04), 381-381. Xu Y, Larson CR, Bauer JJ & Hain TC (2004) Compensation for pitch-shifted auditory feedback during the production of Mandarin tone sequences. The Journal of the Acoustical Society of America, ",
  "content_length": 85791,
  "method": "requests",
  "crawl_time": "2025-12-01 14:37:38"
}