{
  "name": "Niels da Vitoria Lobo",
  "homepage": "https://www.crcv.ucf.edu/person/niels-lobo",
  "status": "success",
  "content": "Niels da Vitoria Lobo â€“ Center for Research in Computer Vision Skip to main content Associate Professor Department of Computer Science University of Central Florida 4328 Scorpius St. HEC 252 Orlando, FL 32816-2364 Phone: (407) 823-2873 Fax: (407) 823-0594 Email: niels@cs.ucf.edu Biography I received the B. Sc. (Honors) degree in Mathematics and Computer Science from Dalhousie University, Canada, and the Ph.D. in Computer Science from the University of Toronto. My graduate students reside in the Computer Vision Laboratory. Research Interests Publications 2022 Khan, Aisha Urooj; Kuehne, Hilde; Gan, Chuang; Lobo, Niels Da Vitoria; Shah, MubarakWeakly Supervised Grounding for VQA in Vision-Language Transformers Conference European Conference on Computer Vision, 2022.Abstract | BibTeX | Links: @conference{Khan2022, title = {Weakly Supervised Grounding for VQA in Vision-Language Transformers}, author = {Aisha Urooj Khan and Hilde Kuehne and Chuang Gan and Niels Da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2018/11/1011.pdf https://www.crcv.ucf.edu/wp-content/uploads/2018/11/1011-supp.pdf https://github.com/aurooj/WSG-VQA-VLTransformers https://youtu.be/dekmVb6lq3I}, year = {2022}, date = {2022-10-23}, urldate = {2022-10-23}, booktitle = {European Conference on Computer Vision}, abstract = {Transformers for visual-language representation learning have been getting a lot of interest and shown tremendous performance on visual question answering (VQA) and grounding. However, most systems that show good performance of those tasks still rely on pre-trained object detectors during training, which limits their applicability to the object classes available for those detectors. To mitigate this limitation, this paper focuses on the problem of weakly supervised grounding in the context of visual question answering in transformers. Our approach leverages capsules by transforming each visual token into a capsule representation in the visual encoder; it then uses activations from language self-attention layers as a text-guided selection module to mask those capsules before they are forwarded to the next layer. We evaluate our approach on the challenging GQA as well as VQA-HAT dataset for VQA grounding. Our experiments show that: while removing the information of masked objects from standard transformer architectures leads to a significant drop in performance, the integration of capsules significantly improves the grounding ability of such systems and provides new state-of-the-art results compared to other approaches in the field.}, keywords = {}, pubstate = {published}, tppubtype = {conference} } CloseTransformers for visual-language representation learning have been getting a lot of interest and shown tremendous performance on visual question answering (VQA) and grounding. However, most systems that show good performance of those tasks still rely on pre-trained object detectors during training, which limits their applicability to the object classes available for those detectors. To mitigate this limitation, this paper focuses on the problem of weakly supervised grounding in the context of visual question answering in transformers. Our approach leverages capsules by transforming each visual token into a capsule representation in the visual encoder; it then uses activations from language self-attention layers as a text-guided selection module to mask those capsules before they are forwarded to the next layer. We evaluate our approach on the challenging GQA as well as VQA-HAT dataset for VQA grounding. Our experiments show that: while removing the information of masked objects from standard transformer architectures leads to a significant drop in performance, the integration of capsules significantly improves the grounding ability of such systems and provides new state-of-the-art results compared to other approaches in the field.Close2021 Ott, Aaron; Mazaheri, Amir; da Vitoria Lobo, Niels; Shah, MubarakDeep Photo Cropper and Enhancer Journal Article In: CoRR, vol. abs/2008.00634, 2021.BibTeX | Links: @article{Ott2021, title = {Deep Photo Cropper and Enhancer}, author = {Aaron Ott and Amir Mazaheri and Niels da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2020/08/Publications_DEEP-PHOTO-CROPPER-AND-ENHANCER.pdf}, year = {2021}, date = {2021-08-07}, urldate = {2021-08-07}, booktitle = {IEEE International Conference on Image Processing}, journal = {CoRR}, volume = {abs/2008.00634}, keywords = {}, pubstate = {published}, tppubtype = {article} } Close Khan, Aisha Urooj; Kuehne, Hilde; Duarte, Kevin; Gan, Chuang; Lobo, Niels Da Vitoria; Shah, MubarakFound a Reason for me? Weakly-supervised Grounded Visual Question Answering using Capsules Conference IEEE Conference on Computer Vision and Pattern Recognition, 2021.BibTeX | Links: @conference{Khan2021b, title = {Found a Reason for me? Weakly-supervised Grounded Visual Question Answering using Capsules}, author = {Aisha Urooj Khan and Hilde Kuehne and Kevin Duarte and Chuang Gan and Niels Da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2018/11/Found-a-Reason-for-me.pdf https://www.crcv.ucf.edu/wp-content/uploads/2018/11/Found-a-Reason-for-me_Supp.pdf https://www.crcv.ucf.edu/wp-content/uploads/2018/11/cvpr21_poster_v2.pdf https://www.crcv.ucf.edu/wp-content/uploads/2018/11/cvpr_2021_5min.mp4}, year = {2021}, date = {2021-06-19}, urldate = {2021-06-19}, publisher = {IEEE Conference on Computer Vision and Pattern Recognition}, keywords = {}, pubstate = {published}, tppubtype = {conference} } Close2020 Khan, Aisha Urooj; Mazaheri, Amir; da Vitoria Lobo, Niels; Shah, MubarakMMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering Conference Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, EMNLP, 2020.BibTeX | Links: @conference{Khan2020b, title = {MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering}, author = {Aisha Urooj Khan and Amir Mazaheri and Niels da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2018/11/Publications_MMFT-BERT.pdf}, year = {2020}, date = {2020-11-16}, booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, EMNLP}, keywords = {}, pubstate = {published}, tppubtype = {conference} } Close Sharghi, Aidean; da Vitoria Lobo, Niels; Shah, MubarakText Synopsis Generation for Egocentric Videos Conference International Conference on Pattern Recognition, 2020.BibTeX | Links: @conference{Sharghi2020, title = {Text Synopsis Generation for Egocentric Videos}, author = {Aidean Sharghi and Niels da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2020/05/Publications_Text-Synopsis-Generation-for-Egocentric-Videos.pdf https://youtu.be/Z2Rpy7MC7QI}, year = {2020}, date = {2020-05-08}, booktitle = {International Conference on Pattern Recognition}, keywords = {}, pubstate = {published}, tppubtype = {conference} } Close2019 Vaca-Castano, Gonzalo; da Vitoria Lobo, Niels; Shah, MubarakHolistic Object Detection and Image Understanding Journal Article In: Computer Vision and Image Understanding, vol. vol. 181, pp. 1-13, 2019.BibTeX | Links: @article{nokey, title = {Holistic Object Detection and Image Understanding}, author = {Gonzalo Vaca-Castano and Niels da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2018/11/Publications_Holistic-object-detection-and-image-understanding.pdf https://www.crcv.ucf.edu/research/projects/holistic-object-detection-and-image-understanding/}, doi = {https://doi.org/10.1016/j.cviu.2019.02.006}, year = {2019}, date = {2019-04-01}, urldate = {2019-04-01}, journal = {Computer Vision and Image Understanding}, volume = {vol. 181}, pages = {1-13}, keywords = {}, pubstate = {published}, tppubtype = {article} } Close Lobo, Niels Da Vitoria; Shah, MubarakUCF's 30-Year REU Site in Computer Vision Journal Article In: Communications of the ACM, January 2019, Vol. 62 No. 1, Pages 31-34, 2019.BibTeX | Links: @article{Lobo2019, title = {UCF's 30-Year REU Site in Computer Vision}, author = {Niels Da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/wp-content/uploads/2020/05/Publications_UCF30YearREUSiteinComputerVision.pdf}, year = {2019}, date = {2019-01-01}, journal = {Communications of the ACM, January 2019, Vol. 62 No. 1, Pages 31-34}, keywords = {}, pubstate = {published}, tppubtype = {article} } Close2017 Prokaj, Jan; da Vitoria Lobo, NielsScale Space Based Grammar for Hand Detection Conference Springer Lecture Notes in Computer Science, 2017.BibTeX@conference{Prokaj2017, title = {Scale Space Based Grammar for Hand Detection}, author = {Jan Prokaj and Niels da Vitoria Lobo }, year = {2017}, date = {2017-08-08}, booktitle = {Springer Lecture Notes in Computer Science}, keywords = {}, pubstate = {published}, tppubtype = {conference} } Close2016 Vaca-Castano, Gonzalo; Das, Samarjit; Sousa, Joao P.; da Vitoria Lobo, Niels; Shah, MubarakImproved scene identification and object detection on egocentric vision of daily activities Journal Article In: Computer Vision and Image Understanding, 2016.BibTeX | Links: @article{Vaca-Castano2016b, title = {Improved scene identification and object detection on egocentric vision of daily activities}, author = {Gonzalo Vaca-Castano and Samarjit Das and Joao P. Sousa and Niels da Vitoria Lobo and Mubarak Shah}, url = {https://www.crcv.ucf.edu/papers/cviu2016-gonzalo.pdf http://dx.doi.org/10.1016/j.cviu.2016.10.016}, year = {2016}, date = {2016-12-22}, journal = {Computer Vision and Image Understanding}, keywords = {}, pubstate = {published}, tppubtype = {article} } Close2015 Kalayeh, Mahdi M; Mussmann, Stephen; Petrakova, Alla; da Vitoria Lobo, Niels; Shah, MubarakUnderstanding trajectory behavior: A motion pattern approach Journal Article I",
  "content_length": 34878,
  "method": "requests",
  "crawl_time": "2025-12-01 14:05:43"
}