{
  "name": "Dawson R. Engler",
  "homepage": "http://web.stanford.edu/~engler",
  "status": "success",
  "content": "Dawson Engler Dawson Engler Associate Professor Computer Science and Electrical Engineering Gates Building 3A-314 353 Serra Mall Stanford University Stanford, CA 94305-9030 engler WHERE stanford DOM edu I am a joint EE/CS associate professor. Before that, I was an irresponsible graduate student in Frans Kaashoek's PDOS group at MIT's Lab for Computer Science, where I co-founded the exokernel operating system project, which formed the basis of my thesis work. I now I have my own students, who sometimes listen to me: Cristian Cadar Daniel Dunbar Philip Guo Ted Kremenek Junfeng Yang I am currently looking a few additional students. If you know how to hack, we should meet. A few awards: ACM Grace Hopper Award, 2008 SIGOPS Mark Weiser Award,2006 Best Paper, OSDI 2008 Best Paper, OSDI 2004 Best Paper, OSDI 2000 Two good recent papers: A few billion lines of code later: using static analysis to find bugs in the real world . Al Bessey, Ken Block, Ben Chelf, Andy Chou, Bryan Fulton, Seth Hallem, Charles Henri-Gros, Asya Kamsky, Scott McPeak, Dawson Engler. Communications of the ACM archive Volume 53 , Issue 2 (February 2010) Pages: 66-75. According to ACM this is their most downloaded paper ever. I wrote it, but everyone else did all (I mean: ALL) of the technical work. It documents the oft-times bizarre things that happened when we took our static bug finding research and commercialized it. It's a light read, full of stuff you are glad happened to other people. Someone other than me did a final edit pass, doing odd things to some transitions and neutering some language, if you want the sharper-edged draft, send email. (I think the information content is about the same in both.) I have 30min, 60min, and 90min talks based on it that I'm always happy to give to avoid real work. Klee: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs. Cristian Cadar, Daniel Dunbar, Dawson Engler, Operating System Design and Implementation (OSDI), Dec, 2008. This is one of the very best technical papers we've done in the past ten years; it won best paper at OSDI. My research focuses on effective, automatic methods for finding lots of bugs in real code. We have used three main approaches: system-specific static analysis, implementation-level model checking, and most recently, using symbolic execution to automatically generate high-coverage tests. The following papers give a reasonable overview of the first two approaches (the Klee paper above describes that last): eXplode: a Lightweight, General System for Finding Serious Storage System Errors, Junfeng Yang, Can Sar, and Dawson Engler, Proceedings of the 7th Symposium on Operating System Design and Implementation, 2006. (postscript, PDF) Bugs as Deviant Behavior: A General Approach to Inferring Errors in Systems Code (postscript) (PDF). Slides: PS, PDF, PPT. Dawson Engler, David Yu Chen, Seth Hallem, Andy Chou, and Benjamin Chelf. Appeared in: Proceedings of the Eighteenth ACM Symposium on Operating Systems Principles, 2001. This paper has some of my favorite ideas, though unfortunately I can't say the same for the writing. If a static checking person was going to read just one of our papers this should be it: I've used its ideas in every static checker I've built since writing it, typically more than once. I've never seen a checker that could not be improved by using its trick of belief analysis to infer what to check or what the state of a checked system is based on what programmers seem to believe. Checking System Rules Using System-Specific, Programmer-Written Compiler Extensions (Best Paper) (postscript) (PDF). Slides: PS, PDF, PPT. Dawson Engler, Benjamin Chelf, Andy Chou, and Seth Hallem. Appeared in: Proceedings of the 4th Symposium on Operating System Design and Implementation. This paper discusses a set of small extensions that found roughly 500 bugs in Linux, OpenBSD, and the Xok exokernel. The extensions were usually less than 100 lines. Our current static checking systems are much more powerful, but the basic approach is roughly the same. I co-founded a company, Coverity, several years ago with three of my students (Seth Hallem, Andy Chou and Ben Chelf) to commercialize this static checking work. Coverity has 500+ customers and 130+ employees. A free trial of the tool can be obtained here. This paper describes the main thing I did before bug finding: Exokernel: An Operating System Architecture for Application-Level Resource Management, Dawson R. Engler, M. Frans Kaashoek and James W. O'Toole This paper appeared in SOSP95 ( slides are available here). It is the most detailed description of what an exokernel is, but is rather dense. The SOSP paper from 1997 (below) has real application numbers and several years of experience, plus a cool trick for incrementally verifying untrusted deterministic code. Some recent talks EXEcution generated Executions: Automatically generating inputs of death. (postscript, PDF, PPT). A 30 minute talk on our latest project: automatically generating concrete inputs that blow up real code. Weird things that surprise academics trying to commercialize a static checking tool. (postscript, PDF, PPT). This is part of an invited talk at SPIN05 and CONCUR05. Using model checking and execution generated tests to find bugs in real code (postscript, PDF, PPT). Invited talk, Usenix Security 2005. Static analysis versus model checking for bug finding (postscript, PDF, PPT). Keynote, SoftMC 2003. Finding bugs with system-specific static analysis (postscript, PDF, PPT). Keynote, PASTE 2002. How to find lots of bugs with system-specific static analysis. (postscript, PDF, PPT). Distinguished lecture, SUNY Stonybrook, 2001. Below are the rest of our papers... Automatic generation of high-coverage tests. Under-constrained execution: making automatic code destruction easy and scalable, Dawson Engler and Daniel Dunbar, International Symposium on Software Testing and Analysis (ISSTA), 2007. (PDF) EXE: Automatically Generating Inputs of Death, (postscript) (PDF) Cristian Cadar, Vijay Ganesh, Peter M. Pawlowski, David L. Dill, Dawson R. Engler, 13th ACM Conference on Computer and Communications Security, 2006. Automatically generating malicious disks using symbolic execution, Junfeng Yang, Can Sar, Paul Twohey, Cristian Cadar, and Dawson Engler. (PDF) (postscript), IEEE Security and Privacy, 2006. This paper uses a system we built, EXE, to automatically generate disk images of death that, when mounted, will cause a file system to crash. Many systems now let untrusted users mount files as file systems, which opens them up to all sorts of exploits, given the somewhat erratic input checking done by current file system code. Automatic test case generation by executing code on symbolic inputs. A technical report containing our SOSP05 submission gives preliminary results: Execution generated test cases: how to make systems code crash itself, CSTR-2005-04 (pdf). The trick is simple and cute. A shortened version appeared as an invited paper in SPIN05 (pdf). The two EXE papers given above are probably better to read. Software model checking Using Model Checking to Find Serious File System Errors (Best Paper) (postscript) (PDF), Junfeng Yang, Paul Twohey, Dawson Engler, and Madanlal Musuvathi, Operating System Design and Implementation (OSDI) 2004. Describes FiSC, a file system model checking tool. We applied it to three widely-used, heavily-tested file systems: ext3, JFS, and ReiserFS. We found serious bugs in all of them, 32 in total. Most have led to patches within a day of diagnosis. For each file system, FiSC found demonstrable events leading to the unrecoverable destruction of metadata and entire directories, including the file system root directory ``/''. The actual bugs we found are here. Model-checking large network protocol implementations (postscript) (PDF), Dawson Engler and Madanlal Musuvathi. Proceedings of the First Conference on Network System Design and Implementation (NSDI), 2004. Describes the challenges in model checking 50K lines of TCP code. One of the surprising results was that it was easier to run the entire Linux kernel in Madan's CMC model checker than extract out TCP in a stand-alone version. Static analysis versus software model checking for bug finding (postscript) (PDF). Extended version with better formatting: (postscript) (PDF), Dawson Engler and Madanlal Musuvathi. Invited paper for VMCAI04. It describes some of our experiences finding bugs with both model checking and static analysis, including some of the less pleasant aspects of both. Slides are available: postscript, PDF, PPT. The paper is a reworked version of a invited paper for the SoftMC 2003 workshop: \"Some lessons from using static analysis and software model checking for bug finding\" (postscript) (PDF), Madanlal Musuvathi and Dawson R. Engler. The writing could be better, but some of the tables are reasonable. Slides are available: postscript, PDF, PPT. CMC: A pragmatic approach to model checking real code (postscript) (PDF) , Madanlal Musuvathi, David Y.W. Park, Andy Chou, Dawson R. Engler, David L. Dill. Appeared in OSDI 2002. A model checker that can check C code directly, dispensing with the need to write a specification. We applied it to three different AODV routing protocol implementations, where it found roughly one bug per 300 lines of code. A Simple Method for Extracting Models from Protocol Code (postscript) (PDF) , David Lie, Andy Chou, Dawson Engler, and David Dill Appeared in ISCA 2001. It shows how to check deeper properties than possible with static analysis by using MC to automatically extract specifications (models) from actual C code and then running these models through a formal verifier. Using Statistical Analysis for Bug Finding From Uncertainty to Belief: Inferring the Specification Within, Ted Kremenek, Paul Twohey, Godmar Back, Andrew Ng, Dawson Engler, Proceedings of the 7th Symposium on Operating System Design and Implementati",
  "content_length": 19207,
  "method": "requests",
  "crawl_time": "2025-12-01 13:00:26"
}