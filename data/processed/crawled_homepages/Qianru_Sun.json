{
  "name": "Qianru Sun",
  "homepage": "https://qianrusun.com",
  "status": "success",
  "content": "Qianru Sun Home Publications Teaching Students & Staffs Others Qianru Sun 孙倩茹 Associate Professor of Computer Science Lee Kong Chian Fellow (2021-2023;2025-2027) School of Computing and Information Systems Singapore Management University Contact: qianrusun \"at\" smu DOT edu DOT sg 80 Stamford Rd, Singapore, 178902 Experiences Since 2019, I have been working in the School of Computing and Information Systems (SCIS), at Singapore Management University (SMU). Here is my faculty profile. Before that, I was a research fellow working with Prof. Tat-Seng Chua at the National University of Singapore and Prof.Dr. Bernt Schiele at the MPI for Informatics, focusing on interesting machine learning problems such as few-shot learning, meta-learning and continual learning and their implementations on computer vision tasks. From 2016 to 2018, I held the Lise Meitner Award Fellowship and worked with Prof.Dr. Bernt Schiele and Prof. Dr. Mario Fritz at the MPI for Informatics, working on basic computer vision tasks such as image classification and generation. I got my Ph.D. degree from Peking University in 2016. My thesis was advised by Prof. Hong Liu, and the topic is human action recognition in videos. In 2014, I visited the research group of Prof. Tatsuya Harada at the University of Tokyo, working on an interesting task of human anomalous action detection in surveillance videos. News We are organizing a workshop on Advances of Generative AI, at SMU, on 27th April 2025 (Sunday). Registration is available for Singapore local students and industrial workers. [webpage] Our paper about LoRA's hyperparameter optimization has been accepted by CVPR'25. Congrats to Zichen. Our survey paper about weakly-supervised semantic segmentation has been published in ACM Computing Surveys. Congrats to Zhaozheng. Three papers respectively about multi-modal LLMs, multi-model editing, and ViT model adaptation have been accepted by NeurIPS'24. See you again in Vancouver. Our paper about semantic scene completion in 3D has been accepted by CVPR'24. Our paper about Stable Diffusion features for discrimination tasks has been accepted by ICLR'24. Its extension work for few-shot tasks has been accepted to CVPR '24. Our paper about online placebos for CIL has been accepted by WACV'24. It is a highly practically efficient work. Two papers about domain adaptation and foundation models, respectively, are accepted by NeurIPS'23. Our paper about few-shot point cloud recognition has been accepted by ICCV'23. Five papers respectively about semantic scene completion, class incremental learning, video anomaly detection, weakly-supervised semantic segmentation, and image synthesis are accepted by CVPR '23. Our paper about open-set visual relation detection is accepted by ICLR'23. [project] I am awarded the \"Outstanding Service Award\" by MMAsia for my contributions to organizing the conference in 2020. news Three papers respectively about face image clustering, OOD generalization, and insufficient data learning are accepted by ECCV'22. Our paper about weakly-supervised semantic segmentation is accepted by CVPR'22. I am awarded \"Outstanding Reviewer\" by NeurIPS'21. Two papers respectively about self-supervised learning and class-incremental learning are accepted by NeurIPS'21. Three papers respectively about causal attention, domain adaptation, and semantic segmentation are accepted by ICCV'21. Our work on food image segmentation has been published. [project] I am awarded \"Lee Kong Chian Fellow\" by SMU. We release a large-scale benchmark for food image segmentation with our pre-trained models using CNN and ViT! [project] I am awarded \"Outstanding Reviewer\" by ICLR'21. FoodAI++, a demo of our food image segmentation, is now online. [demo] Two papers respectively about incremental learning and zero-shot learning are accepted by CVPR'21. The 1st workshop of Causality in Vision at CVPR'21. The best paper is awarded a US$1,000 (cash) prize. [homepage] Two papers respectively about semantic segmentation and few-shot learning are accepted by NeurIPS'20. The extended paper of our CVPR'19 work (MTL) has been accepted by IEEE Transactions on PAMI. Two papers respectively about semantic segmentation and few-shot learning are accepted by ECCV'20. We release the code of E3BM (SOTA few-shot learning results and LITTLE overhead costs)! [github] We release the code of Mnemonics Training (SOTA multi-class incremental learning results on ImageNet)! [github] We release the code of VC R-CNN (SOTA image representation on MS-COCO Detection and Open Images)! [github] Two papers respectively about incremental learning (oral presentation) and unsupervised learning are accepted by CVPR'20. We will host the ACM Multimedia Asia '20 conference in Singapore! [homepage] An article about my research is posted in the \"Research at SMU Nov 2019 Issue\". [link] Our paper about semi-supervised few-shot learning has been accepted by NeurIPS'19. Our paper about few-shot learning has been accepted by CVPR'19. Ph.D. Students Yaoyao Liu 2018 - 2022 (with Bernt Schiele) MPI for Informatics Now: Asst Prof at UIUC lyy[at]illinois.edu Sicheng Yu 2019 - 2022 (with Jing Jiang) SMU Now: ByteDance scyu.2018[at]phdcs.smu.edu.sg Zhaozheng Chen 2020 - 2023 SMU Now: Huawei zhaozhengcc[at]gmail.com Zhongqi Yue 2020 - 2023 (with Hanwang Zhang) NTU Now: Postdoc at NTU yuez0003[at]e.ntu.edu.sg Tan Wang 2020 - 2024 (with Hanwang Zhang) NTU Now: Meta wangt97[at]e.ntu.edu.sg Zilin Luo Since Aug 2021 SMU zilin.luo.2021[at]phdcs.smu.edu.sg Zichen Tian Since Aug 2023 SMU zichen.tian.2023[at]phdcs.smu.edu.sg Jiahao Ying Since Aug 2022 SMU (with Yixin Cao) jhying.2022[at]phdcs.smu.edu.sg Master Students Chunhui Bao Jan 2020-Dec 2021 SMU LOH Yi Lin Jan 2022-Nov 2022 SMU MA Li Jan 2022-Dec 2024 SMU Research Fellows/Assistants Xin Fu Jan 2020-Dec 2020 Research Assistant Beijing Jiaotong University Wei Qin Nov 2019-May 2021 Research Assistant Hefei University of Technology Muhammad Naufal Aug 2020-Dec 2020 Research Student SMU Ying Liu Aug 2020-Mar 2021 Research Assistant SMU Xiongwei Wu Mar 2021-Mar 2022 PostDoc (with Ee-Peng Lim) SMU xwwu[at]smu.edu.sg Xin Zhao Jun 2021-May 2022 Visiting Jilin University Harshit Jain Aug 2021-Dec 2021 Research Student SMU Fengyun Wang Nov 2021-Oct 2022 Research Assistant Nanjing University of Science and Technology Ning Han Nov 2021-Oct 2022 Visiting (with Ee-Peng Lim) Hunan University AW Khai Loong Jan 2022-May 2022 Research Assistant SMU Kaifeng Gao Sep 2022-Sep 2023 Research Assistant Zhejiang University Han Xue Oct 2022-Oct 2023 Visiting Shanghai Jiao Tong University Lv Hui Mar 2023-Feb 2024 Postdoc SMU Zichen Tian Mar 2023-July 2023 Research Engineer SMU Binhui Liu Oct 2023-Oct 2024 Visiting PhD Student Nanjing University of Science and Technology Haolin Li Oct 2023-Oct 2024 Visiting PhD Student Harbin Institute of Technology Liuqing Zhao Oct 2023-Oct 2024 Research Assistant SMU Zhaozheng Chen Feb 2024 - Nov 2024 Research Fellow zhaozhengcc[at]gmail.com Qi Zhang Jan 2025-July 2025 Research Engineer SMU Guangzhao Dai Jan 2025-July 2025 Visiting Student Nanjing University of Science and Technology Publications [Venues] 2025 Unsupervised Visual Chain-of-Thought Reasoning via Preference Optimization Kesen Zhao, Beier Zhu, Qianru Sun, and Hanwang Zhang International Conference on Computer Vision 2025, ICCV'25. [paper] Chain-of-thought (CoT) reasoning greatly improves the interpretability and problem-solving abilities of multimodal large language models (MLLMs). However, existing approaches are focused on text CoT, limiting their ability to leverage visual cues. Visual CoT remains underexplored, and the only work is based on supervised fine-tuning (SFT) that relies on extensive labeled bounding-box data and is hard to generalize to unseen cases. In this paper, we introduce Unsupervised Visual CoT (UV-CoT), a novel framework for image-level CoT reasoning via preference optimization. UV-CoT performs preference comparisons between model-generated bounding boxes (one is preferred and the other is dis-preferred), eliminating the need for bounding-box annotations. We get such preference data by introducing an automatic data generation pipeline. Given an image, our target MLLM (e.g., LLaVA-1.5-7B) generates seed bounding boxes using a template prompt and then answers the question using each bounded region as input. An evaluator MLLM (e.g., OmniLLM-12B) ranks the responses, and these rankings serve as supervision to train the target MLLM with UV-CoT by minimizing negative log-likelihood losses. By emulating human perception--identifying key regions and reasoning based on them--UV-CoT can improve visual comprehension, particularly in spatial reasoning tasks where textual descriptions alone fall short. Our experiments on six datasets demonstrate the superiority of UV-CoT, compared to the state-of-the-art textual and visual CoT methods. Our zero-shot testing on three unseen datasets shows the strong generalization of UV-CoT. 3D Question Answering via only 2D Vision-Language Models Fengyun Wang, Sicheng Yu, Jiawei Wu, Jinhui Tang, Hanwang Zhang, and Qianru Sun Forty-second International Conference on Machine Learning, ICML'25. [paper] Large vision-language models (LVLMs) have significantly advanced numerous fields. In this work, we explore how to harness their potential to address 3D scene understanding tasks, using 3D question answering (3D-QA) as a representative example. Due to the limited training data in 3D, we do not train LVLMs but infer in a zero-shot manner. Specifically, we sample 2D views from a 3D point cloud and feed them into 2D models to answer a given question. When the 2D model is chosen, e.g., LLAVA-OV, the quality of sampled views matters the most. We propose cdViews, a novel approach to automatically selecting critical and diverse Views for 3D-QA. cdViews consists of two key components: viewSelector prioritizing critical views based on their potential to provide answer-specific information, and",
  "content_length": 83857,
  "method": "requests",
  "crawl_time": "2025-12-01 14:13:38"
}