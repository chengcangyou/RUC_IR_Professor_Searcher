{
  "name": "Will Crichton",
  "homepage": "https://willcrichton.net",
  "status": "success",
  "content": "Will Crichton My goal is to empower people to use the full potential of computers through programming. To reach that potential, we need to combine a science of programming with a science of people. For me, these sciences are programming language theory and cognitive psychology, respectively. My research draws on these fields to make programming more usable, learnable, and powerful. If you want to take CS 1377: Tools for Thought in Spring 2026, please do not email me asking for an override. There will be a signup form on the first day of class. Overrides will prioritize students who can only take 1377 in S26. I am an assistant professor at Brown University, where I lead the Cognitive Engineering Lab. Previously, I completed my PhD at Stanford, advised by Pat Hanrahan and Maneesh Agrawala. I did a postdoc also at Brown with Shriram Krishnamurthi. I do research primarily between PL and HCI. I build systems like program slicers , document languages , and type system visualizers . I develop theories like working memory for programmers, psychometrics for programming languages, and type-safe templates for System F. I work on systems languages like Rust, proof assistants like Lean, and UI tools like the browser. My Rust research has been used by over 100,000 developers to date. My research garden (below) explains my current interests in greater detail.Research GardenThis is where I grow my ideas. Click on the sections that interest you.ConceptsResearch interests focused a broad vision for the future.A cognitive theory of computational abstractionsMotivationProgrammers and CS researchers often claim that a language or system is intuitive or for humans. Our field rests on assumptions like structured programming is preferable to GOTOs and static typing is better for large teams than dynamic typing. And fundamentally we all believe that our choice of tools—our choice of computational abstractions—has a significant impact on our productivity, and on the correctness and performance of our programs. Would you choose to program a large system in assembly instead of C? I expect not!This raises the question: how can we justify these beliefs? How can I argue that one set of abstractions is better than another? What are the key variables (task, programmer, environment, etc.) that affect this judgment? Programmers will often use metrics like lines-of-code, but we need better metrics. And while it's important to answer these questions for our existing beliefs, the longer term goal is to help programmers make predictions about the human factors of future systems before the systems are deployed. I am advocating for a predictive cognitive theory of abstraction, as opposed to the iterative design methods predominant in HCI.My angleI approach this problem from the lens of cognitive psychology: using cognitive theories (e.g., working memory, perception, planning) and cognitive experimental methods (e.g., free recall, eye tracking, thinkalouds) to build an understanding of the cognitive aspects of programming. I focus on two angles: How does an abstraction influence a person's ability to decompose programming problems? A central task in programming is to take a problem (build a website to do X, analyze Y feature of a dataset) and break it down into pieces that correspond to features of the language or library at hand (e.g., for loops or List.map). I think a key issue is understanding what it means to think with an abstraction, so one could argue why an abstraction would be better or worse for decomposition. An interesting domain to study is tabular data analytics, because there are dozens of meaningfully different ways to express the same concept. I wrote the Expressiveness Benchmark (2020) as a side project to experiment with different metrics for comparing the expressiveness of analytics languages and APIs. How do abstractions affect the load on cognitive resources during different programming tasks? People have low-level cognitive resources like perception, working memory, and long-term memory that contribute to the higher-level process of conscious thought. Abstractions can influence code's perceptual structure (e.g., reading order or visual salience) and mnemonic structure (e.g., how many facts are needed to understand a piece of code). In The Role of Working Memory in Program Tracing (CHI 2021), I looked at how the most primitive abstractions of programming (variables, arithmetic) relate to working memory. I would love to continue this work with higher-level abstractions! But why am I, a computer scientist, doing psychology research?Disciplinary boundaries are artificial inventions that should never stop you from doing good work! But that aside, psychology as a field prefers to deal with universal psychological phenomena (i.e., aspects of cognition that everyone experiences) over domain-specific psychological phenomena. The kinds of questions I'm asking only affect a small number of experienced programmers, so it's not commonly studied in psychological research. Hence, we computer scientists have to help out!Additionally, I am interested in design-relevant psychology—ideas that can meaningfully influence the decisions made by programmers. Psychologists are generally not thinking about the design-relevance of their research, even if they analyze programmer behavior.Project ideasThese ideas are suitable for a strong programmer with a deep interest in psychology, cognition, and human-centered design of programs. You should (a) have enough programming experience to have a good intuition for what makes programming hard, (b) have enough experience with UI tools to productively implement experimental interfaces, and (c) be prepared to read a lot of psychology books and papers. What is a better metric than lines-of-code for comparing the expressiveness / brevity / quality of languages or libraries? Here's a hypothesis: a proxy for the complexity of a program is the complexity of the argument for why the program is correct. You could operationalize this idea in a proof assistant: is the size-of-proof-of-correctness a better correlate for code complexity than lines-of-code? What are the principles of good examples for illustrating an abstraction? It is broadly true that abstract concepts are best explained through concrete examples, at least at first. But there is an infinite space of examples—how should a teacher (could be a person or an ML model) sample from this space? How should sequences of examples be used to progressively build a mental model of the abstraction in the learner's mind? Is the Sapir-Whorf hypothesis true for programming languages? That is, to what extent does learning a programming language affect how a person thinks about programming problems, even if they're using a different language? For example, if I learn about list processing primitives (map, filter, fold) and then go write for-loops in C, will I approach the same tasks differently? Technical foundations of technical communicationMotivationTechnical communication today (textbooks, academic papers, documentation, etc.) largely looks the same as it did a century ago: plain words wrapping static figures. This is a tragedy. Computers have the capacity to significantly improve technical communication in two ways: Multimodal representations of information. Prose is just one of many representations: charts, diagrams, audio, and video can be more cognitively effective for communicating information (depending on the task and reader). Computers have the capacity to both present and generate multimodal representations in ways that traditional documents cannot. Dynamic interfaces into information. Unlike a book, a computer can talk back. A person can interactively explore complex topics and receive explanations contextualized to their background. This offers a way out of the one-size-fits-all style of communication that is standard today. In fact, computers have been able to do both of these things for decades. That raises the question: why don't we do these things more often? My thesis is that constructing multimodal dynamic documents (rich documents) is simply too much effort. It is the domain of radically talented individuals like Grant Sanderson (3Blue1Brown), Bartosz Ciechanowski, and Bret Victor. Case in point, when machine learning researchers tried to produce such articles at Distill, they stopped because it was too much damn work: We don't believe [anymore] that having a venue is the primary bottleneck to authors producing more Distill-style articles. Instead, we believe the primary bottleneck is the amount of effort it takes to produce these articles and the unusual combination of scientific and design expertise required. My angleI think we need to simultaneously make progress at each layer of the stack of document technologies: What are the most important capabilities of rich documents to design for? That is, if you could make one change to every document in the world, what would have the biggest impact in improving our ability to communicate? First, this means distinguishing flashy features from real cognitive impact. For example, animations are not always better than static pictures. Second, this means weighing the different trade-offs in document design. How much training do readers need in a given feature? How hard is it to for authors to work with? Can it be rendered in the browser, on a phone, or on a Kindle? For example, I first got thinking about documents because I was deeply dissatisfied with my ability to use LaTeX for basic kinds of readability improvements. I rewrote one of my PL papers as a website to try out different concepts for improving the academic paper format: A New Medium for Communicating Research on Programming Languages (HATRA @ SPLASH 2022). What is a stable format for reading and sharing rich documents? PDF has served us well for 30+ years, but it's time for something better. However, while the web technology stack (HTML + CSS + JS) can ",
  "content_length": 43188,
  "method": "requests",
  "crawl_time": "2025-12-01 14:46:39"
}