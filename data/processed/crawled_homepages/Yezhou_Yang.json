{
  "name": "Yezhou Yang",
  "homepage": "https://yezhouyang.engineering.asu.edu",
  "status": "success",
  "content": "Active Perception Group Welcome to the Active Perception Group Combining computer vision, deep learning and AI (Generative AI) algorithms to interpret peoples’ actions and the scene’s geometry. Yezhou (also goes by ‘YZ’) Yang is an Associate Professor at School of Computing and Augmented Intelligence (SCAI), Arizona State University.  He is directing the ASU Active Perception Group. For the latest research, teaching, and entrepreneurial updates, please refer to the following: LinkedIn – Google Scholar – X (Twitter) His primary interests lie in Cognitive Robotics, Computer Vision, and Robot Vision, especially exploring visual primitives in human action understanding from visual input, grounding them by natural language as well as high-level reasoning over the primitives for intelligent robots; His research mainly focused on solutions to visual learning, which significantly reduces the time to program intelligent agents. These solutions involve Computer Vision, Deep Learning, and AI algorithms to interpret peoples’ actions and the scene’s geometry. His research draws on the strengths of the symbolic approach, connectionism, and dynamicism. Before joining ASU, Dr. Yang was a Postdoctoral Research Associate at the Computer Vision Lab and the Perception and Robotics Lab, with the University of Maryland Institute for Advanced Computer Studies. He got his PhD from the Computer Science department of Univeristy of Maryland, with a Ph.D. thesis on MANIPULATION ACTION UNDERSTANDING FOR OBSERVATION AND EXECUTION. A few words to future ASU APGers For future Ph.D. members, our admission is committee based and we have a large AI-related faculty group at ASU. I would encourage you to apply for our CS/CSE/CEN Ph.D. program first. If you are interested in working with ASU APG, you could consider listing my name as your potential Ph.D. advisor. For future Master members, I typically recruit Master students from my CSE 598 Perception in Robotics course, please consider taking it first. All the best with your applications to graduate schools! ‘YZ’ Yezhou Yang Associate Professor, SCAI, ASU Amazon Scholar, Prime Video and MGM Studios Fulton Entrepreneurial Professor (2022-24) Thrust Lead, Situation Awareness, ACT, Science and Technology Centers Tech Lead, Situation Awareness, Institute of Automated Mobility Co-founder, ARGOS Vision Inc. Contact Office: BYENG 562, 699 S Mill Ave. Tempe, AZ 85281 Email: [email protected] Twitter: @Prof_YZ Full Publication List Latest News ASU APG will present two main conference papers (FlowChef and RefEdit) at ICCV 2025. More info soon… [New Book Alert] Advances in Multimodal Information Retrieval and Generation as Part of the book series: Synthesis Lectures on Computer Vision (SLCV) by Springer Nature. Link to the book. One paper to be published at Transactions on Machine Learning Research (TMLR). More info ASU APG will present one main conference paper at NeuRIPS 2024. More info and we will organize the Workshop on Responsibly Building the Next Generation of Multimodal Foundational Models (RBFM) More info ASU APG will present THREE main conference papers at ECCV 2024. More info . ASU APG will present FOUR main conference papers at CVPR 2024. More info . Yezhou “YZ” Yang discussed the safety of autonomous vehicles with Arizona PBS. Watch the interview here . YZ serves as Area Chair for CVPR 2024, AAAI 2024, NeuRIPS 2023 and ICLR 2023, and Associate Editor for ICRA 2024, 2023. ICRA 2023: “CAROM Air – Vehicle Localization and Traffic Scene Reconstruction from Aerial Video” has been accepted and will be presented at the 2023 IEEE International Conference on Robotics and Automation (ICRA) Full draft and Data and code This work features our last two years close collaboration between ASU APG, Rider University, Arizona DOT and the Institute of Automated Mobility . YZ co-organizes WACV 2023 Tutorial on Semantic Data Engineering for Robustness under Multimodal Settings (SERUM). Tutorial Webpage YZ co-organizes CoRL 2022 Workshop on Learning, Perception, and Abstraction for Long-Horizon Planning. Workshop Webpage ASU APG YZ Yang presents APG’s effort towards Robust and Socially-Adept Autonomous Vehicles Through Vehicle Trajectory Sensing for Safety Assessment at the University Research session of ITS AZ conference, mesa, AZ Slides deck ASU APG received a three years NSF Robust Intelligence core research grant (collaborating with Prof. Chitta Baral) to develop An Active Approach for Data Engineering to Improve Vision-Language Tasks. Project public info ASU APG received a three years NSF SaTC research grant (With Prof. Max Yi Ren and Prof. Ni Trieu) to develop Decentralized Attribution and Secure Training of Generative Models. Project public info Pratyay Banerjee and APG PhD Tejas Gokhale: “Weakly Supervised Relative Spatial Reasoning for Visual Question Answering” has been accepted and will be presented at 2021 International Conference on Computer Vision (ICCV’21) Full draft and Data and code APG PhD Xin Ye: “Hierarchical and Partially Observable Goal-driven Policy Learning with Goals Relational Graph” has been accepted and will be presented at 2021 Conference on Computer Vision and Pattern Recognition (CVPR’21) Full draft and Data and code APG PhD Joshua Feinglass: “SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis” has been accepted and will be presented at the annual meeting of the Association for Computational Linguistics (ACL) 2021. Long paper as Oral presentation. Full draft and Data and code APG PhD Xin Ye: “Efficient Robotic Object Search via HIEM: Hierarchical Policy Learning with Intrinsic-Extrinsic Modeling” has been accepted to RA-L and will be presented at IEEE International Conference on Robotics and Automation (ICRA’21) Full draft and Data and code ASU CS PhD Duo Lv and APG PhD Varun Jammula: “CAROM – Vehicle Localization and Traffic Scene Reconstruction from Monocular Cameras on Road Infrastructures” has been accepted and will be presented at IEEE International Conference on Robotics and Automation (ICRA’21) Full draft and Data and code ASU APG Yezhou Yang presents APG’s effort on Visual Recognition beyond Appearances, and its Robotic Applications at the USC ISI NLP seminar on Jan 14th, 2020 Full talk and Q&A APG 2 Papers accepted at ICLR 2021! Changhoon Kim: DECENTRALIZED ATTRIBUTION OF GENERATIVE MODELS Jacob Zhiyuan Fang: and SEED: Self-supervised Distillation For Visual Representation ASU APG Yezhou Yang served as Area Chair for AAAI 2021 ASU APG Yezhou Yang presents APG’s effort on Visual Recognition beyond Appearances, and its Robotic Applications at the ONLINE Special Robotics Seminar, Maryland Robotics Center on December 4, 2020 Full talk and Q&A APG 3 V&L Long Papers accepted at EMNLP 2020 (Two Accepts and one Accept-Finding). Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning and MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering and Diverse Visuo-Lingustic Question Answering (DVLQA) Challenge ASU APG Yezhou presents APG’s effort on Towards Robust and Socially-Adept Autonomous Vehicles and Vehicle Trajectory Sensing using Existing Monocular Traffic Cameras for Safety Assessment at the WORKSHOP ON AUTOMATED VEHICLE SAFETY: VERIFICATION, VALIDATION AND TRANSPARENCY collocated with IEEE ITSC 2020 Program info ASU APG received a three years NSF Cyber-Physical Systems (CPS) research grant (With Prof. Georgios Fainekos and Prof. Jyo Deshmukh (USC)) to develop Spatio-Temporal Logics for Analyzing and Querying Perception Systems. Project public info ASU APG Yezhou presents APG’s effort on Vehicle Trajectory Sensing using Existing Monocular Traffic Cameras for Safety Assessment at the Automated Vehicles Symposium (AVS) breakout session on Safety Assurance of Automated Driving Program info APG PhD Tejas Gokhale: “VQA-LOL: Visual Question Answering under the Lens of Logic” has been accepted and will be presented at 2020 European Conference on Computer Vision (ECCV’20) Full draft and Data and code APG Visiting PhD Zhe Wang and PhD Jacob Zhiyuan Fang: “ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language” has been accepted and will be presented at 2020 European Conference on Computer Vision (ECCV’20) Full draft and Data and code APG master thesis student Kausic Gunasekar: “Low to High Dimensional Modality Hallucination using Aggregated Fields of View for Robust Perception” has been accepted and will be published on Robotics and Automation Letter (RA-L) with a presentation at ICRA 2020 Full draft and Data and Code . APG PhD candidate Mohammad Farhadi: “TKD: Temporal Knowledge Distillation for Active Perception” has been accepted and will be presented at 2020 Winter Conference on Applications of Computer Vision (WACV ’20) Full draft and Data and code ASU APG will participate the Darpa KAIROS program (With USC ISI and UCF teams) to develop AI system for discovering schemas from diverse data. Program public info ASU APG received a three years NSF National Robotics Initiative (NRI) grant (With Prof. Wenlong Zhang and Prof. Yi Ren) to develop Socially-Adept Autonomous Vehicles using active vision and reasoning. Project public info ASU APG received a one year NSF CCRI grant (With Prof. Dijiang Huang ) to develop hand related critical research data services. Project public info ASU APG won the Amazon AWS ML research award 2019! Award info APG PhD student Xin Ye: “GAPLE: Generalizable Approaching Policy LEarning for Robotic Object Searching in Indoor Environment” has been accepted and will be published on Robotics and Automation Letter (RA-L) with a presentation at IROS 2019 Full draft Somak Aditya: “Integrating Knowledge and Reasoning in Image Understanding” has been accepted and will be presented at IJCAI 2019 survey track. Full draft APG PhD student Xin Ye: “Robot Learning of Manipulation Activities with Overall Planning through Precedence Graph” has b",
  "content_length": 17717,
  "method": "requests",
  "crawl_time": "2025-12-01 14:51:02"
}