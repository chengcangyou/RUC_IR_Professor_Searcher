{
  "name": "Cong Hao",
  "homepage": "https://sharclab.ece.gatech.edu",
  "status": "success",
  "content": "Sharc Lab @ Georgia Tech – Software/Hardware Co-Design for Intelligence and Efficiency Software/Hardware Co-Design for Intelligence and Efficiency About Sharc Why Sharc? Software/hardware co-design lab (Sharc) believes in the power of “1 + 1 > 2” — twice the efforts, 20 to 200 times improvements — isn’t it worth it? What to do in Sharc? We explore the interdisciplinary research opportunities: ML-assisted EDA, accelerators for ML, EDA-assisted accelerators, etc. But, we don’t limit ourselves! We always welcome innovative directions and ideas! Who comes to Sharc? Sharc always welcomes excellent students interested in the joint area of hardware design (FPGA, ASIC, etc.) and machine learning (DNNs, GNNs, etc.). We also have a broad interest in computer architecture, graph computation, and electronic design automation (HLS, etc.). Ps. More interested in hardcore machine learning and cool applications? Bug my dear husband, Dr. Pan Li, also at ECE. Research Interests Software-hardware Co-design: hardware-efficient machine learning, ML/system co-design High-performance Reconfigurable Computing: FPGA, embedded system, edge computing Graph Neural Network (GNN) and Graph Computing: GNN for EDA, GNN acceleration Electronic design automation (EDA): high-level synthesis (HLS), domain-specific HLS Announcements We are NOT offering short-term and remote interns (in principle) — sorry about that! Prospective Students ★★ Please read this post first ★★ We are always expecting talented and hardworking students to join Sharc Lab. Please contact Dr. Callie Hao if you’re interested. Expected skills include FPGA, Verilog/HLS, GNN, ML, EDA, or compiler. Recent News [2025. 09] [Paper] Our paper “FIFOAdvisor: A DSE Framework for Automated FIFO Sizing of High-Level Synthesis Designs” (Stefan Abi-Karam, Rishov Sarkar, Suhail Basalama, Jason Cong, Cong Hao) is accepted by ASPDAC’26. [2025. 08] [Paper] Our paper “OmniSim: Simulating Hardware with C Speed and RTL Accuracy for High-Level Synthesis Designs” (Rishov Sarkar, Cong Hao) is accepted by MICRO’26. This is our first MICRO paper! Yeah! [2025. 07] [Paper] Four papers got accepted recently: “LaZagna: An Open-Source Framework for Flexible 3D FPGA Architectural Exploration” (Ismael Youssef, Hang Yang, Cong Hao) is accepted by ICCAD’25 with Best Paper Award! [paper] [Youtube] “Pieceformer: Similarity-Driven Knowledge Transfer via Scalable Graph Transformer in VLSI” (Hang Yang, Yong Liu, Yusheng Hu, Cong Hao) is accepted by MLCAD’25. “HLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level Synthesis Design Tasks“, (Stefan Abi-Karam, Cong Hao) is accepted by ICLAD’25. “Cryptonite: Scalable Accelerator Design for Cryptographic Primitives and Algorithms” (Karthikeya Sharma Maheswaran, Camille Bossut, Andy Wanna, Qirun Zhang, Cong Hao) is accepted by ASAP’25. [2025.06] [Honor] Callie was appointed to ON Semiconductor Junior Professorship. Thank you very much, ECE and Georgia Tech! [link] [2025. 03] [Paper] Our paper “RealProbe: An Automated and Lightweight Performance Profiler for In-FPGA Execution of High-Level Synthesis Designs” (Jiho Kim, Cong Hao) is accepted by FCCM’25 with Best Paper Nomination! Code and documents here. [2024.02] [Honor] Rishov Sarkar is awarded the Oscar P. Cleaver Award, which gives to the Ph.D. students who presented the most outstanding Ph.D. dissertation proposals last year. [link] [2025. 03] [Tutorial] Rishov and Stefan ran a successful tutorial about LightningSim and HLSFactory at ISFPGA’25. Materials here! [2024. 10] [Talk] Callie gave a talk “Agile Hardware Development: Architectures and Tools” at Research Colloquium Lecture Series @ UW ECE. Greatly appreciate Prof. Ang Li’s hosting. [slides] [2024. 09] [Paper & Honor] Our paper “HLSFactory: A Framework Empowering High-Level Synthesis Datasets for Machine Learning and Beyond” (Stefan Abi-Karam, Rishov Sarkar, Allison Seigler, Sean Lowe, Zhigang Wei, Hanqiu Chen, Nanditha Rao, Lizy John, Aman Arora, Cong Hao, collaborated with ASU and UT Austin teams), is accepted by MLCAD’24 and also won the Best Paper Award! [paper] [document] [code] [2024. 04] [Paper] Our paper “LightningSimV2: Faster and Scalable Simulation for High-Level Synthesis via Graph Compilation and Optimization” (Rishov Sarkar, Rachel Paul, Cong Hao) is accepted by FCCM’24. [2024.03] [Honor] Callie is awarded the NSF CAREER Award. All credits go to Callie’s brilliant students, collaborators, and colleagues! [link] [2024. 03] [Paper] Our paper “ICGMM: CXL-enabled Memory Expansion with Intelligent Caching Using Gaussian Mixture Model” (collaborated with Samsung and Duke) is accepted by DAC’24. 2023 [2023. 12] [Talk] Callie gave a keynote talk “Ultra-Low-Latency Graph Neural Networks: Applications and Implementations” at the GTA3 workshop. [slides] [2023.09] [Honor] Callie is selected for the Intel® Rising Star Faculty Award (RSA). Thank you to all of Callie’s brilliant students and fantastic collaborators and colleagues! [link] [link] [2023.09] [Honor] Our work GNNBuilder, led by Stefan Abi-Karam, is awarded the FPL Community Award at FPL’23! It recognizes major open-source contributions that will affect the FPGA community for years [paper] [code] [link] [2023.07] [Paper] Three papers accepted by ICCAD’23. “INR-Arch: A Dataflow Architecture and Compiler for Arbitrary-Order Gradient Computations in Implicit Neural Representation Processing“, Stefan Abi-Karam, Rishov Sarkar, Dejia Xu, Zhiwen Fan, Zhangyang Wang, Cong Hao “Edge-MoE: Memory-Efficient Multi-Task Vision Transformer Architecture with Task-level Sparsity via Mixture-of-Experts“, Rishov Sarkar, Hanxue Liang, Zhiwen Fan, Zhangyang Wang, Cong Hao [paper] [code] “Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural Representation“, Hanqiu Chen, Hang Yang, Stephen BR Fitzmeyer, Cong Hao [paper] [2023. 07] [Talk] Callie gave an invited talk “Smart Reconfigurable Computing for GNNs and Transformers + Smart HLS tool LightningSim” at the ROAD4NN workshop @ DAC’23. [slides] [2023. 05] [Paper] Our paper “GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization” (Stefan Abi-Karam, Cong Hao) is accepted by FPL’23. [paper] [code] [2023.05] [Honor] Our paper LightningSim, led by Rishov Sarkar, is awarded Best Paper Runner-up at FCCM’23! [paper] [code] [link] [2023.03] [Paper] Two papers accepted by FCCM’23. “LightningSim: Fast and Accurate Trace-Based Simulation for High-Level Synthesis“, Rishov Sarkar, Cong Hao “DGNN-Booster: A Generic FPGA Accelerator Framework For Dynamic Graph Neural Network Inference“, Hanqiu Chen, Cong Hao (short paper) [2023.02] [Talk] Callie gave an invited talk “Smart Reconfigurable Computing for GNN and Transformer” at NCSU ECE Colloquia. [slides] [2023. 01] [Paper] Our paper “PreAxC: Error Distribution Prediction for Approximate Computing Quality Control using Graph Neural Networks” (Lakshmi Sathidevi, Abhinav Sharma, Nan Wu, Xun Jiao, Cong Hao) has been accepted by ISQED’23. 2022 [2022. 11] [Paper] Our paper “M5: Multi-modal Multi-Task Model Mapping on Multi-FPGA with Accelerator Configuration Search” (Akshay Karkal Kamath, Stefan Abi-Karam, Ashwin Bhat and Cong Hao) is accepted by DATE’23. [2022. 10] [Paper] Our paper “FlowGNN: A Dataflow Architecture for Real-Time Workload-Agnostic Graph Neural Network Inference” (Rishov Sarkar, Stefan Abi-Karam, Yuqi He, Lakshmi Sathidevi, Cong Hao) is accepted by HPCA’23. [code] [paper] [2022. 10] [Paper] Our paper “Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and GPU” (Hanqiu Chen, Yihan Jiang, Yahya AlHinai, Eunjee Na, Cong Hao) is accepted by IISWC’22. [code] [paper] [2022. 09] [Paper] Two papers accepted by NeurIPS’22. “Unsupervised Learning for Combinatorial Optimization with Principled Objective Design“, Haoyu Peter Wang, Nan Wu, Hang Yang, Cong Hao, Pan Li “M3ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design“, Hanxue Liang, Zhiwen Fan, Rishov Sarkar, Ziyu Jiang, Tianlong Chen, Kai Zou, Yu Cheng, Cong Hao, Zhangyang Wang [2022. 09] [Paper] One paper “Data-Model-Circuit Tri-design for Ultra-light Video Intelligence on Edge Devices“ (Yimeng Zhang, Akshay Karkal Kamath, Qiucheng Wu, Zhiwen Fan, Wuyang Chen, Zhangyang Wang, Shiyu Chang, Sijia Liu, Cong Hao) is accepted by ASP-DAC’22. [2022. 08] [Honor] Our Ph.D. student Rishov Sarkar is awarded Qualcomm Innovation Fellowship together with Zhiwen Fan (supervised by Prof. Atlas Wang) from UT Austin. There are only 19 awardees from over 100+ teams, and Rishov is the only awardee from Georgia Tech! Big congrats and thanks to our collaborators, Zhiwen and Prof. Wang! [medium] [2022. 08] [Honor] Our Ph.D. student Rishov Sarkar is awarded CRNCH Ph.D. Fellowship from Georgia Tech. [2022. 07] [Honor + Talk] Our Ph.D. student Rishov Sarkar won third place in the “University Demo Best Demonstration” at DAC’22! Big congrats! Rishov delivered a really cool demo for a multi-task vision transformer on FPGA. Callie gave a bunch of talks and tutorials (stop bragging!) More details can be found here: [medium] [2022. 06] [Paper] Our invited paper “Robotic Computing on FPGAs: Current Progress, Research Challenges, and Opportunities” at AICAS’22 is online now. [pdf]. Many thanks to our lead author Zishen Wan and collaborators! [2022. 06] [Paper] Our paper “RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation” has been accepted by MICCAI’22. Many thanks to our collaborators, Qing Lv and Prof. Yiyu Shi. [2022. 05] [Paper] Our preprint “FlowGNN: A Dataflow Architecture for Universal Graph Neural Network Inference via Multi-Queue Streaming” is online now. [pdf] [2022. 05] [Paper] Our journal paper, “IronMan-Pro: Multi-objective Design Space Exploration in HLS via Reinforcement Learning and Graph Neural Network based Modeling“, has been accepted by IEEE TCAD. Congratulations to my c",
  "content_length": 18042,
  "method": "requests",
  "crawl_time": "2025-12-01 12:55:04"
}