{
  "name": "Lawrence Rauchwerger",
  "homepage": "https://parasollab.web.illinois.edu/people/rwerger",
  "status": "success",
  "content": "Home Page for Lawrence Rauchwerger | Parasol Laboratory Lawrence Rauchwerger Professor Parasol Laboratory url: http://parasollab.web.illinois.edu/~rwerger/ Siebel School of Computing and Data Science email: University of Illinois at Urbana-Champaign office: 4114 Siebel Center Urbana, IL 61801, USA tel: (217) 244-0968 CV (pdf) Research Projects Publications PACT 2011 PACT 2007 LCPC 2017 LCPC 2003 Publications (incomplete list) Position: It Is Time We Test Neural Computation In Vitro, Frithjof Gressmann, Ashley Chen, Lily Hexuan Xie, Nancy M. Amato, Lawrence Rauchwerger , Proceedings of the 42nd International Conference on Machine Learning, Vol: 267, pp. 81393-81409, Jul 2025. DOI: PMLR 267:81393-81409Keywords: Computational Biology, Machine LearningLinks : [Published] [Talk] BibTex@InProceedings{pmlr-v267-gressmann25a, title = \t {Position: It Is Time We Test Neural Computation In Vitro}, author = {Gressmann, Frithjof and Chen, Ashley and Xie, Lily Hexuan and Amato, Nancy and Rauchwerger, Lawrence}, booktitle = \t {Proceedings of the 42nd International Conference on Machine Learning}, pages = \t {81393--81409}, year = \t {2025}, editor = \t {Singh, Aarti and Fazel, Maryam and Hsu, Daniel and Lacoste-Julien, Simon and Berkenkamp, Felix and Maharaj, Tegan and Wagstaff, Kiri and Zhu, Jerry}, volume = \t {267}, series = \t {Proceedings of Machine Learning Research}, month = \t {13--19 Jul}, publisher = {PMLR}, pdf = \t {https://raw.githubusercontent.com/mlresearch/v267/main/assets/gressmann25a/gressmann25a.pdf}, url = \t {https://proceedings.mlr.press/v267/gressmann25a.html}, abstract = \t {Recent advances in bioengineering have enabled the creation of biological neural networks in vitro, significantly reducing the cost, ethical hurdles, and complexity of experimentation with genuine biological neural computation. In this position paper, we argue that this trend offers a unique and timely opportunity to put our understanding of neural computation to the test. By designing artificial neural networks that can interact and control living neural systems, it is becoming possible to validate computational models beyond simulation and gain empirical insights to help unlock more robust and energy-efficient next-generation AI systems. We provide an overview of key technologies, challenges, and principles behind this development and describe strategies and opportunities for novel machine learning research in this emerging field. We also discuss implications and fundamental questions that could be answered as this technology advances, exemplifying the longer-term impact of increasingly sophisticated in vitro neural networks.} }AbstractRecent advances in bioengineering have enabled the creation of biological neural networks in vitro, significantly reducing the cost, ethical hurdles, and complexity of experimentation with genuine biological neural computation. In this position paper, we argue that this trend offers a unique and timely opportunity to put our understanding of neural computation to the test. By designing artificial neural networks that can interact and control living neural systems, it is becoming possible to validate computational models beyond simulation and gain empirical insights to help unlock more robust and energy-efficient next-generation AI systems. We provide an overview of key technologies, challenges, and principles behind this development and describe strategies and opportunities for novel machine learning research in this emerging field. We also discuss implications and fundamental questions that could be answered as this technology advances, exemplifying the longer-term impact of increasingly sophisticated in vitro neural networks. A primer on in vitro biological neural networks, Frithjof Gressmann, Ashley Chen, Lily Hexuan Xie, Sarah Dowden, Nancy Amato, Lawrence Rauchwerger, NeurIPS 2024 Workshop Machine Learning with new Compute Paradigms, Vancouver, Canada, Dec 2024. Keywords: Machine Learning, Scientific ComputingLinks : [Published] [Manuscript] BibTex@inproceedings{gressmann_primer_2024, title = {A Primer on in Vitro Biological Neural Networks}, author = {Gressmann, Frithjof and Chen, Ashley and Xie, Lily Hexuan and Dowden, Sarah and Amato, Nancy and Rauchwerger, Lawrence}, date = {2024-10-17}, url = {https://openreview.net/forum?id=RdFI2ogt1j}, urldate = {2024-11-04}, eventtitle = {{{NeurIPS}} 2024 {{Workshop Machine Learning}} with New {{Compute Paradigms}}}, langid = {english} } AbstractRecent advances in bioengineering have enabled the creation of biological neural networks in vitro, raising the prospect of novel, unconventional platforms that can leverage genuine biological computation. The technology could help unlock computing paradigms that could be faster, more powerful, and more energy efficient than the silicon-based architectures that dominate today's computing landscape. However, engineering cell cultures for computing applications presents a radical departure from digital von Neumann architectures that computer scientists have grown accustomed to and will require a rethink of the entire stack. Here, we provide a brief overview of the key technologies, principles, and challenges of this emerging interdisciplinary field. We argue that seizing on its potential will require the development of new machine-learning approaches that can process the vast observable activity of neuronal cell cultures and learn to control and make sense of their neural code. Such an effort could provide a pathway for leveraging biological neural networks and contribute to our understanding of what makes biological learning in neurons so incredibly efficient, holding broader lessons for the development of next-generation AI systems. Generating memory allocators from the ground up, Pavlo Pastaryev, Charith Mendis, Lawrence Rauchwerger, In Languages and Compilers for Parallel Programming, LCPC, Lexington, Kentucky, USA, Oct 2023. Keywords: Code Generation, Dynamic Memory Allocation, Profile-Guided OptimizationLinks : [Published] BibTex@article{rauchwergergenerating, title={Generating memory allocators from the ground up}, author={Pastaryev, Pavlo and Mendis, Charith and Rauchwerger, Lawrence} }AbstractGeneral-purpose memory allocators are made to perform well on average for any given program. They thus make decisions which can benefit a broad set of applications and can miss out on possible optimizations. When a given general-purpose allocator does not fit the needs of a program, the developer has a choice of either switching to a different allocator or writing a custom one from scratch. Both options can be quite costly, and can still fail to satisfy the developerâs requirements. We propose a different approach to memory allocation: allocators are automatically generated from the ground up for any given program and optimized for the needed metric. We outline metrics of allocator performance, present a taxonomy of single-threaded memory allocators, and a framework for generating custom allocators based on the taxonomy. We show that allocators generated in such way can match or outperform general-purpose allocators and that different applications benefit from different components of our taxonomy.Provably Optimal Parallel Transport Sweeps on Semi-Structured Grids, Michael P. Adams, Marvin L. Adams, W. Daryl Hawkins, Timmie G. Smith, Lawrence Rauchwerger, Nancy M. Amato, Teresa S. Bailey, Robert D. Falgout, Adam Kunen, Peter Brown, Journal of Computational Physics, Vol: 407, Apr 2020. DOI: 10.1016/j.jcp.2020.109234Keywords: Parallel Algorithms, Scientific ComputingLinks : [Published] BibTex@article{DBLP:journals/jcphy/AdamsAHSRABFKB20, author = {Michael P. Adams and Marvin L. Adams and W. Daryl Hawkins and Timmie G. Smith and Lawrence Rauchwerger and Nancy M. Amato and Teresa S. Bailey and Robert D. Falgout and Adam Kunen and Peter Brown}, title = {Provably optimal parallel transport sweeps on semi-structured grids}, journal = {J. Comput. Phys.}, volume = {407}, pages = {109234}, year = {2020}, url = {https://doi.org/10.1016/j.jcp.2020.109234}, doi = {10.1016/j.jcp.2020.109234}, timestamp = {Fri, 27 Mar 2020 14:16:32 +0100}, biburl = {https://dblp.org/rec/journals/jcphy/AdamsAHSRABFKB20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }AbstractWe have found provably optimal algorithms for full-domain discrete-ordinate transport sweeps on a class of grids in 2D and 3D Cartesian geometry that are regular at a coarse level but arbitrary within the coarse blocks. We describe these algorithms and show that they always execute the full eight-octant (or four-quadrant if 2D) sweep in the minimum possible number of stages for a given Px x Py x Pz partitioning. Computational results confirm that our optimal scheduling algorithms execute sweeps in the minimum possible stage count. Observed parallel efficiencies agree well with our performance model. Our PDT transport code has achieved approximately 68% parallel efficiency with > 1.5M parallel threads, relative to 8 threads, on a simple weak-scaling problem with only three energy groups, 10 direction per octant, and 4096 cells/core. We demonstrate similar efficiencies on a much more realistic set of nuclear-reactor test problems, with unstructured meshes that resolve fine geometric details. These results demonstrate that discrete-ordinates transport sweeps can be executed with high efficiency using more than 106 parallel processes.Bounded Asynchrony and Nested Parallelism for Scalable Graph Processing, Adam Fidel, Nancy M. Amato, Lawrence Rauchwerger, In Proc. Supercomputing (SC), Doctoral Showcase Poster, Denver, CO, Nov 2017. Keywords: Approximate Algorithms, Parallel Graph Algorithms, STAPLLinks : [Published] BibTexN/AAbstractProcessing large-scale graphs has become a critical component in a variety of fields, from scientific computing to social analytics. The irregular access pattern for graph workloads, coupled with complex graph structures and large data",
  "content_length": 189968,
  "method": "requests",
  "crawl_time": "2025-12-01 13:46:05"
}