{
  "name": "Hassan Sajjad 0001",
  "homepage": "https://hsajjad.github.io",
  "status": "success",
  "content": "Hassan Sajjad Search Hassan Sajjad Associate Professor Faculty of Computer Science, Dalhousie University, Halifax, Canada About me I am a Faculty member in the Faculty of Computer Science and Director of HyperMatrix at Dalhousie University, Halifax, Canada. I am an AI researcher with domain expertise in Natural Language Processing and Safe and Trustworthy AI. Moreover, I am a consultant and a mentor blended with entrepreneurial interests. Research Interest I work on developing AI systems that are Safe, Reliable, and Trustworthy. My research addresses fundamental questions that enable AI models to achieve these attributes. A few of the research topics that my group is working on are: Language generation, interpretability and explainability, generalization and robustness, open weight model safety, model editing and steering, compositionality, conformal prediction and LLM agents Recent News Papers 2025 Conference: 2 papers (ICML), 3 papers (NeurIPs, ICLR, EMNLP) Workshop: 3 (TAIG @ICML, LockLLM @NeurIPS, WiNLP @EMNLP) Journal: 1 IJMIR Accepted Papers 2024: 2 papers (NeurIPs), 2 papers (NAACL), 2 papers (EMNLP) Accepted Papers 2023: 3 conference papers (NeurIPS, ICLR, ACL), 1 Journal (JMLR), 3 demo papers (AAAI, ACL, EACL) Service Area chair: NeurIPS 2025/24/23, ARR 2025⁄24, EMNLP 2023 Senior PC: AAAI 2025 Tutorial chair: EMNLP 2023 Reviewer: ICML 2025, TACL Talks Latent Concept-Based Explanation of NLP Models. Workshop on Decoding Decisions: Explainability in ML & Sequential Decision Making, CVPR (May 2025) Navigating Latent Space for Safety, Interpretability and Explainability. New York University Abu Dhabi (May 2025) Are LLMs a Good Model of Human Thought? The Challenge of Compositional Learning. Atlantic Canada AI Summit (May 2025) Latent Space Exploration for Safe and Trustworthy AI Models. Representation learning for NLP at ACL (Aug. 2024) (Keynote) Latent Space Exploration for Safe and Trustworthy AI Models. MBZUAI, Abu Dhabi (Aug. 2024) Latent Space Exploration for Safe and Trustworthy AI Models. AI@Thomson Reuters (Apr. 2024) Latent Concept based Explanation of Deep Learning Models. MBZUAI, Abu Dhabi (Nov. 2023) Latent Concepts in Transformer Models of NLP. UKP, TU Darmstadt, Germany (Jun. 2023) Knowledge Manifolds in Transformer Models of NLP, National Research Council (NRC), Canada (Apr. 2023) Knowledge Manifolds in Transformer Models of NLP, University of Ottawa, Canada (Apr. 2023) Misc NeuroX Toolkit on pip: https://pypi.org/project/neurox/ SugarCrepe++ Dataset: https://huggingface.co/datasets/Aman-J/SugarCrepe_pp} See all previous information here: News, Talks, Publications Cite × Copy Download",
  "content_length": 2651,
  "method": "requests",
  "crawl_time": "2025-12-01 13:19:06"
}