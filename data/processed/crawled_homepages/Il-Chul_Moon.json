{
  "name": "Il-Chul Moon",
  "homepage": "https://aai.kaist.ac.kr",
  "status": "success",
  "content": "카이스트 응용인공지능 연구실 Time-Efficient Weapon-Target Assignment by Actor-Critic Reinforcement Automatic Calibration Framework of Agent-Based Models for Dynamic and Heterogeneous Parameters Modeling and Calibrating Digital Twin of Automatic Garbage Collection System in Sejong City Training Unbiased Diffusion Models From Biased Dataset Label-Noise Robust Diffusion Models Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy Label Learning Unknown Domain Inconsistency Minimization for Domain Generalization Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning Frequency Domain-based Dataset Distillation SAAL: Sharpness-Aware Active Learning Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models This paper proposes a time-efficient model for solving the Weapon-target assignment (WTA) problem with actorcritic reinforcement learning. While typical heuristic algorithms and recently studied artif… Agent-based models (ABMs) highlight the importance of simulation validation, such as qualitative face validation and quantitative empirical validation. In particular, we focused on quantitative valida… In recent years, developing a digital twin for a complex system has been a key research effort in the modeling and simulation (M&S) community. This paper presents one of the digital twin systems for a… With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important. Since generated outputs directly suffer from dataset bias, mitigating … Conditional diffusion models have shown remarkable performance in various generative tasks, but training them requires large-scale datasets that often contain noise in conditional inputs, a.k.a. noisy… For learning with noisy labels, the transition matrix, which explicitly models the relation between noisy label distribution and clean label distribution, has been utilized to achieve the statistical … The objective of domain generalization (DG) is to enhance the transferability of the model learned from a source domain to unobserved domains. To prevent overfitting to a specific domain, Sharpness-Aw… In cooperative multi-agent reinforcement learning (MARL), agents aim to achieve a common goal, such as defeating enemies or scoring a goal. Existing MARL algorithms are effective but still require sig… This paper presents FreD, a novel parameterization method for dataset distillation, which utilizes the frequency domain to distill a small-sized synthetic dataset from a large-sized original dataset. … While deep neural networks play significant roles in many research areas, they are also prone to overfitting problems under limited data instances. To overcome overfitting, this paper introduces the f… The proposed method, Discriminator Guidance, aims to improve sample generation of pre-trained diffusion models. The approach introduces a discriminator that gives explicit supervision to a denoising s… 1 Announcements 20 2099.03 Application to AAILab, KAIST AAILab은 KAIST 산업및시스템공학과, 항공우주공학과(겸임교원 TO, 사전상담필요), AI대학원(KAIST 장학생, 사전상담필요), 데이터사이언스대학원을 통해서 진학할 수 있… 2099.03.20 04 2025.09 [Award] ITRC Challenge 2025 창의도전상(AWS) 수상 연구실 Zeynep, 이석범, 김영민 학생들이 ITRC Challenge 2025에서 창의도전상을 수상하였습니다. 학생들은 'AI-to-Drone'이라는 제목으로 AI기반의 군집드… 2025.09.04 18 2025.02 [Award] 나병후 박사, 공과대학 박사학위 최우수논문상 수상 연구실 졸업생인 나병후 박사가 \"박사학위 최우수논문상\"을 수여받았습니다. 공과대학의 박사학위 최우수논문상은 공과대학장 명의의 상으로 학과에서 추천받은 \"공과대학 우수논문상\" 수상대… 2025.02.18 17 2025.02 [Award] 나형호 박사, Global Leadership Award 수상 나형호 박사가 그동안의 이론적인 연구, 현실적인 프로젝트 공헌을 인정받아 이광형 총장님에게 Global Leadership Award를 받았습니다.나형호 박사는 8년간의 ADD근무… 2025.02.17 Selected Publications Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models Neural Information Processing Systems (NeurIPS 2025) Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models Neural Information Processing Systems (NeurIPS 2025) Preference Optimization by Estimating the Ratio of the Data Distribution Neural Information Processing Systems (NeurIPS 2025) Diffusion Bridge AutoEncoders for Unsupervised Representation Learning International Conference on Learning Representations (ICLR 2025) 상단으로",
  "content_length": 4198,
  "method": "requests",
  "crawl_time": "2025-12-01 13:22:50"
}