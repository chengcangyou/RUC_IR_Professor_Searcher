{
  "name": "Alina Oprea",
  "homepage": "http://www.ccs.neu.edu/home/alina",
  "status": "success",
  "content": "Alina Oprea - Professor - Northeastern University Professor, Khoury College of Computer Sciences I am a Professor at Northeastern University in the Khoury College of Computer Sciences. I obtained a BS in Mathematics and Computer Science from University of Bucharest, Romania in 2000, and MS and PhD in Computer Science from Carnegie Mellon University in 2003 and 2007, respectively. I joined Northeastern University in Fall 2016 after spending 9 years as a Research Scientist at RSA Laboratories. I am the recipient of the Technology Review TR35 award for research in cloud security in 2011, the Google Security and Privacy Award in 2019, and the CMU Cylab Distinguished Alumni Award in 2024. I was on sabbatical at Google Research during the 2022-2023 academic year. I co-direct the Network and Distributed Systems Security (NDS2) Lab together with Cristina Nita-Rotaru. Office: 177 Huntington Ave. Office 516, Boston, MA, 02115 Email: a.oprea@northeastern.edu ðŸ“š Google Scholar ðŸ’¼ LinkedIn ðŸ“„ Resume Research My research interests are broadly at the intersection of AI and cyber security, with a focus on: Adversarial machine learning and trustworthy AI: In collaboration with NIST, we created a comprehensive taxonomy of attacks and mitigations in adversarial ML. Security architectures for LLM agents: We introduced a security architecture for LLM-integrated applications and a system for governing AI agents. Privacy in machine learning: We introduced privacy auditing, a method to empirically estimate the privacy leakage of an ML model that complements theoretical upper bounds on privacy. AI for automating cyber defense: We designed several ML systems for proactive threat detection (Beehive, MADE, PORTFILER, CELEST) and a Hierarchical Multi-Agent Reinforcement Learning System for automating cyber defense. Cloud security: We designed an auditing framework that enables cloud tenants to verify the integrity, freshness, and availability of data stored in the cloud. Publications New Papers and Manuscripts R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model Ali Naseh, Harsh Chaudhari, Jaechul Roh, Mingshi Wu, Alina Oprea, Amir Houmansadr arXiv 2025 arXiv DROP: Poison Dilution via Knowledge Distillation for Federated Learning Georgios Syros, Anshuman Suri, Farinaz Koushanfar, Cristina Nita-Rotaru, Alina Oprea arXiv 2025 arXiv UTrace: Poisoning Forensics for Private Collaborative Learning Evan Rose, Hidde Lycklama, Harsh Chaudhari, Anwar Hithnawi, Alina Oprea arXiv 2024 arXiv Phantom: General Trigger Attacks on Retrieval Augmented Language Generation Harsh Chaudhari, Giorgio Severi, John Abascal, Matthew Jagielski, Christopher A. Choquette-Choo, Milad Nasr, Cristina Nita-Rotaru, Alina Oprea arXiv 2024 arXiv Conference and Journal Publications Exploiting Leaderboards for Large-scale Distribution of Malicious Models Anshuman Suri, Harsh Chaudhari, Yuefeng Peng, Ali Naseh, Amir Houmansadr, Alina Oprea IEEE Security and Privacy Symposium 2026 arXiv SAGA: A Security Architecture for Governing AI Agentic Systems Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea NDSS 2026 arXiv ACE: A Security Architecture for LLM-Integrated App Systems Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru NDSS 2026 arXiv CELEST: Federated Learning for Globally Coordinated Threat Detection Talha Ongun, Simona Boboila, Alina Oprea, Tina Eliassi-Rad, Jason Hiser, Jack W. Davidson IEEE Transactions of Information Forensics and Security (TIFS) 2025 arXiv Paper Cascading Adversarial Bias from Injection to Distillation in Language Models Harsh Chaudhari, Jamie Hayes, Matthew Jagielski, Ilia Shumailov, Milad Nasr, Alina Oprea ACM CCS 2025 arXiv Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation Ali Naseh, Yuefeng Peng, Anshuman Suri, Harsh Chaudhari, Alina Oprea, Amir Houmansadr ACM CCS 2025 arXiv PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense Xavier Cadet, Simona Boboila, Sie Hendrata Dharmawan, Alina Oprea, Peter Chin GameSec 2025 arXiv Paper Model-agnostic clean-label backdoor mitigation in cybersecurity environments Giorgio Severi, Simona Boboila, John Holodnak, Kendra Kratkiewicz, Rauf Izmailov, Alina Oprea MILCOM 2025 arXiv Quantitative Resilience Modeling for Autonomous Cyber Defense Xavier Cadet, Simona Boboila, Edward Koh, Peter Chin, Alina Oprea Reinforcement Learning Conference (RLC) 2025 arXiv Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense Aditya Vikram Singh, Ethan Rathbun, Emma Graham, Lisa Oakley, Simona Boboila, Peter Chin, Alina Oprea Reinforcement Learning Conference (RLC) 2025 arXiv Adversarial Inception for Bounded Backdoor Poisoning in Deep Reinforcement Learning Ethan Rathbun, Alina Oprea, Christopher Amato ICML 2025 arXiv SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents Ethan Rathbun, Christopher Amato, Alina Oprea NeurIPS 2024 arXiv Paper Code User Inference Attacks on Large Language Models Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu EMNLP 2024 arXiv Paper Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model Counting. Lisa Oakley, Steven Holzen, Alina Oprea IEEE Computer Security Foundations Symposium (CSF) 2024 arXiv Paper Code Backdoor Attacks in Peer-to-Peer Federated Learning Georgios Syros, Gokberk Yar, Simona Boboila, Cristina Nita-Rotaru, Alina Oprea. ACM TOPS 2024 arXiv Paper TMI! Finetuned Models Leak Private Information from their Pretraining Data John Abascal, Stanley Wu, Alina Oprea, Jonathan Ullman. In Privacy Enhancing PETS 2024 arXiv Paper Code One-shot Empirical Privacy Estimation for Federated Learning Galen Andrew, Peter Kairouz, Sewoong Oh, Alina Oprea, H. Brendan McMahan, Vinith Suriyakumar. ICLR 2024, Oral arXiv Paper Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning Harsh Chaudhari, Giorgio Severi, Alina Oprea, Jonathan R. Ullman ICLR 2024 arXiv Paper Code Dropout Attacks Andrew Yuan, Alina Oprea, Cheng Tan. IEEE Symposium on Security and Privacy 2024 arXiv Paper Code Unleashing the Power of Randomization in Auditing Differentially Private ML Krishna Pillutla, Galen Andrew, Peter Kairouz, H. Brendan McMahan, Alina Oprea, Sewoong Oh NeurIPS 2023 arXiv Paper Code Poisoning Network Flow Classifiers Giorgio Severi, Simona Boboila, Alina Oprea, John Holodnak, Kendra Kratkiewicz, Jason Matterer ACSAC 2023 arXiv Paper Code Modeling Self-Propagating Malware with Epidemiological Models Alesia Chernikova, Nicolo Gozzi, Nicola Perra, Simona Boboila, Tina Eliassi-Rad, Alina Oprea. Applied Network Science 2023 arXiv Paper Attacking Neural Binary Function Detection Joshua Bundt, Michael Davinroy, Ioannis Agadakos, Alina Oprea, William Robertson RAID 2023 arXiv Paper FL4IoT: IoT Device Fingerprinting and Identification Using Federated Learning. Han Wang, David Eklund, Alina Oprea, and Shahid Raza ACM Transactions on Internet of Things (TOIT) 2023 arXiv How to Combine Membership-Inference Attacks on Multiple Updated Models Matthew Jagielski, Stanley Wu, Alina Oprea, Jonathan Ullman, Roxana Geambasu PETS 2023 arXiv Paper SNAP: Efficient Extraction of Private Properties with Poisoning Harsh Chaudhari, John Abascal, Alina Oprea, Matthew Jagielski, Florian TramÃ¨r, Jonathan R. Ullman IEEE Symposium on Security and Privacy 2023 arXiv Paper Code Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning Antonio Emanuele CinÃ , Kathrin Grosse, Ambra Demontis, Sebastiano Vascon, Werner Zellinger, Bernhard A Moser, Alina Oprea, Battista Biggio, Marcello Pelillo, Fabio Roli ACM Computing Surveys 2023 arXiv Paper SafeNet: The Unreasonable Effectiveness of Ensembles in Private Collaborative Learning Harsh Chaudhari, Matthew Jagielski, Alina Oprea. IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2023 arXiv Paper A Recent Year On the Internet: Measuring and Understanding the Threats to Everyday Internet Devices Afsah Anwar, Yi Hui Chen, Roy Hodgman, Tom Sellers, Engin Kirda, Alina Oprea ACSAC 2022 Paper Poisoning Attacks Against Machine Learning: Can Machine Learning Be Trustworthy? Alina Oprea, Anoop Singhal, and Apostol Vassilev IEEE Computer 2022 Paper Network-Level Adversaries in Federated Learning Giorgio Severi, Matthew Jagielski, Gokberk Yar, Yuxuan Wang, Alina Oprea, Cristina Nita-Rotaru IEEE Conference on Communications and Network Security (CNS) 2022 arXiv Paper Code Cyber Network Resilience against Self-Propagating Malware Attacks Alesia Chernikova, NicolÃ² Gozzi, Simona Boboila, Priyanka Angadi, John Loughner, Matthew Wilden, Nicola Perra, Tina Eliassi-Rad, Alina Oprea ESORICS 2022 arXiv Paper Code FENCE: Feasible Evasion Attacks on Neural Networks in Constrained Environments Alesia Chernikova, Alina Oprea ACM Transactions of Privacy and Security (TOPS) 2022 arXiv Paper Adversarial Robustness Verification and Attack Synthesis in Stochastic Systems Lisa Oakley, Alina Oprea, Stavros Tripakis IEEE Computer Security Foundations Symposium (CSF) 2022 arXiv Paper Code Subpopulation Data Poisoning Attacks Matthew Jagielski, Giorgio Severi, Niklas Pousette-Harger, Alina Oprea ACM CCS 2021 arXiv Paper Code Poisoning Attacks and Data Sanitization Mitigations for Machine Learning Models in Network Intrusion Detection Systems Sridhar Venkatesan, Harshvardhan Sikka, Rauf Izmailov, Ritu Chadha, Alina Oprea, Michael J. De Lucia MILCOM 2021 Paper PORTFILER: Port-Level Network Profiling for Self-Propagating Malware Detection Talha Ongun, Oliver Spohngellert, Benjamin Miller, Simona Boboila, Alina Oprea, Tina Eliassi-Rad, Jason Hiser, Alastair Nottingham, Jack Davidson, Malathi Veeraraghavan IEEE Conference on Communications and Network Security (CNS) 2021 arXiv Paper Living-Off-The-Land Command Detection Using Active Learning Talha Ongun, Jay Stokes, Jonathan Bar Or, Ke Tian, Farid Tajaddodianfar, Joshua Neil, C",
  "content_length": 23969,
  "method": "requests",
  "crawl_time": "2025-12-01 12:54:44"
}