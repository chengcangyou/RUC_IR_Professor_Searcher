{
  "name": "Chao Zhang 0014",
  "homepage": "http://chaozhang.org",
  "status": "success",
  "content": "Chao Zhang Chao Zhang Table of Contents Research 1. Post-Training for LLM Agents 2. Safe and Trustworthy AI 3. Data Evaluation and Benchmarks 4. AI for Scientific Discovery 5. Previous Projects Awards Publications 2025 2024 2023 2022 2021 2020 2019 2018 Earlier Students Quick Links Google Scholar James Edenfield Associate Professor School of Computational Science and Engineering College of Computing Georgia Institute of Technology Office: CODA E1358B Address: 756 W Peachtree St NW, Atlanta, GA 30308 Email: chaozhang@gatech.edu Research My research lies in the areas of data science, machine learning, and AI. My goal is to build advanced large language models and AI agents for complex task-solving and decision-making. My technical efforts center on addressing key challenges in data efficiency, computation efficiency, and model robustness. On the application front, I am deeply interested in harnessing foundation models to advance AI for science. Currently, I am working on the following themes: LLM Post-Training Data and Algorithms for Agents – Developing efficient post-training methods for adapting and fine-tuning LLMs to create intelligent agents that can learn from experience, interact with environments, and improve their reasoning and agentic capabilities. AI Safety and Trustworthy AI – Facilitating responsible and reliable deployment of AI systems through critical techniques including uncertainty quantification, enhancing LLM factuality, improving LLM alignment, and developing robust methods for building trustworthy AI agents. Datasets, Evaluation, and Benchmarks – Creating comprehensive evaluation frameworks, datasets, and benchmarks for assessing AI system performance, particularly focusing on agent capabilities, reasoning abilities, and real-world task completion across diverse domains. AI for Scientific Discovery – Developing foundation models and AI agents to accelerate scientific discovery, with applications in diverse fields such as time series analysis, material science, biomedical and life sciences. Acknowledgment: My work has been generously supported by research funding/gift from NSF (IIS CAREER-2144338, IIS-2106961, IIS-2008334), ONR MURI , Kolon, HomeDepot, ADP, and Adobe. My work has also been recognized by an NSF CAREER Award, a Facebook Faculty Award, an Amazon AWS Machine Learning Research Award, a Google Faculty Research Award, a Kolon Faculty Fellowship, an ACM SIGKDD Dissertation Runner-up Award, and several paper awards from IMWUT (UbiComp), ECML/PKDD, and ML4H. 1. Post-Training for LLM Agents We investigate improving LLM reasoning and agentic abilities by enabling them to evolve through interaction with external environments for feedback. The goal is to better adapt LLMs and enhance their reasoning and agentic capabilities through efficient post-training data collection and algorithmic innovations. Adapting LLM Agents with Universal Feedback Through Communication, NAACL'25 Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training, NAACL'25 BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models, ICML'24 ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search, ICLR'24 AdaPlanner: Adaptive Planning from Feedback with Language Models, NeurIPS'23 2. Safe and Trustworthy AI We aim to develop AI systems that are not only capable but also trustworthy for deployment in various domains. We study LLM factuality (e.g., RAG, agentic search), uncertainty, and alignment. Self-Generated Critiques Boost Reward Modeling for Language Models, NAACL'25 Aligning Large Language Models with Representation Editing: A Control Perspective, NeurIPS'24 RankRAG: Unifying Retrieval-Augmented Generation and Context Ranking in LLMs, NeurIPS'24 ARL2: Aligning Retrievers with Black-box Large Language Models via Self-guided Adaptive Relevance Labeling, ACL'24 Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias, NeurIPS'23 Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution Data, EMNLP'20 3. Data Evaluation and Benchmarks We develop new datasets, benchmarks, and evaluation protocols for training and assessing LLM performance, with particular focus on agent capabilities, reasoning abilities, and real-world task completion. MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering, arXiv'25 Time-MMD: A New Multi-Domain Multimodal Dataset for Time Series Analysis, NeurIPS'24 MUBen: Benchmarking the Uncertainty of Pre-Trained Models for Molecular Property Prediction, TMLR'24 POLYIE: A Dataset of Information Extraction from Polymer Material Scientific Literature, NAACL'24 ToolQA: A Dataset for LLM Question Answering with External Tools, NeurIPS'23 4. AI for Scientific Discovery We aim to leverage AI and foundation models for advancing scientific discovery. We develop domain-specific foundation models and LLM agents for different scientific domains. On the application side, we collaborate with domain-experts to advance scientific discovery in material design, biomedical and life science, and urban science: Efficient Evolutionary Search Over Chemical Space with Large Language Models, ICLR'25 LLMatDesign: Autonomous Materials Discovery with Large Language Models, preprint May the Force be with You: Unified Force-Centric Pre-Training for 3D Molecular Conformations, NeurIPS'23 Contrastive Fitness Learning: Reprogramming Protein Language Models for Low-N Learning of Protein Fitness Landscape, RECOMB'24 T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction, IEEE ITS'20 5. Previous Projects This section includes our previous work on weak supervision, active learning, and uncertainty quantification for language models and traditional machine learning tasks. Learning from Noisy Data and Weak Supervision: Our foundational work on addressing data scarcity challenges through weak supervision and noisy label learning for smaller language models and traditional NLP tasks. DyGen: Fine-Tuning Language Models with Noisy Labels by Dynamics-Enhanced Generative Modeling, KDD'23 Fine-Tuning Pre-trained Language Model with Weak Supervision, NAACL'21 Sparse Conditional Hidden Markov Model for Weakly Supervised Named Entity Recognition, KDD'22 Text Classification Using Label Names Only: A Language Model Self-Training Approach, EMNLP'20 BOND: Bert-Assisted Open-Domain Named Entity Recognition with Distant Supervision, KDD'20 Active Learning and Data Curation: Techniques for efficient data selection and curation to improve model performance with limited labeled data. Cold-start Data Selection for Better Few-shot Fine-tuning of Pretrained Language Models, ACL'23 PRBoost: Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning, ACL'22 AcTune: Uncertainty-Aware Active Self-Training for Active Fine-Tuning of Language Models, NAACL'22 Uncertainty Quantification for Deep Learning: Uncertainty-aware ML models are crucial for building trustworthy AI systems. Many deep learning models produce uncertainty-agnostic point estimates or miscalibrated distributions. We are addressing this issue by designing techniques for quantifying uncertainty in deep learning models. We also study decision-focused learning under uncertainty to make learning informed by downstream decision-making tasks. Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints, AISTATS'25 When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting, KDD'23 End-to-end Stochastic Programming with Energy-based Model, NeurIPS'22 When in Doubt: Neural Non-Parametric Uncertainty Quantification for Epidemic Forecasting, NeurIPS'21 SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates, ICML'20 Awards 2024 GaTech CoC Outstanding Junior Faculty Award 2022 NSF Career Award 2022 ML4H Outstanding Paper Award 2021 Facebook Faculty Research Award 2021 Kolon Faculty Fellowship 2020 Amazon AWS Machine Learning Research Award 2020 Google Faculty Research Award 2019 ACM SIGKDD Dissertation Award Runner-up 2018 ACM IMWUT Distinguished Paper Award 2015 ECML/PKDD Best Student Paper Runner-up Award 2013 Chiang Chen Overseas Graduate Fellowship Publications (* denotes equal contribution) 2025 MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering Rushi Qiang, Yuchen Zhuang, Yinghao Li, Dingu Sagar V K, Rongzhi Zhang, ChangHao Li, Ian Shu-Hei Wong, Sherry Yang, Percy Liang, Chao Zhang, Bo Dai arXiv, 2025 Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, Zheng Li, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2025 Adapting LLM Agents with Universal Communication Feedback Kuan Wang, Yadong Lu, Michael Santacroce, Yeyun Gong, Chao Zhang, Yelong Shen Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2025 Self-Generated Critiques Boost Reward Modeling for Language Models Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, Melanie Kambadur, Dhruv Mahajan, Rui Hou Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2025 LLM-Augmented Chemical Synthesis and Design Decision Programs Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, Chao Zhang International Conference on Machine Learning (ICML), 2025 Efficient Evolutionary Search Over Chemical Space with Large Language Models Haorui Wang, Marta Skreta, C",
  "content_length": 47023,
  "method": "requests",
  "crawl_time": "2025-12-01 12:50:19"
}