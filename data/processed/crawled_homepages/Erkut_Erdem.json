{
  "name": "Erkut Erdem",
  "homepage": "https://web.cs.hacettepe.edu.tr/~erkut",
  "status": "success",
  "content": "Erkut Erdem - Personal Web Page Erkut Erdem Home About Projects Publications Students Teaching Erkut Erdem Professor Computer Vision Laboratory (HUCVL) Dept. of Computer Engineering Hacettepe University Office: 112 Address: Beytepe Campus, Ankara, Turkey TR-06800 e-mail: erkut at cs dot hacettepe dot edu dot tr Phone: +90 312 297 7500 / 122 Fax: +90 (312) 297 7502 My research focuses on advancing computational methods for visual data analysis and modeling. Current research interests: Generative AI • Computer Vision • Language Understanding Hacettepe UniversityFaculty Member2010-now Ecole NationaleSupérieure des TélécommunicationsPost-doctoral Researcher2009-2010 Middle East Technical University1997-2008Ph.D., 2008M.Sc., 2003B.Sc., 2001 University of California Los AngelesVisiting ResearcherOct. 2007 - Dec. 2007 Virginia Bioinformatics Institute, Virginia TechVisiting ResearcherJul. 2004 - Aug. 2004 News and highlights So excited to announce that I am co-affiliated with Koç University and İş Bank Artificial Intelligence Center (KUIS AI) as a research fellow. I'm looking for motivated MSc/PhD students. Scholarships are available, please send me your CV if interested! [August 2025]: Our work on audio-visual saliency prediction in 360 degree videos will be published in IEEE Transactions on Pattern Analysis and Machine Intelligence. [June 2025]: Our work on efficient representation of videos got accepted to ICCV 2025. [November 2024]: Awarded funding from TUBITAK 2247-A - National Outstanding Researchers Program on generative AI approaches for healthcare and remote sensing. [September 2024]: Our work on diffusion-based object removal from images accepted to NeurIPS 2024. [September 2024]: Our work on a GAN-based unified framework for domain adaptation, image synthesis and manipulation accepted to SIGGRAPH Asia 2024. [March 2024]: Our work on sequential compositional generalization in multimodal models accepted to NAACL 2024. [February 2024]: Our work on video synthesis from events will be published in IEEE Transactions on Image Processing. [January 2024]: Our work on evaluating zero-shot linguistic and temporal understanding capabilities of video-language models accepted to ICLR 2024. older items Curriculum Vitae (as of September 2025) Projects As Principal Investigator Project Duration: 3 years (2025-2028) Sponsors: TUBITAK 2247-A - National Outstanding Researchers Program (Award# 123C542) project page Seeing Through Events: End-to-End Approaches to Event-Based Vision Under Extremely Low-Light Conditions Project Duration: 3 years (2022-2025) Sponsors: TUBITAK 1001 - Support Program for Scientific and Technological Research Projects (Award# 121E454) project page A Multimodal and Multilingual Framework for Video Captioning Project Duration: 2 years (2018-2020) Sponsors: TUBITAK and British Council - Newton-Katip Çelebi Fund Institutional Links Grant Programme (Award# 217E054) project page Using Synthetic Data for Deep Person Re-Identification Project Duration: 2 years (2018-2020) Sponsors: TUBITAK 1001 - Support Program for Scientific and Technological Research Projects (Award# 217E029) project page Understanding Images and Visualizing Text: Semantic Inference and Retrieval by Integrating Computer Vision and Natural Language Processing Project Duration: 3 years (2014-2017) Sponsors: TUBITAK 1001 - Support Program for Scientific and Technological Research Projects (Award# 113E116) and European Union under European Cooperation in Science and Technology (COST) Programme (ICT COST IC1037 Action) project page The Use of Multiple Cues and Contextual Knowledge in Computer Vision Project Duration: 3 years (2012-2015) Sponsors: TUBITAK 3501 - Career Development Program (Award# 112E146) project page As Co-Investigator Seeing the Invisible: End-to-End Approaches for Hyperspectral Image Enhancement and Synthesis Project Duration: 30 months (2023-2026) Sponsors: TUBITAK 1001 - Support Program for Scientific and Technological Research Projects (Award# 123E385) project page Quality Assessment of 360-Degree Videos Guided by Audio-Visual Saliency Project Duration: 3 years (2021-2024) Sponsors: TUBITAK 1001 - Support Program for Scientific and Technological Research Projects (Award# 120E501) project page Summarization Approaches Towards Interpreting Big Visual Data Project Duration: 3 years (2017-2020) Sponsors: TUBITAK 1003 - Primary Subjects R&D Funding Program (Award# 116E685) project page City-Wide Video Surveillance System Project Duration: 3 years (2016-2019) Sponsors: TUBITAK 1007 - Public Institutions Research Funding Program (Award# 114G028) project page Selected Publications ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models,I. Kesen, A. Pedrotti, M. Dogan, M. Cafagna, E. C. Acikgoz, L. Parcalabescu, I. Calixto, A. Frank, A. Gatt, A. Erdem, E. ErdemThe International Conference on Learning Representations (ICLR 2024),, Vienna, Austria, May 2024:: pdf:: project page VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs,M. H. Ali, A. Bond, T. Birdal, D. Ceylan, L. Karacan, E. Erdem, A. ErdemIEEE International Conference on Computer Vision (ICCV 2023),, Paris, France, October 2023:: pdf:: project page CLIP-Guided StyleGAN Inversion for Text-Driven Real Image Editing,A. C. Baykal, A. B. Anees, D. Ceylan, E. Erdem, A. Erdem, D. Yuret, ACM Transactions on Graphics, in press:: pdf:: project page CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions,T. Ates, M. S. Atesoglu, C. Yigit, I. Kesen, M. Kobas, E. Erdem, A. Erdem, T. Goksun, D. Yuret, Findings of ACL 2022:: pdf:: project page Burst Photography for Learning to Enhance Extremely Dark Images,A. S. Karadeniz, E. Erdem, A. Erdem, IEEE Transactions on Image Processing, Vol. 30, pp. 9372-9385, 2021:: pdf:: project page A Gated Fusion Network for Dynamic Saliency Prediction,A. Kocak, E. Erdem, A. Erdem, IEEE Transactions on Cognitive and Developmental Systems, accepted for publication:: pdf:: project page mustGAN: multi-stream Generative Adversarial Networks for MR Image Synthesis,M. Yurt, S. UH Dar, A. Erdem, Erkut Erdem, K. K. Oguz, T. Cukur, Medical Image Analysis, Vol. 70, May 2021:: pdf Cross-lingual Visual Pre-training for Multimodal Machine Translation,O. Caglayan, M. Kuyu, M. S. Amac, P. Madhyastha, E. Erdem, A. Erdem, L. Specia, The 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021):: pdf:: project page (with data and code) Belief Regulated Dual Propagation Nets for Learning Action Effects on Articulated Multi-Part Objects, A. E. Tekden, A. Erdem, E. Erdem, M. Imre, M. Y. Seker, and E. Ugur, International Conference on Robotics and Automation (ICRA) 2020, Paris, France, May-June 2020:: pdf:: project page:: video Manipulating Attributes of Natural Scenes via Hallucination,L. Karacan, Z. Akata, A. Erdem and E. Erdem, ACM Transactions on Graphics, accepted for publication, 2019 :: pdf:: project page (with code) Procedural Reasoning Networks for Understanding Multimodal Procedures, M.S. Amac, S. Yagcioglu, A. Erdem, and E. Erdem, The SIGNLL Conference on Computational Natural Language Learning (CoNLL), Hong Kong, November 2019 :: pdf:: project page (with code) Image Synthesis in Multi-Contrast MRI with Conditional Generative Adversarial Networks, S. U. H. Dar, M. Yurt, L. Karacan, A. Erdem, E. Erdem, T. Cukur, IEEE Transactions on Medical Imaging, Vol. 38, No.10, pp. 2375-2388, October 2019:: pdf RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes, S. Yagcioglu, A. Erdem, E. Erdem, and N. Ikizler-Cinbis, Conference on Empirical Methods in Natural Language Processing (EMNLP) 2018, Brussels, Belgium, October-November 2018:: pdf:: project page (with data and leaderboard) Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction, C. Bak, A. Kocak, E. Erdem and A. Erdem, IEEE Transactions on Multimedia, 20(7). pp. 1688-1698, July 2018. :: pdf Image Synthesis in Multi-Contrast MRI with Conditional Generative Adversarial Networks, S. U. H. Dar, M. Yurt, L. Karacan, A. Erdem, E. Erdem, T. Cukur, arXiv preprint arXiv:1802.01221, February 2018 :: pdf Alpha Matting with KL-Divergence Based Sparse Sampling, L. Karacan, A. Erdem and E. Erdem, IEEE Transactions on Image Processing, 26(9), pp. 4523-4536, September 2017 :: pdf Re-evaluating Automatic Metrics for Image Captioning,M. Kilickaya, A. Erdem, N. Ikizler-Cinbis and E. Erdem, The 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2017), Valencia, Spain, April 2017 :: pdf An Objective Deghosting Quality Metric for HDR Images, O. T. Tursun, A. O. Akyuz, A. Erdem and E. Erdem, Computer Graphics Forum (Eurographics 2016), 35(2), pp. 139-152, May 2016:: project page (with code):: pdf Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures,R. Bernardi, R. Cakici, D. Elliott, A. Erdem, E. Erdem, N. Ikizler-Cinbis, F. Keller, A. Muscat, B. Plank, Journal of Artificial Intelligence Research, 55, pp. 409-442, February 2016:: pdf Image Matting with KL-Divergence Based Sparse Sampling,L. Karacan, A. Erdem and E. Erdem, IEEE International Conference on Computer Vision (ICCV 2015),, Santiago, Chile, December 2015 :: project page:: pdf The State of the Art in HDR Deghosting: A Survey and Evaluation,O. T. Tursun, A. O. Akyuz, A. Erdem and E. Erdem, Computer Graphics Forum (Eurographics State-of-the-art Report (STAR) 2015), 34(2), pp. 683-707, May 2015 :: pdf Structure Preserving Image Smoothing via Region Covariances,L. Karacan, E. Erdem and A. Erdem, ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2013), Vol. 32, No. 6, November 2013 :: project page (with code):: pdf Visual saliency estimation by nonlinearly integrating features using region covariances,E. Erdem and A. Erdem, Journal of Vision, Vol. 13, No. 4, pp. 1-20, March 2013 :: project page (with code):: pdf For a full list of publications, pl",
  "content_length": 12030,
  "method": "requests",
  "crawl_time": "2025-12-01 13:07:37"
}