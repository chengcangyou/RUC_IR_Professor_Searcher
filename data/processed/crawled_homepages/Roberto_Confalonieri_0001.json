{
  "name": "Roberto Confalonieri 0001",
  "homepage": "http://www.inf.unibz.it/~rconfalonieri",
  "status": "success",
  "content": "[ Roberto Confalonieri @ UNIPD ] Short Bio Roberto Confalonieri is Associate Professor at the Department of Mathematics of the University of Padua. Prior to that he was Assistant Professor in Computer Science at the Free University of Bozen-Bolzano, and Senior Research Scientist in AI and XAI team lead at Alpha, the first European Moonshot projects company funded by Telefonica Research, working on explainable models of Artificial Intelligence in the health domain. Prior to that he was Project Manager and Researcher at the Smart Data Factory, a technology transfer centre of the Faculty of Computer Science of UniBZ, where he acquired and directed several research projects and collaborations with industries. Roberto received his Ph.D. in Artificial Intelligence (with distinction) from the Polytechnic University of Catalonia (2011), and a M.Sc. in Computer Science from the University of Bologna. He has worked both in industry and in academia, as R&D engineer, assistant professor, and as postdoctoral researcher in several research institutions in Europe (UPC BarcelonaTech, University of Barcelona, IRIT, Goldsmiths College, IIIA-CSIC). Roberto is the PI of 2 research projects (one European); he participated in 4 European projects, and in a number of (Italian) national projects and collaborations with industries. He has published around 50 peer-reviewed articles in AI top conferences (IJCAI, AAAI, ECAI) and journals (AIJ, EAAI, AMAI). He co-edited the book Concept Invention: Foundations, Implementation, Social Aspects and Applications published by Springer in 2018. He is associate editor of the Cognitive Systems Research journal published by Elsevier. He is co-editing the special issue on The Role of Ontologies and Knowledge in Explainable AI to be published in the Semantic Web Journal published by IOS Press. Roberto organised a number of scientific events: he was co-chair of an invited symposium at CogSci 2019, of the series of International workshops of Methods for Interpretation of Industrial Event Logs (MIEL @IDEAL 2018, MIEL @BPM 2019), and Data meets Applied Ontologies (DAO @JOWO 2017, DAO-SI @JOWO 2019), and of C3GI 2018. He is currently organising the 3rd International Workshop on Data Meets Applied Ontologies in Explainable AI (DAO-XAI 2021). He will be the local chair of the 13th International Conference on Computational Creativity (ICCC 2022), to be held in Bolzano. He regularly serves in a number of programme committees as PC and Senior PC member (IJCAI, AAAI, ECAI), and as a reviewer for a number of conferences and journals on AI and ML. Research Interests His primary research interests include Artificial Intelligence, particularly Trustworthy and Explainable AI, and Knowledge Representation and Applied Ontologies, Deep Learning, particularly Computer Vision, and Hyper-spectral Images, and Computational Creativity, particularly Concept Invention, and Concept Evaluation, and Concept Refinement. Academic Curriculum Vitae Get My CV » News Best Paper Award! Our paper Almost certain termination for ALC weakening has been awarded as best paper at the 21st EPIA Conference on Artificial Intelligence. IEEE CIM 2021 Our paper recoXplainer: A Library for Development and Offline Evaluation of Explainable Recommender Systems has been accepted for publication in the IEEE Computational Intelligence Magazine. Speaker at the South Tyrol Free Software Conference - SFSConf 2021 Hyper-spectral image classification for wood recognition. AAAI 2022 Senior PC member of the 36th AAAI Conference on Artificial Intelligence. IJCAI 2022 Member of the novel Program Committee Board, to serve in the PC of IJCAI-ECAI 22, IJCAI 23, and IJCAI 24. IJCAI 2021 Our AIJ publication Using ontologies to enhance human understandability of global post-hoc explanations of black-box models has been accepted for presentation in the Journal Paper Track at the 30th International Joint Conference on Artificial Intelligence (IJCAI-21), August 19 - 26 2021, Virtual Conference. Chair of the Workshop Hyperspectral Images for Inspection Applications in the context of the homonymous EFRE/FESR Project H2I. Guest Editor of the Special Issue The Role of Ontologies and Knowledge in Explainable AI in the Semantic Web Journal published by IOS press. FUZZ-IEEE 2021 Our paper A Framework for Analyzing Fairness, Accountability, Transparency and Ethics: A Use-case in Banking Services has been accepted at the IEEE International Conf. on Fuzzy Systems 2021: Handling Uncertainty in Interpretable Artificial Intelligence, July 11 - 14 2021, Virtual Conference. Chair of the 3rd Edition of the International Workshop on Data Meets Applied Ontologies in Explainable AI . AIJ 2021 Journal paper accepted for publication in AIJ. Our paper Using ontologies to enhance human understandability of global post-hoc explanations of Black-box models has been accepted for publication in the Artificial Intelligence journal. AAAI 2021 Tutorial Accepted: RecoXplainer: An Extensible Toolkit for Explainable Recommender Systems with Ludovik Coba and Markus Zanker. Distinguished Paper Award! Our paper Trepan Reloaded: A knowledge-driven Approach to Explaining Black-box models has been nominated as distinguished paper at ECAI 2020. IJCAI 2021 Senior PC member of the 30th International Joint Conference on Artificial Intelligence. Ass. Editor I have joined the Editorial Board of the Cognitive Systems Research journal published by Elsevier. Selected Projects 2020-2022 Principal Investigator of the project H2I: Hyper-spectral images for the inspection of wood and fruits, EFRE/FESR research project of the Faculty of Computer Science of UniBZ. 2019-2021 Principal Investigator of the project recoXplainer: A Library for Development and Offline Evaluation of Explainable Recommender Systems. 2017-2018 Project manager and Researcher at the Smart Data Factory, the technology transfer lab of the Faculty of Computer Science of UniBZ. 2016-2018 Investigator in the CoCo: Computational Technologies for Concept Invention research project, funded by UniBZ, CRC Call 2016. 2014-2016 Post-doctoral researcher in the COINVENT: Concept Invention Theory European project, funded by the European Commission, under the ICT STREP programme. 2011-2013 Post-doctoral researcher in the ACE: Autonomic Software Engineering for online cultural experiences, European project, funded by the European Commission, under the CHIST-ERA programme. A comprehensive list of the research projects in which I participated can be found in my CV. Courses 2021/22 Advanced Topics in Machine Learning, Master in Computational Data Science, Lectures and Labs. Faculty of Computer Science, UniBZ. 2021/22 Discrete Mathematics, Bachelor in Computer Science, Exercises, Labs. Faculty of Computer Science, UniBZ. 2020/21 Advanced Topics in Machine Learning, Master in Computational Data Science, Lectures and Labs. Faculty of Computer Science, UniBZ. 2020/21 Discrete Mathematics, Bachelor in Computer Science, Exercises, Labs. Faculty of Computer Science, UniBZ. 2019/20 Programming Project, Bachelor in Computer Science, Exercises, Labs. Faculty of Computer Science, UniBZ. 2019/20 Web and Internet Engineering, Bachelor in Computer Science and Bachelor in Informatics and Management of Digital Businesses, Exercises, Labs. Faculty of Computer Science, UniBZ. 2019/20 Answer Set Programming, Modulo de Razonamiento automÃ¡tico, MÃ¡ster universitario en investigaciÃ³n en inteligencia artificial, Universidad Internacional MenÃ©ndez Pelayo. 2016/17 Introduction to Programming, Bachelor in Engineering in Computer Science, Exercises, Labs, University of Barcelona. The list of courses I teach at UNIBZ can be found here. Available Thesis: here. Thesis' proposals × 1. Comparison of different types of explanations and their impact on the user Ethical and legal considerations play a central role in the deployment of Artificial Intelligence systems. These include data privacy requirements (e.g., as set out in GDPR) and accountability (e.g., GDPR's \"right to explain\"). It is therefore crucial to develop frameworks that allow for automatic learning with minimal access to a user's data, while at the same time being able to provide a user-friendly justification for any decision or recommendation made by an ML/DL system. Explainable IA aims at shading the decisions taken by the ML/DL black boxes. While a plethora of approaches have been proposed and developed to generate post-hoc explanations of black boxes for ML/DL, there is not yet a clear understanding and agreement on what properties make explanations good. This thesis will focus on the analysis of the different forms of explanation proposed in the social and cognitive science literature, and automatic learning. The aim of this thesis is, on the one hand, to compile a systematic review of the literature. On the other hand, the aim is to develop a user study that evaluates the different forms of explanation, as well as their impact on user comprehensibility. Finally, to propose which are the properties that make a good explanation. 2. Generation and reasoning with semantic explanations Ethical and legal considerations play a central role in the deployment of Artificial Intelligence systems. These include data privacy requirements (e.g., as set out in GDPR) and accountability (e.g., GDPR's \"right to explain\"). It is therefore crucial to develop frameworks that allow for automatic learning with minimal access to a user's data, while at the same time being able to provide a user-friendly justification for any decision or recommendation made by an ML/DL system. The explainable IA aims at shading the decisions taken by the ML/DL black boxes. While a plethora of approaches have been proposed and developed to generate post-hoc explanations of ML/DL black boxes, only a few of them take into account knowledge coded in the form of logical knowledge bases, ontologies and/or knowledge graphs to associate meaningful semantics to these explanations. ",
  "content_length": 14116,
  "method": "requests",
  "crawl_time": "2025-12-01 14:19:19"
}