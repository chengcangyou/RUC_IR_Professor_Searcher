{
  "name": "Haipeng Luo",
  "homepage": "https://haipeng-luo.net",
  "status": "success",
  "content": "Haipeng Luo Haipeng Luo Home Awards Biography CV Research Publications Group Codes Teaching Courses Haipeng Luo IBM Early Career Chair and Associate Professor Thomas Lord Department of Computer Science University of Southern California Office: GCS 402N Email: haipengl@usc.edu About me I am an associate professor in the Thomas Lord Department of Computer Science at the University of Southern California. Previously I spent one year at Microsoft Research, NYC as a postdoctoral researcher. I obtained my PhD from Princeton University, where I was fortunate enough to be advised by Rob Schapire and also to work closely with Elad Hazan. I received my bachelor degree at Peking University working with Professor Zhen Xiao. I am also currently a Google Visiting Faculty Researcher. Previously I was an Amazon Visiting Academic. Research interests My research interest is in developing practical machine learning algorithms with strong theoretical guarantees, with a focus on online learning bandit problems reinforcement learning learning in games calibration and omniprediction See below for some of my representative papers (a full list can be found here or at Google Scholar). Representative Papers [NeurIPS 2025 Spotlight] Comparator-Adaptive Î¦-Regret: Improved Bounds, Simpler Algorithms, and Applications to Games. Soumita Hait, Ping Li, Haipeng Luo, and Mengxiao Zhang. [NeurIPS 2025 Spotlight] Simultaneous Swap Regret Minimization via KL-Calibration. Haipeng Luo, Spandan Senapati, and Vatsal Sharan. [NeurIPS 2023] No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. Tiancheng Jin, Junyan Liu, ChloÃ© Rouyer, William Chang, Chen-Yu Wei, and Haipeng Luo. [NeurIPS 2022] Near-Optimal No-Regret Learning for General Convex Games. Gabriele Farina, Ioannis Anagnostides, Haipeng Luo, Chung-Wei Lee, Christian Kroer, and Tuomas Sandholm. [COLT 2021 Best Paper Award] Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-box Approach. Chen-Yu Wei and Haipeng Luo. [NeurIPS 2021 Oral] The Best of Both Worlds: Stochastic and Adversarial Episodic MDPs with Unknown Transition. Tiancheng Jin, Longbo Huang, and Haipeng Luo. [NeurIPS 2020 Oral] Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs. Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, and Mengxiao Zhang. [COLT 2018 Best Student Paper Award] Logistic Regression: The Importance of Being Improper. Dylan J. Foster, Satyen Kale, Haipeng Luo, Mehryar Mohri, and Karthik Sridharan. [COLT 2018] More Adaptive Algorithms for Adversarial Bandits. Chen-Yu Wei and Haipeng Luo. [COLT 2017] Corralling a Band of Bandit Algorithms. Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, and Robert E. Schapire. [NeurIPS 2015 Best Paper Award] Fast Convergence of Regularized Learning in Games. Vasilis Syrgkanis, Alekh Agarwal, Haipeng Luo, and Robert E. Schapire. [ICML 2015 Best Paper Award] Optimal and Adaptive Algorithms for Online Boosting. Alina Beygelzimer, Satyen Kale, and Haipeng Luo. [COLT 2015] Achieving All with No Parameters: AdaNormalHedge. Haipeng Luo and Robert E. Schapire. Page generated 2025-09-18 13:22:51 PDT, by jemdoc.",
  "content_length": 3173,
  "method": "requests",
  "crawl_time": "2025-12-01 13:17:23"
}