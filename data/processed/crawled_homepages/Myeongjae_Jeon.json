{
  "name": "Myeongjae Jeon",
  "homepage": "https://sites.google.com/site/myeongjae",
  "status": "success",
  "content": "Myeongjae JeonSearch this siteEmbedded FilesSkip to main contentSkip to navigationResearch Team: OMNIAEmail: mj.jeon_at_postech.ac.krI am an associate professor in the Computer Science and Engineering Department and Graduate School of Artificial Intelligence at POSTECH. Previously, I was an associate professor at UNIST and a visiting professor in the DeepSpeed team at Microsoft. Prior to joining UNIST in 2018 fall, I spent several years in industry with Systems Research Group at Microsoft Research (2015 - 2018) and with Systems Research Group at the ARM Research (2014 - 2015). My prior research work has been deployed in several production systems in Microsoft, including Bing search engine, Open Platform for AI (OpenPAI), and Azure telemetry monitoring system, bringing real-world impacts from systems research.  Currently at POSTECH, I focus on AI systems, real-time big data analytics, and systems for new HW, with my team members at OMNIA Lab.I finished my Ph.D. in Computer Science at Rice University in May 2014, under the supervision of Prof. Alan L. Cox and Prof. Scott Rixner. During my Ph.D. I actively collaborated with Dr. Yuxiong He and Dr. Sameh Elnikety through four internships at Microsoft Research. I received the M.S. degree in computer science from KAIST and the B.E. degree in computer engineering from Kwangwoon University. I won the Best Paper Awards from ICDE 2022 and SYSTOR 2016 and was selected twice as a Meta Faculty Research Award Finalist in 2020 and 2022.I am looking for self-motivated and hard-working students and currently have openings for undergraduate internships and graduate-level studies. If you're interested in building system platforms for AI & big data processing, cloud computing, and various emerging hardware, please reach out by introducing yourself (with your CV and transcript). I highly encourage prospective graduate students to consider an internship with us \"before\" applying to POSTECH. NewsJul. 2025    Serving as the PC at PPoPP'26Mar. 2025    Serving as the PC at NAIC'25Feb. 2025    Serving as the PC at MICRO'25Jan. 2025    Serving as the PC at ASPLOS'26Nov. 2024    Serving as the General Chair at APSys'25Sep. 2024    Serving as the PC at ICDCS'25 (Distributed Systems for AI/ML track)Aug. 2024    Joined POSTECH as an Associate ProfessorMay 2024    Serving as the PC at HPCA'25Feb. 2024    Serving as the PC at APSys'24Dec. 2023    Serving as the PC at ICDCS'24 (AI/ML for Distributed Systems track)Sep. 2023    Serving as the PC at SYSTOR'24May 2023    Giving a talk on systems for on-device continual learning at POSTECH and Ajou U seminarsOct. 2022    My research team and myself are featured in UNIST magazine (link)Oct. 2022    Serving as the PC at ICDCS'23 (AI for Systems and Systems for AI track)Sep. 2022     Selected as a Facebook Faculty Research Award finalistMay 2022    Received Best Paper Award from ICDE'22 (news)Apr. 2022    Giving a talk on systems for continual learning and ML data augmentation at LG AI Research LabFeb. 2022    Giving a talk on streaming analytics with adaptive near-data processing at Computer System SocietyOct. 2021    Serving as the PC at ICDCS'22 (ML on or for Distributed Systems track)Oct. 2021    Serving as a vice session chair at SOSP'21 (Learning track)Sep. 2021    Selected as one of 7 AI research labs by Kakao Brain (We are the only lab in AI systems: news)Nov. 2020    Serving as the PC at ICDCS'21 (ML on or for Distributed Systems track)Jul. 2020     Selected as a Facebook Faculty Research Award finalistApr. 2020    Giving a talk on our ML systems research at Samsung Electronics (for Data & IT center)Jan. 2020    Serving as the PC at ICDCS'20 (Distributed & Federated Learning track)Oct. 2019    Attending Rice CS 35th Anniversary as a panel speaker for \"The Role of Programming Systems while Hardware Specialization is Exploding\" with Kathryn, Mary, Dan, and Felix TeachingComputer architecture 2023 fall, 2021 fallOperating systems 2021 spring, 2020 springParallel computing 2022 fall, 2019 springData structure 2020 fall, 2019 fall, 2018 fallBig data systems (graduate) 2021 fallAI systems (graduate) 2024 fall, 2022 fall, 2020 fall, 2019 springPublicationsGaren: Reliable Cluster Management with Atomic State ReconciliationMingi Kim, Ahnjae Shin, Jaewoo Maeng, Myeongjae Jeon, Byung-Gon ChunEuroSys, Apr. 2026 [PDF]Carbon-Aware Continuous Learning for Sustainable Real-Time Machine Learning AnalyticsGwanjong Park, Osama Khan, Dongho Ha, Myeongjae Jeon, Euiseong SeoEuroSys, Apr. 2026 [PDF]REP: Resource-Efficient Prompting for Rehearsal-Free Continual LearningSungho Jeon, Xinyue Ma, Kwang In Kim, Myeongjae JeonNeurIPS, Dec. 2025 [PDF]Training-Free Exponential Context Extension via Cascading KV CacheJeffrey Willette, Heejun Lee, Youngwan Lee, Myeongjae Jeon, Sung Ju HwangICLR, Apr. 2025 [PDF]A Training-Free Sub-quadratic Cost Transformer Model Serving Framework with Hierarchically Pruned AttentionHeejun Lee, Geon Park, Youngwan Lee, Jaduk Suh, Jina Kim, Wonyong Jeong, Bumsik Kim, Hyemin Lee, Myeongjae Jeon, Sung Ju HwangICLR, Apr. 2025 [PDF]FusionFlow: Accelerating Data Preprocessing for Machine Learning with CPU-GPU CooperationTaeyoon Kim, Chanho Park, Mansur Mukimbekov, Heelim Hong, Minseok Kim, Ze Jin, Changdae Kim, Ji-Yong Shin, Myeongjae JeonVLDB, Aug. 2024 [PDF]Metis: Fast Automatic Distributed Training on Heterogeneous GPUsTaegeon Um, Byungsoo Oh, Minyoung Kang, Woo-Yeon Lee, Goeun Kim, Dongseob Kim, Youngtaek Kim, Mohd Muzzammil, Myeongjae JeonUSENIX ATC, Jul. 2024 [PDF]Blaze: Holistic Caching for Iterative Data ProcessingWon Wook Song, Jeongyoon Eo, Taegeon Um, Myeongjae Jeon, Byung-Gon ChunEuroSys, Apr. 2024 [PDF]Cost-effective On-device Continual Learning over Memory Hierarchy with MiroXinyue Ma, Suyeon Jeong, Minjia Zhang, Di Wang, Jonghyun Choi, Myeongjae JeonACM MobiCom, Oct. 2023 [PDF][Slides][Code]Sponge: Fast Reactive Scaling for Stream Processing with Serverless FrameworksWon Wook Song, Taegeon Um, Sameh Elnikety, Myeongjae Jeon, Byung-Gon ChunUSENIX ATC, Jul. 2023 [PDF][Slides][Code]EnvPipe: Performance-preserving DNN Training Framework for Saving EnergySangjin Choi, Inhoe Koo, Jeongseob Ahn, Myeongjae Jeon, Youngjin KwonUSENIX ATC, Jul. 2023 [PDF][Slides][Code]SWAN: WAN-aware Stream Processing on Geographically-distributed ClustersWon Wook Song, Myeongjae Jeon, Byung-Gon ChunACM APSys, Aug. 2022 [PDF]Sibylla: To Retry or Not To Retry on Deep Learning Job FailureTaeyoon Kim, Suyeon Jeong, Jongseop Lee, Soobee Lee, Myeongjae JeonUSENIX ATC, Jul. 2022 [PDF][Slides][Talk]Memory Harvesting in Multi-GPU Systems with Hierarchical Unified Virtual MemorySangjin Choi, Taeksoo Kim, Jinwoo Jeong, Rachata Ausavarungniurn, Myeongjae Jeon, Youngjin Kwon, Jeongsub AhnUSENIX ATC, Jul. 2022 [PDF][Slides][Talk][Code]CarM: Hierarchical Episodic Memory for Continual LearningSoobee Lee, Minindu Weerakoon, Jonghyun Choi, Minjia Zhang, Di Wang, Myeongjae JeonDAC, Jul. 2022 [PDF][PDF(extended)][Code]Jarvis: Large-scale Server Monitoring with Adaptive Near-data ProcessingAtul Sandur, ChanHo Park, Stavros Volos, Gul Agha, Myeongjae JeonIEEE ICDE, May 2022 (Best Paper) [PDF][PDF(extended)][Code]Streaming Analytics with Adaptive Near-data ProcessingAtul Sandur, ChanHo Park, Stavros Volos, Gul Agha, Myeongjae JeonEMDC, Apr. 2022 [PDF] (Invited paper)Zico: Efficient GPU Memory Sharing for Concurrent DNN TrainingGangmuk Lim, Jeongseob Ahn, Wencong Xiao, Youngjin Kwon, Myeongjae JeonUSENIX ATC, Jul. 2021 [PDF][Talk][Slides][Code/Benchmark]Reliability of Large-scale GPU Clusters for Deep Learning WorkloadsJunjie Qian, Taeyoon Kim, Myeongjae JeonEMDC, Apr. 2021 [PDF] (Invited paper)Approximate Quantiles for Datacenter Telemetry MonitoringGangmuk Lim, Mohamed Hassan, Ze Jin, Stavros Volos, Myeongjae JeonIEEE ICDE, Apr. 2020 [PDF] [PDF(extended)][Talk][Slides] (Short paper)Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training WorkloadsMyeongjae Jeon, Shivaram Venkataraman, Amar Phanishayee, Junjie Qian, Wencong Xiao, Fan YangUSENIX ATC, Jul. 2019 [PDF][Slides][Talk][Trace]StreamBox-HBM: Stream Analytics on High Bandwidth Hybrid MemoryHongyu Miao, Myeongjae Jeon, Gennady Pekhimenko, Kathryn S. McKinley, Felix Xiaozhu LinASPLOS, Apr. 2019 [PDF][Talk][Slides][Code]Tiresias: A GPU Cluster Manager for Distributed Deep LearningJuncheng Gu, Mosharaf Chowdhury, Kang G. Shin, Yibo Zhu, Myeongjae Jeon, Junjie Qian, Hongqiang Liu, Chuanxiong GuoNSDI, Feb. 2019 [PDF][Talk][Slides][Simulator]Accelerated Training for CNN Distributed Deep Learning through Automatic Resource-Aware Layer PlacementJay H. Park, Sunghwan Kim, Jinwon Lee, Myeongjae Jeon, Sam H. NohPreprint, Jan. 2019 [PDF]TerseCades: Efficient Data Compression in Stream ProcessingGennady Pekhimenko, Chuanxiong Guo, Myeongjae Jeon, Peng Huang, Lidong ZhouUSENIX ATC, Jul. 2018 [PDF][Slides]StreamBox: Modern Stream Processing on a Multicore MachineHongyu Miao, Heejin Park, Myeongjae Jeon, Gennady Pekhimenko, Kathryn S. McKinley, Felix Xiaozhu LinUSENIX ATC, Jul. 2017 [PDF][Slides][Code]SSD Failures in Datacenters: What, When and Why?Iyswarya Narayanan, Di Wang, Myeongjae Jeon, Bikash Sharma, Laura Caulfield, Anand Sivasubramaniam, Ben Cutler, Jie Liu, Badriddine Khessib, Kushagra VaidACM SIGMETRICS / IFIP Performance, Jun. 2016 [PDF] (Poster)ACM SYSTOR, Jun. 2016 (Best Student Paper) [PDF]TPC: Target-Driven Parallelism Combining Prediction and Correction to Reduce Tail Latency in Interactive ServicesMyeongjae Jeon, Yuxiong He, Hwanju Kim, Sameh Elnikety, Scott Rixner, Alan L. CoxASPLOS, Apr. 2016 [PDF][Slides]Predictive Parallelization: Taming Tail Latencies in Web SearchMyeongjae Jeon, Saehoon Kim, Seung-Won Hwang, Yuxiong He, Sameh Elnikety, Alan L. Cox, Scott RixnerACM SIGIR, Jul. 2014 [PDF][Slides(pptx)]Reducing DRAM Row Activations with Eager Read/Write ClusteringMyeongjae Jeon, Conglong Li, Alan L. Cox, Scott RixnerACM Transactions on Architecture and Code Optimization (TACO), Dec. 2013 [PDF]Adaptive Parallelism ",
  "content_length": 11524,
  "method": "requests",
  "crawl_time": "2025-12-01 14:02:31"
}