{
  "name": "Gunhee Kim",
  "homepage": "https://vision.snu.ac.kr/gunhee",
  "status": "success",
  "content": "Gunhee Kim @ SNU CSE Home Publication Software Teaching Gunhee Kim, PhD (김건희) Professor @ Vision and Learning Lab Department of Computer Science and Engineering, Integrative Data Science, School of Transdisciplinary Innovations, Interdisciplinary Program in AI, Seoul National University (SNU) CEO and Founder @ RippleAI Email: gunhee at snu.ac.kr or gunhee at rippleai.co Administrative Assistant: Euimi Hong (euimi.hong at vision.snu.ac.kr) [Curriculum Vitae] [Google Scholar] What's new? In 2026, we have 2 AAAI papers. In 2025, we have 1 NeurIPS (Spotlight), 2 EMNLP (2 Main), 2 ICCV, 3 ACL (2 Main, 1 Findings), 1 ICML, 2 CVPR, 2 NAACL (2 Oral) and 3 ICLR papers. In 2024, we have 2 NeurIPS, 2 EMNLP, 1 IEEE TPAMI, 1 TMLR, 2 ECCV (1 Oral), 4 ACL (2 Main, 2 Findings), 1 ICML, 1 CVPR, and 1 ICLR papers. We won the two tracks of LSMDC 2019 LSMDC 2017, 2016 challenges (Annotation and Retrieval, and Fill-in-the-Blank) (October 23, 2017). I'm co-organizing 2nd workshop on Storytelling with Images and Videos (VisStory) along with LSMDC 2016 in ECCV 2016 (October 16, 2016). I won 2015 Naver New faculty award and 2014 SIGKDD doctoral dissertation award. [CMU Link] I opened vision and learning lab at Computer Science and Engineering of Seoul National University (Feb 2015). I was an Postdoctoral Researcher at Disney Research Pittsburgh (Sep 2013 - Jan 2015), and a visiting student at Stanford Vision Lab (Jan 2011 - Apr 2011) and MIT CSAIL (Jan 2009 - Mar 2009). (In Korean) 서울대 교수 지원하기. To Prospective students 인턴 및 대학원 지원자 상시 모집합니다: 자세한 사항은 먼저 이 문서를 읽기 바랍니다. For foreign students: Unless you are already in Korea with valid Korean visa and can work more than 6 months, it is very difficult for us to hire you as intern. Instead, I can accept 0–1 Korean government-funded foreign students [See details of KGSP]. 본 연구실에서 spin-off 스타트업 rippleAI 에서 part-time 및 full-time 개발자 상시 채용합니다. [링크] Education Ph.D. Computer Science Department, Carnegie Mellon University (August 2009 ~ September 2013) Advisor: Eric P. Xing, Committee: Takeo Kanade, Christos Faloutsos, Antonio Torralba Thesis: Reconstruction and Applications of Collective Storylines from Web Photos Collections M.S. The Robotics Institute, Carnegie Mellon University (September 2006 ~ May 2008) Adviors: Martial Hebert, Committee: Christos Faloutsos Thesis: Link Analysis Techniques for Object Modeling and Recognition B.S./M.S. Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST) Selected Projects MAVis: A Benchmark for Attributed Visual Question Answering with Multimodal Documents Seokwon Song, Minsu Park, and Gunhee Kim AAAI 2026 [code] [pdf] Gaussian Blending: Rethinking Alpha Blending in 3D Gaussian Splatting Junseo Koo, Jinseo Jeong, and Gunhee Kim AAAI 2026 [code] [pdf] Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span Heeseung Yun, Joonil Na, Jaeyeon Kim, Calvin Murdock, and Gunhee Kim NeurIPS 2025 (Spotlight) [code] [pdf] Think, Verbalize, then Speak: Bridging Complex Thoughts with Comprehensible Speech Sang Hoon Woo*, Sehun Lee*, Kang-wook Kim, Gunhee Kim EMNLP 2025 [code] [pdf] FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games Jaewoo Ahn*, Junseo Kim*, Heeseung Yun, Jaehyeon Son, Dongmin Park, Jaewoong Cho, Gunhee Kim EMNLP 2025 [code] [pdf] ChartCap: Mitigating Hallucination of Dense Chart Captioning Junyoung Lim, Jaewoo Ahn, and Gunhee Kim ICCV 2025 (Highlight) [code] [pdf] FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields Junhyeog Yun, Minui Hong, and Gunhee Kim ICCV 2025 [code] [pdf] Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates Jaewoo Ahn*, Heeseung Yun*, Dayoon Ko, and Gunhee Kim ACL 2025 [code] [pdf] LPOI: Listwise Preference Optimization for Vision Language Models Fatemeh Pesaran zadeh, Yoojin Oh, and Gunhee Kim ACL 2025 [code] [pdf] When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting Out-of-Distribution Corpora Using GradNormIR Dayoon Ko, Jinyoung Kim, Sohyeon Kim, Jinhyuk Kim, Jaehoon Lee, Seonghak Song, Minyoung Lee, Gunhee Kim ACL 2025 (Findings) [code] [pdf] How to Move Your Dragon: Text-To-Motion Synthesis For Large-Vocabulary Objects Wonkwang Lee, Jongwon Jeong, Taehong Moon, Hyeon-Jong Kim, Jaehyeon Kim, Gunhee Kim, Byeong-Uk Lee ICML 2025 [code] [pdf] HalLoc: Token-level Localization of Hallucinations for Vision Language Models Eunkyu Park, Minyeong Kim, Gunhee Kim CVPR 2025 [code] [pdf] ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams Chris Dongjoo Kim, Jihwan Moon, Sangwoo Moon, Heeseung Yun, Sihaeng Lee, Aniruddha Kembhavi, Soonyoung Lee, Gunhee Kim, Sangho Lee, Christopher Clark CVPR 2025 [code] [pdf] Behavior-SD: Behaviorally Aware Spoken Dialogue Generation with Large Language Models Sehun Lee*, Kang-wook Kim*, and Gunhee Kim NAACL 2025 (Oral) [code] [pdf] SAC Award for Speech Processing and Spoken Language Understanding Is Peeled Apple Still Red? Evaluating LLM's Ability to Understand and Generate Conceptual Combination with Property Type Seokwon Song*, Taehyun Lee*, Jaewoo Ahn, Jae Hyuk Sung, and Gunhee Kim NAACL 2025 (Oral) [code] [pdf] ViSAGe: Video-to-Spatial Audio Generation Jaeyeon Kim, Heeseung Yun, and Gunhee Kim ICLR 2025 [code] [pdf] A longer version is accepted in IJCV Towards Scene-Aware Video-to-Spatial Audio Generation Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning Jaehyeon Son, Soochan Lee, and Gunhee Kim ICLR 2025 [code] [pdf] Meta-Continual Learning of Neural Fields Seungyoon Woo, Junhyeog Yun, and Gunhee Kim ICLR 2025 [code] [pdf] FedAvP: Augment Local Data via Shared Policy in Federated Learning Minui Hong, Junhyeog Yun, Insu Jeon, and Gunhee Kim NeurIPS 2024 [code] [pdf] Sample Selection via Contrastive Fragmentation for Noisy Label Regression Chris Dongjoo Kim*, Sangwoo Moon*, Jihwan Moon, Dongyeon Woo, and Gunhee Kim NeurIPS 2024 [code] [pdf] DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG Jinyoung Kim, Dayoon Ko, and Gunhee Kim EMNLP 2024[code] [pdf] Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback Fatemeh Pesaran zadeh, Juyeon Kim, Jin-Hwa Kim, and Gunhee Kim EMNLP 2024 (Oral) [code] [pdf] When Meta-Learning Meets Online and Continual Learning: A Survey Jaehyeon Son*, Soochan Lee*, and Gunhee Kim IEEE TPAMI 2024 [pdf] [arXiv] Meta-Learning Approach for Joint Multimodal Signals with Multimodal Iterative Adaptation Sehun Lee*, Wonkwang Lee* and Gunhee Kim TMLR 2024 [code] [pdf] Bi-directional Contextual Attention for 3D Dense Captioning Minjung Kim, Hyungsuk Lim, Soonyoung Lee, Bumsoo Kim, and Gunhee Kim ECCV 2024 (Oral) [pdf] Spherical World-Locking for Audio-Visual Localization in Egocentric Videos Heeseung Yun, Calvin Murdock, Ruohan Gao, Ishwarya Ananthabhotla, Anurag Kumar, Jacob Donley, Chao Li, Gunhee Kim, Vamsi Krishna Ithapu ECCV 2024 [pdf] GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge? Dayoon Ko, Jinyoung Kim, Hahyeon Choi, and Gunhee Kim ACL 2024 [code] [pdf] Who Wrote this Code? Watermarking for Code Generation Taehyun Lee*, Seokhee Hong*, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun, Jamin Shin, and Gunhee Kim ACL 2024 [code] [pdf] TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models Jaewoo Ahn, Taehyun Lee, Junyoung Lim, Jin-Hwa Kim, Sangdoo Yun, Hwaran Lee, and Gunhee Kim ACL 2024 (Findings) [code] [pdf] See It All: Contextualized Late Aggregation for 3D Dense Captioning Minjung Kim, Hyung Suk Lim, Seung Hwan Kim, Soonyoung Lee, Bumsoo Kim, and Gunhee Kim ACL 2024 (Findings) [pdf] Learning to Continually Learn with the Bayesian Principle Soochan Lee, Hyeonseong Jeon, Jaehyeon Son, and Gunhee Kim ICML 2024 [code] [pdf] ESR-NeRF: Emissive Source Reconstruction Using LDR Multi-view Images Jinseo Jeong, Junseo Koo, Qimeng Zhang, and Gunhee Kim CVPR 2024 [code] [pdf] Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning Yeda Song*, Dongwook Lee* and Gunhee Kim ICLR 2024 [code] [pdf] Can Language Models Laugh at YouTube Short-form Videos? Dayoon Ko, Sangho Lee, and Gunhee Kim EMNLP 2023 [code] [pdf] mRedditSum: A Multimodal Abstractive Summarization Dataset of Reddit Threads with Images Keighley Overbay, Jaewoo Ahn, Fatemeh Pesaran zadeh, Joonsuk Park and Gunhee Kim EMNLP 2023 [code][pdf] FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions Hyunwoo Kim, Melanie Sclar (UW), Xuhui Zhou (CMU), Ronan Le Bras (AI2), Gunhee Kim, Yejin Choi (UW, AI2) and Maarten Sap (CMU) EMNLP 2023 (Oral) [code] [pdf] SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization Hyunwoo Kim, Jack Hessel (AI2), Liwei Jiang (UW), Peter West (UW), Ximing Lu (UW), Youngjae Yu (Yonsei), Pei Zhou (USC), Ronan Le Bras (AI2), Malihe Alikhani (Northeastern), Gunhee Kim, Maarten Sap (CMU), Yejin Choi (UW, AI2) EMNLP 2023 (Oral) [code & dataset] [pdf] Outstanding Paper Award Recasting Continual Learning as Sequence Modeling Soochan Lee, Jaehyeon Son and Gunhee Kim NeurIPS 2023 [code] [pdf] Federated Learning via Meta-Variational Dropout Insu Jeon, Minui Hong, Junhyeog Yun and Gunhee Kim NeurIPS 2023 [code] [pdf] Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation Heeseung Yun*, Joonil Na* and Gunhee Kim ICCV 2023 [code] [pdf] EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization Minjung Kim, Junseo Koo and Gunhee Kim ICCV 2023 [code] [pdf] MPCHAT: Towards Multimodal Persona-Grounded Conversation Jaewoo Ahn, Yeda Song, Sangdoo Yun (Naver) and Gunhee Kim ACL 2023 [code & dataset] [pdf] Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models Soochan Lee and Gunhee Kim ACL 2023 (Short Findings)[code] [pdf] SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Crea",
  "content_length": 24458,
  "method": "requests",
  "crawl_time": "2025-12-01 13:16:22"
}