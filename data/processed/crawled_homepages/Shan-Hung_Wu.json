{
  "name": "Shan-Hung Wu",
  "homepage": "http://www.cs.nthu.edu.tw/~shwu",
  "status": "success",
  "content": "Shan-Hung Wu å³å°é´» News The website for the course CS565600 Deep Learning is now online My lab is recruiting graduate students who have passion in the following research areas: (Deep) Machine Learning & Generative AI; AI-powered Database/Information Retrieval Systems; Business Intelligence. Prospective students are welcome to set up a chat with me to better understand our topics and projects. Please send me an email with your resume (including your transcript and past projects) first to arrange the meeting time. Biosketch I am a professor in the Department of Computer Science at National Tsing Hua University (NTHU), Taiwan. Since 2016, I have served as the division director for the Division of Academic Information System at the Computer & Communication Center of NTHU. My research interests include: (Deep) Machine Learning; Highly Scalable Database & Information Retrieval Systems; Business Intelligence (for Mobile/Web Applications). I received the Ph.D. degree in Electrical Engineering from the National Taiwan University, Taiwan (Sep 2005 - Feb 2009). Before joining NTHU in 2010, I was a senior research scientist at Telcordia Technologies Inc. (formerly Bellcore) during 2004 and 2010. I am also a part-time programmer. I like to write code with my students, and we have developed some interesting software. I received the Google Faculty Award in 2020. Publications See DBLP for the complete list. MLMachine Learning SYSScalable Systems BIBusiness Intelligence Chia-Hung Yuan and Shan-Hung Wu, \"Neural Tangent Generalization Attacks,\" in Proc. of the 38th Int'l Conf. on Machine Learning (ICML), July 2021 The remarkable performance achieved by Deep Neural Networks (DNNs) in many applications is followed by the rising concern about data privacy and security. Since DNNs usually require large datasets to train, many practitioners scrape data from external sources such as the Internet. However, an external data owner may not be willing to let this happen, causing legal or ethical issues. In this paper, we study the generalization attacks against DNNs, where an attacker aims to slightly modify training data in order to spoil the training process such that a trained network lacks generalizability. These attacks can be performed by data owners and protect data from unexpected use. However, there is currently no efficient generalization attack against DNNs due to the complexity of a bilevel optimization involved. We propose Neural Tangent Generalization Attacks (NTGA) that, to the best of our knowledge, is the first work enabling clean-label, black-box generalization attack against DNNs. We conduct extensive experiments, and the empirical results demonstrate the effectiveness of NTGA. PDF Sup. Slides Code Cheng-Hsin Weng, Yan-Ting Lee, and Shan-Hung Wu, \"On the Trade-off between Adversarial and Backdoor Robustness,\" in Proc. of the 34th Conference on Neural Information Processing Systems (NeurIPS), December 2020 Deep neural networks are shown to be susceptible to both adversarial attacks and backdoor attacks. Although many defenses against an individual type of the above attacks have been proposed, the interactions between the vulnerabilities of a network to both types of attacks have not been carefully investigated yet. In this paper, we conduct experiments to study whether adversarial robustness and backdoor robustness can affect each other and find a trade-offâby increasing the robustness of a network to adversarial examples, the network becomes more vulnerable to backdoor attacks. We then investigate the cause and show how such a trade-off can be exploited for either good or bad purposes. Our findings suggest that future research on defense should take both adversarial and backdoor attacks into account when designing algorithms or robustness measures to avoid pitfalls and a false sense of security. PDF Sup. Slides Code Yi-Hsuan Wu, Chia-Hung Yuan, and Shan-Hung Wu, \"Adversarial Robustness via Runtime Masking and Cleansing,\" in Proc. of the 37th Int'l Conf. on Machine Learning (ICML), July 2020 Deep neural networks are shown to be vulnerable to adversarial attacks. This motivates robust learning techniques, such as the adversarial training, whose goal is to learn a network that is robust against adversarial attacks. However, the sample complexity of robust learning can be significantly larger than that of âstandardâ learning. In this paper, we propose improving the adversarial robustness of a network by leveraging the potentially large test data seen at runtime. We devise a new defense method, called runtime masking and cleansing (RMC), that adapts the network at runtime before making a prediction to dynamically mask network gradients and cleanse the model of the non-robust features inevitably learned during the training process due to the size limit of the training set. We conduct experiments on real-world datasets and the results demonstrate the effectiveness of RMC empirically. PDF Sup. Slides Code Wei-Da Chen and Shan-Hung Wu, \"CNN^2: Viewpoint Generalization via a Binocular Vision,\" in Proc. of the 33rd Conference on Neural Information Processing Systems (NeurIPS), December 2019 The Convolutional Neural Networks (CNNs) have laid the foundation for many techniques in various applications. Despite achieving remarkable performance in some tasks, the 3D viewpoint generalizability of CNNs is still far behind humans visual capabilities. Although recent efforts, such as the Capsule Networks, have been made to address this issue, these new models are either hard to train and/or incompatible with existing CNN-based techniques specialized for different applications. Observing that humans use binocular vision to understand the world, we study in this paper whether the 3D viewpoint generalizability of CNNs can be achieved via a binocular vision. We propose CNN^{2}, a CNN that takes two images as input, which resembles the process of an object being viewed from the left eye and the right eye. CNN^{2} uses novel augmentation, pooling, and convolutional layers to learn a sense of three-dimensionality in a recursive manner. Empirical evaluation shows that CNN^{2} has improved viewpoint generalizability compared to vanilla CNNs. Furthermore, CNN^{2} is easy to implement and train, and is compatible with existing CNN-based specialized techniques for different applications. PDF Sup. Slides Code Ruo-Chun Tzeng and Shan-Hung Wu, \"Distributed, Egocentric Representations of Graphs for Detecting Critical Structures,\" in Proc. of the 36th Int'l Conf. on Machine Learning (ICML), June 2019 We study the problem of detecting critical structures using a graph embedding model. Existing graph embedding models lack the ability to precisely detect critical structures that are specific to a task at the global scale. In this paper, we propose a novel graph embedding model, called the Ego-CNNs, that detects precise critical structures efficiently. An Ego-CNN can be jointly trained with a task model and help explain/discover knowledge for the task. We conduct extensive experiments and the results show that Ego-CNNs (1) can lead to comparable task performance as the state-of- the-art graph embedding models, (2) works nicely with CNN visualization techniques to illustrate the detected structures, and (3) is efficient and can incorporate with scale-free priors, which commonly occurs in social network datasets, to further improve the training efficiency. PDF Sup. Slides Code Ting-Yu Cheng, Kuan-Hua Lin, Xinyang Gong, Kang-Jun Liu, and Shan-Hung Wu, \"Learning User Perceived Clusters with Feature-Level Supervision,\" in Advances In Neural Information Processing Systems (NIPS), December 2016 Semi-supervised clustering algorithms have been proposed to identify data clusters that align with user perceived ones via the aid of side information such as seeds or pairwise constrains. However, traditional side information is mostly at the instance level and subject to the sampling bias, where non-randomly sampled instances in the supervision can mislead the algorithms to wrong clusters. In this paper, we propose learning from the feature-level supervision. We show that this kind of supervision can be easily obtained in the form of perception vectors in many applications. Then we present novel algorithms, called Perception Embedded (PE) clustering, that exploit the perception vectors as well as traditional side information to find clusters perceived by the user. Extensive experiments are conducted on real datasets and the results demonstrate the effectiveness of PE empirically. PDF Sup. Dataset Yan-Fu Liu, Cheng-Yu Hsu, and Shan-Hung Wu, \"Non-Linear Cross-Domain Collaborative Filtering via Hyper-Structure Transfer,\" in Proc. of the 32nd Int'l Conf. on Machine Learning (ICML), July 2015 The Cross Domain Collaborative Filtering (CDCF) exploits the rating matrices from multiple domains to make better recommendations. Existing CDCF methods adopt the sub-structure sharing technique that can only transfer linearly correlated knowledge between domains. In this paper, we propose the notion of Hyper-Structure Transfer (HST) that requires the rating matrices to be explained by the projections of some more complex structure, called the hyper-structure, shared by all domains, and thus allows the non-linearly correlated knowledge between domains to be identified and transferred. Extensive experiments are conducted and the results demonstrate the effectiveness of our HST models empirically. PDF Sup. Shan-Hung Wu, Hao-Heng Chien, Kuan-Hua Lin, and Philip S. Yu, \"Learning the Consistent Behavior of Common Users for Target Node Prediction across Social Networks,\" in Proc. of the 31st Int'l Conf. on Machine Learning (ICML), June 2014 We study the target node prediction problem: given two social networks, identify those nodes/users from one network (called the source network) who are likely to join another (called the target network, with nodes called target nodes). Although this p",
  "content_length": 39565,
  "method": "requests",
  "crawl_time": "2025-12-01 14:26:21"
}