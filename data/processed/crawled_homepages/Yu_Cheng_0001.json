{
  "name": "Yu Cheng 0001",
  "homepage": "https://ych133.github.io",
  "status": "success",
  "content": "About me - Yu Cheng Follow Shatin, N.T. Hong Kong Email Twitter Github Google ScholarI am an Associate Professor in Computer Science and Engineering at the Chinese University of Hong Kong. I am also an affiliated Lead Scientist at Shanghai AI Lab and a Professor at Shanghai Innovation Institute. I got my Ph.D. from Northwestern University in 2015 and my B.S. from Tsinghua University in 2010. My research interests specialize in model compression & efficiency, and large language/multimodality models. From 2021 to 2023, I was a Principal Researcher at Microsoft Research Redmond, where I led several teams to productize these techniques for Microsoft-OpenAI core models (Copilot, DALL-E-2, ChatGPT, GPT-4).I regularly serve as a Senior Area Chair for NeurIPS and ICML and as an Area Chair for CVPR, ICLR, ACL, AAAI, and EMNLP. I also serve as the Action Editor for Transactions on Machine Learning Research (TMLR) and ACM Transactions on Intelligent Systems and Technology (TIST). My papers have won IEEE 2024 SPS Young Author Best Paper Award, Outstanding Paper Award in NeurIPS 2023, and Best Student Paper Honorable Mention in WACV 2021. I am an affiliate professor/faculty at Tsinghua University, Shanghai Jiao Tong University, Fudan University, Zhejiang University, and University of Science and Technology of China.Latest NewsThe team has won first place and a gold medal in the International Physics Olympiad 2025 (IPhO 2025), beating all the models, including Gemini 2.5 Pro, GPT-5 and Grok 4. (October 2025)Serving as Senior Area Chair for ICML 2026 and ACL 2026. (October 2025)Serving as Area Chair for ICLR 2026, AAAI 2026, WACV 2026, and CVPR 2026. (August 2025)Invited talk at NeurIPS 2025 Workshop on Lock-LLM: Prevent Unauthorized Knowledge Use from Large Language Models and NeurIPS 2025 Workshop on Multimodal Algorithmic Reasoning. (July 2025)Invited talk at ICLR 2025 Workshop on Scalable Optimization for Efficient and Adaptive Foundation Models. (Jan. 2025)Our papers DecodingTrust is awarded Best Scientific Cybersecurity Paper of 2024 by the National Security Agency and EnlightenGAN is awarded IEEE SPS Young Author Best Paper Award and the 2024 Cybersecurity Best Paper Award. (Dec. 2024)I organized the Efficient Natural Language and Speech Processing Workshop at NeurIPS 2024. Please consider submitting your work to the workshop. (July 2024)Invited talk at TTIC Summer Workshop on Multimodal Artificial Intelligence. (June 2024)Serving as Senior Area Chair for NeurIPS 2024, and Area Chair for EMNLP 2024. (Apr. 2024)Serving as Senior Area Chair for ICML 2024, Area Chair for NAACL 2024 and ACL 2024. (Jan. 2024)Our work “DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models” has won the Outstanding Paper Award in NeurIPS 2023 (Dec. 2023) I organized the Efficient Natural Language and Speech Processing Workshop at NeurIPS 2023. Please consider submitting your work to the workshop. (Oct. 2023) Serving as Area Chair for CVPR 2024, ICLR 2024, and ACMMM 2024. (Aug. 2023) Invited talk On the Efficiency and Robustness of Foundation Models at the Chinese University of Hong Kong and Tsinghua University. (May 2023) Serving as Senior Area Chair for the Main Track and Datasets & Benchmarks Track of NeurIPS 2023. (Mar. 2023) I organized the Trustworthy and Reliable Large-Scale Machine Learning Models Workshop at ICLR 2023. Please consider submitting your work to the workshop. (Feb. 2023) Invited panel talk at Efficient Natural Language and Speech Processing Workshop at NeurIPS 2022. (Dec. 2022) Invited talk Hardware and Algorithms for Learning On-a-chip Workshop at ICCAD 2022. (Nov. 2022) Invited talk Learning with Limited and Imperfect Data Workshop at ECCV 2022. (Oct. 2022)",
  "content_length": 3736,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:02"
}