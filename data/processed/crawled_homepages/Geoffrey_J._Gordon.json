{
  "name": "Geoffrey J. Gordon",
  "homepage": "http://www.cs.cmu.edu/~ggordon",
  "status": "success",
  "content": "Geoff's Home Page Geoffrey J. Gordon I'm a professor in the Machine Learning Department at Carnegie Mellon.  I am also affiliated with the Robotics Institute.  I'm interested in multi-agent planning, reinforcement learning, decision-theoretic planning, statistical models of difficult data (e.g. maps, video, text), computational learning theory, and game theory.  My group is called the SELECT lab (for SEnse, LEarn, and aCT).  Here is its mailing list. I spent AY 2003-4 as a visiting professor at the Stanford Robotics Lab. Before joining CMU I used to work for Burning Glass Technologies, a company that provided intelligent searching and matching software for resumes and job postings.  The company was headquartered in San Diego, but I worked at their Pittsburgh office. Before that, I was a postdoctoral researcher at the AUTON lab in the Robotics Institute.  Before that, I was a Computer Science PhD student, with advisor Tom Mitchell.  For my RI page, click here. Here are the CMU machine learning lunch page, CS local page, facilities help page, budgeting system, and facilities costing system.  Here is CMU's finger gateway. Contact Office: GHC 8213, x8-7399 (To reach these numbers from outside CMU, first dial 1-412-26.) Shipping address: 6105 Gates Hillman Complex Machine Learning Department Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213 You can email me with user_ID@cs.cmu.edu, where user_ID is part of the URL for this page. Teaching Spring 2023 I am teaching 10-405 and 10-605, Machine Learning with Large Datasets, with Barnabas Poczos. Spring 2022 I taught 10-606 and 10-607, Mathematical Background for ML and Computational Background for ML. I taught these courses before in Fall 2017. These are the same course as 10-600 from Fall 2016, but renumbered since CMU's registration system prefers different numbers for the two minis. Spring 2021 I taught 10-701, Intro to ML, with Aarti Singh. I also taught this course in Fall 2014 with Aarti Singh.  I also taught this course in Fall 2013 with Alex Smola. Fall 2015 I taught 10-601, the masters-level machine learning course, with Aarti Singh.  I also taught this course in Fall 2009 with Miro Dudík. Spring 2013 I taught the MLD Journal Club.  I also taught this course in Spring 2012, in Fall 2011, with Tom Mitchell in Fall 2010, with Aarti Singh in Spring 2010, with Ann Lee several times before that, and with Steve Fienberg several times before that. Fall 2012 I taught 10-725, Optimization, with Ryan Tibshirani.  I also taught this course in Spring 2010 and Spring 2008 with Carlos Guestrin. Spring 2011 I taught 15-780, the graduate AI Star course, with Tuomas Sandholm.  I also taught this course in spring 2009 with Tuomas, and in fall 2007 and Fall 2006 with Ziv Bar-Joseph. Spring 2004 I taught CS23N, Robotics and Machine Learning, with Andrew Ng at Stanford. Summer 2003 I organized the CALD summer school with Tom Mitchell. Fall 2002 I taught 16-899C, Statistical Techniques in Robotics, with Sebastian Thrun. Students Here is a current list of the students I am supervising. Notes, examples, and tutorials These are informal notes rather than polished presentations, so let me know if you find any errors. Art The New Artist: art created by robots, for robots.  (A collaboration led by Axel Straschnoy, of which I am a small part.) Playing games Play some one-card poker. Compute some correlated equilibria. Some slides on what it means to be a reasonable learning algorithm in a repeated game.  I presented these as an invited talk at the AAAI workshop on multiagent learning in 2005. Algorithms for statistical inference A tutorial on spectral learning that we gave at ICML 2012. Some code for spectral learning of dynamical systems. Some code for generalized linear PCA using a Poisson error model (and its matching exponential link function) Some lecture notes on Monte Carlo algorithms, including Matlab demos. Some lecture notes on support vector machines, including a simple Java applet. Some lecture notes on variational algorithms, including k-means clustering and mean-field image segmentation. Notes on Gaussian distributions as they are used in the Kalman filter. An example of how to fit a logistic model using iteratively-reweighted least squares. An example of using gradient descent to fit a discrete exponential family. Matlab code, 2k. Notes on the concave-convex procedure (CCCP) and its relationship to variational bounding algorithms, in PostScript (44k, 20 slides). Notes on Fisher scoring, in PostScript (42k, 8 slides). Notes on boosting, in PostScript (90k, 20 slides). Linear programming and optimization A very simple implementation of an infeasible interior-point method for linear and convex quadratic programs, as a Matlab M-file, and an example of its use. I also have a slightly more sophisticated implementation (also in Matlab).  If you have access to Matlab's quadprog, I'd recommend using that instead; when I wrote this, I did not have access to quadprog. A tutorial on some geometry behind linear programming, in PostScript (780k, 30 slides) (or try PDF). For comparison, here's another short interior point linear programming solver.  This one is due to Yin Zhang and was presented at SIAM 2000; I have basically only reformatted the code so that it's slightly easier to use and read. Support vector machines are an interesting use of optimization, and there is some interior point code for learning SVMs on my SVM page.  This is not really a very good way to optimize SVMs, and perhaps not the best interior-point implementation, but it may be an interesting example. Reinforcement learning A (very partial) annotated bibliography on robot learning via MDPs and related methods.  I made this as an initial cut at readings our multirobot planning group might want to go over. Notes on conditioning (the dogs and bells kind), in PostScript (50k, 20 slides) or PDF (80k). Lecture notes for an intro to reinforcement learning, in PostScript or PDF (215k, 43 slides). Others A tutorial on machine learning for educational data that Emma Brunskill and I gave at NIPS 2012 (or, direct link to the video). Advice for technical speaking, written for our Journal Club course at CMU. Code for path planning via Dijkstra's algorithm and A* search, in Java with a Matlab interface. A tutorial on synthetic division and partial fraction expansion, which are useful in working with the rational functions which arise when analyzing a linear, time-invariant system of differential equations. Software for tracking dots in images.  This is a useful primitive for some types of computational biology experiments: fluorescently tag something, take pictures of it, and track how it moves.  This software isn't very polished, but we couldn't find anything out there for the purpose; so we wrote this, and some friends of mine used it to help with the data for one of the papers below. Notes on edge and corner detectors. The iterated prisoner's dilemma (text, 10k). Slides on rank-based nonparametric statistical tests, as PostScript (115k) or PDF (253k). Matlab code for computing log(exp(a)+exp(b)). A simple tutorial on the Common LISP language, written as class material for the AI core course at CMU. Some publications This list is approximately in reverse chronological order. Some of my publications are also available from the CMU SCS tech reports archive or from arXiv. 2018 Ahmed Hefny, Carlton Downey, Geoffrey Gordon. An Efficient, Expressive and Local Minima-free Method for Learning Controlled Dynamical Systems. In AAAI-18. (sorry, no link yet) (an earlier version of this work was presented at CoRL 2017) Siddarth Srinivasan, Geoff Gordon, and Byron Boots. Learning Hidden Quantum Markov Models. In AISTATS 2018. (sorry, no link yet) 2017 Carlton Downey, Ahmed Hefny, Byron Boots, Geoffrey Gordon, and Boyue Li. Predictive State Recurrent Neural Networks. In Advances in Neural Information Processing Systems (NIPS), 2017. (an earlier version of this work was presented at CoRL 2017; see also the arXiv version below) Han Zhao and Geoffrey Gordon. Linear Time Computation of Moments in Sum-Product Networks. In Advances in Neural Information Processing Systems (NIPS), 2017. Wen Sun, Arun Venkatraman, Geoff Gordon, Byron Boots, and Drew Bagnell. Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction. In Intl. Conf. Machine Learning (ICML), 2017. (See also an earlier arXiv version, next bullet.) Wen Sun, Arun Venkatraman, Geoff Gordon, Byron Boots, and Drew Bagnell. Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction. Technical report arXiv:1703.01030, 2017. Han Zhao and Geoff Gordon. Frank-Wolfe Optimization for Symmetric-NMF under Simplicial Constraint. Technical report arXiv:1706.06348, 2017. Carlton Downey, Ahmed Hefny, Boyue Li, Byron Boots, and Geoffrey Gordon. Predictive State Recurrent Neural Networks. Technical report arXiv:1705.09353, 2017. Renato Negrinho and Geoff Gordon. DeepArchitect: Automatically Designing and Training Deep Architectures. Technical report arXiv:1704.08792, 2017. Carlton Downey, Ahmed Hefny, and Geoffrey Gordon. Practical Learning of Predictive State Representations. Technical report arXiv:1702.04121, 2017. Ahmed Hefny, Carlton Downey, and Geoffrey J. Gordon. Supervised Learning for Controlled Dynamical System Learning. Technical report arXiv:1702.03537, 2017. Dana Van Aken, Andrew Pavlo, Geoffrey J. Gordon, and Bohan Zhang. Automatic Database Management System Tuning Through Large-scale Machine Learning. In ACM SIGMOD, 2017. 2016 H. Zhao, P. Poupart, and G. J. Gordon. A Unified Approach for Learning the Parameters of Sum-Product Networks. In Advances in Neural Informaption Processing Systems (NIPS), 2016. H. Zhao, T. Adel, G. Gordon, and B. Amos. Collapsed variational inference for sum-product networks. In Proc. Intl. Conf. on Machine Learning (ICML), 2016. Z. Marinho, B. Boots, A. Dragan, A. Byravan, G. J. Gordon, and S. Srinivasa. Functi",
  "content_length": 40192,
  "method": "requests",
  "crawl_time": "2025-12-01 13:13:16"
}