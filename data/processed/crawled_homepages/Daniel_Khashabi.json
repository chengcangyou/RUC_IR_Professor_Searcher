{
  "name": "Daniel Khashabi",
  "homepage": "https://danielkhashabi.com",
  "status": "success",
  "content": "Daniel Khashabi Research Themes Talks/Slides Teaching Lab Publication Daniel Khashabi Assistant Professor, Department of Computer Science, Johns Hopkins University Office: Hackerman Hall 316B Email: danielkjhu.edu Other affiliations: Center for Language and Speech Processing Data Science and AI Institute Institute for Assured Autonomy Institute for Data-Intensive Engineering and Science Research Themes I am broadly interested in making language-driven AI systems more helpful, reliable, and efficient. As these systems increasingly engage in reasoning and creative discovery, their impact hinges on balancing open-ended exploration with grounded trustworthiness. At the core of this agenda lies a tension: creative reasoning thrives on revealing novel connections and deep structural parallels across distant domains, yet it is inherently prone to false associations that can undermine, rather than enhance, human productivity. My work draws on algorithmic and statistical tools to develop computational frameworks to harness the benefits of creative reasoning while remaining transparent, verifiable, and aligned with human values—enabling trustworthy, AI-driven discovery. I have pursued this vision along three complementary axes: Understanding the foundations: What fundamental principles govern the intelligent behavior that emerges from large-scale training? And can we use these insights as guiding principles of scaling? Reasoning, communication and interaction: How can we amplify AI’s capacity for reasoning across tasks, contexts, and interactions with the world? How can we characterize the trade-off between generality vs. specialization (sticking to what user wants) in adaptive systems? Safety, oversight and evaluation: How can oversight mechanisms (e.g., debate, red teaming, verification) be formalized and automated at scale? How can AI systems balance autonomy with auditing and safety mechanisms to ensure human trust? Our research is driven by a key real application: accelerating scientific discovery in an era where knowledge grows faster than any individual can absorb. Most of my research is aligned with the following research communities: natural language processing (ACL, NAACL, EMNLP), machine learning and AI (COLM, ICLR, NeurIPS, ICML, AAAI, IJCAI). Information for Prospective Students and Visitors Here is some information for prospective students and visitors. Due to the large number of emails I receive, I cannot respond to every email individually. Please review the information below before contacting me. Current JHU students: If you are an undergraduate or masters student and would like to work on research with my group, please fill out this form. The minimum time commitment is 15 hours per week for six months. Prospective visiting students: Please fill out the above form. For visiting graduate students, the minimum length of a visit is six months. Prospective postdocs: Please email me directly with your CV and I will get back to you if there is an opportunity that is a good fit. Prospective graduate students: Please apply through the system and list me as a potential advisor in your application. There is no need to contact me. Recent Talks 2025, Apple Workshop on Reasoning and Planning (slides) 2025, University of Pennsylvania Computational Linguistics lunch (slides) 2024, University of Cambridge the Language Technology Lab seminar (slides) 2024, Oracle Labs ML seminar (slides) 2024, Tel Aviv NLP seminar (slides) 2024, Forum on ‘‘Engineered AI Systems’’ (slides) 2024, Keynote at ‘‘Engineering for Professionals’’ quarterly meeting (slides) 2024, Workshop on ‘‘LLMs for Healthy Aging’’ (slides) 2023, NYU ‘‘Text-as-Data’’ talk series (slides) 2023, Hopkins Center for Language and Speech Technologies seminar (video) 2023, Hopkins Electrical Engineering department seminars (slides) 2023, Amazon ‘‘Human in the Loop’’ seminar 2023, Hopkins Center for Health Security seminars (slides) 2023, UMD Computational Linguistics seminar (slides) 2023, Applied Physics Lab, Intelligent Systems Center seminars 2022, University of Tehran NLP seminar 2021, University of Glasgow IR seminar (slides) 2021, Johns Hopkins University (slides) 2021, Google AI (slides) 2021, UCLA Big Data and ML seminar (slides) 2021, USC NLP seminar (slides) 2020, Tel Aviv University NLP seminar (slides) 2019, Workshop on Progress Towards the Holy Grail, Conference on Constraint Programming (CP), 2019. (slides) 2019, CMU LTI seminar (slides) 2018, NYU NLP seminar Reasoning-Driven Question Answering. 2018, Stanford NLP seminar (slides) 2018, Mid-Atlantic Student Colloquium on Speech, Language and Learning (slides) Teaching CS 601.471/671, NLP: Self-supervised Models: Spring 2023, Spring 2024, Spring 2025 (not teaching in Spring 2026; apologies to all students who wanted to take this course) CS 601.771, Advances in Self-supervised Models: Fall 2022, Fall 2024, Fall 2025 Intelligence Amplification Lab (IALab) PhD students: Adam Byerly Jack Jingyu Zhang - co-advised w/ Benjamin Van Durme Andrew Wang - co-advised w/ Nick Andrews Jiefu Ou - co-advised w/ Benjamin Van Durme Tianjian Li Hannah Gonzalez - co-advised w/ Benjamin Van Durme Zheyuan “Brian” Zhang - co-advised w/ Tianmin Shu Austen Liao - co-advised w/ Benjamin Van Durme Here’s a team photo from our recent fun outing. We’re also grateful to collaborate with a number of exceptional PhD, MS and undergraduate students who are not listed here. Publication Disclaimer: This material is presented to ensure the timely dissemination of scholarly works. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms invoked by each author's copyright. Genomic Next-Token Predictors are In-Context Learners. Nathan Breslow, Aayush Mishra, Mahler Revsine, Michael C. Schatz, Anqi Liu and Daniel Khashabi. arXiv preprint arXiv:2511.12797, 2025. [code] CreativityPrism: A Holistic Benchmark for Large Language Model Creativity. Zhaoyi Joey Hou, Bowei Alvin Zhang, Yining Lu, Bhiman Kumar Baghel, Anneliese Brei, Ximing Lu, Meng Jiang, Faeze Brahman, Snigdha Chaturvedi, Haw-Shiuan Chang, Daniel Khashabi and Xiang Lorraine Li. arXiv preprint arXiv:2510.20091, 2025. [data] Query Decomposition for RAG: Balancing Exploration-Exploitation. Roxana Petcu, Kenton Murray, Daniel Khashabi, Evangelos Kanoulas, Maarten de Rijke, Dawn Lawrie and Kevin Duh. arXiv preprint arXiv:2510.18633, 2025. World-in-World: World Models in a Closed-Loop World. Jiahan Zhang, Muqing Jiang, Nanru Dai, Taiming Lu, Arda Uzunoglu, Shunchi Zhang, Yana Wei, Jiahao Wang, Vishal M. Patel, Paul Pu Liang, Daniel Khashabi, Cheng Peng, Rama Chellappa, Tianmin Shu, Alan Yuille, Yilun Du and Jieneng Chen. arXiv preprint arXiv:2510.18135, 2025. [project] Gold Panning: Turning Positional Bias into Signal for Multi-Document LLM Reasoning. Adam Byerly and Daniel Khashabi. arXiv preprint arXiv:2510.09770, 2025. The Alignment Waltz: Jointly Training Agents to Collaborate for Safety. Jingyu Zhang, Haozhu Wang, Eric Michael Smith, Sid Wang, Amr Sharaf, Mahesh Pasupuleti, Benjamin Van Durme, Daniel Khashabi, Jason Weston and Hongyuan Zhan. arXiv preprint arXiv:2510.08240, 2025. Safe and Efficient In-Context Learning via Risk Control. Andrea Wynn, Metod Jazbec, Charith Peris, Rinat Khaziev, Anqi Liu, Daniel Khashabi and Eric Nalisnick. arXiv preprint arXiv:2510.02480, 2025. [poster] [code] The Flaw of Averages: Quantifying Uniformity of Performance on Benchmarks. Arda Uzunoglu, Tianjian Li and Daniel Khashabi. arXiv preprint arXiv:2509.25671, 2025. IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning. Aayush Mishra, Daniel Khashabi and Anqi Liu. arXiv preprint arXiv:2509.22621, 2025. [code] Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG. Dayeon Ki, Marine Carpuat, Paul McNamee, Daniel Khashabi, Eugene Yang, Dawn Lawrie and Kevin Duh. arXiv preprint arXiv:2509.1393, 2025. [code] Jointly Reinforcing Diversity and Quality in Language Model Generations. Tianjian Li, Yiming Zhang, Ping Yu, Swarnadeep Saha, Daniel Khashabi, Jason Weston, Jack Lanchantin and Tianlu Wang. arXiv preprint arXiv:2509.02534, 2025. [code] BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases. Mathew J. Koretsky, Maya Willey, Adi Asija, Owen Bianchi, Chelsea X. Alvarado, Tanay Nayak, Nicole Kuznetsov, Sungwon Kim, Mike A. Nalls, Daniel Khashabi and Faraz Faghri. arXiv preprint arXiv:2505.20321, 2025. [data] [code] Lost in the Haystack: Smaller Needles are More Difficult for LLMs to Find. Owen Bianchi, Mathew J. Koretsky, Maya Willey, Chelsea X. Alvarado, Tanay Nayak, Adi Asija, Nicole Kuznetsov, Mike A. Nalls, Faraz Faghri and Daniel Khashabi. arXiv preprint arXiv:2505.18148, 2025. [code] Science Hierarchography: Hierarchical Abstractions of Scientific Literature. Muhan Gao, Jash Shah, Weiqi Wang, Kuan-Hao Huang and Daniel Khashabi. arXiv preprint arXiv:2504.13834, 2025. [data] Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the Evaluation Protocol. Weiqi Wang, Jiefu Ou, Yangqiu Song, Benjamin Van Durme and Daniel Khashabi. arXiv preprint arXiv:2504.10284, 2025. [data] The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure. Niyati Bafna, Tianjian Li, Kenton Murray, David R. Mortensen, David Yarowsky, Hale Sirin and Daniel Khashabi. The Asia-Pacific Chapter of the Association for Computational Linguistics (AACL), 2025. [code] Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback. Dongwei Jiang, Alvin Zhang, Andrew Wang, Nicholas Andrews and Daniel Khashabi. Advances in Neural Information Processing Systems (NeurIPS), 2025. [code] Jailbreak Distillation: Renewable Safety Benchmarking. Jingyu Zhang, Ahmed Elgohary, Xiawei Wang, A S M Iftekhar, Ahmed Magooda, Benjamin Van Durme, Daniel Khashabi and Kyle Jackson. Conference on Empiri",
  "content_length": 35374,
  "method": "requests",
  "crawl_time": "2025-12-01 12:57:18"
}