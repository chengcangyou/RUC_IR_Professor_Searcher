{
  "name": "Soumya Ray",
  "homepage": "http://engr.case.edu/ray_soumya",
  "status": "success",
  "content": "Soumya Ray Soumya Ray (Ph. D., University of Wisconsin-Madison, 2005) Associate Professor Department of Electrical Engineering and Computer Science Case Western Reserve University Office: Olin 516 Office hours: F 9:30am-11:00am Email: sray AT case Mailing Address: Department of EECS, Glennan 320, 10900 Euclid Ave, Cleveland OH 44106-7071 Research Areas: Artificial Intelligence, Machine Learning, Reinforcement Learning and Planning Slack group Github Teaching I teach undergraduate AI (EECS 391) in the spring and graduate machine learning (EECS 440) in the fall. I also teach two other graduate level courses: EECS 496 (Sequential Decision Making) and EECS 497 (Statistical Natural Language Processing). Currently, these last two are offered once every two years. You can visit this page to learn more about these courses. I am the current AI minor advisor. This minor provides a broad foundation in Intelligent Systems. CS majors interested in this minor should take the \"Cognitive Science\" track. All other majors can take either track. SEPIA (Strategy Engine for Programming Intelligent Agents) is a real-time strategy game environment my students and I have built for AI teaching and research (see EAAI paper below). I use it in classes for assignments. It is open source and free to use. Please let me know if you are using/would like to use it. Current teaching: Spring 2019: Introduction to Artificial Intelligence (EECS 391), Senior Project (EECS 395) Advising If you are an undergraduate student interested in AI, please stop by my office (Olin 516) during office hours (or send email for an appointment) to discuss your undergraduate career. The primary requirements are strong programming and mathematics skills. In particular, the following courses will be useful foundational courses: MATH 201, MATH 380, EECS 416. You should aim to take EECS 391 as early as you can (no later than junior year), and follow up with some of the advanced, graduate level courses: EECS 440 (Machine Learning), 442 (Causal Inference), 491 (Probabilistic Graphical Models), 496 (Sequential Decision Making), 497 (Statistical Natural Language Processing), 499 (Algorithmic Robotics), 531 (Computer Vision), 600 (Computational Perception). For a minor, consider Cognitive Science, Math or Statistics. Please note that the AI minor will generally not add anything useful if you are already specializing in AI, unless you take the \"Cognitive Science\" track (but then you should consider a minor in Cognitive Science). If you are a CWRU graduate student interested in AI/machine learning research, and have a solid background in probability and statistics, programming and optimization, you should first take one of my classes. If you like the material and do well, please send me an email for an initial discussion. You can also send me email to be added to my reading group's mailing list (for notifications about papers we will read next). Please note that you will need to have taken EECS 440 or 491 or have a good background in AI to contribute effectively. Please note that I do not generally respond to email from students who have not been admitted to CWRU. If you are interested in AI and have applied to the PhD program in CS, you can send me a note if you want me to review your application. Please make sure to mark \"PhD in CIS (Computer and Information Science)\" in your application, or it may not be considered by the CS program. A note on the distinction between the Computer Science (CS) and Computer Engineering (CE) programs at CWRU: CS deals with the process and theory of computation and its platform-independent implementation. If you are interested in designing algorithms to solve problems, analyzing them and implementing them (using high level languages), CS will suit you. CE deals with the low-level specifics of platforms that implement computational processes. If you are interested in designing VLSI circuits, testing circuit specifications, or novel hardware architectures such as GPU-based computing, CE will suit you. Current Students Arielle Bloostein (MS) Anneliese Braunegg (undergraduate) Caitlin Campbell Yufan Chen David Epstein David Fan (undergraduate) Zicheng Gao (undergraduate) Kristen Hauser Yi Hou (Ph.D.) I-Kung Hsu Zhengkai Jiang Mingxuan Ju Sai Saradha K. L. (MS) Kha-Dinh Luong Ted Timbrell Swetha Srikanthan (MS) Helen Zhao Graduated Students Nikil Pancha (undergraduate, graduated Fall 2018, first job: Pinterest) Sibi Sengottuvel (undergraduate, graduated Fall 2018, first job: Google) William Barbaro (MS, graduated Spring 2018, first job: Yelp inc) Gabriel Ewing (MS, graduated Fall 2017, first job: Google inc ) Sergiy Turchyn (MS, graduated Summer 2017, first job: Google inc) Thesis: A Visual Search Engine for Gesture Annotation Galen Caldwell (undergraduate, graduated Spring 2017, first job: Amazon inc.) Andrew Hamm (undergraduate, graduated Spring 2017, first job: Yelp inc) Julie Kaplan (undergraduate, graduated Spring 2017, first job: Google inc) Nicholas Stevens (undergraduate, graduated Spring 2017, first job: MIM Software) Rui Liu (MS, graduated Fall 2016, currently Ph.D. candidate at University of Michigan) Jon Pfeil (MS, graduated Summer 2016, first job: Google inc) Thesis: Algorithms and Resources for Scalable Natural Language Generation Jeffrey Copeland (undergraduate, graduated Spring 2016) Scott Sosnowski (MS, graduated Spring 2016, first job: Explorys/IBM) Devin Schwab (MS, NDSEG 2015 Fellow, graduated Fall 2015, first position: PhD candidate at Carnegie Mellon University) Thesis: Hierarchical Sampling for Least Squares Policy Iteration Andrew Latham (MS, graduated Summer 2015,first job: Google inc) Gary Doran (Ph. D., graduated Fall 2014, first job: Jet Propulsion Laboratory, Caltech/NASA) Thesis: Distribution-based Multiple-Instance Learning Larry Muhlstein (undergrad, graduated Fall 2014, first position: PhD candidate at University of California San Diego) Kai Liang (MS, graduated Spring 2014, first job: Amazon inc.) Thesis: Fault Localization in Embedded Control System Software Nathan McKinley (MS, graduated Fall 2013, first job: Google inc) Thesis: A Decision-Theoretic Approach to Natural Language Generation Tyler Goeringer (MS, graduated Summer 2013, first job: nVidia inc) Thesis: Massively Parallel Reinforcement Learning with an Application to Video Games Feng Cao (MS, graduated Spring 2012, first job: Amazon inc.) Thesis: Classification, Detection and Prediction of Adverse and Anomalous Events in Medical Robots Tim Ernsberger (MS, graduated Fall 2012, first job: Amazon inc.) Thesis: Integrating Deterministic Planning and Reinforcement Learning for Complex Decision Making Howie Richmond (MS, graduated Fall 2011, first job: MIM Software, co-supervised with Andy Podgurski) Thesis: Bayesian Logistic Regression Models for Software Fault Localization Current Research What are the fundamental aspects of building an intelligent autonomous system? In my opinion, they are: Representation: How does the system represent the world? How does it understand what is relevant? How does it understand what is relevant to its current situation from its previous experience? Decomposition: How does the system learn to break down large problems into efficiently solvable chunks, and compose useful solutions? Coordination and Communication: How does the system work with other such systems to solve large problems? In my research, I am attempting to make progress in understanding these very challenging questions. As well as addressing these fundamental issues, I work with several collaborators to apply AI and machine learning techniques to various application domains, including medicine, cognitive science and business. My reading group web page is here. Machine Learning/Artificial Intelligence Theory and Methods Natural Language Generation Humans are able to generate complex and nearly error-free language in most contexts. How can we enable similar capabilities in artificial systems? Given a communicative goal, a grammar and a world description, this research seeks to derive practical algorithms for fast language generation. (Students: Nathan McKinley, Jon Pfeil, Yi Hou) Hierarchical Reinforcement Learning Humans manage complex tasks by decomposition and also using prior information collected by solving other tasks. How can we integrate these ideas into autonomous agents? This research seeks ways to answer this question. (Students: Kai Liang, Feng Cao, Devin Schwab, Gabriel Ewing) Distribution-based Multiple-Instance Learning The traditional view of multiple-instance learning is that an example is a set of feature vectors. But in many real applications, such as 3D-QSAR, it makes more sense to think of an example as a distribution over feature vectors. This view leads to new theoretical insights into multiple-instance learning, and new ways to explain the observed behavior of algorithms on these problems. (Students: Gary Doran, Andrew Latham, Jeffrey Copeland, Rui Liu) Applied Machine Learning and Artificial Intelligence Machine Learning for Gesture Annotation in Video Understanding when people employ gestures or similar nonverbal communication cues is important for developing automated systems that can communicate with people in a natural manner. We are studying machine learning methods that can learn to recognize and eventually deploy gestures in communication. With the Red Hen Lab, Mark Turner and Francis Steen. (Students: Sergiy Turchyn) Machine Learning for Automated Plaque Classification in OCT images Millions of people die of heart disease every year. A key cause is the development of certain types of \"bad\" plaque in blood vessels, which when ruptured, can interfere with blood flow, leading to thrombosis. Blood vessels can be imaged using intravascular optical coherence tomography (IV-OCT). This technique, however, creates lots of images which have to be manually analyzed to identify problematic plaque types. We are developing automated techniques th",
  "content_length": 30332,
  "method": "requests",
  "crawl_time": "2025-12-01 14:29:58"
}