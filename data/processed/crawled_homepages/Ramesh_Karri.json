{
  "name": "Ramesh Karri",
  "homepage": "http://engineering.nyu.edu/people/ramesh-karri",
  "status": "success",
  "content": "Ramesh Karri | NYU Tandon School of Engineering Skip to Main Content Search NYU Tandon Fulltext search Looking for News or Events? Ramesh Karri Electrical and Computer Engineering Department Chair Professor of ECE Electrical and Computer Engineering Center for Advanced Technology in Telecommunications (CATT) NYU Center for Cybersecurity (CCS) Connect Email rkarri [at] nyu.edu CV/resume cv-ramesh-karri.pdf Phone 646.997.3596 Professor of ECE Co-founded NYU CCS (2009) Co-Directed NYU CCS (2016-2024) Ramesh Karri is a Professor of Electrical and Computer Engineering at New York University. He co-founded the NYU Center for Cyber Security (cyber.nyu.edu) NYU in 2009. He co-directed the center from 2016-2024. He co-founded the Trust-Hub (trust-hub.org) and founded/organizes the Embedded Systems Challenge (csaw.engineering.nyu.edu/esc), the annual red-blue team event. Ramesh Karri holds a Ph.D. in Computer Science and Engineering from the University of California at San Diego, and a B.E in ECE from Andhra University. With a focus on hardware cybersecurity, his research and educational endeavors encompass trustworthy ICs, processors, and cyber-physical systems; security-aware computer-aided design, test, verification, validation, and reliability; nano meets security; hardware security competitions, benchmarks, and metrics; biochip security; and additive manufacturing security. Ramesh has published over 350 articles in prestigious journals and conferences. A Fellow of IEEE, Ramesh's work on hardware cybersecurity has earned numerous best paper award nominations (IEEE S&P 2022, ICCD 2015 and DFTS 2015) and awards (ITC 2014, CCS 2013, DFTS 2013, VLSI Design 2012, ACM Student Research Competition at DAC 2012, ICCAD 2013, DAC 2014, ACM Grand Finals 2013, Kaspersky Challenge, and Embedded Security Challenge). He received the Humboldt Fellowship and the National Science Foundation CAREER award. He is the Editor in Chief of the ACM Journal of Emerging Computing Technologies and an Associate Editor for IEEE and ACM journals. He has had leadership roles in various IEEE conferences like ICCD, HOST, DFTS, and others. He served as an IEEE Computer Society Distinguished Visitor from 2013-2015 and was on the Executive Committee for Security@DAC from 2014-2017. Additionally, he's been on multiple PCs and delivered keynotes on Hardware Security and Trust at events like ESRF, DAC, MICRO. Research Interests Trustworthy Hardware Nano-enabled Security and Assurance Computer Aided Design of Secure Systems, Cybersecurity, GenAI-based Chip Design Education University of Hyderabad 1988 Master of Technology, Computer Science Andhra University 1985 Bachelor of Engineering, Electronics and Communication Engineering University of California, San Diego 1992 Master of Science, Computer Engineering University of California, San Diego 1993 Doctor of Philosophy, Computer Science Experience NYU Tandon School of Engineering Professor Research and teaching in computer engineering. Current research focus is on trustworthy and secure hardware. From: September 2011 to present Polytechnic Institute of New York University Associate Professor Research and teaching in computer engineering. Current research focus is on trustworthy and secure hardware. From: September 1998 to August 2011 Lucent Bell Labs Engineering Research Center, Princeton Member of Technical Staff On-line built-in self test of VLSICs From: June 1997 to July 1998 University of Massachusetts, Amherst Assistant Professor of Electrical and Computer Engineering Research and teaching in computer engineering. From: September 1993 to July 1998 University of California, San Diego Graduate Teaching and Research Assistant From: September 1989 to August 1993 Fifth Generation Computing Group, CMC Research and Development Ce Research Engineer Implemented multiprocessor cache consistency protocols and evaluated their performance and scalability. From: May 1988 to June 1989 Research News View More AI tools can help hackers plant hidden flaws in computer chips, study finds Widely available artificial intelligence systems can be used to deliberately insert hard-to-detect security vulnerabilities into the code that defines computer chips, according to new research from the NYU Tandon School of Engineering, a warning about the potential weaponization of AI in hardware design. In a study published by IEEE Security & Privacy, an NYU Tandon research team showed that large language models like ChatGPT could help both novices and experts create \"hardware Trojans,” malicious modifications hidden within chip designs that can leak sensitive information, disable systems or grant unauthorized access to attackers. To test whether AI could facilitate malicious hardware modifications, the researchers organized a competition over two years called the AI Hardware Attack Challenge as part of CSAW, an annual student-run cybersecurity event held by the NYU Center for Cybersecurity. Participants were challenged to use generative AI to insert exploitable vulnerabilities into open-source hardware designs, including RISC-V processors and cryptographic accelerators, then demonstrate working attacks. \"AI tools definitely simplify the process of adding these vulnerabilities,\" said Jason Blocklove, a Ph.D. candidate in NYU Tandon’s Electrical and Computer Engineering (ECE) Department and lead author of the study. \"Some teams fully automated the process. Others interacted with large language models to understand the design better, identify where vulnerabilities could be inserted, and then write relatively simple malicious code.\" The most effective submissions came from teams that created automated tools requiring minimal human oversight. These systems could analyze hardware code to identify vulnerable locations, then generate and insert custom trojans without direct human intervention. The AI-generated flaws included backdoors granting unauthorized memory access, mechanisms to leak encryption keys, and logic designed to crash systems under specific conditions. Perhaps most concerning, several teams with little hardware expertise successfully created sophisticated attacks. Two submissions came from undergraduate teams with minimal prior knowledge of chip design or security, yet both produced vulnerabilities rated medium to high severity by standard scoring systems. Most large language models include safeguards designed to prevent malicious use, but competition participants found these protections relatively easy to circumvent. One winning team crafted prompts framing malicious requests as academic scenarios, successfully inducing the AI to generate working hardware trojans. Other teams discovered that requesting responses in less common languages could bypass content filters entirely. The permanence of hardware vulnerabilities amplifies the risk. Unlike software flaws that can be corrected through updates, errors in manufactured chips cannot be fixed without replacing the components entirely. \"Once a chip has been manufactured, there is no way to fix anything in it without replacing the components themselves,\" Blocklove said. \"That's why researchers focus on hardware security. We’re getting ahead of problems that don't exist in the real world yet but could conceivably occur. If such an attack did happen, the consequences could be catastrophic.\" The research follows earlier work by the same team demonstrating AI's potential benefits for chip design. In their \"Chip Chat\" project, the researchers showed that ChatGPT could help design a functioning microprocessor. The new study reveals the technology's dual nature. The same capabilities that could democratize chip design might also enable new forms of attack. \"This competition has highlighted both a need for improved LLM guardrails as well as a major need for improved verification and security analysis tools,\" the researchers wrote. The researchers emphasized that commercially available AI models represent only the beginning of potential threats. More specialized open-source models, which remain largely unexplored for these purposes, could prove even more capable of generating sophisticated hardware attacks. The paper’s senior author is NYU Tandon’s Ramesh Karri, Professor and Chair of ECE. Karri is also on the faculty of the Center for Advanced Technology in Telecommunications and co-founded and co-directed the NYU Center for Cybersecurity (CCS). Karri founded the embedded security challenge (ESC), the first hardware security challenge worldwide. Hammond Pearce, Senior Lecturer at UNSW Sydney's School of Computer Science and Engineering and a former NYU Tandon research assistant professor in ECE and CCS, is the other co-author. J. Blocklove, H. Pearce and R. Karri, \"Lowering the Bar: How Large Language Models Can be Used as a Copilot by Hardware Hackers\" in IEEE Security & Privacy, vol. , no. 01, pp. 2-12, PrePrints 5555, doi: 10.1109/MSEC.2025.3600140. Read the Study October 9, 2025 New NYU Tandon-led project will accelerate privacy-preserving computing Today's most advanced cryptographic computing technologies — which enable privacy-preserving computation — are trapped in research labs by one critical barrier: they're thousands of times too slow for everyday use. NYU Tandon, helming a research team that includes Stanford University and the City University of New York, just received funding from a $3.8 million grant from the National Science Foundation to build the missing infrastructure that could make those technologies practical, via a new design platform and library that allows researchers to develop and share chip designs. The problem is stark. Running a simple AI model on encrypted data takes over 10 minutes instead of milliseconds, a four order of magnitude performance gap that impedes many real-world use cases. Current approaches to speeding up cryptographic computing have hit a wall, however. \"The normal tricks that we have to get over this performance bottleneck won’t scale much f",
  "content_length": 25657,
  "method": "requests",
  "crawl_time": "2025-12-01 14:15:27"
}