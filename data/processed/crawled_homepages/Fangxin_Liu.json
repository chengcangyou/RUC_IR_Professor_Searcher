{
  "name": "Fangxin Liu",
  "homepage": "https://mxhx7199.github.io",
  "status": "success",
  "content": "Welcome to Fangxin Liu’s Homepage~ - Fangxin Liu’s Homepage Fangxin LiuAssistant Professor @ School of Computer Sicence, Shanghai Jiao Tong University Follow 800 DongChuan Road, SEIEE Building #03-125, Minhang District, Shanghai Email Github Google Scholar Fangxin (Leon) Liu is an Assistant Professor and Ph.D. supervisor at Shanghai Jiao Tong University (SJTU). I also serve as a Research Fellow at the Shanghai Qi Zhi Institute and a part-time Associate Professor at Shanghai Customs College. My research interests include neural network acceleration (e.g., mixed-precision computing and SW/HW co-design), in-memory computing, and brain-inspired neuromorphic computing.I received my Ph.D. degree in Computer Science and Technology from Shanghai Jiao Tong University in 2023, under the supervision of Prof. Li Jiang. My work has been recognized with several honors, including the Spark Award from HUAWEI, the Outstanding Doctoral Dissertation Award from the Shanghai Computer Society, the ACM China Shanghai Excellent Doctoral Dissertation Award, and the Best Paper Award at DATE 2022. Up to now, I have published over 50 papers (as first or corresponding author), with more than 30 of them in CCF Tier A, including top-tier architecture conferences and journals such as ISCA, MICRO, ASPLOS, HPCA, PPoPP, DAC, IEEE TC, TPDS, and TCAD. My research has been successfully adopted by leading technology companies, including Huawei, Ant Group, ZTE, and Yizhu Tech., to advance real-world applications such as efficient LLM inference, low-precision deployment, and optimized AI compilation. For instance, my work on mixed-precision computing and SW/HW co-design has enabled up to 40% reductions in computational costs for large-scale AI deployments. I am committed to bridging cutting-edge research with practical industry solutions and welcome opportunities for further collaboration. NewsNov./26/2025 O Our two papers on MoE memory bottleneck optimization and 3DGS collaborative rendering acceleration have been accepted to ASPLOS 2026. Congratulations to Ning Yang and all co-authors!Nov./11/2025 Our two papers on graph-based memory optimization and sparse Transformer acceleration have been accepted to PPoPP 2026. Congratulations to Hanjing and all co-authors!Nov./11/2025 Our three papers on Large Number Modular Multiplication, LLM Inference Acceleration, and CPU-GPU Heterogeneous Computing have been accepted to DATE 2026. Congratulations to Haomin, Yuwei, Yuang and all co-authors!Nov./10/2025 Our paper “ASTER: Adaptive Dynamic Layer-Skipping for Efficient Transformer Inference via Markov Decision Process” has been awarded Outstanding Paper in Systems Theme at ACM MM 2025. Congratulations to Junjie and all co-authors!Nov./08/2025 Our two papers on 3D Gaussian Splatting (3DGS) Acceleration have been accepted to HPCA 2026. Congratulations to Haomin and all co-authors!Nov./08/2025 Our paper “SpecQuant” on Frequency-Domain Low-Bit Quantization has been accepted to AAAI 2026. Congratulations to Zhixiong and all co-authors!Nov./03/2025 Our paper “MIXQ” on Mixed-Precision Compiler Acceleration has been accepted to ACM TACO 2025! Congratulations to Shiyuan and all co-authors!Nov./02/2025 Our paper on Variable-Length Encoding for Mixed-Precision LLM Acceleration has been accepted to ACM TACO 2025! Congratulations to Ning Yang and all co-authors!Oct./11/2025 Our team won the First Prize and Third Prize in the 2nd Open Source Community Competition on Integrated Chip and Chiplet Technology (Chinese: 第二届集成芯片和芯粒技术开源社区大赛一等奖), which was held alongside the 3rd Integrated Chip and Chiplet Conference co-hosted by Wuhan University, Institute of Computing Technology of the Chinese Academy of Sciences, and Fudan University . Congratulations to Ning Yang, Junjie and teammates.Sep./20/2025 Our team won the Grand Prize (Chinese: 图计算系统设计大赛特等奖) in the CCF Sys2025 Graph Computing System Design Competition, and was also honored with the Best Project Poster Award (Chinese: 最佳项目海报奖). Congratulations to Zongwu, Chenyang, and teammates.Sep./05/2025 Our paper “BLADE” on DRAM-based LLM Acceleration has been accepted to ASP-DAC 2026. Congratulations to Yilong.Aug./29/2025 The “FlexQuant” quantization framework for LLM Acceleration has been reported by Asystem Team From Ant Group (Chinese: 蚂蚁集团). Congratulations to Zongwu.Aug./21/2025 Our paper on Flexbile Quantization for LLM Acceleration has been accepted to EMNLP 2025. Congratulations to Zongwu and Jinghong.Jul./15/2025 Our paper on Quantum Computing Acceleration has been accepted to MICRO-58 (2025).Jul./06/2025 Our paper on Adaptive Dynamic Layer-skipping Framework for LLM acceleration has been accepted to ACM MM (Oral) 2025. Congratulations to Junjie.Jul./01/2025 Our three papers on PIM-based LLM acceleration, circuit optimization for nonlinear operations, and PCIe tracing for edge AI have been accepted to ICCAD 2025. Congratulations to Yiwe, Zhixiong, and Zhibai.May/03/2025 Our paper on “Collision Ditection Accelerator Based on RRAM-TCAMs” has been accepted by IEEE TCAD 2025! Congratulations to Yijian.Apr./29/2025 Our two papers on “PIM+NeRF” and “PIM+Database (OLAP and OLTP)” have been accepted by ASPLOS 2026! Congratulations to Haomin and Yilong.Apr./16/2025 Our paper on “Enhancing Robustness of Binary Hyper-Dimensional Computing” has been accepted by ACM TACO 2025! Congratulations to Haomin.Mar./22/2025 Our two papers on brain-inspired computing (HDC) and Quantum-Classical Computing have been accepted by ISCA 2025! Congratulations to Haomin.Feb./15/2025 Our four papers on LLM acceleration and FHE have been accepted by DAC 2025 ! Congratulations to Haomin, Zongwu, Ning Yang.Nov./13/2024 Our five papers on the brain-inspired HDC and LLM acceleration have been accepted by DATE 2025! Congratulations to Haomin, Zongwu, Ning Yang.Nov./03/2024 Our two papers on the Acceleration with Sparse Compilation Optimization and Guassian Splatting have been accepted by HPCA 2025! Congratulations to Shiyuan.Nov./01/2024 Our paper “SearchQ” on the post-training & data-free compression on LLMs have been accepted by TCAS-AI 2024! Congratulations to Ning Yang.Oct./03/2024 Our Paper “STCO” on the AI Compilation Optimization have been accepted by TODAES 2024! Congratulations to Shiyuan.Sep./08/2024 Our two papers on the PQ Compression and SNN Quantization have been accepted by ASP-DAC 2025! Congratulations to Zongwu and Haomin.Aug./26/2024 I received a grant from the NSFC Youth Fund titled “Neural Network Hardware-Software Co-design Architecture Based on Adaptive Compression Ecoding”.Aug./22/2024 Our paper on a novel compiler plug-in for efficient SpMM has been accepted by IEEE TCAD 2024! Congratulations to Shiyuan.Aug./2/2024 Our four papers on the Accelerations of LLMs, SNNs, and nested address translation in virtualized environments have been accepted by ICCD 2024! Congratulations to Ning Yang, Zongwu and Longyu.Jul./18/2024 Our two papers on the Accelerators of Spiking Neural Networks and Neural Radiance Fields have been accepted by MICRO 2024! Congratulations to Zongwu.Jul./06/2024 Fangxin Liu received 2023 ACM Shanghai Doctoral Dissertation Award.Jun./07/2024 Our paper on SNN Accelerator has been accepted by TPDS 2024!May/25/2024 Our three papers on DRAM PIM, video acceleration, and LLM acceleration have been accepted by ChinaSys24. We look forward to sharing them in Hangzhou!May/20/2024 Our “LowPASS” A ReRAM-based SNN Accelerator has been accepted by ISLPED 2024! Congratulations to Zongwu.Mar./20/2024 Our “UM-PIM” Data re-layouted machnism has been accepted by ISCA 2024! Congratulations to Yilong.Mar./18/2024 Fangxin Liu received 2023 Shanghai CCF Outstanding Dissertation Award.Feb./27/2024 Our 2 papers have been accepted by DAC 2024! Congratulations to Ning Yang.Dec./29/2023 The “SPARK” acceleration framework has been reported in Jiqizhixin(机器之心).Nov./12/2023 Our paper “RTSA” has been accepted by DATE 2024! Congratulations to Jiahao.Oct./23/2023 Our paper “SPARK” has been accepted by HPCA 2024! Congratulations to Ning Yang.Sep./09/2023 Our 4 papers have been accepted by ASP-DAC 2023! Congratulations to Haomin, Shiyuan, Tian Li.Aug./25/2023 Our paper “PSQ” has been accepted by ICCD 2023! Congratulations to Ning Yang.Jul./21/2023 Our paper “HyperNode” has been accepted by ICCAD 2023! Congratulations to Haomin.Jul./18/2023 Our paper “ERA-BS” has been accepted by TC 2023!Feb./24/2023 Our paper “HyperAttack” has been accepted by DAC 2023!Nov./18/2022 Our paper “SIMSnn” has been accepted by DATE 2023!ResearchCurrent research interests focuses on:LLMs/Neural Network Acceleration (大模型/神经网络训练、推理加速)In-memory Computing (存内计算)Brain-inspired Neuromorphic Computing (神经模态计算)AI Compilation Optimization (AI编译优化)RecruitmentOur team is seeking self-motivated PhD, Master and Undergraduate students who are interested in Computer Architecture, Efficient AI acceleration, and PIM Design. If you are interested, please email me your CV.Recent Visits to this Site",
  "content_length": 8976,
  "method": "requests",
  "crawl_time": "2025-12-01 13:09:06"
}