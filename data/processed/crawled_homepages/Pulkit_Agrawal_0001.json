{
  "name": "Pulkit Agrawal 0001",
  "homepage": "https://people.csail.mit.edu/pulkitag",
  "status": "success",
  "content": "Pulkit Agrawal Pulkit Agrawal I am an Associate Professor in the department of Electrical Engineering and Computer Science (EECS) at MIT. My lab is a part of the Computer Science and Artificial Intelligence Lab (CSAIL), is affiliated with the Laboratory for Information and Decision Systems (LIDS) and involved with NSF AI Institute for Artificial Intelligence and Fundamental Interactions ( IAIFI ). I completed my Ph.D. at UC Berkeley; undergraduate studies from IIT Kanpur. Co-founded SafelyYou Inc. that builds fall prevention technology. Advisor to Tutor Intelligence, Lab0 Inc., and Common Sense Machines. Follow @pulkitology / LinkedIn / Email  / CV  / Biography  / Google Scholar Research The overarching research interest is to build machines that have similar manipulation and locomotion abilities as humans. These machines will automatically and continuously learn about their environment and exhibit both common sense and physical intuition. I refer to this line of work as \"computational sensorimotor learning\". It encompasses problems in peception, control, hardware design, robotics, reinforcement learning, and other learning approaches to control. My past work has also drawn inspiration from cognitive science, and neuroscience. Ph.D. Thesis (Computational Sensorimotor Learning)  / Thesis Talk  / Bibtex TEDxMIT Talk: Why machines can play chess but can't open doors? (i.e., why is robotics hard?) Teaching Courses Computational Sensorimotor Learning Graduate Machine Learning: FA'20, FA'21 Intelligent Robot Manipulation: FA'19 Professional Education These courses are intended for industry professionals and not MIT students. Advanced Reinforcement Learning: Summer'24 Reinforcement Learning: Summer'24 AI in Robotics: Summer'24 Recent Awards to Lab Members Pulkit recieves the IIT Kanpur Young Alumnus Award. Pulkit recieves 2024 IEEE Early Academic Career Award in Robotics and Automation . Meenal Parakh wins the 2024 Charles and Jennifer Johnson MEng Thesis Award. Idan Shenfeld and Zhang-Wei Hong win the 2024 Qualcomm Innvoation Fellowship. Srinath Mahankali wins the 2024 Jeremy Gerstle UROP Award for undergraduate research. Srinath Mahankali wins the 2024 Barry Goldwater Scholarship. Best Paper Award at Conference on Robot Learning (CoRL) 2021 to our work on in-hand object re-orientation. Research Group The lab is an unsual collection of folks working on something that is unconceivable/unthinkable, but not impossible in our lifetime: General Artificial Intelligence. Life is short, do what you must do :-) I like to call my group: Improbable AI Lab. Post Docs Haoshu Fang Branden Romero Graduate Students Antonia Bronars Gabe Margolis Zhang-wei Hong Nolan Fey Younghyo Park Jyothish Pari Idan Shenfeld Aviv Netanyahu Richard Li Martin Peticco Nitish Dashora Seungwook Han Masters of Engineering (MEng. Students) and Undergraduate Researchers (UROPs) Srinath Mahankali, Jagdeep Bhatia, Arthur Hu, Gregory Pylypovych, Kevin Garcia, Yash Prabhu, Locke Cai. Visiting Researchers Sandor Felber, Lars Ankile Openings We have openings for Ph.D. Students, PostDocs, and MIT UROPs/SuperUROPs. If you would like to apply for the Ph.D. program, please apply directly to MIT EECS admissions. For all other positions, send me an e-mail with your resume. Recent Talks Pathway to Robotic Intelligence , MIT Schwarzman College of Computing Talk, 2024. Making Robots as Intelligent as ChatGPT, Forbes, 2023. Robot Learning for the Real World, Forum for Artificial Intelligence, UT Austin, March 2023. Fun with Robots and Machine Learning , Robotics Colloqium, University of Washington, Nov 2022. Navigating Through Contacts , RSS 2022 Workshop in The Science of Bumping into Things. Coming of Age of Robot learning , Technion Robotics Seminar (April 14 2022) / MIT Robotics Seminar (March 2022). Rethinking Robot Learning , Learning to Learn: Robotics Workshop, ICRA'21. Self-Supervised Robot Learning, Robotics Seminar, Robot Learning Seminar, MILA. Challenges in Real-World Reinforcement Learning, IAIFI Seminar, MIT. The Task Specification Problem, Embodied Intelligence Seminar, MIT. Pre-Prints General Reasoning Requires Learning to Reason from the Get-go Seungwook Han, Jyo Pari, Sam Gershman, Pulkit Agrawal arXiv, 2025 paper / bibtex Achieving true reasoning requires a new paradigm for pre-training based on rewards and iterative computation. Known Unknowns: Out-of-Distribution Property Prediction in Materials and Molecules Nofit Segal*, Aviv Netanyahu*, Kevin Greenman, Pulkit Agrawalâ , Rafael GÃ³mez-Bombarelliâ  (*equal contribution; â equal advising) Workshop on AI for Accelerated Materials Design, NeurIPS 2024 (Oral) paper / code / bibtex Extrapolating property prediction in materials science. Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation Nolan Fey, Gabriel B. Margolis, Martin Peticco, Pulkit Agrawal Workshop on Robot Learning, ICLR 2025 (Oral) paper / bibtex Enhancing the sim-to-real transfer for extreme whole-body manipulation. Language Model Personalization via Reward Factorization Idan Shenfeld*, Felix Faltings*, Pulkit Agrawal, Aldo Pacchiano, In submission paper / bibtex Framework for personalizing large models assuming that human preferences lie on a low-dimensional manifold. Publications From Imitation to Refinement â Residual RL for Precise Visual Assembly Lars Ankile, Anthony Simeonov, Idan Shenfeld, Marcel Torne, Pulkit Agrawal ICRA, 2025 paper / project page / code / bibtex Refining behavior-cloned diffusion model policies using RL. Vegetable Peeling: A Case Study in Constrained Dexterous Manipulation Tao Chen, Eric Cousineau, Naveen Kuppuswamy, Pulkit Agrawal ICRA, 2025 project page / arXiv A robotic system that peels vegetables with a dexterous robot hand. ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal ICLR, 2025 paper / bibtex Casting reward selection as a model selection leads to faster learning (upto 8x) and better performance (upto 2x) when training RL agents with provable regret guarantees. Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning Moritz Reuss*, Jyo Pari*, Pulkit Agrawal, Rudolf Lioutikov (*equal contribution) ICLR , 2025 paper / bibtex MoDE is a novel architecture that uses sparse experts and noise-conditioned routing. Diffusion Policy Policy Optimization Allen Z. Ren, Justin Lidard, Lars L. Ankile, Anthony Simeonov, Pulkit Agrawal, Anirudha Majumdar, Benjamin Burchfiel, Hongkai Dai, Max Simchowitz ICLR, 2025 paper / code / bibtex DPPO is an algorithmic framework for fine-tuning diffusion-based policies using reinforcement learning. EyeSight Hand: Design of a Fully-Actuated Dexterous Robot Hand with Integrated Vision-Based Tactile Sensors and Compliant Actuation Branden Romero*, Hao-Shu Fang*, Pulkit Agrawal, Edward Adelson IROS, 2024 paper / project page / bibtex A dexterous hand with proprioceptive actuation fully covered with tactile sensing. Reconciling Reality through Simulation: A Real-To-Sim-to-Real Approach for Robust Manipulation Marcel Torne Villasevil , Anthony Simeonov, Zechu Li, April Chan, Tao Chen, Abhishek Gupta, Pulkit Agrawal RSS, 2024 paper / project page / bibtex A framework to train robots on scans of real-world scenes. Few-Shot Task Learning through Inverse Generative Modeling Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal NeurIPS, 2024 paper / project page / code / bibtex Few-shot continual learning via generative modeling. Random Latent Exploration for Deep Reinforcement Learning Srinath Mahankali, Zhang-Wei Hong, Ayush Sekhari, Alexander Rakhlin, Pulkit Agrawal ICML, 2024 paper / project page / code / bibtex State-of-the-art exploration by optimizing the agent to achieve randomly sampled latent goals. Training Neural Networks From Scratch with Parallel Low-Rank Adapters Minyoung Huh, Brian Cheung, Jeremy Bernstein, Phillip Isola, Pulkit Agrawal arXiv, 2024 paper / project page / bibtex A method for parallel training of large models on computers with limited memory. Value Augmented Sampling for Language Model Alignment and Personalization Seungwook Han, Idan Shenfeld, Akash Srivastava,Yoon Kim, Pulkit Agrawal Workshop on Reliable and Responsible Foundation Models, ICLR 2024 (Oral) paper / bibtex Algorithm for inference-time augmentation of Large Language Models. Lifelong Robot Learning with Human Assisted Language Planners Meenal Parakh*, Alisha Fong*, Anthony Simeonov, Abhishek Gupta, Tao Chen, Pulkit Agrawal (*equal contribution) ICRA , 2024 paper / project page / bibtex An LLM-based task planner that can learn new skills opens doors for continual learning. Learning Force Control for Legged Manipulation Tifanny Portela, Gabriel B. Margolis, Yandong Ji, Pulkit Agrawal ICRA, 2024 paper / project page / bibtex Learning to control the force applied by a legged robot's arm for compliant and forceful manipulation. Curiosity-driven Red-teaming for Large Language Models Zhang-Wei Hong, Idan Shenfeld, Tsun-Hsuan Wang, Yung-Sung Chuang, Aldo Pareja, James R. Glass, Akash Srivastava, Pulkit Agrawal ICLR, 2024 paper / code / bibtex Maximizing Quadruped Velocity by Minimizing Energy Srinath Mahankali*, Chi-Chang Lee*, Gabriel B. Margolis, Zhang-Wei Hong, Pulkit Agrawal ICRA, 2024 paper / project page / bibtex Principled energy minimization increases robot's agility. JUICER: Data-Efficient Imitation Learning for Robotic Assembly Lars Ankile, Anthony Simeonov, Idan Shenfeld, Pulkit Agrawal IROS, 2024 paper / project page / code / bibtex Learning complex assembly skills from few human demonstrations. Rank2Reward: Learning Shaped Reward Functions from Passive Video Daniel Yang, Davin Tjia, Jacob Berg, Dima Damen, Pulkit Agrawal, Abhishek Gupta ICRA, 2024 paper / project page / code / bibtex Learning reward functions from videos of human demonstrations. Everyday finger: a robotic finger that meet",
  "content_length": 32613,
  "method": "requests",
  "crawl_time": "2025-12-01 14:13:24"
}