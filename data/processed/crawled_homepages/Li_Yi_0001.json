{
  "name": "Li Yi 0001",
  "homepage": "https://iiis.tsinghua.edu.cn/en/People/Faculty/YiLi.htm",
  "status": "success",
  "content": "ï»¿ Yi Li-Institute for Interdisciplinary Information Sciences (IIIS) Home IIIS Headlines Institute Seminars About IIIS Introduction Message From Dean Current Leadership History News Latest News Media Coverage People Faculty Research Honorary Professors Adjunct Instructors Postdocs Administrative Staff Lab Assistants Yao Class About Yao Class Admission Graduate Graduate Programs Graduate Admission CQI Introduction Faculty Research Overview CQI News Research Organization Research Groups Latest Research Research Report Campus Campus Events Student Life Join Us Faculty Recruitment Postdoctoral Recruitment Staff Recruitment Alumni IIIS Alumni Community Giving People Faculty Research Honorary Professors Adjunct Instructors Postdocs Administrative Staff Lab Assistants Li Yi 3D computer vision, 3D deep learning, robot perception, computer graphics, geometric processing About I am an Assistant Professor in the Institute for Interdisciplinary Information Sciences (IIIS) at Tsinghua University. I received my Ph.D. from Stanford University, advised by Professor Leonidas J. Guibas. And I spent a wonderful time at Google as a Research Scientist after graduation, working closely with Professor Thomas Funkhouser. Prior to joining Stanford, I got my bachelor's degree in Electronic Engineering from Tsinghua University. My recent research interests focus on 3D perception, human-robot interaction and embodied AI, with the goal of equipping robotic agent with the ability of understanding and interacting with the 3D world. Recruiting I am actively looking for motivated visiting students, interns, PhDs, and postdocs. Please feel free to email me if you are interested. Â§ For PhD applicants, please contact me at least half a year prior to your application. Â§ For visiting students or research interns, we have openings for long-term internship (six months or longer). Both undergraduate and graduate students are welcomed. Please email me with your CV and transcript to apply. News Â§ NEW [2025/02] Five papers accepted to CVPR 2025. Â§ NEW [2025/01] Two papers accepted to ICLR 2025. Â§ NEW [2024/12] I am invited to be a speaker in the third Workshop on Reconstruction of Human-Object Interactions (RHOBIN) at CVPR 2025. Â§ NEW [2024/12] I am organizing the 1st Workshop on Humanoid Agents at CVPR 2025. Â§ NEW [2024/11] I am invited to be a speaker in Learning Robot Fine and Dexterous Manipulation Workshop at CoRL 2024 (video recording). Â§ NEW [2024/11] Two papers accepted to 3DV 2025. Â§ [2024/09] One paper accepted to NeurIPS 2024. Â§ [2024/07] Three papers accepted to ECCV 2024 and one paper accepted to ACMMM 2024 as oral. Â§ [2024/03] Four papers accepted to CVPR 2024. Â§ [2024/01] Two papers accepted to ICRA 2024 with one also accepted to Robotics and Automation Letters (RA-L). Â§ [2024/01] Two papers accepted to ICLR 2024 with one as spotlight. Â§ [2023/12] Two papers accepted to AAAI 2024. Â§ [2023/07] Four papers accepted to ICCV 2023. Â§ [2023/06] I will serve as an Area Chair for CVPR 2024. Â§ [2023/04] One paper accepted to ICML 2023 and one paper accepted to SIGGRAPH 2023. Â§ [2023/03] I serve as an Area Chair for NeurIPS 2023. Â§ [2023/03] Seven papers accepted to CVPR 2023. Â§ [2023/01] Two papers accepted to ICLR 2023. Â§ [2023/01] Two papers accepted to AAAI 2023 as orals. Â§ [2022/10] I serve as an Area Chair for CVPR 2023. Â§ [2022/09] One paper accepted to ECCV 2022 and one paper accepted to SIGGRAPH Asia 2022. Â§ [2022/03] Seven papers accepted to CVPR 2022. Â§ [2021/09] Two papers accepted to NeurIPS 2021 and one paper accepted to ICCV 2021. Â§ [2021/05] I serve as an Area Chair for CVPR 2022. Â§ [2021/05] I am organizing The 1st Workshop on Simulation Technology for Embodied AI at ICCV 2021. Â§ [2021/03] Two papers accepted at CVPR 2021 (one oral included). Recent Projects *: equivalent contribution, â : corresponding author Deep Object-Centric 3D PerceptionLi YiPh.D. ThesisPDF Learning Physics-Based Full-Body Human Reaching and Grasping from Brief Walking ReferencesYitang Li*, Mingxian Lin*, Zhuo Lin, Yipeng Deng, Yue Cao, Li Yiâ CVPR 2025PDF Project CORE4D : A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangementYun Liu*, Chengwen Zhang*, Ruofan Xing, Bingda Tang, Bowen Yang, Li Yiâ CVPR 2025PDF Project Data Code MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic DataZifan Wang*, Ziqing Chen*, Junyu Chen*, Jilong Wang, Yuxin Yang, Yunze Liu, Xueyi Liu, He Wang, Li Yiâ CVPR 2025PDF Video MAP: Unleashing Hybrid Mamba-Transformer Vision Backbone's Potential with Masked Autoregressive PretrainingYunze Liu, Li Yiâ CVPR 2025PDF Code PartRM: Modeling Part-Level Dynamics with Large Cross-State Reconstruction ModelMingju Gao*, Yike Pan*, Huan-ang Gao*, Zongzheng Zhang, Wenyi Li, Hao Dong, Hao Tang, Li Yi, Hao Zhaoâ CVPR 2025PDF Project Dataset&Models Code DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human ReferencesXueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yiâ ICLR 2025PDF Project Code VILA-U: a Unified Foundation Model Integrating Visual Understanding and GenerationYecheng Wu*, Zhuoyang Zhang*, Junyu Chen, Haotian Tang, Dacheng Li, Yunhao Fang, Ligeng Zhu, Enze Xie, Hongxu Yin, Li Yi, Song Han, Yao LuICLR 2025PDF Project Code Interactive Humanoid: Online Full-Body Motion Reaction Synthesis with Social Affordance Canonicalization and ForecastingYunze Liu, Changxi Chen, Li Yiâ 3DV 2025PDF Project ImOV3D: Learning Open Vocabulary Point Clouds 3D Object Detection from Only 2D ImagesTiming Yang*, Yuanliang Ju*, Li Yiâ NeurIPS 2024PDF Code ShapeLLM: Universal 3D Object Understanding for Embodied InteractionZekun Qi, Runpei Dong, Shaochen Zhang, Haoran Geng, Chunrui Han, Zheng Ge, He Wang, Li Yiâ , Kaisheng Maâ ECCV 2024PDF Project Code QuasiSim: Parameterized Quasi-Physical Simulators for Dexterous Manipulations TransferXueyi Liu, Kangbo Lyu, Jieqiong Zhang, Tao Du, Li Yiâ ECCV 2024PDF Project Code FreeMotion: MoCap-Free Human Motion Synthesis with Multimodal Large Language ModelsZhikai Zhang, Yitang Li, Haofeng Huang, Mingxian Lin, Li Yiâ ECCV 2024PDF Project PhysReaction: Physically Plausible Real-Time Humanoid Reaction Synthesis via Forward Dynamics Guided 4D ImitationYunze Liu, Changxi Chen, Chenjing Ding, Li Yiâ ACMMM 2024 (Oral, top 3.9%)PDF Project GenH2R: Learning Generalizable Human-to-Robot Handover via Scalable Simulation, Demonstration, and ImitationZifan Wang*, Junyu Chen*, Ziqing Chen, Pengwei Xie, Rui Chen, Li Yiâ CVPR 2024PDF Project TACO: Benchmarking Generalizable Bimanual Tool-ACtion-Object UnderstandingYun Liu, Haolin Yang, Xu Si, Ling Liu, Zipeng Li, Yuxiang Zhang, Yebin Liu, Li Yiâ CVPR 2024PDF Project GenN2N: Generative NeRF2NeRF TranslationXiangyue Liu, Han Xue, Kunming Luo, Ping Tanâ , Li Yiâ CVPR 2024PDF Project Code Physics-aware Hand-object Interaction DenoisingHaowen Luo, Yunze Liu, Li Yiâ CVPR 2024PDF DreamLLM: Synergistic Multimodal Comprehension and CreationRunpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, Jinrong Yang, Liang Zhao, Jianjian Sun, Hongyu Zhou, Haoran Wei, Xiangwen Kong, Xiangyu Zhang, Kaisheng Maâ , Li Yiâ ICLR 2024 (Spotlight, top 5%)PDF Project Code GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising DiffusionXueyi Liu, Li Yiâ ICLR 2024PDF Project OpenReview Enhancing Generalizable 6D Pose Tracking of an In-Hand Object with Tactile SensingYun Liu*, Xiaomeng Xu*, Weihang Chen, Haocheng Yuan, He Wang, Jing Xu, Rui Chen, Li Yiâ RA-L with a presentation at ICRA 2024PDF CrossVideo: Self-supervised Cross-modal Contrastive Learning for Point Cloud Video UnderstandingYunze Liu, Changxi Chen, Zifan Wang, Li Yiâ ICRA 2024PDF Semantic Complete Scene Forecasting from a 4D Dynamic Point Cloud SequenceZifan Wang*, Zhuorui Ye*, Haoran Wu*, Junyu Chen, Li Yiâ AAAI 2024PDF Project Full-Body Motion Reconstruction with Sparse Sensing from Graph PerspectiveFeiyu Yao, Zongkai Wuâ , Li Yiâ AAAI 2024PDF NSM4D: Neural Scene Model Based Online 4D Point Cloud Sequence UnderstandingYuhao Dong*, Zhuoyang Zhang*, Yunze Liu, Li Yiâ arXiv:2310.08326 [cs.CV], Oct 2023PDF TransTouch: Learning Transparent Objects Depth Sensing Through Sparse TouchesLiuyu Bian, Pengyang Shi, Weihang Chen, Jing Xu, Li Yiâ , Rui Chenâ IROS 2023PDF Video Code LeaF: Learning Frames for 4D Point Cloud Sequence UnderstandingYunze Liu, Junyu Chen, Zekai Zhang, Li Yiâ ICCV 2023PDF Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical DeformationXueyi Liu, Bin Wang, He Wang, Li Yiâ ICCV 2023PDF Project Code UniDexGrasp++: Improving Dexterous Grasping Policy Learning via Geometry-aware Curriculum and Iterative Generalist-Specialist LearningWeikang Wan*, Haoran Geng*, Yun Liu, Zikang Shan, Yaodong Yang, Li Yi, He WangICCV 2023PDF Project Code 3D Implicit Transporter for Temporally Consistent Keypoint DiscoveryChengliang Zhong, Yuhang Zheng, Yupeng Zheng, Hao Zhao, Li Yi, Xiaodong Mu, Ling Wang, Pengfei Li, Guyue Zhou, Chao Yang, Xinliang Zhang, Jian ZhaoICCV 2023PDF Code ArrangementNet: Learning Scene Arrangements for Vectorized Indoor Scene ModelingJingwei Huang, Shanshan Zhang, Bo Duan, Yanfeng Zhang, Xiaoyang Guo, Mingwei Sun, Li YiSIGGRAPH 2023 (Journal Track) Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative PretrainingZekun Qi*, Runpei Dong*, Guofan Fan, Zheng Ge, Xiangyu Zhang, Kaisheng Maâ , Li Yiâ ICML 2023PDF Code Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud Sequence Representation LearningZhuoyang Zhang*, Yuhao Dong*, Yunze Liu, Li Yiâ CVPR 2023PDF Project Code CAMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation SynthesisJuntian Zheng*, Lixing Fang*, Qingyuan Zheng*, Yun Liu, Li Yiâ CVPR 2023PDF Project Code JacobiNeRF: NeRF Shaping with Mutual Information GradientsXiaomeng Xu, Yanchao Y",
  "content_length": 18749,
  "method": "requests",
  "crawl_time": "2025-12-01 13:46:55"
}