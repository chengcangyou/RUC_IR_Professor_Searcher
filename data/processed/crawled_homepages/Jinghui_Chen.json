{
  "name": "Jinghui Chen",
  "homepage": "https://jinghuichen.github.io",
  "status": "success",
  "content": "Jinghui Chen | Home Jinghui Chen Assistant Professor, Ph.D. Penn State University Email: jzc5917 [at] psu [dot] edu About I am an Assistant Professor in the College of Information Sciences and Technology at Penn State University. I received my Ph.D. in the Department of Computer Science, University of California, Los Angeles (UCLA) working with Prof. Quanquan Gu in 2021. I received my B.E. in the Department of Electrical Engineering and Information Science at the University of Science and Technology of China in 2015. Prospective Students: I’m looking for highly motivated PhD/intern students to join my group. (details). If you’re interested in joining my lab, please fill and see instructions in the following form (feel free to skip optional questions). Research Interests: My research interests broadly include the theory and applications in different aspects of machine learning, with particular interests on building efficient and trustworthy machine learning models. Recently, we are particularly interested in the following research topics: Trustworthiness and safety issues in Large Language Models (LLM alignments, LLM robustness, etc.) Security and privacy issues for other emerging machine learning models (multimodal foundation models, federated learning, diffusion models, etc.) Efficient optimization strategies for training large scale foundataion models/federated learning (adaptive gradient optimizers, parameter-efficient training, etc.) News [09/2025] One paper is accepted to NeurIPS 2025! [08/2025] One paper is accepted to EMNLP 2025! [08/2025] One paper is accepted to CCS 2025! [05/2025] One paper is accepted to ACL 2025! [05/2025] Two papers are accepted to ICML 2025! [01/2025] One paper is accepted to NAACL 2025! [01/2025] One paper is accepted to USENIX 2025! [09/2024] Three papers are accepted to NeurIPS 2024! [09/2024] One paper is accepted to EMNLP 2024! [05/2024] Two papers are accepted to ACL 2024! [05/2024] Two papers are accepted to ICML 2024! [03/2024] Two papers are accepted to NAACL 2024! [01/2024] Two papers are accepted to ICLR 2024! [12/2023] One paper is accepted to AAAI 2024! [12/2023] Two papers are accepted to USENIX 2024! [09/2023] Five papers are accepted to NeurIPS 2023! [08/2023] We are organizing the Workshop on Federated Learning in the Age of Foundation Models at NeurIPS 2023 (FL@FM-NeurIPS’23). Submissions are welcome! [08/2023] Our paper is accepted to CIKM 2023: \"RoCourseNet: Robust Training of a Prediction Aware Recourse Model\" [05/2023] Our paper is accepted to KDD 2023: \"PAT: Geometry-Aware Hard-Label Black-Box Adversarial Attacks on Text\" [05/2023] Our paper is accepted to UAI 2023: \"Benign Overfitting in Adversarially Robust Linear Classification\" [04/2023] Our paper is accepted to ICML 2023: \"Graph Contrastive Backdoor Attacks\" [01/2023] Our paper is accepted to WWW 2023: \"Do Language Models Plagiarize?\" [01/2023] Our paper is accepted to ICLR 2023: \"Spectral Augmentation for Self-Supervised Learning on Graphs\" [12/2022] Our paper is accepted to AAAI 2023: \"On the Vulnerability of Backdoor Defenses for Federated Learning\" [09/2022] Our paper is accepted to NeurIPS 2022: \"One-shot Neural Backdoor Erasing via Adversarial Weight Masking\" [05/2022] Our paper is accepted to KDD 2022: \"LeapAttack: Hard-Label Adversarial Attack on Text via Gradient-Based Optimization\" [05/2022] Our paper is accepted to ICML 2022: \"Communication-Efficient Adaptive Federated Learning\" [05/2022] Dr. Chen recieved received Cisco Faculty Research Award! [01/2022] Our paper is accepted to ICLR 2022: \"Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations\" [01/2022] Our paper is accepted to AISTATS 2022: \"Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization\" [12/2021] Our paper is accepted to AAAI 2022: \"Efficient Robust Training via Backward Smoothing\" [09/2021] Our paper is accepted to NeurIPS 2021: \"Do Wider Neural Networks Really Help Adversarial Robustness?\" [06/2021] I recieved UCLA Outstanding Graduate Student Research Award. [04/2021] I will join the College of Information Sciences and Technology (IST) at Penn State University (PSU) in Fall 2021 as a tenure-track assistant professor. [07/2020] Released Model Robustness (ADBD) Leaderboard under RayS attack: Benchmarking state-of-the-art robust trained models with ADBD metric [05/2020] Our paper is accepted to KDD 2020: \"RayS: A Ray Searching Method for Hard-label Adversarial Attack\" [04/2020] Our paper is accepted to IJCAI 2020: \"Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks\" [04/2020] We just launched a project using machine learning and AI to combat Covid-19! Live data visualization and new cases / peak predictions [01/2020] Our paper is accepted to AISTATS 2020: \"Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models\" [11/2019] Our paper is accepted to AAAI 2020: \"A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks\" Publications Full publications on Google Scholar. E indicates authors with equal contribution. underline indicates students supervised. All At PSU AltLoRA: Towards Better Gradient Approximation in Low-Rank Adaptation with Alternating Projections Xin Yu, Yujia Wang, Jinghui Chen, and Lingzhou Xue, in Proceedings of the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS), San Diego, CA, USA, 2025. [Paper] Phi: Preference Hijacking in Multi-modal Large Language Models at Inference Time Yifan Lan, Yuanpu Cao, Weitong Zhang, Lu Lin, and Jinghui Chen, in Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP), Suzhou, China, 2025. [Paper] You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors Bochuan Cao, Changjiang Li, Ting Wang, and Jinghui Chen, in Proceedings of the 32nd ACM Conference on Computer and Communications Security (CCS), Taipei, Taiwan, 2025. [Paper] Ditect: Lightweight Harmful Content Detector for Text-to-Image Generation Hangfan Zhang, Bochuan Cao, Jinghui Chen, Lu Lin, Jinyuan Jia, and Dinghao Wu, in ICCV 2025 Workshop on Building Foundation Models You Can Trust (ICCV-T2FM), 2025. [Paper] JoPA: Explaining Large Language Model's Generation via Joint Prompt Attribution Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, and Lu Lin, in Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL), Vienna, Austria, 2025. [Paper] Shadow-Activated Backdoor Attacks on Multimodal Large Language Models Ziyi Yin, Muchao Ye, Yuanpu Cao, Aofei Chang, Jiaqi Wang, Han Liu, Jinghui Chen, Ting Wang, Fenglong Ma, in Findings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL Findings), Vienna, Austria, 2025. [Paper] TruthFlow: Truthful LLM Generation via Representation Flow Correction Hanyu Wang, Bochuan Cao, Yuanpu Cao, and Jinghui Chen, in Proceedings of the 42nd International Conference on Machine Learning (ICML), Vancouver, Canada, 2025. [Paper] AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models Yaopei Zeng, Yuanpu Cao, Bochuan Cao, Yurui Chang, Jinghui Chen, and Lu Lin, in Proceedings of the 42nd International Conference on Machine Learning (ICML), Vancouver, Canada, 2025. [Paper] PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection Lee, Jooyoung, Toshini Agrawal, Adaku Uchendu, Thai Le, Jinghui Chen, and Dongwon Lee, in Proceedings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), Albuquerque, New Mexico, 2025. [Paper] WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response Tianrong Zhang, Bochuan Cao, Yuanpu Cao, Lu Lin, Prasenjit Mitra and Jinghui Chen, in Findings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL Findings), Albuquerque, New Mexico, 2025. [Paper] Watch the Watchers! On the Security Risks of Robustness-Enhancing Diffusion Models Changjiang Li, Ren Pang, Bochuan Cao, Jinghui Chen, Fenglong Ma, Shouling Ji and Ting Wang, in Proceedings of the 34th USENIX Security Symposium (USENIX), Seattle, WA, USA, 2025. [Paper] Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization Yuanpu Cao, Tianrong Zhang, Bochuan Cao, Ziyi Yin, Lu Lin, Fenglong Ma and Jinghui Chen, in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, 2024. [Paper] DFBA: Data Free Backdoor Attacks Bochuan Cao, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, Jinghui Chen Bo Li, and Dawn Song, in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, 2024. [Paper] FedMeKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection Jiaqi WangE, Xiaochen WangE, Lingjuan Lyu, Jinghui Chen and Fenglong Ma, in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, 2024. [Paper] FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models Xiaochen WangE, Jiaqi WangE, Houping Xiao, Jinghui Chen and Fenglong Ma, in Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP), Miami, Florida, 2024. [Paper] On the Data Heterogeneity in Adaptive Federated Learning Yujia Wang, Jinghui ChenE, in Transactions on Machine Learning Research (TMLR), 2024. [Paper] Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM Bochuan CaoE, Yuanpu CaoE, Lu Lin, and Jinghui Chen, in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL), Bangkok, Thailand, 2024. [Paper] Jailbreak Open-Sourced Large Language Models via Enfor",
  "content_length": 40731,
  "method": "requests",
  "crawl_time": "2025-12-01 13:31:02"
}