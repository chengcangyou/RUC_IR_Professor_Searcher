{
  "name": "Yue Cheng 0001",
  "homepage": "http://tddg.github.io",
  "status": "success",
  "content": "Yue Cheng mrz7dp _AT_ virginia.edu SDS,CS@UVA Data Systems Researcher I am an Associate Professor of Data Science and Computer Science at the University of Virginia. My research covers a range of topics including distributed systems, serverless and cloud computing, storage systems, operating systems, and high-performance computing. My current research focuses on designing scalable, high-performance, and easy-to-use computer systems that manage and process huge volume of data. Currently I am working on: (1) LLM systems: making LLM applications elastic and scalable; (2) Serverless and FaaS: improving serverless computing using a end-to-end approach that cuts across the entire ecosystem stack: (stateful) applications, middleware, platforms, and low-level OS; (3) Storage for AI: rethinking storage system designs and data reduction techniques for AI applications. I am the recipient of an NSF CAREER Award (2021), an Amazon Research Award (2021), a Meta Research Award (2022), the IEEE CS TCHPC Early Career Researchers Award for Excellence in HPC (2022), and a Samsung GRO 2023 Award (2023). I was ranked among the Stanford‚Äôs World‚Äôs Top 2% Scientists in 2024. I received my Ph.D. degree in Computer Science from Virginia Tech, working with Dr. Ali R. Butt. During my Ph.D. I spent two summers at IBM Research Almaden in 2013 and 2014, and six months at Dell EMC Princeton Office in 2015. selected projects Most of my projects are open-source and available on our group‚Äôs GitHub page. Our recent focus is on: Designing first-gen Serverless AI platforms for Large Language Model (LLM) applications, Rethinking storage system design in the era of Generative AI and LLMs. I‚Äôm looking for motivated graduate/undergrad interns interested in conducting research in cutting-edge LLM systems areas (serverless AI, LLM agents, storage for ML/AI models/datasets). Please fill out this form if you are interested! Also feel free to reach out via email. For our most recent projects, check our latest preprints and publication. Serverless AI: Interactive ML/AI workloads require elastic access to heterogeneous compute resources (GPU, CPU). We explore new serverless execution paradigms to enable efficient GPU utilization and scalable and elastic GPU management for LLM fine-tuning and inference. NotebookOS implements on-demand GPUs for Jupyter Notebook-based interactive training workloads. ZenFlow accelerates LLM fine-tuning by prioritizing and decoupling parameter updates across fast GPU and slow CPU, minimizing GPU stalls while preserving accuracy. ZenFlow had been adopted into DeepSpeed. MorphServe enables flexible and elastic GPU memory scaling for bursty LLM inference workloads via dynamic model layer quantization and KVC resizing. [NotebookOS preprint [ASPLOS‚Äô26]] [ZenFlow preprint] [MorphServe preprint] Storage Systems for AI: We are rethinking storage system design to sustain the exponential AI data explosion. ZipLLM and BitX are new lossless compressing algorithms that reduce the LLM storage footprint by 50%. ELF and ELVES near-losslessly compress ML models to achieve effective model storage reduction. SHADE and FedCaSe automatically and intelligently cache the most important training samples without losing training quality. [ZipLLM preprint [NSDI‚Äô26]] [VLDB‚Äô24]: [GitHub] [SoCC‚Äô24]: [GitHub] [FAST‚Äô23]: [GitHub] FaaS Platform Management: We design innovative systems solutions to make FaaS truly elastic. A highly scalable container provisioning framework that can provision thousands of 10+GB serverless function containers with just a few seconds. FaaSNet [ATC‚Äô21] and CIDRE [ASPLOS‚Äô25] are both deployed at Alibaba Function Compute. [ASPLOS‚Äô25]: [GitHub] [ATC‚Äô21]: [GitHub] [Alibaba Cloud Blog] Serverless Cloud Storage: Storing large and small objects on a dynamic fleet of serverless functions with only 3% of ElastiCache‚Äôs cost but without sacrificing performance and availability. [ASPLOS‚Äô23]: [GitHub] [VLDB‚Äô23]: [GitHub] [FAST‚Äô20]: [GitHub] Serverless Parallel Computing: Scaling out Python parallel programs (e.g., Dask applications) on FaaS without worrying about tedious cluster management. Wukong uses a new decentralized scheduling technique, which decentralizes resource orchestration to each individual serverless function, thereby enabling high elasticity and high scalability. [SoCC‚Äô20]: [GitHub] [PDSW‚Äô19] Serverless Function OS Scheduling: Linux CFS is not ideal for short-lived serverless function workloads. This project rethinks OS scheduling to minimize function turnaround time. [ATC‚Äô24]: [GitHub] [SC‚Äô22]: [GitHub] news Aug 2025 üöÄ ZenFlow has now been officially adopted into DeepSpeed and is also featured on the PyTorch blog. Aug 2025 üéâ Congrats to Ruizhe and Yuqi on the acceptance of their paper to IMC 2025! Aug 2025 üì¢ New Course Alert: I‚Äôll be teaching CS6501 Serverless AI in Fall 25! This course features a hands-on project powered by AI coding assistance. Jul 2025 üéì Ben Carver successfully defended his Ph.D. dissertation. Congratulations, Dr. Carver!! Ben will be joining the AI Networking Infrastructure team @ Meta (NYC) as a Research Scientist, where he‚Äôll work on cutting-edge infrastructure to support next-gen AI. Jul 2025 üéâ Congrats to Zirui, Tingfeng, and Zhaoyuan on the acceptance of ZipLLM to NSDI 2026! We analyzed all publicly available LLM repos on Hugging Face and built effective, efficient data reduction algorithms tailored for massive-scale LLM storage. Stay tuned for more updates! Jun 2025 üéâ Congrats to Ben and Jingyuan on the acceptance of NotebookOS to ASPLOS 2026! In this work, we built a GPU-efficient distributed Notebook platform that enables on-demand GPU allocation for interactive training workloads such as LLM fine-tuning. Stay tuned for more updates on the project! Jan 2025 üéâ Congrats to Qichang on the acceptance of CIDRE to ASPLOS 2025! This paper systematically studies the challenges of concurrent serverless function invocations and presents a novel function container orchestration algorithm that speculatively chooses between a delayed warm start and a cold start. Jan 2025 Congrats to Ruizhe on the IPFS data management work accepted to WWW 2025! Sep 2024 Congrats to Redwan on FedCaSe on federated learning I/O caching and scheduling accepted to SoCC 2024! Sep 2024 üëã A warm welcome to our newest members: Zirui Wang and Tingfeng Lan! Sep 2024 Thrilled to receive an NSF CSSI Elements grant on developing a sustainable and GPU-efficient cyberinfrastructure for Notebooks (w/ Co-PI Geoffrey Fox). Thanks, NSF! Jul 2024 Excited to receive an NSF REU Site grant (lead PI: Claudia Scholz). Thanks, NSF! Jun 2024 Congrats to Yuqi and Ruizhe on ALPS accepted to USENIX ATC 2024! ALPS learns workload intelligence from the user space to inform serverless function scheduling in the kernel space. May 2024 This summer Yuqi will be doing a student researcher internship at Google and Zhaoyuan will be doing a research internship at Samsung. Congrats! Apr 2024 Excited to receive an NSF OAC Core grant on building a distributed graph learning cyberinfrastructure for large spatiotemporal prediction (w/ Liang Zhao from Emory). Thanks, NSF! Mar 2024 Congrats to Ruizhe on the IPFS analysis work accepted to SIGMETRICS 2024! We answered questions about accessibility, content, and performance of IPFS in this research. Mar 2024 Congrats to Zhaoyuan and Zirui on their work accepted to VLDB 2024! In this work, Zhaoyuan analyzed a large dataset of real-world pre-trained ML models collected from Hugging Face. Based on the analysis study, he designed a new storage compression method for reducing the storage requirement of pre-trained models at scale. Feb 2024 Congrats to Rui on his work accepted to VLDB 2024! In this work, Rui systematically studied the algorithmic complexity vulnerabilities of dynamic learned indexes. Jan 2024 Check our latest survey on resource-efficient LLMs. Oct 2023 Excited to receive a Samsung GRO 2023 Award on New Storage for Large ML Training (w/ Ali Anwar from UMN). Thanks, Samsung Advanced Institute of Technology and Samsung Memory Solutions Lab, for the generous support on our research! Oct 2023 Serving as the general co-chair of ACM HotStorage‚Äô24. Consider submitting your exciting early ideas! Jun 2023 üéì My first Ph.D. student Jingyuan Zhang successfully defended his Ph.D. dissertation. Congratulations, Dr. Zhang! Jingyuan will be joining the cloud-native infrastructure team @ ByteDance (San Jose, CA). Apr 2023 Congrats to Ben, Runzhou, and Jingyuan on the acceptance of ŒªFS to ASPLOS 2023! The acceptance of ŒªFS at ASPLOS‚Äô23 marks yet another significant milestone of our serverless storage project series. Don‚Äôt forget to check out our projects: Episode I - InfiniCache, Episode II - InfiniStore, and our latest work, Episode III - ŒªFS. Feb 2023 Congrats to Jingyuan, Ben, and the team on the acceptance of InfiniStore to VLDB 2023! Dec 2022 Congrats to Redwan, Ahmad, and Yuqi on their paper on deep learning I/O caching accepted to FAST 2023! Sep 2022 I am honored to be selected for the 2022 IEEE CS TCHPC Early Career Researchers Award for Excellence in High Performance Computing. Sep 2022 Congrats to Zhaoyuan on his paper accepted to DRBSD-8 co-located with SC 2022! Sep 2022 Excited to receive a Meta Research Award for AI System Hardware/Software Codesign. Thanks, Meta Research! Aug 2022 In Fall ‚Äò22, I am joining the School of Data Science and the Department of Computer Science at the University of Virginia. Jul 2022 SFS is nominated as a Best Student Paper Award Finalist at SC 2022! Congrats to Yuqi! Jun 2022 Congrats to Yuqi on his paper on serverless function scheduling accepted to SC 2022! May 2022 This summer my students will intern at MSR (Ben Carver), ByteDance (Yuqi Fu, Jingyuan Zhang), and Argonne National Lab (Zhaoyuan Su)! Congrats! May 2022 üèÜ Thrilled to receive an Outstanding Teaching Award from CS @ Mason! Aug 2021 Congrats to Li and Haoliang on rKube accepted to SoCC 2021! Aug 2021 A collaborative FMSG grant funded by",
  "content_length": 17818,
  "method": "requests",
  "crawl_time": "2025-12-01 14:53:28"
}