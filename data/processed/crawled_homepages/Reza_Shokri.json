{
  "name": "Reza Shokri",
  "homepage": "https://www.comp.nus.edu.sg/~reza",
  "status": "success",
  "content": "Reza SHOKRI Reza SHOKRI Dean's Chair Associate Professor CS Department, School of Computing National University of Singapore (NUS) Data Privacy and Trustworthy Machine Learning Research Lab Email: firstname@comp.nus.edu.sg Twitter: @rzshokri Phone: +65-651-64464 Office: COM2-03-60 Mailing Address: Dept. of Computer Science, NUS School of Computing, 13 Computing Drive, Computing 1, #03-27, Singapore 117417. My research is in data privacy and trustworthy machine learning. I am interested in designing methods to quantitatively measure the privacy risks of data processing algorithms, and build scalable schemes for generalizable machine learning models that are also privacy-preserving, robust, interpretable, and fair. Our research is on analyzing the trade-offs between different pillars of trust in machine learning for practical scenarios, and on resolving such conflicts with rigorous mathematical guarantees. There are currently no open positions in my group. Honors and Awards Intel's 2023 Outstanding Researcher Award Asian Young Scientist Fellowship 2023 Best Paper Award at ACM Conference on Fairness, Accountability, and Transparency (FAccT) 2023 NUS School of Computing Faculty Teaching Excellence Award 2023 ➙ Recent Student Feedback: [CS5562-Trustworthy Machine Learning] Facebook Faculty Research Award 2021 IEEE Security and Privacy (S&P) Test-of-Time Award 2021 VMWare Early Career Faculty Award 2021 Intel Research Award (Private AI Collaborative Research Institute) 2021 NUS Presidential Young Professorship, 2019-2023 NUS Early Career Research Award 2019 Caspar Bowden Award for Outstanding Research in Privacy Enhancing Technologies 2018 Swiss National Science Foundation Fellowship 2013 Runner-up for PET Award for Outstanding Research in Privacy Enhancing Technologies 2012 Selected Research Papers (see also Google Scholar and arXiv) M Meeus, L Wutschitz, S Zanella-BÃ©guelin, S Tople, R Shokri â The Canaryâs Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text, 2025 M Xia, V Ruehle, S Rajmohan, R Shokri â Minerva: A Programmable Memory Test Benchmark for Language Models, 2025 S Abdelnabi, A Gomaa, E Bagdasarian, P O Kristensson, R Shokri â Firewalls to Secure Dynamic LLM Agentic Networks, 2025 P Ganesh, R Shokri, G Farnadi â Rethinking Hallucinations: Correctness, Consistency, and Prompt Multiplicity, 2025 Hongyan Chang, Hamed Hassani, Reza Shokriâ Watermark Smoothing Attacks against Language Models, 2025 Prakhar Ganesh, Cuong Tran, Reza Shokri, and Ferdinando Fioretto ➙ The Data Minimization Principle in Machine Learning ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2025 Jiashu Tao and Reza Shokri ➙ Range Membership Inference Attacks IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 2025 Yao Tong, Jiayuan Ye, Sajjad Zarifzadeh, and Reza Shokri ➙ How Much of My Dataset Did You Use? Quantitative Data Usage Inference in Machine Learning Oral International Conference on Learning Representations (ICLR), 2025 Sajjad Zarifzadeh, Philippe Liu, and Reza Shokri ➙ Low-Cost High-Power Membership Inference Attacks ➙ [ICML talk, long talk] Oral International Conference on Machine Learning (ICML), 2024 Hongyan Chang, Brandon Edwards, Anindya S Paul, and Reza Shokri ➙ Efficient Privacy Auditing in Federated Learning USENIX Security Symposium, 2024 Jiayuan Ye, Anastasia Borovykh, Soufiane Hayou, and Reza Shokri ➙ Leave-one-out Distinguishability in Machine Learning International Conference on Learning Representations (ICLR), 2024 Niloofar Mireshghallah, Hyunwoo Kim, Xuhui Zhou, Yulia Tsvetkov, Maarten Sap, Reza Shokri, and Yejin Choi ➙ Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory Spotlight International Conference on Learning Representations (ICLR), 2024 Jiayuan Ye, Zhenyu Zhu, Fanghui Liu, Reza Shokri, and Volkan Cevher ➙ Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks Conference on Neural Information Processing Systems (NeurIPS), 2023 Also to be Presented at the Theory and Practice of Differential Privacy (TPDP), 2023 Chendi Wang, Buxin Su, Jiayuan Ye, Reza Shokri, and Weijie J. Su ➙ Unified Enhancement of Privacy Bounds for Mixture Mechanisms via f-Differential Privacy Conference on Neural Information Processing Systems (NeurIPS), 2023 Prakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri ➙ On The Impact of Machine Learning Randomness on Group Fairness ➙ [talk by Prakhar Ganesh] ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2023 Best Paper Award Hongyan Chang and Reza Shokri ➙ Bias Propagation in Federated Learning International Conference on Learning Representations (ICLR), 2023 Zebang Shen, Jiayuan Ye, Anmin Kang, Hamed Hassani, and Reza Shokri ➙ Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning International Conference on Learning Representations (ICLR), 2023 Jiayuan Ye and Reza Shokri ➙ Differentially Private Learning Needs Hidden State (Or Much Faster Convergence) Conference on Neural Information Processing Systems (NeurIPS), 2022 Also presented at the Symposium on Foundations of Responsible Computing (FORC), 2022 Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda, Vincent Bindschaedler, and Reza Shokri ➙ Enhanced Membership Inference Attacks against Machine Learning Models ➙ [code] ACM Conference on Computer and Communications Security (CCS), 2022 Florian TramÃ¨r, Reza Shokri, Ayrton San Joaquin, Hoang Le, Matthew Jagielski, Sanghyun Hong, and Nicholas Carlini ➙ Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets ACM Conference on Computer and Communications Security (CCS), 2022 Media: The Register, TechXplore Fatemehsadat Mireshghallah, Kartik Goyal, Archit Uniyal, Taylor Berg-Kirkpatrick, and Reza Shokri ➙ Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks The Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022 Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tramer ➙ What Does it Mean for a Language Model to Preserve Privacy? ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2022 Media: MIT Technology Review Neel Patel, Reza Shokri, and Yair Zick ➙ Model Explanations with Differential Privacy ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2022 Rishav Chourasia*, Jiayuan Ye*, and Reza Shokri ➙ Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent ➙ [talk by Jiayuan Ye] Spotlight Conference on Neural Information Processing Systems (NeurIPS), 2021 Hongyan Chang, and Reza Shokri ➙ On the Privacy Risks of Algorithmic FairnessIEEE European Symposium on Security and Privacy (EuroSP), 2021 Also presented at FTC PrivacyCon, 2021 Reza Shokri, Martin Strobel, and Yair Zick ➙ On the Privacy Risks of Model ExplanationsAAAI/ACM Conference on AI, Ethics, and Society (AIES), 2021 Also presented at FTC PrivacyCon, 2021 Media: Harvard Business Review Sasi Kumar Murakonda, Reza Shokri, and George Theodorakopoulos ➙ Quantifying the Privacy Risks of Learning High-Dimensional Graphical ModelsInternational Conference on Artificial Intelligence and Statistics (AISTATS), 2021 Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, and Reza Shokri ➙ On Adversarial Bias and the Robustness of Fair Machine LearningarXiv:2006.08669, 2020 Te Juin Lester Tan, and Reza Shokri ➙ Bypassing Backdoor Detection Algorithms in Deep Learning ➙ [talk]IEEE European Symposium on Security and Privacy (EuroSP), 2020 Congzheng Song, and Reza Shokri ➙ Robust Membership Encoding: Inference Attacks and Copyright Protection for Deep LearningACM ASIA Conference on Computer and Communications Security (ASIACCS), 2020 Anshul Aggarwal, Trevor Carlson, Reza Shokri, and Shruti Tople ➙ SOTERIA: In Search of Efficient Neural Networks for Private InferencearXiv:2007.12934, 2020 Liwei Song, Reza Shokri, and Prateek Mittal ➙ Privacy Risks of Securing Machine Learning Models against Adversarial Examples ➙ [talk by L. Song] ACM Conference on Computer and Communications Security (CCS), 2019 Milad Nasr, Reza Shokri, and Amir Houmansadr ➙ Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning ➙ [code] ➙ [talk by M. Nasr] IEEE Symposium on Security and Privacy (S&P) -- Oakland, 2019 Hongyan Chang, Virat Shejwalkar, Reza Shokri, and Amir Houmansadr ➙ Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box Knowledge Transfer arXiv:1912.11279, 2019 Milad Nasr, Reza Shokri, and Amir Houmansadr ➙ Machine Learning with Membership Privacy using Adversarial Regularization ➙ [code] ➙ [talk by A. Houmansadr] ACM Conference on Computer and Communications Security (CCS), 2018. Tyler Hunt, Congzheng Song, Reza Shokri, Vitaly Shmatikov, and Emmett Witchel ➙ Chiron: Privacy-preserving Machine Learning as a Service arXiv:1803.05961, 2018 Media: ZDNet Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov ➙ Membership Inference Attacks against Machine Learning Models ➙ [code] ➙ [tool] ➙ [datasets] ➙ [talk] IEEE Symposium on Security and Privacy (S&P) -- Oakland, 2017. The Caspar Bowden Award for Outstanding Research in Privacy Enhancing Technologies 2018. Vincent Bindschaedler, Reza Shokri, and Carl Gunter ➙ Plausible Deniability for Privacy-Preserving Data Synthesis ➙ [code] VLDB Endowment International Conference on Very Large Data Bases (PVLDB), 2017. Vincent Bindschaedler and Reza Shokri. ➙ Synthesizing Plausible Privacy-Preserving Location Traces ➙ [code] ➙ [talk by V. Bindschaedler] IEEE Symposium on Security and Privacy (S&P) -- Oakland, 2016. Reza Shokri, George Theodorakopoulos, and Carmela Troncoso ➙ Privacy Games along Location Traces: A Game-Theoretic Framework for Optimizing Location Privacy ACM Transactions on Privacy and Security (TOPS), 2016. Richa",
  "content_length": 18777,
  "method": "requests",
  "crawl_time": "2025-12-01 14:17:07"
}