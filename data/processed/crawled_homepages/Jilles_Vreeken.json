{
  "name": "Jilles Vreeken",
  "homepage": "http://people.mmci.uni-saarland.de/~jilles",
  "status": "success",
  "content": "Cluster of Excellence | Multimodal Computing and Interaction Cluster of Excellence on Multimodal Computing and Interaction Mission The past three decades have brought dramatic changes in the way we live and work. This phenomenon is widely characterized as the advent of the Information Society. It is fueled by the power of information technology to acquire, store, process and transmit data compactly, inexpensively, and at greater speeds than ever before. Two decades ago most digital content was textual. Today, graphics and audiovisual I/O devices are in widespread use and modern devices have multimedia capabilities. As a result, current digital content additionally comprises speech, audio, video and graphics. Ubiquitous sensing devices further increase the global volume of digital data. The availability of digital content in different modalities and the increasingly pervasive access to the Internet combine to make a host of information available to anyone, at any time. A deluge of multimodal information is openly available across a surprising variety of Internet platforms. New devices such as smartphones, time-of-flight cameras, and motion sensors are abundant. Users can easily create rich and novel forms of multimodal content, and they can interact with virtual characters and other forms of augmented reality. Given these trends, the Cluster of Excellence on Multimodal Computing and Interaction (MMCI) has addressed the challenge to organize, understand, and search multimodal information in a robust, efficient, intelligent and privacy preserving manner, and to create dependable systems that support natural and intuitive multi- modal interaction. We have successfully made major inroads towards the Deep Integration of Language and Knowledge, Augmented Reality, Multimodal Dialog with the Environment, and Information Privacy and Accountability, and our results provide a major step forward towards a unified understanding of multimodal computing and multimodal systems. Overview The Cluster of Excellence on Multimodal Computing and Interaction (MMCI) was established by the German Research Foundation (DFG) within the framework of the German Excellence Initiative in 2007 and successfully renewed in 2012. MMCI originally comprised the Computer Science and (UdS-CS) and Language Science and Technology (UdS-LST) departments of Saarland University, the Max Planck Institute for Informatics (MPI-INF), the German Research Center for Artificial Intelligence (DFKI), and the Max Planck Institute for Software Systems (MPI-SWS).Â Together these institutions form what is now known as “Saarland Informatics Campus (SIC)”.Â In 2011, the Center for IT-Security, Privacy and Accountability (CISPA) that was established in 2011 as a national BMBF-funded competence center for IT security and Privacy at Saarland University and meanwhile became the CISPA Helmholtz Center for Information Security in 2018 was added as a cooperation partner. During the reporting period we have seen significant growth of the research base on Saarland Informatics Campus on all levels. A particular emphasis of MMCI has been on the promotion of young researchers, and as such, we have committed the majority of allocated funds to our independent research group (IRG) program: We attracted a pool of highly talented young researchers to MMCI and successfully hired 43 independent research group leaders during the reporting period. Our IRG leaders have achieved outstanding results, and we have seen an unusual amount of collaboration within the Cluster. At the time of writing, one group is still ongoing, all other IRG leaders received offers for faculty positions following their stay with MMCI. Many former IRG leaders continue to maintain close ties to the Cluster, and a multitude of joint publications attest to the quality of this sustained collaboration. In our research we have significantly advanced towards our overall goal, to organize, understand, search and interface the wealth of multimodal information in a robust, efficient and intelligent way, and to create dependable systems that support natural and intuitive multimodal interaction, and researchers affiliated with MMCI have left their mark in the international research community. Partners  Participating institutions of the host university Computer Science Department (UdS-CS), SaarbrÃ¼cken Department of Language Science and Technology (UdS-LST), SaarbrÃ¼cken Center of Bioinformatics (UdS-CBI), SaarbrÃ¼cken  Participating non-university institutions Max Planck Institute for Informatics (MPI-INF), SaarbrÃ¼cken German Research Center for Artificial Intelligence (DFKI), SaarbrÃ¼cken Max Planck Institute for Software Systems (MPI-SWS), SaarbrÃ¼cken  Most important cooperation partners Intel Visual Computing Institute (IVCI), SaarbrÃ¼cken Globus Innovative Retail Laboratory (IRL), St. Wendel CISPA Helmholtz Center for Information Security, SaarbrÃ¼cken Research Areas (RA) RA 1 â Text and Speech Processing Language is the most natural and expressive medium for human communication and interaction. The richness of language derives from its grounding in our knowledge of the world and the immediate linguistic and non-linguistic context. In Research Area 1, we focused on structurally informed models of distributional semantics, using unsupervised and minimally supervised approaches that combine linguistic knowledge with linguistic information. We substantially extended our work by going beyond intra-sentential context in two directions. On the one hand, we created text-level models of discourse relations and script knowledge, and applied these models to improve text-level comprehension. On the other hand, we have advanced cross-modal methods that deeply integrate language processing with both extra-linguistic knowledge and visual information, and lead to more naturalistic interaction with dialog systems and avatars. Furthermore, our methodological contributions regarding neurophysiological and pupillometric measures have enabled us to investigate situated human-computer interaction in greater detail. Our results have significantly contributed to improvements in several types of natural language processing tasks: the offline extraction of complex knowledge from text to feed knowledge bases; the online semantic interpretation (disambiguation and composition) required for deep text understanding, enrichment of text documents, and deep question answering; the understanding of pictures and visual scenes; and the integration of speech and vision modalities to enrich spoken-language understanding and generation technologies in virtual interactive environments. RA 2 â Visual Computing Visual Computing is a cross-disciplinary research area integrating and advancing computer graphics, computer vision and machine learning methods. Visual Computing includes in particular the areas of image analysis â such as image processing, computer vision, pattern recognition â and image synthesis â such as geometric modeling, computer graphics, scientific visualization. At the same time acquisition, transmission, and efficient representation of visual data also play a role. While textual information processing by computers is a well-established and successful area, the quality, speed and robustness of many current visual computing algorithms is still behind human capabilities and requires more research. We have made contributions towards a coherent and robust bottom-up framework for key problems in visual computing, and we have extended our focus on the integration of different, complementary approaches and modalities within visual computing. A particular focus of our work is understanding of visual information. Scientific challenges cover the entire pipeline from single-sensor processing, over spatial and temporal fusion to the complete description of large-scale sensor streams. At the same time we observe a tremendous increase in both the quantity as well as the diversity of visual sensors embedded in a wide variety of digital devices and environments as well as due to the increasing storage of sensor data â such as surveillance data, personal storage of visual data, or simply the Internet. While storing and indexing large amounts of visual data has made tremendous progress, understanding visual data still lacks far behind. Therefore our long-term goal is to make progress on how to process, structure, access, and truly understand visual data both for online use as well as for large-scale databases. Machine learning has been a core enabler for progress in the area of visual computing. As a result it becomes more and more important to understand both privacy implications of sharing and using visual data and security questions related to the use of machine learning techniques. Over the last few years we have investigated various aspects at the intersection of privacy and security on the one hand and visual computing and machine learning on the other hand. Also, the interaction between modern algorithms and modern multimedia hardware such as smartphones, multicore processors, GPUs, time-of-flight cameras, and Kinect cameras has become an important issue in our research. We have also contributed to computational photography, a rapidly emerging field where imaging hardware and algorithms from image processing and computer graphics are combined in a fruitful way. Last but not least, our visual computing approaches have gained robustness from incorporating adaptivity, prior knowledge, and concepts from machine learning. RA 3 â Algorithmic Foundations Multimodal computing and interaction require smart algorithmics. Ever larger data sets need to be processed and analyzed; networks of interacting and sometimes competing agents evolve dynamically and to very large sizes; the fact that more and more tasks are handled by computerized systems increases the importance of reliability and correctness; and NP-complete optimization problems arise in almo",
  "content_length": 116946,
  "method": "requests",
  "crawl_time": "2025-12-01 13:30:41"
}