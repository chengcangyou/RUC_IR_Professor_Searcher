{
  "name": "Michael Fairbank",
  "homepage": "https://www.essex.ac.uk/people/fairb54300/michael-fairbank",
  "status": "success",
  "content": "Michael Fairbank | University of Essex University of Essex homepage Skip to content I'm looking for... Courses Research People Something else Course query Course level Select Level Undergraduate Postgraduate Prefer to see our subject areas? Browse courses by subject Research query Looking for funded postgraduate opportunities? View doctoral training partnerships Browse postgraduate research opportunities Person query We are different and we are the same. #WeAreEssex Search query Looking for student or staff information? Student Directory Staff Directory Courses Course query Course level Select Level Undergraduate Postgraduate Prefer to see our subject areas? Browse courses by subject Research Research query Looking for funded postgraduate opportunities? View doctoral training partnerships Browse postgraduate research opportunities People Person query We are different and we are the same. #WeAreEssex Something else Search query Looking for student or staff information? Student Directory Staff Directory University of Essex homepage Michael Fairbank People Dr Michael Fairbank Senior Lecturer School of Computer Science and Electronic Engineering (CSEE) Email m.fairbank@essex.ac.uk Location 1NW.3.19, Colchester Campus Academic support hours Mondays 11am-12pm. Room: 1NW.3.19 Profile Research Teaching and supervision Publications Grants and funding Contact Profile Research Teaching and supervision Publications Grants and funding Contact Profile Qualifications BSc Mathematical Physics (Nottingham University, 1994) MSc Knowledge Based Systems Edinburgh University, (1995) PhD Computer Science (City University London, 2014) FHEA The Higher Education Academy, (2024) Research and professional activities Research interests Neural Networks Open to supervise Adaptive Dynamic Programming + Reinforcement Learning Open to supervise Optimisation Open to supervise Control Theory Open to supervise Financial Forecasting Open to supervise AI in games Open to supervise Current research Neural-Network Learning Algorithms I am always trying to develop new and improved learning algorithms for training neural networks. The highlight of this work is the Deep Learning in Target Space publication. More information about this project Algorithms for Adaptive Dynamic Programming and Reinforcement Learning I work on algorithms for Adaptive Dynamic Programming (which is a sister-field of Reinforcement Learning), trying to develop new algorithms / prove algorithms converge/run efficiently, etc. One of the key outputs of this work is a convergence proof for learning with a greedy policy and function approximation for Value-Gradient Learning. This is highlighted in the paper \"An Equivalence Between Adaptive Dynamic Programming With a Critic and Backpropagation Through Time\", which proves equivalence between a method that uses an approximated value-function (i.e. a neural network) and a pre-existing method which has the proven convergence guarantees. Hence the proven convergence guarantees of the second method transfer over the the value-function based method. Other interesting papers on this topic which I've published include the papers \"Value-gradient learning\", \"A Comparison of Learning Speed and Ability to Cope Without Exploration between DHP and TD(0)\", and \"The divergence of reinforcement learning algorithms with value-iteration and function approximation\". See my publications list for details on these papers. More information about this project Neurocontrol applications I am very interested in making neural networks control systems, i.e. neurocontrol. I have applied this technique for industrial control problems. Particularly for power system controllers, to improve energy efficiency of renewable generators. Papers on this topic include \"Neural-network vector controller for permanent-magnet synchronous motor drives: Simulated and hardware-validated results\" and related papers on Motors and Grid-Connected Converters. A fun neurocontrol topic is described in the paper \"A Minimal “Functionally Sentient” Organism Trained With Backpropagation Through Time\", by M Pisheh Var, M Fairbank, S Samothrakis Adaptive Behavior, linked to below. This aims to show a minimal example where we can make a neural network emulate all of the external behaviours of minimal sentient organism. More information about this project Teaching and supervision Current teaching responsibilities Game Artificial Intelligence (CE811) Physics-Based Games (CE812) Current supervision William Voisine Degree subject: Computer Science Degree type: Doctor of Philosophy David Barragan Alcantar Degree subject: Computer Science Degree type: Doctor of Philosophy Rio Surendran Degree subject: Computational Finance Degree type: Doctor of Philosophy Previous supervision Mohammad Abdollahi Thesis title: Integrated Demand Management and Vehicle Routing Problem in Attended Home Delivery Degree subject: Operational Research Degree type: Doctor of Philosophy Awarded date: 27/6/2024 Mahrad Pisheh Var Thesis title: Minimalistic Adaptive Dynamic-Programming Agents for Memory-Driven Exploration Degree subject: Computer Science Degree type: Doctor of Philosophy Awarded date: 20/6/2024 Chen Chen Thesis title: Stock Market Investment Using Machine Learning Degree subject: Computational Finance Degree type: Doctor of Philosophy Awarded date: 23/12/2022 Piers Williams Thesis title: Artificial Intelligence in Co-Operative Games with Partial Observability Degree subject: Intelligent Games and Game Intelligence Degree type: Doctor of Philosophy Awarded date: 14/2/2019 Publications Journal articles (15) Fairbank, M., Prokhorov, D., Barragan-Alcantar, D., Samothrakis, S. and Li, S., (2025). Neurocontrol for Fixed-Length Trajectories in Environments with Soft Barriers. Neural Networks. 184, 107034-107034 Abdollahi, M., Yang, X., Fairbank, M. and Nasri, M., (2023). Demand Management in Time-slotted Last-mile Delivery via Dynamic Routing with Forecast Orders. European Journal of Operational Research. 309 (2), 704-718 Pisheh Var, M., Fairbank, M. and Samothrakis, S., (2023). A Minimal “Functionally Sentient” Organism Trained with Backpropagation Through Time. Adaptive Behavior. 31 (6), 531-544 Fairbank, M., Samothrakis, S. and Citi, L., (2022). Deep Learning in Target Space. Journal of Machine Learning Research. 23, 1-46 Gao, Y., Li, S., Xiao, Y., Dong, W., Fairbank, M. and Lu, B., (2022). An Iterative Optimization and Learning-based IoT System for Energy Management of Connected Buildings. IEEE Internet of Things Journal. 9 (21), 1-1 Dong, W., Li, S., Fu, X., Li, Z., Fairbank, M. and Gao, Y., (2021). Control of a Buck DC/DC Converter Using Approximate Dynamic Programming and Artificial Neural Networks. IEEE Transactions on Circuits and Systems Part 1: Regular Papers. 68 (4), 1760-1768 Li, S., Won, H., Fu, X., Fairbank, M., Wunsch, DC. and Alonso, E., (2020). Neural-Network Vector Controller for Permanent-Magnet Synchronous Motor Drives: Simulated and Hardware-Validated Results. IEEE Transactions on Cybernetics. 50 (7), 3218-3230 Alonso, E., Fairbank, M. and Mondragon, E., (2015). Back to optimality: a formal framework to express the dynamics of learning optimal behavior. Adaptive Behavior. 23 (4), 206-215 Fu, X., Li, S., Fairbank, M., Wunsch, DC. and Alonso, E., (2015). Training Recurrent Neural Networks With the Levenberg-Marquardt Algorithm for Optimal Control of a Grid-Connected Converter. IEEE Transactions on Neural Networks and Learning Systems. 26 (9), 1900-1912 Li, S., Fairbank, M., Johnson, C., Wunsch, DC., Alonso, E. and Proao, JL., (2014). Artificial Neural Networks for Control of a Grid-Connected Rectifier/Inverter Under Disturbance, Dynamic and Power Converter Switching Conditions. IEEE Transactions on Neural Networks and Learning Systems. 25 (4), 738-750 Fairbank, M., Prokhorov, D. and Alonso, E., (2014). Clipping in Neurocontrol by Adaptive Dynamic Programming. IEEE Transactions on Neural Networks and Learning Systems. 25 (10), 1909-1920 Fairbank, M., Li, S., Fu, X., Alonso, E. and Wunsch, D., (2014). An adaptive recurrent neural-network controller using a stabilization matrix and predictive inputs to solve a tracking problem under disturbances. Neural Networks. 49, 74-86 Fairbank, M., Alonso, E. and Prokhorov, D., (2013). An Equivalence Between Adaptive Dynamic Programming With a Critic and Backpropagation Through Time. IEEE Transactions on Neural Networks and Learning Systems. 24 (12), 2088-2100 Fairbank, M., Alonso, E. and Prokhorov, D., (2012). Simple and fast calculation of the second-order gradients for globalized dual heuristic dynamic programming in neural networks.. IEEE Transactions on Neural Networks and Learning Systems. 23 (10), 1671-1676 Fairbank, M. and Alonso, E., (2012). Efficient calculation of the Gauss-Newton approximation of the Hessian matrix in neural networks.. Neural Computation. 24 (3), 607-610 Show all Book chapters (1) Fairbank, M., Prokhorov, D. and Alonso, E., (2012). Approximating Optimal Control with Value Gradient Learning. In: Reinforcement Learning and Approximate Dynamic Programming for Feedback Control. Wiley. 142- 161. 9781118104200 Conferences (22) Pisheh Var, M., Fairbank, M. and Samothrakis, S., (2023). Finding Eulerian tours in mazes using amemory-augmented fixed policy function Samothrakis, S., Matran-Fernandez, A., Abdullahi, U., Fairbank, M. and Fasli, M., (2022). Grokking-like effects in counterfactual inference Venugopal, I., Tollich, J., Fairbank, M. and Scherp, A., (2021). A Comparison of Deep-Learning Methods forAnalysing and Predicting Business Processes Krause, A. and Fairbank, M., (2020). Baseline win rates for neural-network based trading algorithms Volkovas, R., Fairbank, M., Woodward, JR. and Lucas, S., (2020). Practical Game Design Tool: State Explorer Volkovas, R., Fairbank, M., Woodward, JR. and Lucas, S., (2019). Mek: Mechanics Prototyping Tool for 2D Tile-Based Turn-Based Deterministic Games Volkovas, R., Fairbank, M., Woodward, JR. and Lucas",
  "content_length": 15411,
  "method": "requests",
  "crawl_time": "2025-12-01 13:57:57"
}