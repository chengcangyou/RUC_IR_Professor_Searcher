{
  "name": "Chongyang Tao",
  "homepage": "https://chongyangtao.github.io",
  "status": "success",
  "content": "Chongyang Tao (陶重阳) - Home Chongyang Tao (陶重阳) Home Publications Team Activities Teaching 中文 Associate Professor (Tenure track) BDBC & SKLSDE School of Computer Science and Engineering, Beihang University No. 37 Xueyuan Road, Haidian District, Beijing, P.R. China, 100083 Email: chongyang@buaa.edu.cn Biography Hi, I am Chongyang Tao, a pre-tenure associate professor in the School of Computer Science and Engineering at Beihang University, working with Prof. Shuai Ma. Previously, I was a senior scientist at Microsoft, where I had the privilege of working with Wei Wu, Daxin Jiang, Xiubo Geng and Jian-guang Lou on projects such as Microsoft Xiaoice, ChatwithBING, the Bing Retrieval/Generative Model, and WizardLM. I received my Ph.D. degree from Peking University in 2020, under the supervision of Prof. Dongyan Zhao, and the B. Eng degree from Sichuan University in 2015. My research lie in natural language processing and information retrieval, especially in deep learning models with their applications in dialogue systems, data intelligence, effective and generalizable IR. More specifically, my research vision centers on flexibly and effectively ushering humans into the world of knowledge through natural language. This includes understanding complex user inputs in human-machine intelligence and seeking knowledge from various data sources based on these inputs. I have published over 70 papers in prestigious conferences and journals such as ACL, EMNLP, ICLR, NeurIPS, SIGIR, KDD, and TOIS. I have been honored with the NLPCC Outstanding Paper Award and the Aminer AI-2000 Scholar, and have served as area chairs or meta-reviewers for leading academic conferences like KDD, WWW, EMNLP, and CCKS. Hiring I am actively seeking highly motivated students and interns to join my research team. If you are interested in working with me on generative language models, information retrieval, data intelligence and related interdisciplinary topics, please don't hesitate to reach out. News [Jan.2025]: Our papers got accepted to WWW 2025 and ICLR 2025. [Dec.2024]: Our paper got accepted to AAAI 2025. [Dec.2024]: Our paper got accepted to TKDE. [Nov.2024]: Our paper got accepted to TOSEM. [Oct.2024]: Our paper got accepted to WSDM 2025. [Oct.2024]: Our papers got accepted to EMNLP 2024. [May.2024]: Our papers got accepted to ACL 2024. [Jan.2024]: Present a comprehensive survey on knowledge distillation of LLMs with UMD, UTS and HKU. [Github] [机器之心] [Jan.2024]: Our papers got accepted to ICLR 2024. [Jan.2024]: Our paper got accepted to EACL 2024. [Dec.2023]: Our paper got accepted to AAAI 2024. [Oct.2023]: Our papers got accepted to EMNLP 2023. [Sep.2023]: Present a simple yet effective Question Re-reading Method (Re2) for improving reasoning in LLMs. [Aug.2023]: WizardCoder achieves the 1st-rank on Multilingual Code Models Evaluation Leaderboard. [澎湃报道] [Jun.2023]: WizardLM achieves the 1st-rank of the opensource models on Standford AlpacaEval Leaderboard. [May.2023]: Propose InteR to facilitate knowledge retrieval via the interaction between SEs and LLMs. [Code] [Apr.2023]: Release WizardLM expertized in following complex instructions. [Github] (Over 8K Stars) [WizardLM Pages] [Huggingface] [Beeboom: 12 Best LLMs in 2024] [华尔街见闻] [May.2023]: Our paper got accepted to KDD 2023. [May.2023]: Our papers got accepted to ACL 2023. [Jan.2023]: Our paper got accepted to WWW 2023. [Jan.2023]: Our papers got accepted to ICLR 2023. Last updated: Aug 2024. Site modified from this template.",
  "content_length": 3510,
  "method": "requests",
  "crawl_time": "2025-12-01 12:51:28"
}