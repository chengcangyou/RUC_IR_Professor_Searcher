{
  "name": "Congyi Zhang 0001",
  "homepage": "https://cong-yi.github.io",
  "status": "success",
  "content": "Congyi Zhang I am an Assistant Professor in the Computer Science Department at UT Dallas. Prior to this position, I was a postdoctoral research and teaching fellow in the Department of Computer Science at UBC with Prof. Alla Sheffer. I also served as a research associate at HKU CS working with Prof. Wenping Wang. I spent a year as a visiting researcher at the Max Planck Institute for Informatics with Prof. Christian Theobalt. I earned my Ph.D. in computer science from Peking University and my B.Sc. in mathematics from Fudan University. My recent research topics are focused on neural shape representation, AI for 3D content generation, human–computer interaction, and 3D reconstruction. I am currently looking for self-motivated Ph.D. students starting in Spring/Fall 2026. If you’re interested in working with me, please feel free to send me your CV. Selected Publications For a complete and always up-to-date list, please check out my Google Scholar page. TOG NESI: Neural Explicit-Shape-Intersection-Based Geometry Representation Congyi Zhang, Jinfan Yang, Eric Hedlin, Suzuran Takikawa, Nicholas Vining, Kwang Moo Yi, Wenping Wang, and Alla Sheffer ACM Trans. Graph., Jul 2025 (will be presented at SIGGRAPH Asia 2025) Abs DOI arXiv Website Compressed representations of 3D shapes that are compact, accurate, and can be processed efficiently directly in compressed form, are extremely useful for digital media applications. Recent approaches in this space focus on learned implicit or parametric representations. While implicits are well suited for tasks such as in-out queries, they lack natural 2D parameterization, complicating tasks such as texture or normal mapping. Conversely, parametric representations support the latter tasks but are ill-suited for occupancy queries. We propose a novel learned alternative to these approaches, based on intersections of localized explicit, or height-field, surfaces. Since explicits can be trivially expressed both implicitly and parametrically, NESI directly supports a wider range of processing operations than implicit alternatives, including occupancy queries and parametric access. We represent input shapes using a collection of differently oriented height-field bounded half-spaces combined using volumetric Boolean intersections. We first tightly bound each input using a pair of oppositely oriented height-fields, forming a Double Height-Field (DHF) Hull. We refine this hull by intersecting it with additional localized height-fields (HFs) that capture surface regions in its interior. We minimize the number of HFs necessary to accurately capture each input and compactly encode both the DHF hull and the local HFs as neural functions defined over subdomains of (mathbb R^2) . This reduced dimensionality encoding delivers high-quality compact approximations. Given similar parameter count, or storage capacity, NESI significantly reduces approximation error compared to the state-of-the-art, especially at lower parameter counts. TOG NeuPPS: Neural Piecewise Parametric Surfaces Lei Yang, Yongqing Liang, Xin Li, Congyi Zhang, Guying Lin, Cheng Lin, Alla Sheffer, Scott Schaefer, John Keyser, and Wenping Wang ACM Trans. Graph., Oct 2025 Abs DOI Piecewise parametric surfaces have long been established as prevalent geometric representations; however, they often require surface refinement or sophisticated quadrangulation to accurately represent complex geometries. Geometric deep learning has shown that neural networks can provide greater representational power than conventional methods. Nevertheless, approaches using a single parametric surface for shape fitting struggle to capture fine-grained geometric details, while multi-patch methods fail to ensure seamless connections between adjacent patches. We present Neural Piecewise Parametric Surfaces (NeuPPS), the first piecewise neural surface representation that allows for coarse patch layouts composed of arbitrary n-sided surface patches to model complex surface geometries with high precision, offering enhanced flexibility compared to traditional parametric surfaces. This new surface representation guarantees, by construction, the continuity between adjacent patches, a property that other neural patch-based approaches cannot ensure. Two novel components are introduced: a learnable feature complex and a continuous mapping function approximated by multi-layer perceptrons (MLPs). We apply the proposed NeuPPS to surface fitting and shape space learning tasks. Extensive experiments demonstrate the advantages of NeuPPS over traditional parametric representations and existing patch-based learning approaches. SIGGRAPH Asia 2025 NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling Pengfei Wang, Qiujie Dong, Fangtian Liang, Hao Pan, Lei Yang, Congyi Zhang, Guying Lin, Caiming Zhang, Yuanfeng Zhou, Changhe Tu, and 4 more authors ACM Trans. Graph., Dec 2025 Abs arXiv Neural implicit shape representation has drawn significant attention in recent years due to its smoothness, differentiability, and topological flexibility. However, directly modeling the shape of a neural implicit surface, especially as the zero-level set of a neural signed distance function (SDF), with sparse geometric control is still a challenging task. Sparse input shape control typically includes 3D curve networks or, more generally, 3D curve sketches, which are unstructured and cannot be connected to form a curve network, and therefore more difficult to deal with. While 3D curve networks or curve sketches provide intuitive shape control, their sparsity and varied topology pose challenges in generating high-quality surfaces to meet such curve constraints. In this paper, we propose NeuVAS, a variational approach to shape modeling using neural implicit surfaces constrained under sparse input shape control, including unstructured 3D curve sketches as well as connected 3D curve networks. Specifically, we introduce a smoothness term based on a functional of surface curvatures to minimize shape variation of the zero-level set surface of a neural SDF. We also develop a new technique to faithfully model G^0 sharp feature curves as specified in the input curve sketches. Comprehensive comparisons with the state-of-the-art methods demonstrate the significant advantages of our method. TOG Patch-Grid: An Efficient and Feature-Preserving Neural Implicit Surface Representation Guying Lin*, Lei Yang*, Congyi Zhang, Hao Pan, Yuhan Ping, Guodong Wei, Taku Komura, John Keyser, and Wenping Wang ACM Trans. Graph., Apr 2025 (will be presented at SIGGRAPH 2025, * equal contribution) Abs DOI arXiv Neural implicit representations are known to be more compact for depicting 3D shapes than traditional discrete representations. However, the neural representations tend to round sharp corners or edges and struggle to represent surfaces with open boundaries. Moreover, they are slow to train. We present a unified neural implicit representation, called Patch-Grid, that fits to complex shapes efficiently, preserves sharp features, and effectively models surfaces with open boundaries and thin geometric features. Our superior efficiency comes from embedding each surface patch into a local latent volume and decoding it using a shared MLP decoder, which is pretrained on various local surface geometries. With this pretrained decoder fixed, fitting novel shapes and local shape updates can be done efficiently. The faithful preservation of sharp features is enabled by adopting a novel merge grid to perform local constructive solid geometry (CSG) combinations of surface patches in the cells of an adaptive Octree, yielding better robustness than using a global CSG construction as proposed in the literature. Experiments show that our Patch-Grid method faithfully captures shapes with complex sharp features, open boundaries and thin structures, and outperforms existing learning-based methods in both efficiency and quality for surface fitting and local shape updates. SIGGRAPH 2025 CMD: Controllable Multiview Diffusion for 3D Editing and Progressive Generation Peng Li, Suizhi Ma, Jialiang Chen, Yuan Liu†, Congyi Zhang, Wei Xue, Wenhan Luo†, Alla Sheffer, Wenping Wang, and Yike Guo In ACM SIGGRAPH 2025 Conference Papers, Vancouver, BC, CA, Aug 2025 († corresponding author) Abs arXiv Code Website Recently, 3D generation methods have shown their powerful ability to automate 3D model creation. However, most 3D generation methods only rely on an input image or a text prompt to generate a 3D model, which lacks the control of each component of the generated 3D model. Any modifications of the input image lead to an entire regeneration of the 3D models. In this paper, we introduce a new method called CMD that generates a 3D model from an input image while enabling flexible local editing of each component of the 3D model. In CMD, we formulate the 3D generation as a conditional multiview diffusion model, which takes the existing or known parts as conditions and generates the edited or added components. This conditional multiview diffusion model not only allows the generation of 3D models part by part but also enables local editing of 3D models according to the local revision of the input image without changing other 3D parts. Extensive experiments are conducted to demonstrate that CMD decomposes a complex 3D generation task into multiple components, improving the generation quality. Meanwhile, CMD enables efficient and flexible local editing of a 3D model by just editing one rendered image. TVCG A Potential Field Method for Tooth Motion Planning in Orthodontic Treatment Yumeng Liu, Yuexin Ma, Lei Yang, Congyi Zhang†, Guangshun Wei, Runnan Chen, Min Gu, Jia Pan, Zhengbao Yang, Taku Komura, and 4 more authors IEEE Transactions on Visualization and Computer Graphics, 2025 († corresponding author) Abs DOI Invisible orthodontics, commonly known as clear alignment treatment, offers a more comfortable and aesthetically pleasing alternative in orthodontic",
  "content_length": 29219,
  "method": "requests",
  "crawl_time": "2025-12-01 12:55:03"
}