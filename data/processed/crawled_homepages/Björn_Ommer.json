{
  "name": "Björn Ommer",
  "homepage": "https://ommer-lab.com/people/ommer",
  "status": "success",
  "content": "Prof. Dr. Björn Ommer - Computer Vision & Learning Group Skip to content Head of Computer Vision & Learning Group,Institute of Computer Science,Ludwig Maximilian University of Munich Akademiestr. 7D-80799 Munich Tel.(office): +49 (0)89/2180-73431Tel.(secret.): +49 (0)89/2180-73430FAX: +49 (0)89/2180-9973431Email: b.ommer (at) lmu (dot) de »» Open PhD and PostDoc Positions »» our work on Stable Diffusion Short Bio Björn Ommer is a full professor at LMU where he heads the Computer Vision & Learning Group (previously Computer Vision Group Heidelberg). Before he was a full professor at the Department of Mathematics and Computer Science of Heidelberg University and also served as a one of the directors of the Interdisciplinary Center for Scientific Computing (IWR) and of the Heidelberg Collaboratory for Image Processing (HCI). He has studied computer science together with physics as a minor subject at the University of Bonn, Germany. After that he pursued his doctoral studies in computer science at ETH Zurich. He received his Ph.D. degree from ETH Zurich for his dissertation “Learning the Compositional Nature of Objects for Visual Recognition” which was awarded the ETH Medal. Thereafter, Björn held a post-doc position in the Computer Vision Group of Jitendra Malik at UC Berkeley. He serves as as LMU’s Chief AI Officer, as co-director of the Bavarian AI Council, as coordinator of the Bavarian AI Foundation Model Initiative of the StMWK, as an associate editor for the journal IEEE T-PAMI, and previously for Pattern Recognition Letters. Björn is an ELLIS Fellow, an ELLIS unit faculty of the ELLIS unit Munich, affiliated with the Helmholtz foundation, and a PI of the Munich Center for Machine Learning (MCML). He has served as program chair for GCPR, as Senior Area Chair and Area Chair for multiple CVPR, ICCV, ECCV, and NeurIPS conferences, and as workshop and tutorial organizer at these venues. Björn delivered the opening keynote at NeurIPS’23, was awarded the German AI-Prize 2024, the Technology-Prize of Eduard-Rhein-Foundation 2024, and the work leading to Stable Diffusion has been nominated for the German Future Prize of the President of Germany (“Deutscher Zukunftspreis des Bundespräsidenten für Technik und Innovation”). Research Interests All aspects of semantic image and video understanding based on (deep) machine learning; esp.: generative approaches for visual synthesis (e.g. Stable Diffusion), invertible deep models for explainable AI, deep metric and representation learning, and self-supervised learning paradigms and their interdisciplinary applications in the digital humanities and neurosciences. >> Research pages Publications Please see the publications page. PhD or Master Thesis Supervision I have the privilege of working with a great team who are incredibly gifted and nice to be with and our lab is located in beautiful downtown Munich. If you want to join: I am supervising Master and PhD students and PostDocs on topics of Computer Vision and Machine Learning in the faculty of Mathematics, Informatics, and Statistics at LMU. If you are interested please see our open positions. Selected Talks and Publications in Popular Science Stable Diffusion in the Press, Generative AI and the Future of Intelligence, Opening Keynote at re:publica’25 (English version) Op-ed in Frankfurter Allgemeine Zeitung (FAZ), (freely accessible Reprint), p.3, Jan 16, 2025 Generative AI: Future-Proofing Germany’s Innovation Hub, Keynote @ DLD, 2025 Opening keynote at NeurIPS’23 Generative AI: What’s Next?, Keynote @ DLD AI Summit, 2023 Generative AI: Brave New World?, Keynote @ re:publica (engl. translation), 2023 Visual Synthesis for Understanding our (Visual) World, Talk @ TUM AI Lecture Series, 2022 These Neural Networks Have Superpowers!, Video on Two-Minute-Papers about our VQGAN paper (CVPR’21 oral). Self-Supervision: Learning to Learn, Talk @ Heidelberg AI, 01/2019. Das Objekt jenseits der Digitalisierung, The Future of the Digital Humanities beyond Digitization, Talk @ Deutsches Museum, 12/2018. AI Learned How To Generate Human Appearance, Video on Two-Minute-Papers about our CVPR’18 paper on disentangling human behavior and appearance. Painter AI Fools Art Historians, Video on Two-Minute-Papers about our ECCV’18 paper on artistic style transfer. Improving Stroke Treatment Through Machine Learning, report on interdisciplinary project with neuroscientists from ETH Zurich. Björn Ommer, From Chaos to Image – The Grammar of Patterns, in: Universitas 68(810): 46-55, 2013. Björn Ommer, Vom Pixel zum Bild – Wie Computer das Sehen lernen und die Forschungsarbeiten von Geistes- und Naturwissenschaftlern unterstützen können, in: Ruperto Carola Magazine, 02/2011. Automatische Bildanalyse – Blinde Computer sollen sehen lernen, in: Spiegel Online news report, 22.07.2011. NewsFoundation Model Initiative Stable Diffusion - Advanced image synthesis for all! Stable Diffusion in the Press Open PhD and PostDoc Positions2025 1 paper accepted at NeurIPS’25 4 papers accepted at ICCV’25: • SCFlow: Implicitly Learning Style and Content Disentanglement with Flow Models • Art-FM: Stochastic Interpolants for Revealing Stylistic Flows across the History of Art • TREAD: Token Routing for Efficient Architecture-agnostic Diffusion Training • What If: Understanding Motion Through Sparse Interactions Generative AI and the Future of Intelligence, Opening Keynote at re:publica'25 The European Way. A Blueprint for Reclaiming Our Digital Future 4 papers accepted at CVPR’25: • CleanDIFT: Diffusion Features without Noise (ORAL) • Attribute Control in T2I by Semantic Directions • Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment • Latent Drifting in Diffusion for Counterfactual Synthesis (Highlight) 2 papers (DepthFM & DisCLIP) at AAAI’25 + 1 paper at WACV’25 Awarded Technology-Prize of Eduard-Rhein-Foundation Medical Physics article on analyzing CT enhancement2024 Awarded German AI-Prize’24 Nominated German Future Prize of the President of Germany 4 papers accepted at ECCV'24 on: • Conditional LoRAs for 0-Shot Control & Altering of T2I-Models • ZigMa: Zigzag Mamba Diffusion Model • 3D Gaussian Splatting for 3D Stylization using Wasserstein-2 Distance • Flow Matching for Boosting Latent Diffusion Eurographics overview article on Diffusion Models Medical Physics article on benchmarking AI-based CT image denoising2022 GCPR'22 Honorable Mention for paper on ArtFID: Quantitative Evaluation of Neural Style Transfer NeurIPS'22 article on retrieval-augmented diffusion models Nature article using image registration to analyze neuropathic pain CVPR'22 tutorial on Deep Visual Similarity and Metric Learning T-PAMI publication accepted on • Shared feature learning for Deep Metric Learning (PDF Download) CVPR'22 on latent diffusion models for high-res image synthesis, a.k.a. LDM & Stable Diffusion, source code & models 2021 PLOS ONE article on Interactive Retrieval in Art Collections 2 papers accepted at NeurIPS'21 on: • Multinomial Diffusion for Improving Autoregressive Image Synthesis • Analyzing OOD Generalization in Deep Metric Learning T-PAMI publication accepted on • Improving Deep Metric Learning by divide and conquer (PDF Download) Nature Machine Intelligence article on unsupervised behavior analysis & magnification (uBAM) for biomedical diagnostics 3 papers accepted at ICCV'21 on: • Transformers for Geometry-Free 3D Novel-View Synthesis • iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis • Self-Supervised LiDAR Scene Flow and Motion Segmentation (ORAL) ICML'21 paper accepted on self-distillation for deep metric learning 6 papers accepted at CVPR'21 on: • Taming Transformers for Hi-Res Image Synthesis • Learning Object Dynamics for Interactive Video Synthesis • Stochastic Image-to-Video Synthesis • Stroke-based Style Transfer • Behavior-driven Synthesis of Human Dynamics • Learning Exposure Correction Best Paper Award at CVPR'21—AI for Content Creation WS on • High-Res Complex Scene Synthesis with Transformers ICRA'21 paper accepted on 3D object detection 2020 NeurIPS'20 ORAL on cINNs for Network-to-Network Translation T-PAMI publication accepted on • Shared feature learning for Deep Metric Learning PLoS ONE publication on weakly supervised transliteration alignment for cuneiform sign detection GCPR'20 ORAL on unsupervised part learning by disentangling 2 papers accepted at ECCV'20 on: • Explainable AI and semantic image manipulation • Deep Metric Learning beyond discriminative features ICML'20 paper accepted on • Generalization in Deep Metric Learning Best Paper Award at CVPR'20—AI for Content Creation WS on • Interpretable Models for Visual Synthesis 3 papers accepted at CVPR'20 on: • Explainable AI • Reinforcement Learning for Deep Metric Learning • Unsupervised Behavior Analytics 2019 3 papers accepted at ICCV'19 Best paper finalist at CVPR'19 3 papers accepted at CVPR'19 CategoriesNo categories",
  "content_length": 8949,
  "method": "requests",
  "crawl_time": "2025-12-01 13:05:18"
}