{
  "name": "Ke Li 0011",
  "homepage": "https://www.math.ias.edu/~ke.li",
  "status": "success",
  "content": "Ke Li Ke Li I am an Assistant Professor at Simon Fraser University in beautiful Vancouver, Canada. I was previously at Google and the Institute for Advanced Study (IAS) in Princeton, and received my Ph.D. from UC Berkeley, where I was advised by Jitendra Malik, and my bachelor's in computer science from the University of Toronto. My research interests are in machine learning, computer vision and algorithms. I can be reached by e-mail at keli [at] sfu [dot] ca. While at the IAS, I organized the IAS Seminar Series on Theoretical Machine Learning with Sanjeev Arora - check out past seminars here and on Twitter. Google Scholar  |  Twitter Prospective MSc/PhD Students: I will be taking on a few new students this year. If you are interested in working with me, please fill out this form. Due to the volume of emails I receive, I am unfortunately unable to respond to every email; however, I review submissions through the form regularly and will reach out to selected students. Prospective SFU Undergraduate/MPCS Students: If you are interested in working on a research or capstone project on AI or related areas, please fill out this form. For a quick introduction to my research, see the following talk videos: IAS Workshop on Theory of Deep Learning (Video) (Slides): this is on generative modelling and nearest neighbour search and is aimed at machine learning researchers CMU ML/Duolingo Seminar (Video) (Slides): this is an extended version of the above (with more details on nearest neighbour search) and is aimed at machine learning graduate students CIFAR Deep Learning and Reinforcement Learning Summer School (Video) (Slides): this is on generative modelling and is aimed at a broader audience in the style of a tutorial IAS Special Year Seminar (Video): this is on meta-learning and is aimed at machine learning researchers Research Directions I am interested in tackling fundamental problems that cannot be solved using a straightforward application of conventional techniques. Below are the major areas that I contributed to: Generative Modelling (Slides on Unconditional Generative Modelling) (Slides on Conditional Generative Modelling): Most generative models are latent variable models, including variational autoencoders (VAEs), generative adversarial nets (GANs) and diffusion probabilistic models. The gold standard for training generative models is with maximum likelihood estimation (MLE) — however, it is not feasible to use MLE for modern, highly expressive generative models because the marginal log-likelihood is intractable. As a result, the evidence lower bound (ELBO), a lower bound on the marginal log-likelihood, is often maximized instead. The ELBO is only a good approximation to the marginal log-likelihood if the variational distribution is close to the true posterior, and so an expressive variational distribution is required. Diffusion probabilistic models increase the expressivity of the variational distribution by taking it to be the result of applying many small transformations to an analytical distribution, but do so at the expense of sampling time. We are developing an alternative approach known as Implicit Maximum Likelihood Estimation (IMLE) that maximizes a different lower bound to the marginal log-likelihood without needing to choose a variational distribution and the approximation quality improves with the expressivity of the genrative model. This makes it possible to sidestep the long sampling time of diffusion models, while still maintaining a good approximation to MLE. Related papers: RS-IMLE  |  Adaptive IMLE  |  Implicit Maximum Likelihood Estimation  |  Conditional IMLE  |  On the Implicit Assumptions of GANs Neural Rendering: Popular neural renderers based on 3D Gaussian splatting (3DGS) struggle with post-hoc geometry deformations and motion. Common artifacts include surface tearing or disintegration, and frozen or teleporting parts. This is caused by fundamental limitations of splatting — the shapes of primitives cannot adapt to arbitrary deformations and primitives can hardly move when they are too far from the true position due to vanishing gradients. We are developing an alternative approach known as Proximity Attention Point Rendering (PAPR) that gets around these issues. We reconsider how to form a continuous shape from a discrete point set — rather than filling gaps between points with splats, PAPR interpolates between them using a learned attention kernel. We demonstrated PAPR's capability to learn a point cloud from arbitrary initialization, render at high fidelity under non-rigid post-hoc deformations to the point cloud, and learn large transformations to the point cloud to model scene changes. Related papers: Proximity Attention Point Rendering  |  PAPR in Motion Fast Nearest Neighbour Search (Slides): The method of k-nearest neighbours is widely used in machine learning, statistics, bioinformatics and database systems. Attempts at devising fast algorithms, however, have come up against a recurring obstacle: the curse of dimensionality. Almost all exact algorithms developed over the past 40 years exhibited a time complexity that is exponential in ambient or intrinsic dimensionality, and such persistent failure in overcoming the curse of dimensionality led to conjectures that doing so is impossible. We showed that, surprisingly, this is in fact possible — we developed an exact randomized algorithm whose query time complexity is linear in ambient dimensionality and sublinear in intrinsic dimensionality. The key insight is to avoid the popular strategy of space partitioning, which we argue gives rise to the curse of dimensionality. We demonstrated a speedup of 1-2 orders of magnitude over locality-sensitive hashing (LSH). Related papers: Fast k-Nearest Neighbour Search via Dynamic Continuous Indexing  |  Fast k-Nearest Neighbour Search via Prioritized DCI Learning to Optimize (Slides): While machine learning has been applied to a wide range of domains, one domain that has conspicuously been left untouched is the design of tools that power machine learning itself. In this line of work, we ask the following question: is it possible to automate the design of algorithms used in machine learning? We introduced the first framework for learning a general-purpose iterative optimization algorithm automatically. The key idea is to treat the design of an optimization algorithm as a reinforcement learning/optimal control problem and view a particular update formula (and therefore a particular optimization algorithm) as a particular policy. Finding the optimal policy then corresponds to finding the best optimization algorithm. We parameterize the update formula using a neural net and train it using reinforcement learning to avoid the problem of compounding errors. This has inspired various subsequent work on meta-learning. Related papers: Learning to Optimize  |  Learning to Optimize Neural Nets Students Mehran Aghabozorgi Tristan Engst Alireza Moazeni Shichong Peng Chirag Vashist Yanshu Zhang Selected Papers Generative Modelling MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation (Project Page) (Code) Yuxiang Fu, Qi Yan, Lele Wang, Ke Li, Renjie Liao IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025 Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis (Project Page) (Code) (Video) Chirag Vashist, Shichong Peng, Ke Li European Conference on Computer Vision (ECCV), 2024 DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion (Project Page) (Code) (Video) Kiyohiro Nakayama, Mikaela Angelina Uy, Jiahui Huang, Shi-Min Hu, Ke Li, Leonidas J Guibas IEEE/CVF International Conference on Computer Vision (ICCV), 2023 Adaptive IMLE for Few-shot Pretraining-free Generative Modelling (Project Page) (Code) (Video) Mehran Aghabozorgi, Shichong Peng, Ke Li International Conference on Machine Learning (ICML), 2023 CHIMLE: Conditional Hierarchical IMLE for Multimodal Conditional Image Synthesis (Project Page) (Code) (Video) Shichong Peng, Alireza Moazeni, Ke Li Advances in Neural Information Processing Systems (NeurIPS), 2022 Micro and Macro Level Graph Modeling for Graph Variational Auto-Encoders (Code) (Slides) Kiarash Zahirnia, Oliver Schulte, Parmis Naddaf, Ke Li Advances in Neural Information Processing Systems (NeurIPS), 2022 Multimodal Shape Completion via Implicit Maximum Likelihood Estimation (Code) Himanshu Arora, Saurabh Mishra, Shichong Peng, Ke Li, Ali Mahdavi-Amiri IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022 Variational Model Inversion Attacks (Code) Kuan-Chieh Wang, Yan Fu, Ke Li, Ashish Khisti, Richard Zemel, Alireza Makhzani Advances in Neural Information Processing Systems (NeurIPS), 2021 Gotta Go Fast When Generating Data with Score-Based Models (Code) (Blog Post) Alexia Jolicoeur-Martineau, Ke Li*, RÃ©mi PichÃ©-Taillefer*, Tal Kachman*, Ioannis Mitliagkas arXiv:2105.14080, 2021 Generating Unobserved Alternatives (Project Page) (Code) Shichong Peng, Ke Li arXiv:2011.01926, 2020 Inclusive GAN: Improving Data and Minority Coverage in Generative Models (Code) Ning Yu, Ke Li, Peng Zhou, Jitendra Malik, Larry Davis, Mario Fritz European Conference on Computer Vision (ECCV), 2020 Multimodal Image Synthesis with Conditional Implicit Maximum Likelihood Estimation Ke Li*, Shichong Peng*, Tianhao Zhang*, Jitendra Malik International Journal of Computer Vision (IJCV), 2020 Diverse Image Synthesis from Semantic Layouts via Conditional IMLE (Project Page) (Code) (Talk) Ke Li*, Tianhao Zhang*, Jitendra Malik IEEE/CVF International Conference on Computer Vision (ICCV), 2019 Non-Adversarial Image Synthesis with Generative Latent Nearest Neighbors (Code) (Talk) Yedid Hoshen, Ke Li, Jitendra Malik IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019 On the Implicit Assumptions of GANs (Poster) Ke Li, Jitendra ",
  "content_length": 16581,
  "method": "requests",
  "crawl_time": "2025-12-01 13:41:18"
}