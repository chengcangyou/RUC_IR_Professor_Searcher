{
  "name": "Phil D. Green",
  "homepage": "https://www.sheffield.ac.uk/dcs/people/academic/philip-green",
  "status": "success",
  "content": "Emeritus Professor Philip Green | Computer Science | The University of Sheffield Skip to main content Search sheffield.ac.uk Close menu × School of Computer Science School of Computer Science Menu Emeritus Professor Philip Green PhD School of Computer Science Honorary Academic Member of the Speech and Hearing (SpandH) research group Open staff member portrait in a modal window p.green@sheffield.ac.uk +44 114 222 1828 Regent Court (DCS) Full contact details Emeritus Professor Philip Green School of Computer Science Regent Court (DCS) 211 Portobello Sheffield S1 4DP Personal website Profile Phil Green is an Emeritus Professor of Computer Science in the Speech and Hearing group which he founded when he came to Sheffield in 1985. His first degree, in Cybernetics was awarded by the University of Reading in 1967 and his PhD, from Keele University, in 1971. He was head of Computer Science from 2004 to 2008. Research interests Professor Green has worked in several areas of speech research, particularly Automatic Speech Recognition, Auditory Scene Analysis and, latterly, Clinical Applications of Speech Technology. He has been involved in research projects worth around £30m and has coordinated 5 International collaborations. Publications Books (2017) Biomedical Engineering Systems and Technologies. Springer International Publishing. Journal articles Gonzalez-Lopez JA, Gomez-Alanis A, Pérez-Córdoba JL & Green PD (2022) Non-parallel articulatory-to-acoustic conversion using multiview-based time warping. Applied Sciences, 12(3). Alharbi S, Hasan M, Simons AJH, Brumfitt S & Green P (2020) Sequence labeling to detect stuttering events in read speech. Computer Speech & Language, 62. View this article in WRRO Gonzalez JA & Green PD (2018) A real-time silent speech system for voice restoration after total laryngectomy. Revista de Logopedia, Foniatría y Audiología, 38(4), 148-154. Gonzalez JA, Cheah LA, Gomez AM, Green PD, Gilbert JM, Ell SR, Moore RK & Holdsworth E (2017) Direct Speech Reconstruction From Articulatory Sensor Data by Machine Learning. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 25(12), 2362-2374. View this article in WRRO Malavasi M, Turri E, Atria JJ, Christensen H, Marxer R, Desideri L, Coy A, Tamburini F & Green P (2017) An innovative speech-based user interface for smarthomes and IoT solutions to help people with speech and motor disabilities. Studies in Health Technology and Informatics, 242, 306-313. View this article in WRRO Gilbert JM, Gonzalez Lopez JA, Cheah LA, Ell SR, Green P, Moore RK & Holdsworth E (2017) Restoring speech following total removal of the larynx by a learned transformation from sensor data to acoustics. Journal of the Acoustical Society of America, 141(3), EL307-EL307. View this article in WRRO Gonzalez JA, Cheah LA, Green PD, Gilbert JM, Ell SR, Moore RK & Holdsworth E (2017) Restoring Speech Following Total Removal of the Larynx. Studies in Health Technology and Informatics, 242, 314-321. View this article in WRRO Gonzalez JA, Cheah LA, Gilbert JM, Bai J, Ell SR, Green PD & Moore RK (2016) A silent speech system based on permanent magnet articulography and direct synthesis. Computer Speech & Language, 39, 67-87. View this article in WRRO Martínez D, Lleida E, Green P, Christensen H, Ortega A & Miguel A (2015) Intelligibility Assessment and Speech Recognizer Word Accuracy Rate Prediction for Dysarthric Speakers in a Factor Analysis Subspace. ACM Transactions on Accessible Computing, 6(3). Barker J, Vincent E, Ma N, Christensen H & Green P (2013) The PASCAL CHiME speech separation and recognition challenge. Computer Speech & Language, 27(3), 621-633. Ma N, Barker J, Christensen H & Green P (2013) A hearing-inspired approach for distant-microphone speech recognition in the presence of multiple sources. Computer Speech & Language, 27(3), 820-836. Hawley MS, Cunningham SP, Green PD, Enderby P, Palmer R, Sehgal S & O'Neill P (2013) A voice-input voice-output communication aid for people with severe speech impairment . IEEE Transactions on Neural Systems and Rehabilitation Engineering, 21(1), 23-31. View this article in WRRO Creer S, Cunningham S, Green PD & Yamagishi J (2012) Building personalised synthetic voices for individuals with severe speech impairment. Computer Speech and Language, 27(6), 1178-1193. Green PD (2012) Small-Vocabulary Speech Recognition Using a Silent Speech Interface Based on Magnetic Sensing. Speech Communication. Ma N, Barker J, Christensen H & Green P (2012) Combining Speech Fragment Decoding and Adaptive Noise Floor Modeling. IEEE Transactions on Audio, Speech, and Language Processing, 20(3), 818-827. Ahmad Khan Z, Green P, Creer S & Cunningham S (2011) Reconstructing the Voice of an Individual Following Laryngectomy. Augmentative and Alternative Communication, 27(1), 61-66. Gilbert JM, Rybchenko SI, Hofe R, Ell SR, Fagan MJ, Moore RK & Green P (2010) Isolated word recognition of silent speech using magnetic implants and sensors. Medical Engineering & Physics, 32(10), 1189-1197. Hofe R, Ell SR, Fagan MJ, Gilbert JM, Green PD, Moore RK & Rybchenko SI (2010) Evaluation of a silent speech interface based on magnetic sensing. Proceedings of the 11th Annual Conference of the International Speech Communication Association Interspeech 2010, 246-249. Carmichael J, Wan V & Green P (2008) Combining neural network and rule-based systems for dysarthria diagnosis. Proceedings of the Annual Conference of the International Speech Communication Association Interspeech, 2226-2229. Ma N, Green P, Barker J & Coy A (2007) Exploiting correlogram structure for robust speech recognition with multiple speech sources . Speech Communication, 49(12), 874-891. View this article in WRRO Hawley MS, Enderby P, Green P, Cunningham S, Brownsell S, Carmichael J, Parker M, Hatzis A, O’Neill P & Palmer R (2007) A speech-controlled environmental control system for people with severe dysarthria. Medical Engineering & Physics, 29(5), 586-593. Parker M, Cunningham S, Enderby P, Hawley M & Green P (2006) Automatic speech recognition and training for severely dysarthric users of assistive technology: The STARDUST project. Clinical Linguistics & Phonetics, 20(2-3), 149-156. Parker G, Parker I & Brotchie H (2006) Mood state effects of chocolate. Journal of Affective Disorders, 92(2-3), 149-159. Parveen S & Green P (2004) Speech enhancement with missing data techniques using recurrent neural networks. ICASSP IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, 1, I733-I736. Cooke M, Green P, Josifovski L & Vizinho A (2001) Robust automatic speech recognition with missing and unreliable acoustic data. Speech Communication, 34(3), 267-285. Williams SM, Green PD, Nicolson RI & Baker KL (1995) Mapping the auditory scene. Language and Cognitive Processes, 10(3-4), 419-421. Green PD, Cooke MP & Crawford MD (1995) Auditory scene analysis and hidden Markov model recognition of speech in noise. ICASSP IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, 1, 401-404. Cooke M, Brown GJ, Crawford M & Green P (1993) Computational auditory scene analysis: listening to several things at once. Endeavour, 17(4), 186-190. Green P (1985) SPEECH RECOGNITION - WHAT IS HAPPENING NOW.. Computer Bulletin London, 1(pt 3), 5-7. Green PD & Wood AR (1984) KNOWLEDGE-BASED SPEECH UNDERSTANDING: TOWARDS A REPRESENTATIONAL APPROACH.. undefined, 337-340. Hofe R, Bai J, Cheah LA, Ell SR, Gilbert JM, Moore RK & Green PD () Performance of the MVOCA silent speech interface across multiple speakers. Interspeech 2013, 1140-1143. Hofe R, Ell SR, Fagan MJ, Gilbert JM, Green PD, Moore RK & Rybchenko SI () Speech synthesis parameter generation for the assistive silent speech interface MVOCA. Interspeech 2011, 3009-3012. Green P & Wood A () A representational approach to knowledge-based acoustic-phonetic processing in speech recognition. ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing, 11, 1205-1208. Book chapters Gonzalez JA, Cheah LA, Gilbert JM, Bai J, Ell SR, Green PD & Moore RK (2017) Voice restoration after laryngectomy based on magnetic sensing of articulator movement and statistical articulation-to-speech conversion (pp. 295-316). View this article in WRRO Cheah LA, Gilbert JM, Gonzalez JA, Bai J, Ell SR, Green PD & Moore RK (2017) Towards an intraoral-based silent speech restoration system for post-laryngectomy voice replacement (pp. 22-38). View this article in WRRO Cooke MP & Green PD (1988) On Finding Objects in Spectrograms: A Multiscale Relaxation Labelling Approach, Recent Advances in Speech Understanding and Dialog Systems (pp. 129-133). Springer Berlin Heidelberg Creer S, Green P, Cunningham S & Yamagishi J () Building Personalized Synthetic Voices for Individuals with Dysarthria using the HTS Toolkit, Computer Synthesized Speech Technologies (pp. 92-115). IGI Global Conference proceedings Alharbi S, Hasan M, Simons AJH, Brumfitt S & Green P (2018) A lightly supervised approach to detect stuttering in children's speech. Proceedings of Interspeech 2018 (pp 3433-3437). Hyderabad, India, 2 September 2018 - 2 September 2018. View this article in WRRO Sehgal S, Cunningham S & Green P (2018) Phase-Based Feature Representations for Improving Recognition of Dysarthric Speech. 2018 IEEE Spoken Language Technology Workshop (SLT) (pp 13-20), 18 December 2018 - 21 December 2018. Cheah LA, Gilbert JM, Gonzalez JA, Green PD, R. Ell S, K. Moore R & Holdsworth E (2018) A Wearable Silent Speech Interface based on Magnetic Sensors with Motion-Artefact Removal. Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies, 19 January 2018 - 21 January 2018. Coy A, Green P, Cunningham S, Christensen H, Atria JJ, Rudzicz F, Malavasi M & Desideri L (2018) Embedding speech technology into intelligent tutoring systems using the CloudCAST speech technology platform. Lecture Notes in Computer S",
  "content_length": 29555,
  "method": "requests",
  "crawl_time": "2025-12-01 14:12:06"
}