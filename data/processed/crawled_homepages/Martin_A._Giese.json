{
  "name": "Martin A. Giese",
  "homepage": "http://www.compsens.uni-tuebingen.de/compsens/index.php/people?view=member&task=show&id=1",
  "status": "success",
  "content": "People +49 7071 2989137 compsens@medizin.uni-tuebingen.de Personal Page Prof. Dr. Giese, Martin A. Room: 5.532a Section for Computational Sensomotorics Department of Cognitive Neurology Hertie Institute for Clinical Brain Research Centre for Integrative Neuroscience University Clinic Tübingen Otfried-Müller-Str. 25 72076 Tübingen, Germany +497071 2989124 martin.giese@uni-tuebingen.de Download CV Research Interests Neural models for high level vision Movement analysis and computational modelling of the motor system Motion- and action perception Movement disoders Psychophysics of action and social perception and of sensorimotor control Short CV M. Giese has studied Electrical Engineering and Psychology at the Ruhr University in Bochum. After a Postdoc at the Dept. of Brain and Cognitive Science at M.I.T., he founded in 2000 the Boston Research Laboratory von Honda Americas. From 2001 bis 2007 he was leader of a Junior Research Group at the Hertie Institute for Clinical Brain Research at the University of Tübingen. He received his habilitation at the Dept. for Informatics at the University of Ulm. From  2007 to 2008 he was Senior Lecturer at the Dept. of Psychology at the University of Wales, Bangor. Since 2008 he is head of the Section for Computational Sensomotorics at the Centre for Integrative Neuroscience and the Hertie Institute.  He is KO spokesperson of the Else Kroener Fresenius Foundation Graduate School ‘Clin Brain: Artificial Intelligence in Brain Science’, and head of the department ‘N3: Neurorehabilitation, Neuroprosthetics, and Neurotechnology’ at the Hertie Institute for Clinical Brain Research. His scientific intersts are neuroscience and related technical applications. The main topic of his lab are th perception and control of complex body motion, neural modeling, and technical and clincial application of learning-based representations for then syntheis and analysis of body movement. M Giese founded the Masters track 'Neural Informaiton Processing' at the Graduate Training  Centre for Neuroscience in Tübingen.He is Associate editor of the ACM Transaction on Applied Perception, and of Frontiers in Computational Neurosciences. In addition, he is Vertrauensdozent of the German National Merit Foundation. Kurzlebenslauf M. Giese hat Elektrotechnik und Psychologie an der Ruhr-Universität Bochum studiert. Nach einem Postdoc am Dept. of Brain and Cognitive Science am M.I.T., begründete er 2000 das Boston Research Laboratory von Honda Americas. Von 2001 bis 2007 war er Leiter einer Nachwuchsgruppe am Hertie Institut in Tübingen und habilitierte sich für Informatik an der Universität Ulm. Von 2007-2008 nahm er eine Position als Senior Lecturer am Dept. of Psychology der University of Wales, Bangor an. Seit 2008 ist er Leiter der Sektion für Theoretische Sensomotrik am Centrum für Integrative Neurowissenschaften und dem Hertie- Institut. Er ist KO Sprecher des Else-Kroener-Fresenius-Foundation Graduiertekollegs ‘Clin Brain: Artificial Intelligence in Brain Science’, und Leiter der Abteilung 'N3: Neurorehabilitation, Neuroprosthetics, and Neurotechnology' am Hertie Institut für klinische Hirnforschung. Seine wissenschaftlichen Interessen liegen auf dem Gebiet der Neurowissenschaften und verwandten technischen Anwendungen. Sein Hauptinteresse gilt der Wahrnehmung und Kontrolle von Körperbewegungen, neuronalen Modellen und technischen und klinischen Anwendungen lernbasierter Repräsentationen für die Synthese und Analyse von Bewegungen.  M. Giese ist Begründer des Masters-Programms ‚Neural Information Processing‘ am Graduate Training Center for Neuroscience, Tübingen, und  Vertrauensdozent der Studienstiftung des deutschen Volkes. Er ist Associate Editor der Zeitschriften ACM Transactions on Applied Perception und von Frontiers in Computational Neruosciences. Projects RELEVANCE: How body relevance drives brain organization Learning Hierarchical Models for Motor Control Neural mechanisms underlying the visual analysis of intent Modeling of human robot interaction and use of humanoid robots for rehabilitation training Synthesis of complex locomotion behavior for humanoid robots based on biological principles Selected Publications Lappe, A., Bognár, A., Nejad, G. G., Mukovskiy, A., Martini, L. M., Giese, M. A. et al. (2024). Parallel Backpropagation for Shared-Feature Visualization. Advances in Neural Information Processing Systems(37), 22993-23012. More Parallel Backpropagation for Shared-Feature Visualization Authors: Lappe, Alexander; Bognár, Anna Nejad, Ghazaleh Ghamkhari Mukovskiy, Albert; Martini, Lucas M.; Giese, Martin A.; Vogels, Rufin Research Areas: Biomedical and Biologically Motivated Technical Applications Type of Publication: Article Journal: Advances in Neural Information Processing Systems Number: 37 Pages: 22993-23012 Year: 2024 Full text: PDF Online version [Bibtex] Christensen, A., Taubert, N., in ’t Veld, E. M., de Gelder, B. & Giese, M. A. (2024). Perceptual encoding of emotions in interactive bodily expressions. iScience. VOLUME 27, ISSUE 1, 108548, JANUARY 19, 2024. More Perceptual encoding of emotions in interactive bodily expressions Abstract: For social species, e.g., primates, the perceptual analysis of social interactions is an essential skill for survival, emerging already early during development. While real-life emotional behavior includes predominantly interactions between conspecifics, research on the perception of emotional body expressions has primarily focused on perception of single individuals. While previous studies using point-light or video stimuli of interacting people suggest an influence of social context on the perception and neural encoding of interacting bodies, it remains entirely unknown how emotions of multiple interacting agents are perceptually integrated. We studied this question using computer animation by creating scenes with two interacting avatars whose emotional style was independently controlled. While participants had to report the emotional style of a single agent, we found a systematic influence of the emotion expressed by the other, which was consistent with the social interaction context. The emotional styles of interacting individuals are thus jointly encoded. Authors: Christensen, Andrea Taubert, Nick; in ’t Veld, Elisabeth M.J. Huis de Gelder, Beatrice Giese, Martin A. Research Areas: Uncategorized Type of Publication: Article Full text: PDF Online version [Bibtex] Barliya, A., Krausz, N., Naaman, H., Chiovetto, E., Giese, M. A. & Flash, T. (2024). Human arm redundancy: a new approach for the inverse kinematics problem. Royal Society Open Science, 11. More Human arm redundancy: a new approach for the inverse kinematics problem Abstract: The inverse kinematics (IK) problem addresses how both humans and robotic systems coordinate movement to resolve redundancy, as in the case of arm reaching where more degrees of freedom are available at the joint versus hand level. This work focuses on which coordinate frames best represent human movements, enabling the motor system to solve the IK problem in the presence of kinematic redundancies. We used a multi-dimensional sparse source separation method to derive sets of basis (or source) functions for both the task and joint spaces, with joint space represented by either absolute or anatomical joint angles. We assessed the similarities between joint and task sources in each of these joint representations, finding that the time-dependent profiles of the absolute reference frame’s sources show greater similarity to corresponding sources in the task space. This result was found to be statistically significant. Our analysis suggests that the nervous system represents multi-joint arm movements using a limited number of basis functions, allowing for simple transformations between task and joint spaces. Additionally, joint space seems to be represented in an absolute reference frame to simplify the IK transformations, given redundancies. Further studies will assess this finding’s generalizability and implications for neural control of movement. Authors: Barliya, Avi Krausz, Nili Naaman, Hila Chiovetto, Enrico Giese, Martin A.; Flash, Tamar Research Areas: Biomedical and Biologically Motivated Technical Applications Type of Publication: Article Full text: PDF [Bibtex] Li, B., Solanas, M. P., Marrazzo, G., Raman, R., Taubert, N., Giese, M. A. et al. (2023). A large-scale brain network of species-specific dynamic human body perception. Progress in Neurobiology, 221. More A large-scale brain network of species-specific dynamic human body perception Abstract: This ultrahigh field 7 T fMRI study addressed the question of whether there exists a core network of brain areas at the service of different aspects of body perception. Participants viewed naturalistic videos of monkey and human faces, bodies, and objects along with mosaic-scrambled videos for control of low-level features. Independent component analysis (ICA) based network analysis was conducted to find body and species modulations at both the voxel and the network levels. Among the body areas, the highest species selectivity was found in the middle frontal gyrus and amygdala. Two large-scale networks were highly selective to bodies, dominated by the lateral occipital cortex and right superior temporal sulcus (STS) respectively. The right STS network showed high species selectivity, and its significant human body-induced node connectivity was focused around the extrastriate body area (EBA), STS, temporoparietal junction (TPJ), premotor cortex, and inferior frontal gyrus (IFG). The human body-specific network discovered here may serve as a brain-wide internal model of the human body serving as an entry point for a variety of processes relying on body descriptions as part of their more specific categorization, action, or expression recognition functions. Authors: Li, Baichen Solanas, Marta Poyo Marrazzo, Giuseppe Raman, Rajani Taubert, Nick; Giese, Martin A.; Vogels",
  "content_length": 13392,
  "method": "requests",
  "crawl_time": "2025-12-01 13:54:15"
}