{
  "name": "Weiwei Xu",
  "homepage": "http://www.cad.zju.edu.cn/home/weiweixu",
  "status": "success",
  "content": "è®¸å¨å¨ è®¸å¨å¨ English æµæ±å¤§å­¦è®¡ç®æºå­¦é¢CAD&CGå½å®¶éç¹å®éªå®¤ æµæ±çæ­å·å¸è¥¿æ¹åºä½æ­å¡è·¯388å·æµæ±å¤§å­¦ç´«éæ¸¯æ ¡åº, èæ°ä¼æ¥¼516å®¤ é®ä»¶: xww@ cad.zju.edu.cn ä¸ªäººç®ä» ç°ä»»æµæ±å¤§å­¦CAD&CGå½å®¶éç¹å®éªå®¤é¿èææï¼æè²é¨é¿æ±å­¦è ãæ¾ä»»æ¥æ¬ç«å½é¦å¤§å­¦åå£«åï¼å¾®è½¯äºæ´²ç ç©¶é¢ç½ç»å¾å½¢ç»ç ç©¶å, æ­å·å¸èå¤§å­¦æµæ±çé±æ±å­¦è ç¹èææãä¸»è¦ç ç©¶æ¹åä¸ºæºè½å¾å½¢å¾åå¤çï¼æ¶µçä¸ç»´è§è§ãç©çä»¿çãæ°å­å­ªçåèæç°å®ãå¨å½å å¤é«æ°´å¹³å­¦æ¯ä¼è®®åæååè¡¨è®ºæ100ä½ç¯ï¼å ¶ä¸­ACM Transactions on Graphics, IEEE TVCG, åIEEE CVPRï¼ NIPSï¼AAAIç­CCF-Aç±»è®ºæ50ä½ç¯ãè·ä¸­å½åç¾å½ææä¸å©15é¡¹ãæå¼åçä¸ç»´æ³¨ååéå»ºææ¯å¨å ä¸´ä¸ç»´æä»ªãå¨æäººä½ä¸ç»´éå»ºãç¾åº¦é¿æ³¢ç½èªå¨é©¾é©¶ä»¿çãåä¸ºæ²³å¾å¤§åºæ¯éå»ºä¸­åºç¨ã2014å¹´åå½å®¶èªç¶ç§å­¦åºéä¼ç§éå¹´åºéèµå©ï¼ä¸»æå½å®¶èªç¶ç§å­¦åºééç¹é¡¹ç®ä¸é¡¹ï¼è·æµæ±çèªç¶ç§å­¦äºç­å¥ä¸é¡¹ã å­¦æ¯æå¡ å½é å­¦æ¯ä¼è®®å ±åä¸»å¸­: ACM VRST 2013,2014 å½é å­¦æ¯ä¼è®®è®ºæå§åä¼å§å: Pacific Graphics, ACM Symposium on Geometry Processing, CASA, IEEE Virtual Reality, GMP, SPM å®¡ç¨¿: ACM SIGGRAPH, ACM SIGGRAPH Asia, IEEE Visualization, IEEE TVCG, SGP, Computers & Graphics æçä¿¡æ¯ï¼ å¸¸å¹´ææ¶è®¡ç®æºæ¹åç¡å£«ãåå£«ååå£«åï¼æ¬¢è¿èªæé©±å¨ï¼æå¿äºé«æ°´å¹³ç§ç ä¸è½¯ä»¶å¼åçå­¦çç³è¯·æ¥èã åè¡¨è®ºæï¼ 2025 FaTNET: Feature-alignment transformer network for human pose transfer Yu Luo, Chengzhi Yuan, Lin Gao, Weiwei Xu, Xiaosong Yang, Pengjie Wang Pose-guided person image generation involves converting an image of a person from a source pose to a target pose. This task presents significant challenges due to the extensive variability and occlusion. Existing methods heavily rely on CNN-based architectures, which are constrained by their local receptive fields and often struggle to preserve the details of style and shape. To address this problem, we propose a novel framework for human pose transfer with transformers, which can employ global dependencies and keep local features as well. The proposed framework consists of transformer encoder, feature alignment network and transformer synthetic network, enabling the generation of realistic person images with desired poses. The core idea of our framework is to obtain a novel prior image aligned with the target image through the feature alignment network in the embedded and disentangled feature space, and then synthesize the final fine image through the transformer synthetic network by recurrently warping the result of previous stage with the correlation matrix between aligned features and source images. In contrast to previous convolution and non-local methods, ours can employ the global receptive field and preserve detail features as well. The results of qualitative and quantitative experiments demonstrate the superiority of our model in human pose transfer. ACM Pattern Recognition [Paper] [ Code ] [ Video ] BuildingBlock: A Hybrid Approach for Structured Building Generation Junming Huang, Chi Wang, Letian Li, Changxin Huang, Qiang Dai, Weiwei Xu Three-dimensional building generation is vital for applications in gaming, virtual reality, and digital twins, yet current methods face challenges in producing diverse, structured, and hierarchically coherent buildings. We propose BuildingBlock, a hybrid approach that integrates generative models, procedural content generation (PCG), and large language models (LLMs) to address these limitations. Specifically, our method introduces a two-phase pipeline: the Layout Generation Phase (LGP) and the Building Construction Phase (BCP). LGP reframes box-based layout generation as a point-cloud generation task, utilizing a newly constructed architectural dataset and a Transformer-based diffusion model to create globally consistent layouts. With LLMs, these layouts are extended into rule-based hierarchical designs, seamlessly incorporating component styles and spatial structures. The BCP leverages these layouts to guide PCG, enabling local-customizable, high-quality structured building generation. Experimental results demonstrate BuildingBlock âs effectiveness in generating diverse and hierarchically structured buildings, achieving state-of-the-art results on multiple benchmarks, and paving the way for scalable and intuitive architectural workflows. In Proceedings of SIGGRAPH Conference Papers '25 [Paper] [ Code ] [ Video ] Physics-inspired Estimation of Optimal Cloth Mesh Resolution Diyang Zhang, Zhendong Wang, Zegao Liu, Xinming Pei, Weiwei Xu, Huamin Wang In this paper, we tackle an important yet often overlooked question: What is the optimal mesh resolution for cloth simulation, without relying on preliminary simulations? The optimal resolution should be sufficient to capture fine details of all potential wrinkles, while avoiding an unnecessarily high resolution that wastes computational time and memory on excessive vertices. This challenge stems from the complex nature of wrinkle distribution, which varies spatially, temporally, and anisotropically across different orientations. To address this, we propose a method to estimate the optimal cloth mesh resolution, based on two key factors: material stiffness and boundary conditions.To determine the influence of material stiffness on wrinkle wavelength and amplitude, we apply the experimental theory presented by Cerda and Mahadevan [2003] to calculate the optimal mesh resolution for cloth fabrics. Similarly, for boundary conditions influencing local wrinkle formation, we use the same scaling law to determine the source resolution for stationary boundary conditions introduced by garment-making techniques such as shirring, folding, stitching, and down-filling, as well as predicted areas accounting for dynamic wrinkles introduced by collision compression caused by human motions. To ensure a smooth transition between different source resolutions, we apply another experimental theory from [Vandeparre et al. 2011] to compute the transition distance. A mesh sizing map is introduced to facilitate smooth transitions, ensuring precision in critical areas while maintaining efficiency in less important regions. Based on these sizing maps, triangular meshes with optimal resolution distribution are generated using Poisson sampling and Delaunay triangulation. The resulting method can not only enhance the realism and precision of cloth simulations but also support diverse application scenarios, making it a versatile solution for complex garment design. In Proceedings of SIGGRAPH Conference Papers '25 [Paper] [ Code ] [ Video ] 4D Gaussian Videos with Motion Layering Pinxuan Dai, Peiquan Zhang, Zheng Dong, Ke Xu, Yifan Peng, Dandan Ding, Yujun Shen, Yin Yang, Xinguo Liu, Rynson W. H. Lau, Weiwei Xu Online free-view navigation in volumetric videos requires high-quality rendering and real-time streaming in order to provide immersive user experiences. However, existing methods (e.g., dynamic NeRF and 3DGS) may not handle dynamic scenes with complex motions, and their models may not be streamable due to storage and bandwidth constraints. In this paper, we propose a novel 4D Gaussian Video (4DGV) approach that enables the creation and streaming of photorealistic, volumetric videos for dynamic scenes over the Internet. The core of our 4DGV is a novel streamable group of Gaussians (GOG) representation based on motion layering. Each GOG consists of static and dynamic points obtained via lifting 2D segmentation into 3D in motion layering, where the deformation of each dynamic point is represented as the temporal offset of its attributes. We also adaptively convert static points back to dynamic points to handle the appearance change, (e.g., moving shadows and reflections), of static objects through optimization. To support real-time streaming of 4DGVs, we show that by applying quantization on Gaussian attributes and H.265 encoding on deformation offsets, our GOG representation can be significantly compressed (to around 6% of the original model size) without sacrificing the accuracy (PSNR loss less than 0.01dB). Extensive experiments on standard benchmarks demonstrate that our method outperforms state-of-the-art volumetric video approaches, with superior rendering quality and minimum storage overheads. ACM Transactions on Graphics (SIGGRAPH 2025, Journal track) [Paper] [ Code ] [ Video ] Neural Shell Texture Splatting: More Details and Fewer Primitives Xin Zhang, Anpei Chen, Jincheng Xiong, Pinxuan Dai, Yujun Shen, Weiwei Xu Gaussian splatting techniques have shown promising results in novel view synthesis, achieving high fidelity and efficiency. However, their high reconstruction quality comes at the cost of requiring a large number of primitives. We identify this issue as stemming from the entanglement of geometry and appearance in Gaussian Splatting. To address this, we introduce a neural shell texture, a global representation that encodes texture information around the surface. We use Gaussian primitives as both a geometric representation and texture field samplers, efficiently splatting texture features into image space. Our evaluation demonstrates that this disentanglement enables high parameter efficiency, fine texture detail reconstruction, and easy textured mesh extraction, all while using significantly fewer primitives. IEEE ICCV 2025 [Paper] [ Code ] [ Video ] Interpretable procedural material graph generation via diffusion models from reference images Xiaoyu Lv, Zizhao Wu, Jiamin Xu, Xiaoling Gu, Ming Zeng, Weiwei Xu Procedural materials, generated through algorithmic processes, offer advantages such as resolution independence, editability, and real-time rendering capabilities. Despite these merits, constructing procedural material graphs remains a labor-intensive task. Recen",
  "content_length": 137942,
  "method": "requests",
  "crawl_time": "2025-12-01 14:46:00"
}