{
  "name": "Jonathan H. Huggins",
  "homepage": "http://jhhuggins.org",
  "status": "success",
  "content": "Jonathan Huggins Jonathan Huggins Assistant Professor, Boston University Department of Mathematics & Statistics Faculty of Computing & Data Sciences About me I am an Assistant Professor in the Department of Mathematics & Statistics and the Faculty of Computing & Data Sciences at Boston University. My formal bio has more details about my background. My research centers on the development of fast, trustworthy learning and inference methods that balance the need for computational efficiency and the desire for statistical optimality with the inherent imperfections that come from real-world problems, large datasets, and complex models. My current applied work is focused on developing software tools and computational methods for (1) accelerating and improving large-scale forecasting of ecological systems and (2) enabling more effective scientific discovery from high-throughput and multi-modal genomic data. Joining my group If you are currently enrolled in, or accepted to, a BU graduate program, feel free to reach out to me about research opportunities. I can advise students in Math & Statistics, Computer Science, Bioinformatics, and CDS. I am not able to reply to all inquiries from students who are at other universities or are applying to BU graduate programs. Interests Large-scale learning Bayesian computation Robust inference Statistical genetics Education Ph.D. in Computer Science, 2018 Massachusetts Institute of Technology B.A. in Mathematics, 2012 Columbia University Projects Stochastic Methods for Data Science: An in-progress book that provides an introduction to the interplay between stochastic process theory and algorithms in data science, with a focus (large-scale) stochastic optimization and Markov chain Monte Carlo. It is designed to be accessible to advanced undergraduates, graduate students, and researchers working in machine learning, statistics, and related fields. VIABEL: A Python package that provides two core features: Easy-to-use, lightweight, flexible variational inference algorithms that are agnostic to how the model is constructed (just provide a log density and its gradient). Post hoc diagnostics for the accuracy of continuous approximations to (unnormalized) distributions. A canonical application is to diagnose the accuracy of variational approximations. ShorTeX: A LaTeX package that aims to streamline LaTeX writing, particularly math. It automatically includes and configures commons packages, and provides functionality to, among other things, (1) make LaTeX math code shorter and more readable, (2) avoid the verbose commands and boilerplate common in LaTeX, and (3) avoid multi-key presses (curly braces, capital letters, etc.) where reasonable. It is being developed by myself, Trevor Campbell, and Jeffrey Negrea. Preprints & Working Papers Quantitative Error Bounds for Scaling Limits of Stochastic Iterative Algorithms Xiaoyu Wang, MikoÅaj J. Kasprzak, Jeffrey Negrea, Solesne Bourguin, Jonathan H. Huggins arXiv:2501.12212 [stat.ML], 2025. Preprint PDF Robust discovery of mutational signatures using power posteriors Catherine Xue, Jeffrey W. Miller, Scott L. Carter, Jonathan H. Huggins bioRxiv 2024.10.23.619958, 2024. Preprint Structurally Aware Robust Model Selection for Mixtures Jiawei Li, Jonathan H. Huggins arXiv:2403.00687 [stat.ME], 2024. Preprint PDF Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics Jeffrey Negrea, Jun Yang, Haoyue Feng, Daniel M. Roy, Jonathan H. Huggins arXiv:2207.12395 [stat.CO], 2022. Preprint PDF Calibrated Model Criticism Using Split Predictive Checks Jiawei Li, Jonathan H. Huggins arXiv:2203.15897 [stat.ME], 2022. Preprint PDF Publications More Publications Tuning-Free Coreset Markov Chain Monte Carlo via Hot DoG Naitong Chen, Jonathan H. Huggins, Trevor Campbell Proc. of the 41st Conference on Uncertainty in Artificial Intelligence, 2025. PDF A Framework for Improving the Reliability of Black-box Variational Inference Manushi Welandawe, Michael Riis Andersen, Aki Vehtari, Jonathan H. Huggins Journal of Machine Learning Research 25(219): 1â71, 2024. PDF Reproducible Parameter Inference Using Bagged Posteriors Jonathan H. Huggins, Jeffrey W. Miller Electronic Journal of Statistics 18(1): 1549â1585, 2024. PDF Independent finite approximations for Bayesian nonparametric inference Tin D. Nguyen, Jonathan H. Huggins, Lorenzo Masoero, Lester Mackey, Tamara Broderick Bayesian Analysis, 2024. PDF A Targeted Accuracy Diagnostic for Variational Approximations Yu Wang, Mikołaj Kasprzak, Jonathan H. Huggins In Proc. of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS), Valencia, Spain. PMLR: Volume 108, 2023. Preprint PDF Reproducible Model Selection Using Bagged Posteriors Jonathan H. Huggins, Jeffrey W. Miller Bayesian Analysis 18(1): 79-104, 2023. PDF The Mutational Signature Comprehensive Analysis Toolkit (musicatk) for the Discovery, Prediction, and Exploration of Mutational Signatures Aaron Chevalier, Shiyi Yang, Zainab Khurshid, Nathan Sahelijo, Tong Tong, Jonathan H. Huggins, Masanao Yajima, Joshua D. Campbell Cancer Research 81(23), 2021. PDF Challenges and Opportunities in High-dimensional Variational Inference Akash K. Dhaka*, Alejandro Catalina*, Manushi Welandawe, Michael Riis Andersen, Jonathan H. Huggins, Aki Vehtari In Proc. of the 35th Annual Conference on Neural Information Processing Systems (NeurIPS), 2021. Preprint PDF Bidirectional contact tracing could dramatically improve COVID-19 control William J. Bradshaw, Ethan C. Alley, Jonathan H. Huggins, Alun L. Lloyd, Kevin M. Esvelt Nature Communications 12(232), 2021. PDF Code Robust, Accurate Stochastic Optimization for Variational Inference Akash K. Dhaka, Alejandro Catalina, Michael Riis Andersen, Mans Magnusson, Jonathan H. Huggins, Aki Vehtari In Proc. of the 34th Annual Conference on Neural Information Processing Systems (NeurIPS), 2020. Preprint PDF Thesis Scaling Bayesian inference: theoretical foundations and practical methods Jonathan H. Huggins Ph.D. thesis, Massachusetts Institute of Technology, 2018. PDF Miscellanea The feasibility of targeted test-trace-isolate for the control of SARS-CoV-2 variants William J. Bradshaw, Jonathan H. Huggins, Alun L. Lloyd, Kevin M. Esvelt F1000Research 10(291), 2021. Preprint Reconstructing probabilistic trees of cellular differentiation from single-cell RNA-seq data Miriam Shiffman, William T. Stephenson, Geoffrey Schiebinger, Jonathan H. Huggins, Trevor Campbell, Aviv Regev, Tamara Broderick arXiv:1811.11790 [q-bio.QM], 2018. Preprint PDF Practical bounds on the error of Bayesian posterior approximations: A nonasymptotic approach Jonathan H. Huggins, Mikołaj Kasprzak, Trevor Campbell, Tamara Broderick arXiv:1809.09505 [stat.TH], 2018. Preprint PDF Detailed Derivations of Small-variance Asymptotics for some Hierarchical Bayesian Nonparametric Models Jonathan H. Huggins, Ardavan Saeedi, Matthew J. Johnson arXiv:1501.00052 [stat.ML], 2014. Preprint PDF Infinite Structured Hidden Semi-Markov Models Jonathan H. Huggins, Frank Wood arXiv:1407.0044 [stat.ME], 2014. Preprint PDF Recent & Upcoming Talks More Talks Reproducible Statistical Inference Dec 15, 2024 18th International Joint Conference on Computational and Financial Econometrics (CFE) and Computational and Methodological Statistics (CMStatistics) Gaussian Process Surrogates for Bayesian Inverse Problems Oct 9, 2024 Flatiron Institute (Center for Computational Mathematics Colloquium) Reproducible Statistical Inference Mar 13, 2024 University of Waterloo Statistics Seminar Reproducible (Bayesian) Statistical Inference Nov 13, 2023 BAYSM 2023 Robust, structurally-aware inference for mixture models Aug 8, 2023 JSM 2023 Robust, structurally-aware inference for mixture models May 18, 2023 Boston University (Biostatistics Seminar) Robust, structurally-aware inference for mixture models Mar 16, 2023 BayesComp 2023 Trustworthy variational inference Oct 21, 2022 Texas A&M University, Conference on Advances in Data Science Calibrated model criticism using split predictive checks Jun 29, 2022 ISBA World Meeting Algorithmically robust, general-purpose variational inference Apr 13, 2022 SIAM Conference on Uncertainty Quantification (UQ22) – Minisymposium on ‘Variational Inference Bridging Application and Theory’ Short Bio Jonathan Huggins is an Assistant Professor in the Department of Mathematics & Statistics and the Faculty of Computing & Data Sciences at Boston University. He is also a Data Science Faculty Fellow and an affiliated faculty member of the Department of Computer Science, the BU URBAN Program, and the BU Program in Bioinformatics. He is a recipient of an NSF CAREER award and a BlackwellâRosenbluth Award, which recognizes outstanding junior Bayesian researchers based on their overall contribution to the field and to the community. Prior to joining BU, he was a Postdoctoral Research Fellow in the Department of Biostatistics at Harvard. He completed his Ph.D. in Computer Science at the Massachusetts Institute of Technology in 2018. Previously, he received a B.A. in Mathematics from Columbia University and an S.M. in Computer Science from the Massachusetts Institute of Technology. His research centers on the development of fast, trustworthy learning and inference methods that balance the need for computational efficiency and the desire for statistical optimality with the inherent imperfections that come from real-world problems, large datasets, and complex models. His current applied work is focused on developing software tools and computational methods for (1) accelerating and improving large-scale forecasting of ecological systems and (2) enabling more effective scientific discovery from high-throughput and multi-modal genomic data. His research is supported by the National Institutes of Health, the National Science Foundation, and the Department of Defense. Contact huggins -at- bu -dot- edu CCDS 427, 665 Commonwealth Ave, Bo",
  "content_length": 10061,
  "method": "requests",
  "crawl_time": "2025-12-01 13:33:35"
}