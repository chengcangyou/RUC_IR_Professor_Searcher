{
  "name": "Michael Gleicher",
  "homepage": "http://pages.cs.wisc.edu/~gleicher",
  "status": "success",
  "content": "Michael Gleicher's Web PageMichael GleicherProfessorDepartment of Computer SciencesUniversity of Wisconsin, Madison1205 University AveMadison, WI 53706, USAgleicher@cs.wisc.eduOffice: 6588 Mortgridge Hall (the new CS building!)Office Hour: Fall 2025: Wednesday 2-3pm (except Nov 5)I am a professor working in areas related to Visual Computing. My research these days is mainly about robotics and data visualization. With both, I am interested in how we can make them useful for people. I remain interested in animation, virtual reality, multimedia, …A brief biography will tell you how I got here. You can see a reasonably current CV, but you probably are looking for papers, talks, videos or advice.Teaching: CS765 Data Visualization (Fall 2025)I have some pages with various Advice I generally give to students. This includes the format for status reports, what I’d like to see in Prelims and Theses, my grad school FAQ, or my advice on how to give a talk.You might be interested in my grad school FAQ. Come and talk to me if you’re interested in data visualization, robotics, computer graphics or related topics. If you are an undergrad and looking to work on a project, please see Undergrad Research, Projects and Directed Studies. If you are asking about a reference letter, please see Reference Letters for Students in Classes.If you’re interested in joining our group, come talk to me! If you aren’t a student at Wisconsin yet, please look at my grad school FAQ, particularly the last few questions.Current Research ThemesThe projects list was more than slightly out of date. I need to revitalize it. But, there are several things going on with robotics (tele-operation, providing awareness to remote users, using novel sensors, …) and visualization (summarization, text collection exploration, uncertainty, …).Shared Autonomy for Robotic Inspection: We are developing robot solutions to automate inspection, where a mobile robot with a set of sensors scans through a space. Such applications involve a human collaborator, to specify the task, to supervise operation, to assess the results, or to guide the robot through challenging aspects. We seek to develop systems that share control: automating as much as possible, but allowing for user contributions as necessary. This application project is driving techical work in motion synthesis, mobile sensing, and user experience.Visualization Theory: Summarization, Uncertainty, ...: We are exploring very basic questions in how to present information with visualizations. We are examining the central concept of summarization to understand how people use summaries and what strategies can be used to create them. This leads to a broader concept of understanding how people use visualizations to ask and answer questions. We are trying to codify the process for creating effective visualizations to make it easier for designers.Awareness of (and with) Robots: We are interested in how we can help human stakeholders (operators, observers, etc.) have appropriate understanding of robots and their situations. This requires us to design methods (such as visualizations) that help communicate robot state, environment, plans, and history to users. One aspect that we explore is using robots to provide viewpoints (move cameras) to help observe robots (or other aspects of the environments).Novel Sensors for Robotics Applications: We are exploring how we can use emerging sensors in robotics applications. New sensors offer different tradeoffs and capabilities which provides opportunities for robotics usages. For example, we are working with Single Photon Avalanche Diode (SPAD) time of flight sensors which provide distance information in small, low-power packages. These sensors provide different information than more traditional ones: for example providing statistical distributions over an area, rather than detailed measurements.Selected Past (but recent) ThemesCommunicating Physical Interactions: We are working on ways for people and robots to communicate to each other about how objects should be manipulated in the world. Manipulations necessarily involve physical interactions (e.g., forces must be applied correctly). We are exploring ways for people to tell robots how to act with appropriate forces (e.g., to teach manipulation skills) as well as for robots to communicate back to people about the actions they are performing.Communicative Robot Motions: If robots are going to work around people, it will be important that people can interpret the robots movements correctly. We are developing ways to make robots move such that people will interpret them correctly. For example, we are considering how to design robot control algorithms such that the resulting movements are understandable, predictable, aesthetically pleasing, and convey a sense of appropriate affect (e.g. confidence).Interacting with Machine Learning: People interact with machine learning systems in many ways: they must build them, debug them, diagnose them, decide to trust them, gain insights on their data from them, etc. We are exploring this in both directions: How do we build machine learning tools into interactive data analysis in order to help people interpret large and complex data? How do we build interaction tools that can help people construct and diagnose machine learning models?Visualizing Comparisons for Data Science: Data interpretation tasks often involve making comparisons among the data, or can be thought of as comparisons. We are developing better visualization tools for performing comparisons for various data challenges, as well as to developing better methods for inventing new designs.Perceptual Principles for Visualization: Understanding how people see can inform how we should design visualizations. We have been exploring how recent results in perception (e.g., ensemble encoding) can be exploited to create novel visualization designs, and how principles of perception can inform visualization designs.Video, Animation and Image Authoring: Our goal is to make it easier for people to create useable images and video. For example, we have developed methods for improving pictures and video as a post-process (e.g. removing shadows and stabilizing video). We have also worked on adapting imagery for use in new settings (e.g. image and video retargeting or automatic video editing) and making use of large image collections (e.g. intestingness detection or panorama finding).TeachingThese are the main classes I teach. You can see more on the Graphics Group Courses Page.CS765 Visualization: This class is taught regularly. I taught it in Fall 2024. In the past, I taught it Fall 2022 Fall 2021, Fall 2020, Fall 2019, Fall 2018, Fall 2017, Spring 2018 and several times before that as “special topics” experiments.CS559 Computer Graphics: In Spring of 2025 I taught an Accelerated Honors Section, and supporting Dr. Young Wu who is teaching the regular section. I also taught this in Spring 2023, Spring 2022, Spring 2021, Spring 2020. and Spring 2019. There are lots of previous offereings going back to 1999. (I’ve tried to recreate the web pages)Older classes are so old they’ve been removed from the catalog!CS777: Computer Animation is a graduate level CS class for people with some graphics background. This taught was taught regularly in the past (2013, 2011, 2006, 2004, 2003). It kindof died off from lack of interest (student interest and my interest)CS679 Computer Games Technologies: this class was popular, so I tried to teach it regularly for several years 2012, 2011, 2010).Advanced Graphics: In the Spring of 2009, I taught an Advanced Graphics class.You can find other information on graphics group classes on the Graphics Group Courses Page.Selected Recent PublicationsA (pretty) complete list is available here. Here are some selected recent ones:Robotics/SensingRAL ‘24 (ICRA ‘25) Using a Distance Sensor to Detect Deviations in a Planar Surface w/Sifferman, Sun and GuptaRAL ‘24 (ICRA ‘25): Motion Comparator: Visual Comparison of Robot Motions w/Wang, Pesekis and Jiang - Visualization applied to robotics!ICRA ‘24: IKLink: End-Effector Trajectory Tracking with Minimal Reconfigurations w/Wang and SiffermanCVPR ‘24: Towards 3D Vision with Low-Cost Single-Photon Cameras w/ Mu, Sifferman, et al.VisualizationArxiv ‘25: Augmenting a Large Language Model with a Combination of Text and Visual Data for Conversational Visualization of Global Geospatial Data w/Mena, Kouyoumdjian, Viola and YnnermanTVCG ‘25 (Vis ‘24): Beware of Validation by Eye: Visual Validation of Linear Trends in Scatterplots w/ Baum, Chang, and von LandesbergerArxiv ‘24: Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design w/Bai and Leppanan - This is the AbstractsViewer paper (yes, you can try the demo).SectionsHomePapersTalksVideosAdviceUseful LinksCS765 Fall 2025CS559 Spring 2025List of all pages",
  "content_length": 8907,
  "method": "requests",
  "crawl_time": "2025-12-01 13:58:03"
}